[
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid trellis frames or hanging baskets and reach goal. The agent’s state, the goal position and the multiple obstacles: trellis frames or hanging baskets locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into pet dryer and reach goal. The agent’s state, the goal position and the pet dryer locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_pet_dryer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pet_dryer = calculate_distance_min(s_agent, s_pet_dryer) \n    penalty_collision = -20 if (d_agent_pet_dryer < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into heat lamp and reach goal. The agent’s state, the goal position and the heat lamp locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_heat_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_heat_lamp = calculate_distance_min(s_agent, s_heat_lamp) \n    penalty_collision = -20 if (d_agent_heat_lamp < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into chair and reach goal. The agent’s state, the goal position and the chair locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -20 if (d_agent_chair < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid three service counters and reach goal. The agent’s state, the goal position and the multiple obstacles: three service counters locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into treat bin and reach goal. The agent’s state, the goal position and the treat bin locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_treat_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_treat_bin = calculate_distance_min(s_agent, s_treat_bin) \n    penalty_collision = -20 if (d_agent_treat_bin < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into service counter and reach goal. The agent’s state, the goal position and the service counter locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_service_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_service_counter = calculate_distance_min(s_agent, s_service_counter) \n    penalty_collision = -20 if (d_agent_service_counter < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into wall and reach goal. The agent’s state, the goal position and the wall locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -20 if (d_agent_wall < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into pet toy display and reach goal. The agent’s state, the goal position and the pet toy display locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_pet_toy_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pet_toy_display = calculate_distance_min(s_agent, s_pet_toy_display) \n    penalty_collision = -20 if (d_agent_pet_toy_display < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into dog and reach goal. The agent’s state, the goal position and the dog locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_dog, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dog = calculate_distance_min(s_agent, s_dog) \n    penalty_collision = -20 if (d_agent_dog < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid glass enclosure, customers and fish tank and reach goal. The agent’s state, the goal position and the multiple obstacles: glass enclosure, customers and fish tank locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid pet toy display, units and computers and reach goal. The agent’s state, the goal position and the multiple obstacles: pet toy display, units and computers locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into heat lamp and reach goal. The agent’s state, the goal position and the heat lamp locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_heat_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_heat_lamp = calculate_distance_min(s_agent, s_heat_lamp) \n    penalty = -20 if (d_agent_heat_lamp < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into scraching post and reach goal. The agent’s state, the goal position and the scratching post locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_scratching_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scratching_post = calculate_distance_min(s_agent, s_scratching_post) \n    penalty = -20 if (d_agent_scratching_post < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid pet toy display, adoption desk and play sign and reach goal. The agent’s state, the goal position and the multiple obstacles: pet toy display, adoption desk and play sign locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid kennel gate and grooming tables and reach goal. The agent’s state, the goal position and the multiple obstacles: kennel gate and grooming tables locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into desk and reach goal. The agent’s state, the goal position and the desk locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -20 if (d_agent_desk < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into litter box and reach goal. The agent’s state, the goal position and the litter box locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_litter_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_litter_box = calculate_distance_min(s_agent, s_litter_box) \n    penalty_collision = -20 if (d_agent_litter_box < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into door plants, backaquarium aisle room and kennel gate and reach goal. The agent’s state, the goal position and the multiple obstacles: door plants, backaquarium aisle room and kennel gate locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into bench, pet dryer and adoption desk and reach goal. The agent’s state, the goal position and the multiple obstacles: bench, pet dryer and adoption desk locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and reach goal. The agent’s state, the goal position are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of concrete columns or clown makeup tables and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles: concrete columns or clown makeup tables's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to reach goal and needs to steer of fire ring. The system has access to the drone’s state and the goal and fire ring' information. Write a Python reward function",
        "chosen": "def reward(s_agent, s_fire_ring, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fire_ring = calculate_distance_min(s_agent, s_fire_ring) \n    penalty_collision = -20 if (d_agent_fire_ring < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of spotlight and reach goal. The system has access to the drone’s state, the goal, the spotlight's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_spotlight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlight = calculate_distance_min(s_agent, s_spotlight) \n    penalty_collision = -20 if (d_agent_spotlight < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to reach goal and needs to steer of the table. The system has access to the drone’s state and the goal and table's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -20 if (d_agent_table < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of three snack counters and it and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of popcorn stand and reach goal. The system has access to the drone’s state, the goal, the popcorn stand's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_popcorn_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_popcorn_stand = calculate_distance_min(s_agent, s_popcorn_stand) \n    penalty_collision = -20 if (d_agent_popcorn_stand < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of snack counter and reach goal. The system has access to the drone’s state, the goal, the snack counter's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_snack_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snack_counter = calculate_distance_min(s_agent, s_snack_counter) \n    penalty_collision = -20 if (d_agent_snack_counter < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of wall and reach goal. The system has access to the drone’s state, the goal, the wall's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -20 if (d_agent_wall < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to reach goal and needs to steer of juggling prop. The system has access to the drone’s state and the goal and juggling props. Write a Python reward function",
        "chosen": "def reward(s_agent, s_juggling_prop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_juggling_prop = calculate_distance_min(s_agent, s_juggling_prop) \n    penalty_collision = -20 if (d_agent_juggling_prop < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of clown and reach goal. The system has access to the drone’s state, the goal, the clown's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_clown, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clown = calculate_distance_min(s_agent, s_clown) \n    penalty_collision = -20 if (d_agent_clown < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of animal enclosure, customers, and water tank and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of juggling prop, units, and computers and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of spotlight and reach goal. The system has access to the drone’s state, the goal, the spotlight's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_spotlight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlight = calculate_distance_min(s_agent, s_spotlight) \n    penalty = -20 if (d_agent_spotlight < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of tightrope pole and reach goal. The system has access to the drone’s state, the goal, the tightrope pole's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pole = calculate_distance_min(s_agent, s_pole) \n    penalty = -20 if (d_agent_pole < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of juggling prop, ticket desk, and play sign and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of cage gate and clown makeup tables and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of ticket desk and reach goal. The system has access to the drone’s state, the goal, the ticket desk's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_ticket_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_desk = calculate_distance_min(s_agent, s_ticket_desk) \n    penalty_collision = -20 if (d_agent_ticket_desk < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of sawdust pit and reach goal. The system has access to the drone’s state, the goal, the sawdust pit's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_pit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pit = calculate_distance_min(s_agent, s_pit) \n    penalty_collision = -20 if (d_agent_pit < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of Circus's incurtain entrance plants, backanimal cage room, and cage gate and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of audience bench, fire ring, and ticket desk and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to reach goal. The system has access to the drone’s state and the goal. Write a Python reward function",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with concrete columns or editor desks and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with box and arrive at goal. Information about the agent’s state, its goal, the box's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -20 if (d_agent_box < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with table and arrive at goal. Information about the agent’s state, its goal, the table's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -20 if (d_agent_table < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with three news desks and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with coffee machine and arrive at goal. Information about the agent’s state, its goal, the coffee machine's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_machine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_machine = calculate_distance_min(s_agent, s_coffee_machine) \n    penalty_collision = -20 if (d_agent_coffee_machine < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with news desk and arrive at goal. Information about the agent’s state, its goal, the news desk's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_news_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_news_desk = calculate_distance_min(s_agent, s_news_desk) \n    penalty_collision = -20 if (d_agent_news_desk < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with background and arrive at goal. Information about the agent’s state, its goal, the background's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_background, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_background = calculate_distance_min(s_agent, s_background) \n    penalty_collision = -20 if (d_agent_background < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with microphone stand and arrive at goal. Information about the agent’s state, its goal, the microphone stand's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_microphone_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone_stand = calculate_distance_min(s_agent, s_microphone_stand) \n    penalty_collision = -20 if (d_agent_microphone_stand < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with journalist and arrive at goal. Information about the agent’s state, its goal, the journalist is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_journalist, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_journalist = calculate_distance_min(s_agent, s_journalist) \n    penalty_collision = -20 if (d_agent_journalist < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with archive shelf, anchor and camera and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle: archive shelf, anchor and camera is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with microphone stand, staff and computers and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle: microphone stand, staff and computers is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with news box and arrive at goal. Information about the agent’s state, its goal, the news box's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty = -20 if (d_agent_box < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with rig and arrive at goal. Information about the agent’s state, its goal, the rig's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_rig, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rig = calculate_distance_min(s_agent, s_rig) \n    penalty = -20 if (d_agent_rig < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with microphone stand, reception desk and play sign and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle: microphone stand, reception desk and play sign is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with sliding partition and editor desks and arrive at goal. Information about the agent’s state, its goal, the many obstacle: sliding partition and editor desks is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with reception desk and arrive at goal. Information about the agent’s state, its goal, the reception desk is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_reception_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_desk = calculate_distance_min(s_agent, s_reception_desk) \n    penalty_collision = -20 if (d_agent_ticket_desk < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with printer and arrive at goal. Information about the agent’s state, its goal, the printer's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_printer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_printer = calculate_distance_min(s_agent, s_printer) \n    penalty_collision = -20 if (d_agent_printer < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with in glass door plants, backanimal cage room and sliding partition and arrive at goal. Information about the agent’s state, its goal, the many obstacle:in glass door plants, backanimal cage room and sliding partition is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with staff bench, camera tripod and reception desk and arrive at goal. Information about the agent’s state, its goal, the many obstacle: staff bench, camera tripod and reception desk is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom and arrive at goal. Information about the agent’s state, its goal. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with concrete columns or scoring desks and need to land on goal. Information about the agents state, its goal, the concrete columns or scoring desks's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and do not bump system. Information about the agents state and its goal and sytsem's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_system, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_system = calculate_distance_min(s_agent, s_system) \n    penalty_collision = -20 if (d_agent_system < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with locker and need to land on goal. Information about the agents state, its goal, the locker's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_locker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_locker = calculate_distance_min(s_agent, s_locker) \n    penalty_collision = -20 if (d_agent_locker < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and do not collide table. Information about the agents state, table's state and its goal is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -20 if (d_agent_table < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with it and need to land on goal and avoid three shoe counter. Information about the agents state, its goal, the multiple shoe counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and do not to bump snack bar. Information about the agents state and its goal, and snack bar's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_snack_bar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snack_bar = calculate_distance_min(s_agent, s_snack_bar) \n    penalty_collision = -20 if (d_agent_snack_bar < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with shoe counter and need to land on goal. Information about the agents state, its goal, the shoe counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_shoe_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shoe_counter = calculate_distance_min(s_agent, s_shoe_counter) \n    penalty_collision = -20 if (d_agent_shoe_counter < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and avoid collision wall. Information about the agents state and its goal, wall's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -20 if (d_agent_wall < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with Detect ball polisher and do not hitting with ball polisher and need to land on goal. Information about the agents state, its goal, the Detect ball polisher and do not hitting with ball polisher's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball_polisher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball_polisher = calculate_distance_min(s_agent, s_ball_polisher) \n    penalty_collision = -20 if (d_agent_ball_polisher < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with bowler and need to land on goal. Information about the agents state, its goal, the bowler's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_bowler, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bowler = calculate_distance_min(s_agent, s_bowler) \n    penalty_collision = -20 if (d_agent_bowler < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal. Avoid collision with ball rack, customers and pinsetter machine. Information about the agents state and its goal, multiple obstacle's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with ball polisher, scoreboard and clown and need to land on goal. Information about the agents state, its goal, the ball polisher, scoreboard and clown's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with locker and need to land on goal. Information about the agents state, its goal, the locker's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_locker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_locker = calculate_distance_min(s_agent, s_locker) \n    penalty = -20 if (d_agent_locker < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with overhead lights and need to land on goal. Information about the agents state, its goal, the overhead lights's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_light = calculate_distance_min(s_agent, s_light) \n    penalty = -20 if (d_agent_light < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with ball polisher, ticket counter and play sign and need to land on goal. Information about the agents state, its goal, the ball polisher, ticket counter and play sign's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with lane divider and scoring desks and need to land on goal. Information about the agents state, its goal, the lane divider and scoring desks's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with ticket counter and need to land on goal. Information about the agents state, its goal, the ticket counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_ticket_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_counter = calculate_distance_min(s_agent, s_ticket_counter) \n    penalty_collision = -20 if (d_agent_ticket_counter < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with scoreboard and need to land on goal. Information about the agents state, its goal, the scoreboard's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -20 if (d_agent_scoreboard < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with Bowling Alley's inentrance door plants, backanimal cage room and lane divider and need to land on goal. Information about the agents state, its goal, the multiple obstacle: Bowling Alley's inentrance door plants, backanimal cage room and lane divider's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with player bench, ball return system and ticket counter and need to land on goal. Information about the agents state, its goal, the multiple obstacle: the player bench, ball return system and ticket counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal. Information about the agents state and its goal is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along Castle. \n Objectives: It must avoid colliding with concrete columns or scribe desks. \n Conditions: The states of the agent, goal, the columns and the scribe desks are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy Castle. \n Objectives: Detect drawbridge and aviod it. \n Conditions: The states of the agent, goal, the drawbridge are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drawbridge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drawbridge = calculate_distance_min(s_agent, s_drawbridge) \n    penalty_collision = -20 if (d_agent_drawbridge < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Castle open workknightce. Objectives: It must avoid colliding with gatehouse. Conditions: States of the drone and the gatehouse are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_gatehouse, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gatehouse = calculate_distance_min(s_agent, s_gatehouse) \n    penalty_collision = -20 if (d_agent_gatehouse < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a great hall, the drone must maneuver around scribe desk. All entity states (agent, goal, table) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -20 if (d_agent_table < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a great hall. Requirement: Detect the three armory counters and do not collide with it. Given: The states for the drone and many armory counters are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a ablution Castle during experiments. \n Objectives: So not collide with banquet table. \n Conditions: The states of the agent, goal, the banquet table are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_banquet_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banquet_table = calculate_distance_min(s_agent, s_banquet_table) \n    penalty_collision = -20 if (d_agent_banquet_table < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate Castle. Objectives: Do not collide hit with the sword. Conditions: States of the agent, sword are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_sword, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sword = calculate_distance_min(s_agent, s_sword) \n    penalty_collision = -20 if (d_agent_sword < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a great hall, the drone must steer clear of wall. All states (agent, goal, stone wall) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_stone_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone_wall = calculate_distance_min(s_agent, s_stone_wall) \n    penalty_collision = -20 if (d_agent_stone_wall < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: ticket booth. Avoid: Detect armor stand and do not hitting with armor stand. Known: Agent, goal, armor stand states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_armor_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_armor_stand = calculate_distance_min(s_agent, s_armor_stand) \n    penalty_collision = -20 if (d_agent_armor_stand < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Castle. Objectives: It must avoid colliding with knight. Conditions: The states of the drone, goal and knight are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_knight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_knight = calculate_distance_min(s_agent, s_knight) \n    penalty_collision = -20 if (d_agent_knight < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through Castle. Objectives: Avoid collision with weapon rack, customers and trapdoor mechanism. Conditions: The states of the agent, goal, weapon rack, customers and trapdoor mechanism are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Castle. Objectives: It must avoid colliding with any armor stand, wa and computers. Conditions: Agent's, goal's armor stand, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through Castle. Objectives: Do not collide with gatehouse. Conditions: The states of the drone, goal and the gatehouse are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_gatehouse, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gatehouse = calculate_distance_min(s_agent, s_gatehouse) \n    penalty = -20 if (d_agent_gatehouse < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Castle and must avoid contact with the torch stand. The states of the drone, goal and the torch stand are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_torch_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_torch_stand = calculate_distance_min(s_agent, s_torch_stand) \n    penalty = -20 if (d_agent_torch_stand < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in Castle. It must avoid colliding with the armor stand, drawbridges and castle gates. The states of the agent, goal, incastle gate plants, drawbridges and castle gates are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in Castle. It must avoid colliding with the golden chalice and armor stand. The states of the drone, goal and the golden chalice and armor stand are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in Castle. It must avoid colliding with the curtain. Agent's state, goal's state and curtain's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -20 if (d_agent_curtain < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Castle. Goal: It must avoid colliding with royal banner. Assumptions: The states of the drone, goal and the royal banner's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_banner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banner = calculate_distance_min(s_agent, s_banner) \n    penalty_collision = -20 if (d_agent_banner < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Castle. Goal: It must avoid colliding with Castle's incastle gate plants, backanimal cage room and stone wall divider. Assumptions: The Agent's state, goal's state, incastle gate plants, backanimal cage room and stone wall divider's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Castle. Goal: Detect wooden bench, drawbridge and gatehouse and do not collide. Assumptions: The states of the drone, goal, wooden bench, drawbridge and gatehouse state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Castle. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along Pet Store. \n Objectives: It must avoid colliding with concrete columns or grooming tables. \n Conditions: The states of the agent, goal, the aquarium aisle, and the grooming tables are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy Pet Store. \n Objectives: Detect pet dryer and aviod it. \n Conditions: The states of the agent, goal, the pet dryer are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_pet_dryer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pet_dryer = calculate_distance_min(s_agent, s_pet_dryer) \n    penalty_collision = -20 if (d_agent_pet_dryer < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Pet Store open workspace. Objectives: It must avoid colliding with heat lamp. Conditions: States of the drone and the heat lamp are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_heat_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_heat_lamp = calculate_distance_min(s_agent, s_heat_lamp) \n    penalty_collision = -20 if (d_agent_heat_lamp < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a store floor, the drone must maneuver around grooming table. All entity states (agent, goal, chair) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -20 if (d_agent_chair < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a store floor. Requirement: Detect the three service counters and do not collide with it. Given: The states for the drone and many service counters are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a ablution Pet Store during experiments. \n Objectives: So not collide with treat bin. \n Conditions: The states of the agent, goal, the treat bin are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_treat_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_treat_bin = calculate_distance_min(s_agent, s_treat_bin) \n    penalty_collision = -20 if (d_agent_treat_bin < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate Pet Store. Objectives: Do not collide hit with service counter. Conditions: States of the agent, service counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_service_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_service_counter = calculate_distance_min(s_agent, s_service_counter) \n    penalty_collision = -20 if (d_agent_service_counter < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a store floor, the drone must steer clear of wall. All states (agent, goal, wall) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -20 if (d_agent_wall < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: checkout counter. Avoid: Detect pet toy display and do not hitting with pet toy display. Known: Agent, goal, pet toy display states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_pet_toy_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pet_toy_display = calculate_distance_min(s_agent, s_pet_toy_display) \n    penalty_collision = -20 if (d_agent_pet_toy_display < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Pet Store. Objectives: It must avoid colliding with a dog. Conditions: The states of the drone, goal and the dog are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dog, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dog = calculate_distance_min(s_agent, s_dog) \n    penalty_collision = -20 if (d_agent_dog < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through Pet Store. Objectives: Avoid collision with glass enclosure, customers and fish tank. Conditions: The states of the agent, goal, glass enclosure, customers and fish tank are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Pet Store. Objectives: It must avoid colliding with any pet toy display, units and computers. Conditions: Agent's, goal's pet toy display, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through Pet Store. Objectives: Do not collide with heat lamp. Conditions: The states of the drone, goal and the heat lamp are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_heat_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_heat_lamp = calculate_distance_min(s_agent, s_heat_lamp) \n    penalty = -20 if (d_agent_heat_lamp < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Pet Store and must avoid contact with the scratching post. The states of the drone, goal and the scratching post are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_scratching_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scratching_post = calculate_distance_min(s_agent, s_scratching_post) \n    penalty = -20 if (d_agent_scratching_post < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in Pet Store. It must avoid colliding with the pet toy display, adoption desk and play sign. The states of the agent, goal, insliding door plants, pet dryers and sliding doors are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in Pet Store. It must avoid colliding with kennel gate and grooming tables and other obstacles. The states of the drone, goal and the pet statue and pet_toy_display are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in Pet Store. It must avoid colliding with the adoption desk. Agent's state, goal's state and adoption desk's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -20 if (d_agent_desk < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Pet Store. Goal: It must avoid colliding with litter box. Assumptions: The states of the drone, goal and the litter box's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_litter_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_litter_box = calculate_distance_min(s_agent, s_litter_box) \n    penalty_collision = -20 if (d_agent_litter_box < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Pet Store. Goal: It must avoid colliding with Pet Store's insliding door plants, backaquarium aisle room and kennel gate. Assumptions: The Agent's state, goal's state, insliding door plants, backaquarium aisle room and kennel gate's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Pet Store. Goal: Detect customer bench, pet dryer and adoption desk and do not collide. Assumptions: The states of the drone, goal, customer bench, pet dryer and adoption desk state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Pet Store. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along Circus. \n Objectives: It must avoid colliding with concrete columns or clown makeup tables. \n Conditions: The states of the agent, goal, the animal cage, and the clown makeup tables are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy Circus. \n Objectives: Detect fire ring and aviod it. \n Conditions: The states of the agent, goal, the fire ring are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fire_ring, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fire_ring = calculate_distance_min(s_agent, s_fire_ring) \n    penalty_collision = -20 if (d_agent_fire_ring < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Circus open workclownce. Objectives: It must avoid colliding with spotlight. Conditions: States of the drone and the spotlight are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_spotlight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlight = calculate_distance_min(s_agent, s_spotlight) \n    penalty_collision = -20 if (d_agent_spotlight < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a circus ring, the drone must maneuver around clown makeup table. All entity states (agent, goal, table) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -20 if (d_agent_table < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a circus ring. Requirement: Detect the three snack counters and do not collide with it. Given: The states for the drone and many snack counters are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a ablution Circus during experiments. \n Objectives: So not collide with popcorn stand. \n Conditions: The states of the agent, goal, the popcorn stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_popcorn_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_popcorn_stand = calculate_distance_min(s_agent, s_popcorn_stand) \n    penalty_collision = -20 if (d_agent_popcorn_stand < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate Circus. Objectives: Do not collide hit with snack counter. Conditions: States of the agent, snack counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_snack_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snack_counter = calculate_distance_min(s_agent, s_snack_counter) \n    penalty_collision = -20 if (d_agent_snack_counter < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a circus ring, the drone must steer clear of wall. All states (agent, goal, wall) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -20 if (d_agent_wall < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: ticket booth. Avoid: Detect juggling prop and do not hitting with juggling prop. Known: Agent, goal, juggling prop states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_juggling_prop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_juggling_prop = calculate_distance_min(s_agent, s_juggling_prop) \n    penalty_collision = -20 if (d_agent_juggling_prop < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Circus. Objectives: It must avoid colliding with clown. Conditions: The states of the drone, goal and clown are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_clown, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clown = calculate_distance_min(s_agent, s_clown) \n    penalty_collision = -20 if (d_agent_clown < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through Circus. Objectives: Avoid collision with animal enclosure, customers and water tank. Conditions: The states of the agent, goal, animal enclosure, customers and water tank are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Circus. Objectives: It must avoid colliding with any juggling prop, units and computers. Conditions: Agent's, goal's juggling prop, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through Circus. Objectives: Do not collide with spotlight. Conditions: The states of the drone, goal and the spotlight are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_spotlight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlight = calculate_distance_min(s_agent, s_spotlight) \n    penalty = -20 if (d_agent_spotlight < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Circus and must avoid contact with the tightrope pole. The states of the drone, goal and the tightrope pole are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pole = calculate_distance_min(s_agent, s_pole) \n    penalty = -20 if (d_agent_pole < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in Circus. It must avoid colliding with the juggling prop, ticket desk and play sign. The states of the agent, goal, incurtain entrance plants, fire rings and curtain entrances are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in Circus. It must avoid colliding with cage gate and clown makeup tables. The states of the drone, goal and the circus statue and juggling_prop are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in Circus. It must avoid colliding with the ticket desk. Agent's state, goal's state and ticket desk's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ticket_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_desk = calculate_distance_min(s_agent, s_ticket_desk) \n    penalty_collision = -20 if (d_agent_ticket_desk < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: It must avoid colliding with sawdust pit. Assumptions: The states of the drone, goal and the sawdust pit's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_pit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pit = calculate_distance_min(s_agent, s_pit) \n    penalty_collision = -20 if (d_agent_pit < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: It must avoid colliding with Circus's incurtain entrance plants, backanimal cage room and cage gate. Assumptions: The Agent's state, goal's state, incurtain entrance plants, backanimal cage room and cage gate's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: Detect audience bench, fire ring and ticket desk and do not collide. Assumptions: The states of the drone, goal, audience bench, fire ring and ticket desk state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with concrete columns or editor desks and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with box and arrive at goal. Information about the agent’s state, its goal, the box's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -20 if (d_agent_box < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with table and arrive at goal. Information about the agent’s state, its goal, the table's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -20 if (d_agent_table < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with three news desks and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 8 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with coffee machine and arrive at goal. Information about the agent’s state, its goal, the coffee machine's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_machine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_machine = calculate_distance_min(s_agent, s_coffee_machine) \n    penalty_collision = -20 if (d_agent_coffee_machine < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with news desk and arrive at goal. Information about the agent’s state, its goal, the news desk's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_news_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_news_desk = calculate_distance_min(s_agent, s_news_desk) \n    penalty_collision = -20 if (d_agent_news_desk < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with background and arrive at goal. Information about the agent’s state, its goal, the background's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_background, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_background = calculate_distance_min(s_agent, s_background) \n    penalty_collision = -20 if (d_agent_background < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with microphone stand and arrive at goal. Information about the agent’s state, its goal, the microphone stand's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_microphone_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone_stand = calculate_distance_min(s_agent, s_microphone_stand) \n    penalty_collision = -20 if (d_agent_microphone_stand < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with journalist and arrive at goal. Information about the agent’s state, its goal, the journalist is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_journalist, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_journalist = calculate_distance_min(s_agent, s_journalist) \n    penalty_collision = -20 if (d_agent_journalist < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with archive shelf, anchor and camera and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle: archive shelf, anchor and camera is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with microphone stand, staff and computers and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle: microphone stand, staff and computers is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with news box and arrive at goal. Information about the agent’s state, its goal, the news box's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty = -20 if (d_agent_box < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with rig and arrive at goal. Information about the agent’s state, its goal, the rig's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_rig, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rig = calculate_distance_min(s_agent, s_rig) \n    penalty = -20 if (d_agent_rig < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with microphone stand, reception desk and play sign and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle: microphone stand, reception desk and play sign is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with sliding partition and editor desks and arrive at goal. Information about the agent’s state, its goal, the many obstacle: sliding partition and editor desks is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with reception desk and arrive at goal. Information about the agent’s state, its goal, the reception desk is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_reception_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_desk = calculate_distance_min(s_agent, s_reception_desk) \n    penalty_collision = -20 if (d_agent_ticket_desk < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with printer and arrive at goal. Information about the agent’s state, its goal, the printer's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_printer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_printer = calculate_distance_min(s_agent, s_printer) \n    penalty_collision = -20 if (d_agent_printer < ob_threshold) else 8 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with in glass door plants, backanimal cage room and sliding partition and arrive at goal. Information about the agent’s state, its goal, the many obstacle:in glass door plants, backanimal cage room and sliding partition is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with staff bench, camera tripod and reception desk and arrive at goal. Information about the agent’s state, its goal, the many obstacle: staff bench, camera tripod and reception desk is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom and arrive at goal. Information about the agent’s state, its goal. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with concrete columns or scoring desks and need to land on goal. Information about the agents state, its goal, the concrete columns or scoring desks's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -21 if (d_agent_multiple_obstacle_min < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and do not bump system. Information about the agents state and its goal and sytsem's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_system, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_system = calculate_distance_min(s_agent, s_system) \n    penalty_collision = -21 if (d_agent_system < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with locker and need to land on goal. Information about the agents state, its goal, the locker's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_locker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_locker = calculate_distance_min(s_agent, s_locker) \n    penalty_collision = -21 if (d_agent_locker < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and do not collide table. Information about the agents state, table's state and its goal is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -21 if (d_agent_table < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with it and need to land on goal and avoid three shoe counter. Information about the agents state, its goal, the multiple shoe counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -21 if (d_agent_multiple_obstacle_min < ob_threshold) else 11 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and do not to bump snack bar. Information about the agents state and its goal, and snack bar's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_snack_bar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snack_bar = calculate_distance_min(s_agent, s_snack_bar) \n    penalty_collision = -21 if (d_agent_snack_bar < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with shoe counter and need to land on goal. Information about the agents state, its goal, the shoe counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_shoe_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shoe_counter = calculate_distance_min(s_agent, s_shoe_counter) \n    penalty_collision = -21 if (d_agent_shoe_counter < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and avoid collision wall. Information about the agents state and its goal, wall's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -21 if (d_agent_wall < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with Detect ball polisher and do not hitting with ball polisher and need to land on goal. Information about the agents state, its goal, the Detect ball polisher and do not hitting with ball polisher's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball_polisher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball_polisher = calculate_distance_min(s_agent, s_ball_polisher) \n    penalty_collision = -21 if (d_agent_ball_polisher < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with bowler and need to land on goal. Information about the agents state, its goal, the bowler's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_bowler, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bowler = calculate_distance_min(s_agent, s_bowler) \n    penalty_collision = -21 if (d_agent_bowler < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal. Avoid collision with ball rack, customers and pinsetter machine. Information about the agents state and its goal, multiple obstacle's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -21 if (d_agent_multiple_obstacles_min < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with ball polisher, scoreboard and clown and need to land on goal. Information about the agents state, its goal, the ball polisher, scoreboard and clown's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -21 if (d_agent_multiple_obstacles_min < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with locker and need to land on goal. Information about the agents state, its goal, the locker's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_locker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_locker = calculate_distance_min(s_agent, s_locker) \n    penalty = -21 if (d_agent_locker < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with overhead lights and need to land on goal. Information about the agents state, its goal, the overhead lights's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_light = calculate_distance_min(s_agent, s_light) \n    penalty = -21 if (d_agent_light < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with ball polisher, ticket counter and play sign and need to land on goal. Information about the agents state, its goal, the ball polisher, ticket counter and play sign's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -21 if (d_agent_multiple_obstacles_min < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with lane divider and scoring desks and need to land on goal. Information about the agents state, its goal, the lane divider and scoring desks's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -21 if (d_agent_multiple_obstacles_min < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with ticket counter and need to land on goal. Information about the agents state, its goal, the ticket counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_ticket_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_counter = calculate_distance_min(s_agent, s_ticket_counter) \n    penalty_collision = -21 if (d_agent_ticket_counter < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with scoreboard and need to land on goal. Information about the agents state, its goal, the scoreboard's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -21 if (d_agent_scoreboard < ob_threshold) else 11 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with Bowling Alley's inentrance door plants, backanimal cage room and lane divider and need to land on goal. Information about the agents state, its goal, the multiple obstacle: Bowling Alley's inentrance door plants, backanimal cage room and lane divider's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -21 if (d_agent_multiple_obstacles_min < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with player bench, ball return system and ticket counter and need to land on goal. Information about the agents state, its goal, the multiple obstacle: the player bench, ball return system and ticket counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -21 if (d_agent_multiple_obstacles_min < ob_threshold) else 11 \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal. Information about the agents state and its goal is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 26 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense concrete columns or scribe desks and avoid obstacle. With the states of the agent and the multiple obstcales: concrete columns or scribe desks available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense drawbridge and avoid obstacle. With the states of both the agent and the drawbridge available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_drawbridge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drawbridge = calculate_distance_min(s_agent, s_drawbridge) \n    penalty_collision = -20 if (d_agent_drawbridge < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense gatehouse and avoid obstacle. With the states of both the agent and the gatehouse available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_gatehouse, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gatehouse = calculate_distance_min(s_agent, s_gatehouse) \n    penalty_collision = -20 if (d_agent_gatehouse < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense table and avoid obstacle. With the states of both the agent and the table available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -20 if (d_agent_table < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense three armory counters and avoid obstacle. With the states of both the agent and the multiple armory counters available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense banquet table and avoid obstacle. With the states of both the agent and the banquet table available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_banquet_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banquet_table = calculate_distance_min(s_agent, s_banquet_table) \n    penalty_collision = -20 if (d_agent_banquet_table < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense sword and avoid obstacle. With the states of both the agent and the sword available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_sword, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sword = calculate_distance_min(s_agent, s_sword) \n    penalty_collision = -20 if (d_agent_sword < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense stone wall and avoid obstacle. With the states of both the agent and the stone wall available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_stone_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone_wall = calculate_distance_min(s_agent, s_stone_wall) \n    penalty_collision = -20 if (d_agent_stone_wall < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense armor stand and avoid obstacle. With the states of both the agent and the armor stand available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_armor_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_armor_stand = calculate_distance_min(s_agent, s_armor_stand) \n    penalty_collision = -20 if (d_agent_armor_stand < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense avoid knight and obstacle. With the states of both the agent and the knight available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_knight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_knight = calculate_distance_min(s_agent, s_knight) \n    penalty_collision = -20 if (d_agent_knight < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense armor stand and computers and avoid obstacle. With the states of both the agent and the multiple obstacle: armor stand and computers available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense golden chalice and armor stand and avoid obstacle. With the states of both the agent and the golden chalice and armor stand available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense gatehouse and avoid obstacle. With the states of both the agent and the gatehouse available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_gatehouse, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gatehouse = calculate_distance_min(s_agent, s_gatehouse) \n    penalty = -20 if (d_agent_gatehouse < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense torch stand and avoid obstacle. With the states of both the agent and the torch stand available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_torch_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_torch_stand = calculate_distance_min(s_agent, s_torch_stand) \n    penalty = -20 if (d_agent_torch_stand < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense light and avoid obstacles. With the states of both the agent and the light available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense light and avoid obstacles. With the states of both the agent and the light available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense surtian and avoid obstacles. With the states of both the agent and the curtain available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -20 if (d_agent_curtain < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense banner and avoid obstacles. With the states of both the agent and the banner available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_banner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banner = calculate_distance_min(s_agent, s_banner) \n    penalty_collision = -20 if (d_agent_banner < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense Castle's incastle gate plants, backanimal cage room and stone wall divider and avoid obstacles. With the states of both the agent and the multiple obstacle:Castle's incastle gate plants, backanimal cage room and stone wall divider available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense light and wall and avoid obstacles. With the states of both the agent and the light and wall available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to to reach goal. With the states of both the agent and the goal available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid trellis frames or hanging baskets and reach goal. The agent’s state, the goal position and the multiple obstacles: trellis frames or hanging baskets locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into pet dryer and reach goal. The agent’s state, the goal position and the pet dryer locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_pet_dryer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pet_dryer = calculate_distance_min(s_agent, s_pet_dryer) \n    penalty_collision = -20 if (d_agent_pet_dryer < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into heat lamp and reach goal. The agent’s state, the goal position and the heat lamp locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_heat_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_heat_lamp = calculate_distance_min(s_agent, s_heat_lamp) \n    penalty_collision = -20 if (d_agent_heat_lamp < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into chair and reach goal. The agent’s state, the goal position and the chair locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -20 if (d_agent_chair < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid three service counters and reach goal. The agent’s state, the goal position and the multiple obstacles: three service counters locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into treat bin and reach goal. The agent’s state, the goal position and the treat bin locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_treat_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_treat_bin = calculate_distance_min(s_agent, s_treat_bin) \n    penalty_collision = -20 if (d_agent_treat_bin < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into service counter and reach goal. The agent’s state, the goal position and the service counter locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_service_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_service_counter = calculate_distance_min(s_agent, s_service_counter) \n    penalty_collision = -20 if (d_agent_service_counter < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into wall and reach goal. The agent’s state, the goal position and the wall locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -20 if (d_agent_wall < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into pet toy display and reach goal. The agent’s state, the goal position and the pet toy display locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_pet_toy_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pet_toy_display = calculate_distance_min(s_agent, s_pet_toy_display) \n    penalty_collision = -20 if (d_agent_pet_toy_display < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into dog and reach goal. The agent’s state, the goal position and the dog locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_dog, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dog = calculate_distance_min(s_agent, s_dog) \n    penalty_collision = -20 if (d_agent_dog < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid glass enclosure, customers and fish tank and reach goal. The agent’s state, the goal position and the multiple obstacles: glass enclosure, customers and fish tank locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid pet toy display, units and computers and reach goal. The agent’s state, the goal position and the multiple obstacles: pet toy display, units and computers locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into heat lamp and reach goal. The agent’s state, the goal position and the heat lamp locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_heat_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_heat_lamp = calculate_distance_min(s_agent, s_heat_lamp) \n    penalty = -20 if (d_agent_heat_lamp < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into scraching post and reach goal. The agent’s state, the goal position and the scratching post locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_scratching_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scratching_post = calculate_distance_min(s_agent, s_scratching_post) \n    penalty = -20 if (d_agent_scratching_post < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid pet toy display, adoption desk and play sign and reach goal. The agent’s state, the goal position and the multiple obstacles: pet toy display, adoption desk and play sign locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid kennel gate and grooming tables and reach goal. The agent’s state, the goal position and the multiple obstacles: kennel gate and grooming tables locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into desk and reach goal. The agent’s state, the goal position and the desk locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -20 if (d_agent_desk < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into litter box and reach goal. The agent’s state, the goal position and the litter box locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_litter_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_litter_box = calculate_distance_min(s_agent, s_litter_box) \n    penalty_collision = -20 if (d_agent_litter_box < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into door plants, backaquarium aisle room and kennel gate and reach goal. The agent’s state, the goal position and the multiple obstacles: door plants, backaquarium aisle room and kennel gate locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into bench, pet dryer and adoption desk and reach goal. The agent’s state, the goal position and the multiple obstacles: bench, pet dryer and adoption desk locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -5*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and reach goal. The agent’s state, the goal position are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of concrete columns or clown makeup tables and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles: concrete columns or clown makeup tables's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -16 if (d_agent_multiple_obstacle_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to reach goal and needs to steer of fire ring. The system has access to the drone’s state and the goal and fire ring' information. Write a Python reward function",
        "chosen": "def reward(s_agent, s_fire_ring, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fire_ring = calculate_distance_min(s_agent, s_fire_ring) \n    penalty_collision = -16 if (d_agent_fire_ring < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of spotlight and reach goal. The system has access to the drone’s state, the goal, the spotlight's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_spotlight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlight = calculate_distance_min(s_agent, s_spotlight) \n    penalty_collision = -16 if (d_agent_spotlight < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to reach goal and needs to steer of the table. The system has access to the drone’s state and the goal and table's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -16 if (d_agent_table < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of three snack counters and it and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -16 if (d_agent_multiple_obstacle_min < ob_threshold) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of popcorn stand and reach goal. The system has access to the drone’s state, the goal, the popcorn stand's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_popcorn_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_popcorn_stand = calculate_distance_min(s_agent, s_popcorn_stand) \n    penalty_collision = -16 if (d_agent_popcorn_stand < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of snack counter and reach goal. The system has access to the drone’s state, the goal, the snack counter's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_snack_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snack_counter = calculate_distance_min(s_agent, s_snack_counter) \n    penalty_collision = -16 if (d_agent_snack_counter < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of wall and reach goal. The system has access to the drone’s state, the goal, the wall's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -16 if (d_agent_wall < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to reach goal and needs to steer of juggling prop. The system has access to the drone’s state and the goal and juggling props. Write a Python reward function",
        "chosen": "def reward(s_agent, s_juggling_prop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_juggling_prop = calculate_distance_min(s_agent, s_juggling_prop) \n    penalty_collision = -16 if (d_agent_juggling_prop < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of clown and reach goal. The system has access to the drone’s state, the goal, the clown's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_clown, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clown = calculate_distance_min(s_agent, s_clown) \n    penalty_collision = -16 if (d_agent_clown < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of animal enclosure, customers, and water tank and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -16 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of juggling prop, units, and computers and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -16 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of spotlight and reach goal. The system has access to the drone’s state, the goal, the spotlight's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_spotlight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlight = calculate_distance_min(s_agent, s_spotlight) \n    penalty = -16 if (d_agent_spotlight < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of tightrope pole and reach goal. The system has access to the drone’s state, the goal, the tightrope pole's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pole = calculate_distance_min(s_agent, s_pole) \n    penalty = -16 if (d_agent_pole < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of juggling prop, ticket desk, and play sign and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -16 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of cage gate and clown makeup tables and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -16 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of ticket desk and reach goal. The system has access to the drone’s state, the goal, the ticket desk's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_ticket_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_desk = calculate_distance_min(s_agent, s_ticket_desk) \n    penalty_collision = -16 if (d_agent_ticket_desk < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of sawdust pit and reach goal. The system has access to the drone’s state, the goal, the sawdust pit's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_pit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pit = calculate_distance_min(s_agent, s_pit) \n    penalty_collision = -16 if (d_agent_pit < ob_threshold) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of Circus's incurtain entrance plants, backanimal cage room, and cage gate and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -16 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to steer clear of audience bench, fire ring, and ticket desk and reach goal. The system has access to the drone’s state, the goal, the multiple obstacles's state. Write a Python reward function",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -16 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside the circus, a drone is flying and needs to reach goal. The system has access to the drone’s state and the goal. Write a Python reward function",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along Circus. \n Objectives: It must avoid colliding with concrete columns or clown makeup tables. \n Conditions: The states of the agent, goal, the animal cage, and the clown makeup tables are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy Circus. \n Objectives: Detect fire ring and aviod it. \n Conditions: The states of the agent, goal, the fire ring are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fire_ring, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fire_ring = calculate_distance_min(s_agent, s_fire_ring) \n    penalty_collision = -20 if (d_agent_fire_ring < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Circus open workclownce. Objectives: It must avoid colliding with spotlight. Conditions: States of the drone and the spotlight are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_spotlight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlight = calculate_distance_min(s_agent, s_spotlight) \n    penalty_collision = -20 if (d_agent_spotlight < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a circus ring, the drone must maneuver around clown makeup table. All entity states (agent, goal, table) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -20 if (d_agent_table < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a circus ring. Requirement: Detect the three snack counters and do not collide with it. Given: The states for the drone and many snack counters are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a ablution Circus during experiments. \n Objectives: So not collide with popcorn stand. \n Conditions: The states of the agent, goal, the popcorn stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_popcorn_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_popcorn_stand = calculate_distance_min(s_agent, s_popcorn_stand) \n    penalty_collision = -20 if (d_agent_popcorn_stand < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate Circus. Objectives: Do not collide hit with snack counter. Conditions: States of the agent, snack counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_snack_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snack_counter = calculate_distance_min(s_agent, s_snack_counter) \n    penalty_collision = -20 if (d_agent_snack_counter < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a circus ring, the drone must steer clear of wall. All states (agent, goal, wall) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -20 if (d_agent_wall < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: ticket booth. Avoid: Detect juggling prop and do not hitting with juggling prop. Known: Agent, goal, juggling prop states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_juggling_prop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_juggling_prop = calculate_distance_min(s_agent, s_juggling_prop) \n    penalty_collision = -20 if (d_agent_juggling_prop < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Circus. Objectives: It must avoid colliding with clown. Conditions: The states of the drone, goal and clown are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_clown, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clown = calculate_distance_min(s_agent, s_clown) \n    penalty_collision = -20 if (d_agent_clown < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through Circus. Objectives: Avoid collision with animal enclosure, customers and water tank. Conditions: The states of the agent, goal, animal enclosure, customers and water tank are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Circus. Objectives: It must avoid colliding with any juggling prop, units and computers. Conditions: Agent's, goal's juggling prop, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through Circus. Objectives: Do not collide with spotlight. Conditions: The states of the drone, goal and the spotlight are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_spotlight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlight = calculate_distance_min(s_agent, s_spotlight) \n    penalty = -20 if (d_agent_spotlight < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Circus and must avoid contact with the tightrope pole. The states of the drone, goal and the tightrope pole are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pole = calculate_distance_min(s_agent, s_pole) \n    penalty = -20 if (d_agent_pole < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in Circus. It must avoid colliding with the juggling prop, ticket desk and play sign. The states of the agent, goal, incurtain entrance plants, fire rings and curtain entrances are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in Circus. It must avoid colliding with cage gate and clown makeup tables. The states of the drone, goal and the circus statue and juggling_prop are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in Circus. It must avoid colliding with the ticket desk. Agent's state, goal's state and ticket desk's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ticket_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_desk = calculate_distance_min(s_agent, s_ticket_desk) \n    penalty_collision = -20 if (d_agent_ticket_desk < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: It must avoid colliding with sawdust pit. Assumptions: The states of the drone, goal and the sawdust pit's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_pit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pit = calculate_distance_min(s_agent, s_pit) \n    penalty_collision = -20 if (d_agent_pit < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: It must avoid colliding with Circus's incurtain entrance plants, backanimal cage room and cage gate. Assumptions: The Agent's state, goal's state, incurtain entrance plants, backanimal cage room and cage gate's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: Detect audience bench, fire ring and ticket desk and do not collide. Assumptions: The states of the drone, goal, audience bench, fire ring and ticket desk state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with concrete columns or editor desks and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacle_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with box and arrive at goal. Information about the agent’s state, its goal, the box's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -15 if (d_agent_box < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with table and arrive at goal. Information about the agent’s state, its goal, the table's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with three news desks and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacle_min < ob_threshold) else 8 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with coffee machine and arrive at goal. Information about the agent’s state, its goal, the coffee machine's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_machine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_machine = calculate_distance_min(s_agent, s_coffee_machine) \n    penalty_collision = -15 if (d_agent_coffee_machine < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with news desk and arrive at goal. Information about the agent’s state, its goal, the news desk's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_news_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_news_desk = calculate_distance_min(s_agent, s_news_desk) \n    penalty_collision = -15 if (d_agent_news_desk < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with background and arrive at goal. Information about the agent’s state, its goal, the background's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_background, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_background = calculate_distance_min(s_agent, s_background) \n    penalty_collision = -15 if (d_agent_background < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with microphone stand and arrive at goal. Information about the agent’s state, its goal, the microphone stand's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_microphone_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone_stand = calculate_distance_min(s_agent, s_microphone_stand) \n    penalty_collision = -15 if (d_agent_microphone_stand < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with journalist and arrive at goal. Information about the agent’s state, its goal, the journalist is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_journalist, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_journalist = calculate_distance_min(s_agent, s_journalist) \n    penalty_collision = -15 if (d_agent_journalist < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with archive shelf, anchor and camera and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle: archive shelf, anchor and camera is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with microphone stand, staff and computers and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle: microphone stand, staff and computers is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with news box and arrive at goal. Information about the agent’s state, its goal, the news box's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty = -15 if (d_agent_box < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with rig and arrive at goal. Information about the agent’s state, its goal, the rig's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_rig, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rig = calculate_distance_min(s_agent, s_rig) \n    penalty = -15 if (d_agent_rig < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with microphone stand, reception desk and play sign and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle: microphone stand, reception desk and play sign is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with sliding partition and editor desks and arrive at goal. Information about the agent’s state, its goal, the many obstacle: sliding partition and editor desks is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with reception desk and arrive at goal. Information about the agent’s state, its goal, the reception desk is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_reception_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_desk = calculate_distance_min(s_agent, s_reception_desk) \n    penalty_collision = -15 if (d_agent_ticket_desk < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with printer and arrive at goal. Information about the agent’s state, its goal, the printer's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_printer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_printer = calculate_distance_min(s_agent, s_printer) \n    penalty_collision = -15 if (d_agent_printer < ob_threshold) else 8 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with in glass door plants, backanimal cage room and sliding partition and arrive at goal. Information about the agent’s state, its goal, the many obstacle:in glass door plants, backanimal cage room and sliding partition is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with staff bench, camera tripod and reception desk and arrive at goal. Information about the agent’s state, its goal, the many obstacle: staff bench, camera tripod and reception desk is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom and arrive at goal. Information about the agent’s state, its goal. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with concrete columns or scoring desks and need to land on goal. Information about the agents state, its goal, the concrete columns or scoring desks's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacle_min < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and do not bump system. Information about the agents state and its goal and sytsem's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_system, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_system = calculate_distance_min(s_agent, s_system) \n    penalty_collision = -22 if (d_agent_system < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with locker and need to land on goal. Information about the agents state, its goal, the locker's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_locker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_locker = calculate_distance_min(s_agent, s_locker) \n    penalty_collision = -22 if (d_agent_locker < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and do not collide table. Information about the agents state, table's state and its goal is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -22 if (d_agent_table < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with it and need to land on goal and avoid three shoe counter. Information about the agents state, its goal, the multiple shoe counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacle_min < ob_threshold) else 12 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and do not to bump snack bar. Information about the agents state and its goal, and snack bar's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_snack_bar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snack_bar = calculate_distance_min(s_agent, s_snack_bar) \n    penalty_collision = -22 if (d_agent_snack_bar < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with shoe counter and need to land on goal. Information about the agents state, its goal, the shoe counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_shoe_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shoe_counter = calculate_distance_min(s_agent, s_shoe_counter) \n    penalty_collision = -22 if (d_agent_shoe_counter < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and avoid collision wall. Information about the agents state and its goal, wall's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -22 if (d_agent_wall < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with Detect ball polisher and do not hitting with ball polisher and need to land on goal. Information about the agents state, its goal, the Detect ball polisher and do not hitting with ball polisher's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball_polisher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball_polisher = calculate_distance_min(s_agent, s_ball_polisher) \n    penalty_collision = -22 if (d_agent_ball_polisher < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with bowler and need to land on goal. Information about the agents state, its goal, the bowler's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_bowler, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bowler = calculate_distance_min(s_agent, s_bowler) \n    penalty_collision = -22 if (d_agent_bowler < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal. Avoid collision with ball rack, customers and pinsetter machine. Information about the agents state and its goal, multiple obstacle's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacles_min < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with ball polisher, scoreboard and clown and need to land on goal. Information about the agents state, its goal, the ball polisher, scoreboard and clown's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacles_min < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with locker and need to land on goal. Information about the agents state, its goal, the locker's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_locker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_locker = calculate_distance_min(s_agent, s_locker) \n    penalty = -22 if (d_agent_locker < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with overhead lights and need to land on goal. Information about the agents state, its goal, the overhead lights's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_light = calculate_distance_min(s_agent, s_light) \n    penalty = -22 if (d_agent_light < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with ball polisher, ticket counter and play sign and need to land on goal. Information about the agents state, its goal, the ball polisher, ticket counter and play sign's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacles_min < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with lane divider and scoring desks and need to land on goal. Information about the agents state, its goal, the lane divider and scoring desks's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacles_min < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with ticket counter and need to land on goal. Information about the agents state, its goal, the ticket counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_ticket_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_counter = calculate_distance_min(s_agent, s_ticket_counter) \n    penalty_collision = -22 if (d_agent_ticket_counter < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with scoreboard and need to land on goal. Information about the agents state, its goal, the scoreboard's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -22 if (d_agent_scoreboard < ob_threshold) else 12 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with Bowling Alley's inentrance door plants, backanimal cage room and lane divider and need to land on goal. Information about the agents state, its goal, the multiple obstacle: Bowling Alley's inentrance door plants, backanimal cage room and lane divider's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacles_min < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with player bench, ball return system and ticket counter and need to land on goal. Information about the agents state, its goal, the multiple obstacle: the player bench, ball return system and ticket counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacles_min < ob_threshold) else 12 \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal. Information about the agents state and its goal is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 27 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along Circus. \n Objectives: It must avoid colliding with concrete columns or clown makeup tables. \n Conditions: The states of the agent, goal, the animal cage, and the clown makeup tables are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -23 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy Circus. \n Objectives: Detect fire ring and aviod it. \n Conditions: The states of the agent, goal, the fire ring are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fire_ring, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fire_ring = calculate_distance_min(s_agent, s_fire_ring) \n    penalty_collision = -23 if (d_agent_fire_ring < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Circus open workclownce. Objectives: It must avoid colliding with spotlight. Conditions: States of the drone and the spotlight are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_spotlight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlight = calculate_distance_min(s_agent, s_spotlight) \n    penalty_collision = -23 if (d_agent_spotlight < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a circus ring, the drone must maneuver around clown makeup table. All entity states (agent, goal, table) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -23 if (d_agent_table < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a circus ring. Requirement: Detect the three snack counters and do not collide with it. Given: The states for the drone and many snack counters are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -23 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a ablution Circus during experiments. \n Objectives: So not collide with popcorn stand. \n Conditions: The states of the agent, goal, the popcorn stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_popcorn_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_popcorn_stand = calculate_distance_min(s_agent, s_popcorn_stand) \n    penalty_collision = -23 if (d_agent_popcorn_stand < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate Circus. Objectives: Do not collide hit with snack counter. Conditions: States of the agent, snack counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_snack_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snack_counter = calculate_distance_min(s_agent, s_snack_counter) \n    penalty_collision = -23 if (d_agent_snack_counter < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a circus ring, the drone must steer clear of wall. All states (agent, goal, wall) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -23 if (d_agent_wall < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: ticket booth. Avoid: Detect juggling prop and do not hitting with juggling prop. Known: Agent, goal, juggling prop states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_juggling_prop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_juggling_prop = calculate_distance_min(s_agent, s_juggling_prop) \n    penalty_collision = -23 if (d_agent_juggling_prop < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Circus. Objectives: It must avoid colliding with clown. Conditions: The states of the drone, goal and clown are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_clown, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clown = calculate_distance_min(s_agent, s_clown) \n    penalty_collision = -23 if (d_agent_clown < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through Circus. Objectives: Avoid collision with animal enclosure, customers and water tank. Conditions: The states of the agent, goal, animal enclosure, customers and water tank are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -23 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Circus. Objectives: It must avoid colliding with any juggling prop, units and computers. Conditions: Agent's, goal's juggling prop, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -23 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through Circus. Objectives: Do not collide with spotlight. Conditions: The states of the drone, goal and the spotlight are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_spotlight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlight = calculate_distance_min(s_agent, s_spotlight) \n    penalty = -23 if (d_agent_spotlight < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Circus and must avoid contact with the tightrope pole. The states of the drone, goal and the tightrope pole are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pole = calculate_distance_min(s_agent, s_pole) \n    penalty = -23 if (d_agent_pole < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in Circus. It must avoid colliding with the juggling prop, ticket desk and play sign. The states of the agent, goal, incurtain entrance plants, fire rings and curtain entrances are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -23 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in Circus. It must avoid colliding with cage gate and clown makeup tables. The states of the drone, goal and the circus statue and juggling_prop are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -23 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in Circus. It must avoid colliding with the ticket desk. Agent's state, goal's state and ticket desk's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ticket_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_desk = calculate_distance_min(s_agent, s_ticket_desk) \n    penalty_collision = -23 if (d_agent_ticket_desk < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: It must avoid colliding with sawdust pit. Assumptions: The states of the drone, goal and the sawdust pit's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_pit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pit = calculate_distance_min(s_agent, s_pit) \n    penalty_collision = -23 if (d_agent_pit < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: It must avoid colliding with Circus's incurtain entrance plants, backanimal cage room and cage gate. Assumptions: The Agent's state, goal's state, incurtain entrance plants, backanimal cage room and cage gate's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -23 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: Detect audience bench, fire ring and ticket desk and do not collide. Assumptions: The states of the drone, goal, audience bench, fire ring and ticket desk state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -23 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -3**d_agent_goal\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < goal_threshold) else -d_agent_goal*3 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid trellis frames or hanging baskets and reach goal. The agent’s state, the goal position and the multiple obstacles: trellis frames or hanging baskets locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into pet dryer and reach goal. The agent’s state, the goal position and the pet dryer locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_pet_dryer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pet_dryer = calculate_distance_min(s_agent, s_pet_dryer) \n    penalty_collision = -20 if (d_agent_pet_dryer < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into heat lamp and reach goal. The agent’s state, the goal position and the heat lamp locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_heat_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_heat_lamp = calculate_distance_min(s_agent, s_heat_lamp) \n    penalty_collision = -20 if (d_agent_heat_lamp < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into chair and reach goal. The agent’s state, the goal position and the chair locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -20 if (d_agent_chair < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid three service counters and reach goal. The agent’s state, the goal position and the multiple obstacles: three service counters locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into treat bin and reach goal. The agent’s state, the goal position and the treat bin locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_treat_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_treat_bin = calculate_distance_min(s_agent, s_treat_bin) \n    penalty_collision = -20 if (d_agent_treat_bin < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into service counter and reach goal. The agent’s state, the goal position and the service counter locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_service_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_service_counter = calculate_distance_min(s_agent, s_service_counter) \n    penalty_collision = -20 if (d_agent_service_counter < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into wall and reach goal. The agent’s state, the goal position and the wall locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -20 if (d_agent_wall < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into pet toy display and reach goal. The agent’s state, the goal position and the pet toy display locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_pet_toy_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pet_toy_display = calculate_distance_min(s_agent, s_pet_toy_display) \n    penalty_collision = -20 if (d_agent_pet_toy_display < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into dog and reach goal. The agent’s state, the goal position and the dog locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_dog, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dog = calculate_distance_min(s_agent, s_dog) \n    penalty_collision = -20 if (d_agent_dog < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid glass enclosure, customers and fish tank and reach goal. The agent’s state, the goal position and the multiple obstacles: glass enclosure, customers and fish tank locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid pet toy display, units and computers and reach goal. The agent’s state, the goal position and the multiple obstacles: pet toy display, units and computers locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into heat lamp and reach goal. The agent’s state, the goal position and the heat lamp locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_heat_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_heat_lamp = calculate_distance_min(s_agent, s_heat_lamp) \n    penalty = -20 if (d_agent_heat_lamp < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into scraching post and reach goal. The agent’s state, the goal position and the scratching post locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_scratching_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scratching_post = calculate_distance_min(s_agent, s_scratching_post) \n    penalty = -20 if (d_agent_scratching_post < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid pet toy display, adoption desk and play sign and reach goal. The agent’s state, the goal position and the multiple obstacles: pet toy display, adoption desk and play sign locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid kennel gate and grooming tables and reach goal. The agent’s state, the goal position and the multiple obstacles: kennel gate and grooming tables locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into desk and reach goal. The agent’s state, the goal position and the desk locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -20 if (d_agent_desk < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into litter box and reach goal. The agent’s state, the goal position and the litter box locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_litter_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_litter_box = calculate_distance_min(s_agent, s_litter_box) \n    penalty_collision = -20 if (d_agent_litter_box < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into door plants, backaquarium aisle room and kennel gate and reach goal. The agent’s state, the goal position and the multiple obstacles: door plants, backaquarium aisle room and kennel gate locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and must avoid crashing into bench, pet dryer and adoption desk and reach goal. The agent’s state, the goal position and the multiple obstacles: bench, pet dryer and adoption desk locations are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -math.log(d_agent_log) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating inside the Pet Store and reach goal. The agent’s state, the goal position are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along Circus. \n Objectives: It must avoid colliding with concrete columns or clown makeup tables. \n Conditions: The states of the agent, goal, the animal cage, and the clown makeup tables are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy Circus. \n Objectives: Detect fire ring and aviod it. \n Conditions: The states of the agent, goal, the fire ring are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fire_ring, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fire_ring = calculate_distance_min(s_agent, s_fire_ring) \n    penalty_collision = -20 if (d_agent_fire_ring < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Circus open workclownce. Objectives: It must avoid colliding with spotlight. Conditions: States of the drone and the spotlight are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_spotlight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlight = calculate_distance_min(s_agent, s_spotlight) \n    penalty_collision = -20 if (d_agent_spotlight < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a circus ring, the drone must maneuver around clown makeup table. All entity states (agent, goal, table) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -20 if (d_agent_table < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a circus ring. Requirement: Detect the three snack counters and do not collide with it. Given: The states for the drone and many snack counters are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a ablution Circus during logeriments. \n Objectives: So not collide with popcorn stand. \n Conditions: The states of the agent, goal, the popcorn stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_popcorn_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_popcorn_stand = calculate_distance_min(s_agent, s_popcorn_stand) \n    penalty_collision = -20 if (d_agent_popcorn_stand < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate Circus. Objectives: Do not collide hit with snack counter. Conditions: States of the agent, snack counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_snack_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snack_counter = calculate_distance_min(s_agent, s_snack_counter) \n    penalty_collision = -20 if (d_agent_snack_counter < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a circus ring, the drone must steer clear of wall. All states (agent, goal, wall) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -20 if (d_agent_wall < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: ticket booth. Avoid: Detect juggling prop and do not hitting with juggling prop. Known: Agent, goal, juggling prop states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_juggling_prop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_juggling_prop = calculate_distance_min(s_agent, s_juggling_prop) \n    penalty_collision = -20 if (d_agent_juggling_prop < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Circus. Objectives: It must avoid colliding with clown. Conditions: The states of the drone, goal and clown are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_clown, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clown = calculate_distance_min(s_agent, s_clown) \n    penalty_collision = -20 if (d_agent_clown < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through Circus. Objectives: Avoid collision with animal enclosure, customers and water tank. Conditions: The states of the agent, goal, animal enclosure, customers and water tank are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating Circus. Objectives: It must avoid colliding with any juggling prop, units and computers. Conditions: Agent's, goal's juggling prop, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through Circus. Objectives: Do not collide with spotlight. Conditions: The states of the drone, goal and the spotlight are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_spotlight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlight = calculate_distance_min(s_agent, s_spotlight) \n    penalty = -20 if (d_agent_spotlight < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Circus and must avoid contact with the tightrope pole. The states of the drone, goal and the tightrope pole are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pole = calculate_distance_min(s_agent, s_pole) \n    penalty = -20 if (d_agent_pole < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in Circus. It must avoid colliding with the juggling prop, ticket desk and play sign. The states of the agent, goal, incurtain entrance plants, fire rings and curtain entrances are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in Circus. It must avoid colliding with cage gate and clown makeup tables. The states of the drone, goal and the circus statue and juggling_prop are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in Circus. It must avoid colliding with the ticket desk. Agent's state, goal's state and ticket desk's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ticket_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_desk = calculate_distance_min(s_agent, s_ticket_desk) \n    penalty_collision = -20 if (d_agent_ticket_desk < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: It must avoid colliding with sawdust pit. Assumptions: The states of the drone, goal and the sawdust pit's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_pit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pit = calculate_distance_min(s_agent, s_pit) \n    penalty_collision = -20 if (d_agent_pit < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: It must avoid colliding with Circus's incurtain entrance plants, backanimal cage room and cage gate. Assumptions: The Agent's state, goal's state, incurtain entrance plants, backanimal cage room and cage gate's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: Detect audience bench, fire ring and ticket desk and do not collide. Assumptions: The states of the drone, goal, audience bench, fire ring and ticket desk state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Circus. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with concrete columns or editor desks and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacle_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with box and arrive at goal. Information about the agent’s state, its goal, the box's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -15 if (d_agent_box < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with table and arrive at goal. Information about the agent’s state, its goal, the table's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with three news desks and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacle_min < ob_threshold) else 8 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with coffee machine and arrive at goal. Information about the agent’s state, its goal, the coffee machine's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_machine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_machine = calculate_distance_min(s_agent, s_coffee_machine) \n    penalty_collision = -15 if (d_agent_coffee_machine < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with news desk and arrive at goal. Information about the agent’s state, its goal, the news desk's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_news_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_news_desk = calculate_distance_min(s_agent, s_news_desk) \n    penalty_collision = -15 if (d_agent_news_desk < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with background and arrive at goal. Information about the agent’s state, its goal, the background's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_background, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_background = calculate_distance_min(s_agent, s_background) \n    penalty_collision = -15 if (d_agent_background < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with microphone stand and arrive at goal. Information about the agent’s state, its goal, the microphone stand's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_microphone_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone_stand = calculate_distance_min(s_agent, s_microphone_stand) \n    penalty_collision = -15 if (d_agent_microphone_stand < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with journalist and arrive at goal. Information about the agent’s state, its goal, the journalist is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_journalist, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_journalist = calculate_distance_min(s_agent, s_journalist) \n    penalty_collision = -15 if (d_agent_journalist < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with archive shelf, anchor and camera and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle: archive shelf, anchor and camera is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with microphone stand, staff and computers and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle: microphone stand, staff and computers is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with news box and arrive at goal. Information about the agent’s state, its goal, the news box's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty = -15 if (d_agent_box < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with rig and arrive at goal. Information about the agent’s state, its goal, the rig's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_rig, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rig = calculate_distance_min(s_agent, s_rig) \n    penalty = -15 if (d_agent_rig < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with microphone stand, reception desk and play sign and arrive at goal. Information about the agent’s state, its goal, the multiple obstacle: microphone stand, reception desk and play sign is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with sliding partition and editor desks and arrive at goal. Information about the agent’s state, its goal, the many obstacle: sliding partition and editor desks is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with reception desk and arrive at goal. Information about the agent’s state, its goal, the reception desk is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_reception_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_desk = calculate_distance_min(s_agent, s_reception_desk) \n    penalty_collision = -15 if (d_agent_ticket_desk < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with printer and arrive at goal. Information about the agent’s state, its goal, the printer's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_printer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_printer = calculate_distance_min(s_agent, s_printer) \n    penalty_collision = -15 if (d_agent_printer < ob_threshold) else 8 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with in glass door plants, backanimal cage room and sliding partition and arrive at goal. Information about the agent’s state, its goal, the many obstacle:in glass door plants, backanimal cage room and sliding partition is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom while avoiding collisions with staff bench, camera tripod and reception desk and arrive at goal. Information about the agent’s state, its goal, the many obstacle: staff bench, camera tripod and reception desk is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 8 \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the newsroom and arrive at goal. Information about the agent’s state, its goal. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with concrete columns or scoring desks and need to land on goal. Information about the agents state, its goal, the concrete columns or scoring desks's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacle_min < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and do not bump system. Information about the agents state and its goal and sytsem's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_system, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_system = calculate_distance_min(s_agent, s_system) \n    penalty_collision = -22 if (d_agent_system < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with locker and need to land on goal. Information about the agents state, its goal, the locker's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_locker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_locker = calculate_distance_min(s_agent, s_locker) \n    penalty_collision = -22 if (d_agent_locker < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and do not collide table. Information about the agents state, table's state and its goal is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -22 if (d_agent_table < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with it and need to land on goal and avoid three shoe counter. Information about the agents state, its goal, the multiple shoe counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacle_min < ob_threshold) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and do not to bump snack bar. Information about the agents state and its goal, and snack bar's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_snack_bar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snack_bar = calculate_distance_min(s_agent, s_snack_bar) \n    penalty_collision = -22 if (d_agent_snack_bar < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with shoe counter and need to land on goal. Information about the agents state, its goal, the shoe counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_shoe_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shoe_counter = calculate_distance_min(s_agent, s_shoe_counter) \n    penalty_collision = -22 if (d_agent_shoe_counter < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal and avoid collision wall. Information about the agents state and its goal, wall's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -22 if (d_agent_wall < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with Detect ball polisher and do not hitting with ball polisher and need to land on goal. Information about the agents state, its goal, the Detect ball polisher and do not hitting with ball polisher's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball_polisher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball_polisher = calculate_distance_min(s_agent, s_ball_polisher) \n    penalty_collision = -22 if (d_agent_ball_polisher < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with bowler and need to land on goal. Information about the agents state, its goal, the bowler's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_bowler, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bowler = calculate_distance_min(s_agent, s_bowler) \n    penalty_collision = -22 if (d_agent_bowler < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal. Avoid collision with ball rack, customers and pinsetter machine. Information about the agents state and its goal, multiple obstacle's state is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacles_min < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with ball polisher, scoreboard and clown and need to land on goal. Information about the agents state, its goal, the ball polisher, scoreboard and clown's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacles_min < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with locker and need to land on goal. Information about the agents state, its goal, the locker's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_locker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_locker = calculate_distance_min(s_agent, s_locker) \n    penalty = -22 if (d_agent_locker < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with overhead lights and need to land on goal. Information about the agents state, its goal, the overhead lights's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_light = calculate_distance_min(s_agent, s_light) \n    penalty = -22 if (d_agent_light < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with ball polisher, ticket counter and play sign and need to land on goal. Information about the agents state, its goal, the ball polisher, ticket counter and play sign's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacles_min < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with lane divider and scoring desks and need to land on goal. Information about the agents state, its goal, the lane divider and scoring desks's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacles_min < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with ticket counter and need to land on goal. Information about the agents state, its goal, the ticket counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_ticket_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_counter = calculate_distance_min(s_agent, s_ticket_counter) \n    penalty_collision = -22 if (d_agent_ticket_counter < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with scoreboard and need to land on goal. Information about the agents state, its goal, the scoreboard's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -22 if (d_agent_scoreboard < ob_threshold) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with Bowling Alley's inentrance door plants, backanimal cage room and lane divider and need to land on goal. Information about the agents state, its goal, the multiple obstacle: Bowling Alley's inentrance door plants, backanimal cage room and lane divider's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacles_min < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley while avoiding collisions with player bench, ball return system and ticket counter and need to land on goal. Information about the agents state, its goal, the multiple obstacle: the player bench, ball return system and ticket counter's information is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -22 if (d_agent_multiple_obstacles_min < ob_threshold) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates through the Bowling alley and need to land on goal. Information about the agents state and its goal is available. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 28 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense concrete columns or scribe desks and avoid obstacle. With the states of the agent and the multiple obstcales: concrete columns or scribe desks available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense drawbridge and avoid obstacle. With the states of both the agent and the drawbridge available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_drawbridge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drawbridge = calculate_distance_min(s_agent, s_drawbridge) \n    penalty_collision = -20 if (d_agent_drawbridge < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense gatehouse and avoid obstacle. With the states of both the agent and the gatehouse available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_gatehouse, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gatehouse = calculate_distance_min(s_agent, s_gatehouse) \n    penalty_collision = -20 if (d_agent_gatehouse < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense table and avoid obstacle. With the states of both the agent and the table available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -20 if (d_agent_table < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense three armory counters and avoid obstacle. With the states of both the agent and the multiple armory counters available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense banquet table and avoid obstacle. With the states of both the agent and the banquet table available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_banquet_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banquet_table = calculate_distance_min(s_agent, s_banquet_table) \n    penalty_collision = -20 if (d_agent_banquet_table < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense sword and avoid obstacle. With the states of both the agent and the sword available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_sword, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sword = calculate_distance_min(s_agent, s_sword) \n    penalty_collision = -20 if (d_agent_sword < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense stone wall and avoid obstacle. With the states of both the agent and the stone wall available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_stone_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone_wall = calculate_distance_min(s_agent, s_stone_wall) \n    penalty_collision = -20 if (d_agent_stone_wall < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense armor stand and avoid obstacle. With the states of both the agent and the armor stand available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_armor_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_armor_stand = calculate_distance_min(s_agent, s_armor_stand) \n    penalty_collision = -20 if (d_agent_armor_stand < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense avoid knight and obstacle. With the states of both the agent and the knight available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_knight, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_knight = calculate_distance_min(s_agent, s_knight) \n    penalty_collision = -20 if (d_agent_knight < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense armor stand and computers and avoid obstacle. With the states of both the agent and the multiple obstacle: armor stand and computers available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense golden chalice and armor stand and avoid obstacle. With the states of both the agent and the golden chalice and armor stand available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense gatehouse and avoid obstacle. With the states of both the agent and the gatehouse available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_gatehouse, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gatehouse = calculate_distance_min(s_agent, s_gatehouse) \n    penalty = -20 if (d_agent_gatehouse < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense torch stand and avoid obstacle. With the states of both the agent and the torch stand available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_torch_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_torch_stand = calculate_distance_min(s_agent, s_torch_stand) \n    penalty = -20 if (d_agent_torch_stand < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense light and avoid obstacles. With the states of both the agent and the light available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense light and avoid obstacles. With the states of both the agent and the light available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense surtian and avoid obstacles. With the states of both the agent and the curtain available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -20 if (d_agent_curtain < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense banner and avoid obstacles. With the states of both the agent and the banner available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_banner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banner = calculate_distance_min(s_agent, s_banner) \n    penalty_collision = -20 if (d_agent_banner < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense Castle's incastle gate plants, backanimal cage room and stone wall divider and avoid obstacles. With the states of both the agent and the multiple obstacle:Castle's incastle gate plants, backanimal cage room and stone wall divider available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to sense light and wall and avoid obstacles. With the states of both the agent and the light and wall available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -math.log(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is moving through a castle. Its mission is to to reach goal. With the states of both the agent and the goal available, create a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal*2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along shop. \n Objectives: It must avoid colliding with concrete columns or cashier desks. \n Conditions: The states of the agent, goal, the columns and the cashier desks are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy shop. \n Objectives: Detect automatic sliding door and aviod it. \n Conditions: The states of the agent, goal, the automatic sliding door are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_automatic_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_automatic_sliding door = calculate_distance_min(s_agent, s_automatic_door) \n    penalty_collision = -25 if (d_agent_automatic_sliding_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating shop open workshopperce. Objectives: It must avoid colliding with security gate. Conditions: States of the drone and the security gate are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_security_gate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_gate = calculate_distance_min(s_agent, s_security_gate) \n    penalty_collision = -25 if (d_agent_security_gate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a supermarket aisle, the drone must maneuver around cashier desk. All entity states (agent, goal, cashier desk) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -25 if (d_agent_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a supermarket aisle. Requirement: Detect the three checkout counters and do not collide with it. Given: The states for the drone and many checkout counters are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a shop. \n Objectives: So not collide with promo desk. \n Conditions: The states of the agent, goal, the promo desk are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_promo_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_promo_desk = calculate_distance_min(s_agent, s_promo_desk) \n    penalty_collision = -25 if (d_agent_promo_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate shop. Objectives: Do not collide hit with the clothing rack. Conditions: States of the agent, clothing rack are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_clothing_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clothing_rack = calculate_distance_min(s_agent, s_clothing_rack) \n    penalty_collision = -25 if (d_agent_clothing_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a supermarket aisle, the drone must steer clear of wall. All states (agent, goal, glass partition) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_glass_partition, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_partition = calculate_distance_min(s_agent, s_glass_partition) \n    penalty_collision = -25 if (d_agent_glass_partition < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: checkout area. Avoid: Detect mannequin and do not hitting with mannequin. Known: Agent, goal, mannequin states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_mannequin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mannequin = calculate_distance_min(s_agent, s_mannequin) \n    penalty_collision = -25 if (d_agent_mannequin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating shop. Objectives: It must avoid colliding with shopper. Conditions: The states of the drone, goal and shopper are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shopper, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shopper = calculate_distance_min(s_agent, s_shopper) \n    penalty_collision = -25 if (d_agent_shopper < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through shop. Objectives: Avoid collision with product rack, customers and freight elevator platform. Conditions: The states of the agent, goal, product rack, customers and freight elevator platform are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating shop. Objectives: It must avoid colliding with any mannequin, wa and computers. Conditions: Agent's, goal's mannequin, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through shop. Objectives: Do not collide with security gate. Conditions: The states of the drone, goal and the security gate are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_security_gate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_gate = calculate_distance_min(s_agent, s_security_gate) \n    penalty = -25 if (d_agent_security_gate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along shop and must avoid contact with the signage stand. The states of the drone, goal and the signage stand are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_signage_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signage_stand = calculate_distance_min(s_agent, s_signage_stand) \n    penalty = -25 if (d_agent_signage_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in shop. It must avoid colliding with the mannequin, automatic sliding doors and security shutters. The states of the agent, goal, potted plants near entrance, automatic sliding doors and security shutters are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in shop. It must avoid colliding with the glass display item and mannequin. The states of the drone, goal and the glass display item and mannequin are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in shop. It must avoid colliding with the PVC strip curtain. Agent's state, goal's state and PVC strip curtain's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -25 if (d_agent_curtain < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: It must avoid colliding with cloth. Assumptions: The states of the drone, goal and the cloth's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_cloth, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cloth = calculate_distance_min(s_agent, s_cloth) \n    penalty_collision = -25 if (d_agent_cloth < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: It must avoid colliding with shop's potted plants near entrance, back stockroom area and glass divider. Assumptions: The Agent's state, goal's state, potted plants near entrance, back stockroom area and glass divider's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: Detect wooden bench, automatic sliding door and security gate and do not collide. Assumptions: The states of the drone, goal, wooden bench, automatic sliding door and security gate state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is inspecting in festival. \n Objectives:  It must avoid colliding with the festival banner. \n Conditions: Agent's state, goal's state and festival banner's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_banner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banner = calculate_distance_min(s_agent, s_banner) \n    penalty_collision = -25 if (d_agent_banner < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is inspecting in festival. \n Objectives:  It must avoid colliding with the tent curtain. \n Conditions: Agent's state, goal's state and tent curtain's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -25 if (d_agent_curtain < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying in festival. \n Objectives:  It must avoid colliding with the souvenir stand. \n Conditions: Agent's state, goal's state and souvenir stand's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_souvenir_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_souvenir_stand = calculate_distance_min(s_agent, s_souvenir_stand) \n    penalty_collision = -25 if (d_agent_souvenir_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is moving in festival. \n Objectives:  It must avoid colliding with the game booth. \n Conditions: Agent's state, goal's state and game booth's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_game_booth, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_game_booth = calculate_distance_min(s_agent, s_game_booth) \n    penalty_collision = -25 if (d_agent_game_booth < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is inspecting in festival. \n Objectives:  It must avoid colliding with the signpost. \n Conditions: Agent's state, goal's state and signpost's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_signpost, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signpost = calculate_distance_min(s_agent, s_signpost) \n    penalty_collision = -25 if (d_agent_signpost < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is moving in festival. \n Objectives:  It must avoid colliding with the parade float. \n Conditions: Agent's state, goal's state and parade float's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_parade_float, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_parade_float = calculate_distance_min(s_agent, s_parade_float) \n    penalty_collision = -25 if (d_agent_parade_float < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is inspecting in festival. \n Objectives:  It must avoid colliding with the food stall. \n Conditions: Agent's state, goal's state and food stall's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_food_stall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_food_stall = calculate_distance_min(s_agent, s_food_stall) \n    penalty_collision = -25 if (d_agent_food_stall < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is moving in festival. \n Objectives:  It must avoid colliding with the wooden fence. \n Conditions: Agent's state, goal's state and wooden fence's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wooden_fence, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wooden_fence = calculate_distance_min(s_agent, s_wooden_fence) \n    penalty_collision = -25 if (d_agent_wooden_fence < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is inspecting in festival. \n Objectives:  It must avoid colliding with the rope divider. \n Conditions: Agent's state, goal's state and rope divider's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rope_divider, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope_divider = calculate_distance_min(s_agent, s_rope_divider) \n    penalty_collision = -25 if (d_agent_rope_divider < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is inspecting in festival. \n Objectives:  It must avoid colliding with the festival lantern. \n Conditions: Agent's state, goal's state and festival lantern's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lantern, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lantern = calculate_distance_min(s_agent, s_lantern) \n    penalty_collision = -25 if (d_agent_lantern < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying in festival. \n Objectives:  It must avoid colliding with the performer. \n Conditions: Agent's state, goal's state and performer's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_performer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_performer = calculate_distance_min(s_agent, s_performer) \n    penalty_collision = -25 if (d_agent_performer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is moving in festival. \n Objectives:  It must avoid colliding with the festival archway. \n Conditions: Agent's state, goal's state and festival archway's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_archway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_archway = calculate_distance_min(s_agent, s_archway) \n    penalty_collision = -25 if (d_agent_archway < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying in festival. \n Objectives:  It must avoid colliding with the stage light. \n Conditions: Agent's state, goal's state and stage light's state are avaialable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stage_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stage_light = calculate_distance_min(s_agent, s_stage_light) \n    penalty_collision = -25 if (d_agent_stage_light < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is inspecting in festival. \n Objectives:  It must avoid colliding with the tent pole. \n Conditions: Agent's state, goal's state and tent pole's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tent_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tent_pole = calculate_distance_min(s_agent, s_tent_pole) \n    penalty_collision = -25 if (d_agent_tent_pole < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is inspecting in festival. \n Objectives:  It must avoid colliding with the crowd barrier. \n Conditions: Agent's state, goal's state and crowd barrier's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_crowd_barrier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crowd_barrier = calculate_distance_min(s_agent, s_crowd_barrier) \n    penalty_collision = -25 if (d_agent_crowd_barrier < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is moving in festival. \n Objectives:  It must avoid colliding with the decorative arch plants. \n Conditions: Agent's state, goal's state and decorative arch plants's state are avaialable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_arch_plants, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_arch_plants = calculate_distance_min(s_agent, s_arch_plants) \n    penalty_collision = -25 if (d_agent_arch_plants < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is inspecting in festival. \n Objectives:  It must avoid colliding with the stage platform. \n Conditions: Agent's state, goal's state and stage platform's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stage_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stage_platform = calculate_distance_min(s_agent, s_stage_platform) \n    penalty_collision = -25 if (d_agent_stage_platform < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is inspecting in festival. \n Objectives:  It must avoid colliding with the festival-goer. \n Conditions: Agent's state, goal's state and festival-goer's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_festival_goer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_festival_goer = calculate_distance_min(s_agent, s_festival_goer) \n    penalty_collision = -25 if (d_agent_festival_goer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying in festival. \n Objectives:  It must avoid colliding with the ticket counter. \n Conditions: Agent's state, goal's state and ticket counter's state are avaialable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ticket_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_counter = calculate_distance_min(s_agent, s_ticket_counter) \n    penalty_collision = -25 if (d_agent_ticket_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is inspecting in festival. \n Objectives:  It must avoid colliding with the music speaker. \n Conditions: Agent's state, goal's state and music speaker's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -25 if (d_agent_speaker < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is moving in festival. \n Objectives:  It must avoid colliding with the drum set. \n Conditions: Agent's state, goal's state and drum set's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drum_set, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drum_set = calculate_distance_min(s_agent, s_drum_set) \n    penalty_collision = -25 if (d_agent_drum_set < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in restaurant. It must avoid colliding with the dining table. Agent's state, goal's state and dining table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -25 if (d_agent_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in restaurant. It must avoid colliding with the waiter. Agent's state, goal's state and waiter's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_waiter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_waiter = calculate_distance_min(s_agent, s_waiter) \n    penalty_collision = -25 if (d_agent_waiter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in restaurant. It must avoid colliding with the kitchen counter. Agent's state, goal's state and kitchen counter's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kitchen_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kitchen_counter = calculate_distance_min(s_agent, s_kitchen_counter) \n    penalty_collision = -25 if (d_agent_kitchen_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's dining table, waiter and serving cart. Assumptions: The Agent's state, goal's state and the states of the drone, goal, dining table, waiter, and serving cart are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's kitchen counter and swinging door. Assumptions: The Agent's state, goal's state and the states of the drone, goal, kitchen counter, and swinging door are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in restaurant. It must avoid colliding with the waiter. Agent's state, goal's state and waiter's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_waiter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_waiter = calculate_distance_min(s_agent, s_waiter) \n    penalty_collision = -25 if (d_agent_waiter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's bar counter and high stool. Assumptions: The Agent's state, goal's state and the states of the drone, goal, bar counter, and high stool are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's glass partition and potted plant. Assumptions: The Agent's state, goal's state and the states of the drone, goal, glass partition, and potted plant are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's chair, tray return station and trash bin. Assumptions: The Agent's state, goal's state and the states of the drone, goal, chair, tray return station, and trash bin are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's salad bar and beverage dispenser. Assumptions: The Agent's state, goal's state and the states of the drone, goal, salad bar, and beverage dispenser are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in restaurant. It must avoid colliding with the customer. Agent's state, goal's state and customer's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -25 if (d_agent_customer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's coat rack and umbrella stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal, coat rack, and umbrella stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's customer, baby high chair and stroller parking. Assumptions: The Agent's state, goal's state and the states of the drone, goal, customer, baby high chair, and stroller parking are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's heat lamp stand and service pass window. Assumptions: The Agent's state, goal's state and the states of the drone, goal, heat lamp stand, and service pass window are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in restaurant. It must avoid colliding with the food trolley. Agent's state, goal's state and food trolley's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_food_trolley, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_food_trolley = calculate_distance_min(s_agent, s_food_trolley) \n    penalty_collision = -25 if (d_agent_food_trolley < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in restaurant. It must avoid colliding with the chair. Agent's state, goal's state and chair's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -25 if (d_agent_chair < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's sauce station and napkin holder. Assumptions: The Agent's state, goal's state and the states of the drone, goal, sauce station, and napkin holder are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's wine shelf, bottle display and bar sink. Assumptions: The Agent's state, goal's state and the states of the drone, goal, wine shelf, bottle display, and bar sink are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's ice machine and water cooler. Assumptions: The Agent's state, goal's state and the states of the drone, goal, ice machine, and water cooler are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's soup kettle and bread warmer. Assumptions: The Agent's state, goal's state and the states of the drone, goal, soup kettle, and bread warmer are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's bus tub cart, chandelier and dirty dish rack. Assumptions: The Agent's state, goal's state and the states of the drone, goal, bus tub cart, chandelier and dirty dish rack are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's ceiling fan and chandelier. Assumptions: The Agent's state, goal's state and the states of the drone, goal, ceiling fan, and chandelier are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's table divider screen and privacy curtain. Assumptions: The Agent's state, goal's state and the states of the drone, goal, table divider screen, and privacy curtain are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's POS terminal stand, poster stand and receipt printer. Assumptions: The Agent's state, goal's state and the states of the drone, goal, POS terminal stand, poster stand and receipt printer are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's hand sanitizer stand and poster stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal, hand sanitizer stand, and poster stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Restaurant. Goal: It must avoid colliding with Restaurant's emergency exit door, crowd control stanchion and signboard. Assumptions: The Agent's state, goal's state and the states of the drone, goal, emergency exit door, crowd control stanchion, and signboard are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the office. It must avoid colliding with the rolling chair. Agent's state, goal's state and rolling chair's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rolling_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rolling_chair = calculate_distance_min(s_agent, s_rolling_chair) \n    penalty_collision = -25 if (d_agent_rolling_chair < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the office. It must avoid colliding with the paper shredder. Agent's state, goal's state and paper shredder's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_paper_shredder, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paper_shredder = calculate_distance_min(s_agent, s_paper_shredder) \n    penalty_collision = -25 if (d_agent_paper_shredder < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Office. Goal: It must avoid colliding with Office's cubicle wall, rolling chair and glass partition. Assumptions: The Agent's state, goal's state and the states of the drone, goal, cubicle wall, rolling chair, and glass partition are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Office. Goal: It must avoid colliding with Office's printer station and paper shredder. Assumptions: The Agent's state, goal's state and the states of the drone, goal, printer station, and paper shredder are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the office. It must avoid colliding with the umbrella stand. Agent's state, goal's state and umbrella stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_umbrella_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_umbrella_stand = calculate_distance_min(s_agent, s_umbrella_stand) \n    penalty_collision = -25 if (d_agent_umbrella_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Office. Goal: It must avoid colliding with Office's conference table, projector screen and ceiling light. Assumptions: The Agent's state, goal's state and the states of the drone, goal, conference table, projector screen, and ceiling light are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Office. Goal: It must avoid colliding with Office's floor cable tray and power strip. Assumptions: The Agent's state, goal's state and the states of the drone, goal, floor cable tray, and power strip are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Office. Goal: It must avoid colliding with Office's coat rack and umbrella stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal, coat rack, and umbrella stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Office. Goal: It must avoid colliding with Office's potted plant and water cooler. Assumptions: The Agent's state, goal's state and the states of the drone, goal, potted plant, and water cooler are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Office. Goal: It must avoid colliding with Office's filing cabinet and open drawer. Assumptions: The Agent's state, goal's state and the states of the drone, goal, filing cabinet, and open drawer are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the office. It must avoid colliding with the whiteboard on wheels. Agent's state, goal's state and whiteboard's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -25 if (d_agent_whiteboard < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the office. It must avoid colliding with the recycling bin. Agent's state, goal's state and recycling bin's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_recycling_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_recycling_bin = calculate_distance_min(s_agent, s_recycling_bin) \n    penalty_collision = -25 if (d_agent_recycling_bin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Office. Goal: It must avoid colliding with Office's server rack and network cable bundle. Assumptions: The Agent's state, goal's state and the states of the drone, goal, server rack, and network cable bundle are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Office. Goal: It must avoid colliding with Office's sliding door and door closer arm. Assumptions: The Agent's state, goal's state and the states of the drone, goal, sliding door, and door closer arm are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Office. Goal: It must avoid colliding with Office's elevator, lobby pillar and queue stanchion. Assumptions: The Agent's state, goal's state and the states of the drone, goal, elevator lobby pillar, and queue stanchion are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Office. Goal: It must avoid colliding with Office's whiteboard on wheels, network cable bundle and marker stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal, whiteboard, network cable bundle and marker stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Office. Goal: It must avoid colliding with Office's recycling bin, trash bin and cardboard box stack. Assumptions: The Agent's state, goal's state and the states of the drone, goal, recycling bin, trash bin, and cardboard box stack are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Office. Goal: It must avoid colliding with Office's stairwell handrail, whiteboard and wet floor sign. Assumptions: The Agent's state, goal's state and the states of the drone, goal, stairwell handrail, whiteboard and wet floor sign are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Office. Goal: It must avoid colliding with Office's hand sanitizer stand and poster stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal, hand sanitizer stand, and poster stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Office. Goal: It must avoid colliding with Office's standing desk and monitor arm. Assumptions: The Agent's state, goal's state and the states of the drone, goal, standing desk, and monitor arm are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Office. Goal: It must avoid colliding with Office's bookshelf, whiteboard and step ladder. Assumptions: The Agent's state, goal's state and the states of the drone, goal, bookshelf, whiteboard and step ladder are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Office. Goal: It must avoid colliding with Office's meeting pod wall and acoustic panel. Assumptions: The Agent's state, goal's state and the states of the drone, goal, meeting pod wall, and acoustic panel are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Office. Goal: It must avoid colliding with Office's coffee cart and milk crate. Assumptions: The Agent's state, goal's state and the states of the drone, goal, coffee cart, and milk crate are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Office. Goal: It must avoid colliding with Office's mail cart and parcel trolley. Assumptions: The Agent's state, goal's state and the states of the drone, goal, mail cart, and parcel trolley are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Office. Goal: It must avoid colliding with Office's floor outlet cover, cable management pole and rug edge. Assumptions: The Agent's state, goal's state and the states of the drone, goal, floor outlet cover, cable management pole, and rug edge are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the park bench. Agent's state, goal's state and park bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_park_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_park_bench = calculate_distance_min(s_agent, s_park_bench) \n    penalty_collision = -25 if (d_agent_park_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the trash can. Agent's state, goal's state and trash can's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_can, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_can) \n    penalty_collision = -25 if (d_agent_trash_can < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's  tree, park bench and glass partition. Assumptions: The Agent's state, goal's state and the states of the drone, goal, tree, park bench, and glass partition are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's bush and trash can. Assumptions: The Agent's state, goal's state and the states of the drone, goal, bush, and trash can are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the lamp post. Agent's state, goal's state and lamp post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lamp_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp_post = calculate_distance_min(s_agent, s_lamp_post) \n    penalty_collision = -25 if (d_agent_lamp_post < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's picknick table, lamp post and human. Assumptions: The Agent's state, goal's state and the states of the drone, goal, picknick table, lamp post, and human are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's visitor and slide. Assumptions: The Agent's state, goal's state and the states of the drone, goal, visitor, and slide are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's swing and lamp post. Assumptions: The Agent's state, goal's state and the states of the drone, goal, swing, and lamp post are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's apple tree and water cooler. Assumptions: The Agent's state, goal's state and the states of the drone, goal, apple tree, and water cooler are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's scooter and fountain. Assumptions: The Agent's state, goal's state and the states of the drone, goal, scooter, and fountain are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the information board. Agent's state, goal's state and information board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_information_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_information_board = calculate_distance_min(s_agent, s_information_board) \n    penalty_collision = -25 if (d_agent_information_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the picnic table. Agent's state, goal's state and picnic table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_picnic_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_picnic_table = calculate_distance_min(s_agent, s_picnic_table) \n    penalty_collision = -25 if (d_agent_picnic_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's scooter and bicycle. Assumptions: The Agent's state, goal's state and the states of the drone, goal, server rack, and bicycle are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's trash bin and fence. Assumptions: The Agent's state, goal's state and the states of the drone, goal, trash bin, and fence are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's fence, fountain and tree. Assumptions: The Agent's state, goal's state and the states of the drone, goal, fence fountain, and tree are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's information board, bicycle and railing. Assumptions: The Agent's state, goal's state and the states of the drone, goal, information board, bicycle and railing are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's picnic table, trash bin and children. Assumptions: The Agent's state, goal's state and the states of the drone, goal, picnic table, trash bin, and children are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's stairwell handrail, information board and signs. Assumptions: The Agent's state, goal's state and the states of the drone, goal, stairwell handrail, information board and signs are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's wheelchair and poster stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal, wheelchair, and poster stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's standing table and monkey bar. Assumptions: The Agent's state, goal's state and the states of the drone, goal, standing table, and monkey bar are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's monkey bar, information board and step ladder. Assumptions: The Agent's state, goal's state and the states of the drone, goal, monkey bar, information board and step ladder are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's meeting pod wall and steam. Assumptions: The Agent's state, goal's state and the states of the drone, goal, meeting pod wall, and steam are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's coffee cart and food truck. Assumptions: The Agent's state, goal's state and the states of the drone, goal, coffee cart, and food truck are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's food truck and vehicle. Assumptions: The Agent's state, goal's state and the states of the drone, goal, food truck, and vehicle are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's vehicle, rope and bridge. Assumptions: The Agent's state, goal's state and the states of the drone, goal, vehicle, cable management pole, and bridge are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along shop. \n Objectives: It must avoid colliding with concrete columns or cashier desks. \n Conditions: The states of the agent, goal, the columns and the cashier desks are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy shop. \n Objectives: Detect automatic sliding door and aviod it. \n Conditions: The states of the agent, goal, the automatic sliding door are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_automatic_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_automatic_sliding door = calculate_distance_min(s_agent, s_automatic_door) \n    penalty_collision = -25 if (d_agent_automatic_sliding_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating shop open workshopperce. Objectives: It must avoid colliding with security gate. Conditions: States of the drone and the security gate are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_security_gate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_gate = calculate_distance_min(s_agent, s_security_gate) \n    penalty_collision = -25 if (d_agent_security_gate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a supermarket aisle, the drone must maneuver around cashier desk. All entity states (agent, goal, cashier desk) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -25 if (d_agent_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a supermarket aisle. Requirement: Detect the three checkout counters and do not collide with it. Given: The states for the drone and many checkout counters are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a shop. \n Objectives: So not collide with promo desk. \n Conditions: The states of the agent, goal, the promo desk are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_promo_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_promo_desk = calculate_distance_min(s_agent, s_promo_desk) \n    penalty_collision = -25 if (d_agent_promo_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate shop. Objectives: Do not collide hit with the clothing rack. Conditions: States of the agent, clothing rack are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_clothing_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clothing_rack = calculate_distance_min(s_agent, s_clothing_rack) \n    penalty_collision = -25 if (d_agent_clothing_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a supermarket aisle, the drone must steer clear of wall. All states (agent, goal, glass partition) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_glass_partition, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_partition = calculate_distance_min(s_agent, s_glass_partition) \n    penalty_collision = -25 if (d_agent_glass_partition < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: checkout area. Avoid: Detect mannequin and do not hitting with mannequin. Known: Agent, goal, mannequin states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_mannequin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mannequin = calculate_distance_min(s_agent, s_mannequin) \n    penalty_collision = -25 if (d_agent_mannequin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating shop. Objectives: It must avoid colliding with shopper. Conditions: The states of the drone, goal and shopper are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shopper, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shopper = calculate_distance_min(s_agent, s_shopper) \n    penalty_collision = -25 if (d_agent_shopper < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through shop. Objectives: Avoid collision with product rack, customers and freight elevator platform. Conditions: The states of the agent, goal, product rack, customers and freight elevator platform are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating shop. Objectives: It must avoid colliding with any mannequin, wa and computers. Conditions: Agent's, goal's mannequin, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through shop. Objectives: Do not collide with security gate. Conditions: The states of the drone, goal and the security gate are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_security_gate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_gate = calculate_distance_min(s_agent, s_security_gate) \n    penalty = -25 if (d_agent_security_gate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along shop and must avoid contact with the signage stand. The states of the drone, goal and the signage stand are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_signage_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signage_stand = calculate_distance_min(s_agent, s_signage_stand) \n    penalty = -25 if (d_agent_signage_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in shop. It must avoid colliding with the mannequin, automatic sliding doors and security shutters. The states of the agent, goal, potted plants near entrance, automatic sliding doors and security shutters are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in shop. It must avoid colliding with the glass display item and mannequin. The states of the drone, goal and the glass display item and mannequin are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in shop. It must avoid colliding with the PVC strip curtain. Agent's state, goal's state and PVC strip curtain's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -25 if (d_agent_curtain < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: It must avoid colliding with cloth. Assumptions: The states of the drone, goal and the cloth's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_cloth, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cloth = calculate_distance_min(s_agent, s_cloth) \n    penalty_collision = -25 if (d_agent_cloth < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: It must avoid colliding with shop's potted plants near entrance, back stockroom area and glass divider. Assumptions: The Agent's state, goal's state, potted plants near entrance, back stockroom area and glass divider's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: Detect wooden bench, automatic sliding door and security gate and do not collide. Assumptions: The states of the drone, goal, wooden bench, automatic sliding door and security gate state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with festival banner. The information of the drone, the goal, and festival banner are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_banner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banner = calculate_distance_min(s_agent, s_banner) \n    penalty_collision = -25 if (d_agent_banner < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with tent curtain. The information of the drone, the goal, and tent curtain are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -25 if (d_agent_curtain < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with souvenir stand. The information of the drone, the goal, and souvenir stand are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_souvenir_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_souvenir_stand = calculate_distance_min(s_agent, s_souvenir_stand) \n    penalty_collision = -25 if (d_agent_souvenir_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with game booth. The information of the drone, the goal, and game booth are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_game_booth, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_game_booth = calculate_distance_min(s_agent, s_game_booth) \n    penalty_collision = -25 if (d_agent_game_booth < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with signpost. The information of the drone, the goal, and signpost are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_signpost, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signpost = calculate_distance_min(s_agent, s_signpost) \n    penalty_collision = -25 if (d_agent_signpost < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with parade float. The information of the drone, the goal, and parade float are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_parade_float, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_parade_float = calculate_distance_min(s_agent, s_parade_float) \n    penalty_collision = -25 if (d_agent_parade_float < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with food stall. The information of the drone, the goal, and food stall are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_food_stall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_food_stall = calculate_distance_min(s_agent, s_food_stall) \n    penalty_collision = -25 if (d_agent_food_stall < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with wooden fence. The information of the drone, the goal, and wooden fence are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_wooden_fence, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wooden_fence = calculate_distance_min(s_agent, s_wooden_fence) \n    penalty_collision = -25 if (d_agent_wooden_fence < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with rope divider. The information of the drone, the goal, and rope divider are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_rope_divider, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope_divider = calculate_distance_min(s_agent, s_rope_divider) \n    penalty_collision = -25 if (d_agent_rope_divider < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with festival lantern. The information of the drone, the goal, and festival lantern are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_lantern, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lantern = calculate_distance_min(s_agent, s_lantern) \n    penalty_collision = -25 if (d_agent_lantern < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with performer. The information of the drone, the goal, and performer are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_performer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_performer = calculate_distance_min(s_agent, s_performer) \n    penalty_collision = -25 if (d_agent_performer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with festival archway. The information of the drone, the goal, and festival archway are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_archway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_archway = calculate_distance_min(s_agent, s_archway) \n    penalty_collision = -25 if (d_agent_archway < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with stage light. The information of the drone, the goal, and stage light are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_stage_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stage_light = calculate_distance_min(s_agent, s_stage_light) \n    penalty_collision = -25 if (d_agent_stage_light < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with tent pole. The information of the drone, the goal, and tent pole are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_tent_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tent_pole = calculate_distance_min(s_agent, s_tent_pole) \n    penalty_collision = -25 if (d_agent_tent_pole < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with crowd barrier. The information of the drone, the goal, and crowd barrier are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_crowd_barrier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crowd_barrier = calculate_distance_min(s_agent, s_crowd_barrier) \n    penalty_collision = -25 if (d_agent_crowd_barrier < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with decorative arch plants. The information of the drone, the goal, and decorative arch plants are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_arch_plants, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_arch_plants = calculate_distance_min(s_agent, s_arch_plants) \n    penalty_collision = -25 if (d_agent_arch_plants < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with stage platform. The information of the drone, the goal, and stage platform are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_stage_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stage_platform = calculate_distance_min(s_agent, s_stage_platform) \n    penalty_collision = -25 if (d_agent_stage_platform < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with festival-goer. The information of the drone, the goal, and festival-goer are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_festival_goer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_festival_goer = calculate_distance_min(s_agent, s_festival_goer) \n    penalty_collision = -25 if (d_agent_festival_goer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with ticket counter. The information of the drone, the goal, and ticket counter are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_ticket_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_counter = calculate_distance_min(s_agent, s_ticket_counter) \n    penalty_collision = -25 if (d_agent_ticket_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with music speaker. The information of the drone, the goal, and music speaker are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -25 if (d_agent_speaker < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with drum set. The information of the drone, the goal, and drum set are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_drum_set, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drum_set = calculate_distance_min(s_agent, s_drum_set) \n    penalty_collision = -25 if (d_agent_drum_set < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with table using its own state, the table's state, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -25 if (d_agent_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with waiter using its own state, the waiter status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_waiter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_waiter = calculate_distance_min(s_agent, s_waiter) \n    penalty_collision = -25 if (d_agent_waiter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with kitchen counter using its own state, the kitchen counter status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_kitchen_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kitchen_counter = calculate_distance_min(s_agent, s_kitchen_counter) \n    penalty_collision = -25 if (d_agent_kitchen_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with Restaurant's dining table, waiter and serving cart using its own state, the multiple obstacle: Restaurant's dining table, waiter and serving cart status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with  Restaurant's kitchen counter and swinging door using its own state, the many obstacle: Restaurant's kitchen counter and swinging door status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < ob_threshold) else 10 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with snackbar using its own state, the snackbar status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_snackbar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snackbar = calculate_distance_min(s_agent, s_snackbar) \n    penalty_collision = -20 if (d_agent_snackbar < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with customer using its own state, the customer status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -20 if (d_agent_customer < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with wall using its own state, the wall status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -20 if (d_agent_wall < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with food trolley using its own state, the Detect ball polisher and food trolley status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_food_trolley, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_food_trolley = calculate_distance_min(s_agent, s_food_trolley) \n    penalty_collision = -25 if (d_agent_food_trolley < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with sauce station and napkin holder using its own state, the multiple obstacle: sauce station and napkin holder status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with shelf, bottle display and bar sink using its own state, the multiple obstacle: shelf, bottle display and bar sink status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with ice machine and water cooler using its own state, the bice machine and water cooler status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with soup kettle and bread warmer using its own state, the multiple item: soup kettle and bread warmer status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with ceiling fan and chandelier using its own state, the multiple obstacle: ceiling fan and chandelier status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with table divider screen and privacy curtain using its own state, the table divider screen and privacy curtain status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with POS terminal stand, poster stand and receipt printer using its own state, the multiple obstacle: POS terminal stand, poster stand and receipt printer status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with hand sanitizer stand and poster stand using its own state, the many obstacle: hand sanitizer stand and poster stand status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with chef using its own state, the chef status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_chef, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chef = calculate_distance_min(s_agent, s_chef) \n    penalty_collision = -20 if (d_agent_chef_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with tresor using its own state, the tresor status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_tresor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tresor_min = calculate_distance_min(s_agent, s_tresor) \n    penalty_collision = -20 if (d_agent_tresor_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with frame using its own state, the frame status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_frame, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_frame_min = calculate_distance_min(s_agent, s_frame) \n    penalty_collision = -20 if (d_agent_frame_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with chair using its own state, the chair status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (rolling chair) and reach target, and must avoid collisions by using its own state and the rolling chair’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_rolling_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rolling_chair = calculate_distance_min(s_agent, s_rolling_chair) \n    penalty_collision = -27 if (d_agent_rolling_chair < 0.6) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (paper shredder) and reach target, and must avoid collisions by using its own state and the papper shredder’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_paper_shredder, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paper_shredder = calculate_distance_min(s_agent, s_paper_shredder) \n    penalty_collision = -27 if (d_agent_paper_shredder < 0.6) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (cubicle wall, rolling chair and glass partition) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (printer station and paper shredder) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (umbrella stand) and reach target, and must avoid collisions by using its own state and the umbrella stand’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_umbrella_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_umbrella_stand = calculate_distance_min(s_agent, s_umbrella_stand) \n    penalty_collision = -27 if (d_agent_umbrella_stand < 0.6) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (conference table, projector screen and ceiling light) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (floor cable tray and power strip) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (coat rack and umbrella stand) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (potted plant and water cooler) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (filing cabinet and open drawer) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (whiteboard on wheels) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -27 if (d_agent_whiteboard < 0.6) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (recycling bin) and reach target, and must avoid collisions by using its own state and the recycling bin’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_recycling_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_recycling_bin = calculate_distance_min(s_agent, s_recycling_bin) \n    penalty_collision = -27 if (d_agent_recycling_bin < 0.6) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (server rack and network cable bundle) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (sliding door and door closer arm) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (elevator, lobby pillar and queue stanchion) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (whiteboard on wheels, network cable bundle and marker stand) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (recycling bin, trash bin and cardboard box stack) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (stairwell handrail, whiteboard and wet floor sign) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (hand sanitizer stand and poster stand) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (standing desk and monitor arm) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (bookshelf, whiteboard and step ladder) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (meeting pod wall and acoustic panel) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (coffee cart and milk crate) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (mail cart and parcel trolley) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (floor outlet cover, cable management pole and rug edge) and reach target, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the park bench. Agent's state, goal's state and park bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_park_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_park_bench = calculate_distance_min(s_agent, s_park_bench) \n    penalty_collision = -25 if (d_agent_park_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the trash can. Agent's state, goal's state and trash can's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_can, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_can) \n    penalty_collision = -25 if (d_agent_trash_can < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's  tree, park bench and glass partition. Assumptions: The Agent's state, goal's state and the states of the drone, goal, tree, park bench, and glass partition are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's bush and trash can. Assumptions: The Agent's state, goal's state and the states of the drone, goal, bush, and trash can are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the lamp post. Agent's state, goal's state and lamp post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lamp_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp_post = calculate_distance_min(s_agent, s_lamp_post) \n    penalty_collision = -25 if (d_agent_lamp_post < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's picknick table, lamp post and human. Assumptions: The Agent's state, goal's state and the states of the drone, goal, picknick table, lamp post, and human are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's visitor and slide. Assumptions: The Agent's state, goal's state and the states of the drone, goal, visitor, and slide are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's swing and lamp post. Assumptions: The Agent's state, goal's state and the states of the drone, goal, swing, and lamp post are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's apple tree and water cooler. Assumptions: The Agent's state, goal's state and the states of the drone, goal, apple tree, and water cooler are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's scooter and fountain. Assumptions: The Agent's state, goal's state and the states of the drone, goal, scooter, and fountain are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the information board. Agent's state, goal's state and information board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_information_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_information_board = calculate_distance_min(s_agent, s_information_board) \n    penalty_collision = -25 if (d_agent_information_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the picnic table. Agent's state, goal's state and picnic table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_picnic_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_picnic_table = calculate_distance_min(s_agent, s_picnic_table) \n    penalty_collision = -25 if (d_agent_picnic_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's scooter and bicycle. Assumptions: The Agent's state, goal's state and the states of the drone, goal, server rack, and bicycle are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's trash bin and fence. Assumptions: The Agent's state, goal's state and the states of the drone, goal, trash bin, and fence are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's fence, fountain and tree. Assumptions: The Agent's state, goal's state and the states of the drone, goal, fence fountain, and tree are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's information board, bicycle and railing. Assumptions: The Agent's state, goal's state and the states of the drone, goal, information board, bicycle and railing are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's picnic table, trash bin and children. Assumptions: The Agent's state, goal's state and the states of the drone, goal, picnic table, trash bin, and children are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's stairwell handrail, information board and signs. Assumptions: The Agent's state, goal's state and the states of the drone, goal, stairwell handrail, information board and signs are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's wheelchair and poster stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal, wheelchair, and poster stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's standing table and monkey bar. Assumptions: The Agent's state, goal's state and the states of the drone, goal, standing table, and monkey bar are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's monkey bar, information board and step ladder. Assumptions: The Agent's state, goal's state and the states of the drone, goal, monkey bar, information board and step ladder are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's meeting pod wall and steam. Assumptions: The Agent's state, goal's state and the states of the drone, goal, meeting pod wall, and steam are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's coffee cart and food truck. Assumptions: The Agent's state, goal's state and the states of the drone, goal, coffee cart, and food truck are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's food truck and vehicle. Assumptions: The Agent's state, goal's state and the states of the drone, goal, food truck, and vehicle are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's vehicle, rope and bridge. Assumptions: The Agent's state, goal's state and the states of the drone, goal, vehicle, cable management pole, and bridge are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along shop. \n Objectives: It must avoid colliding with concrete columns or cashier desks. \n Conditions: The states of the agent, goal, the columns and the cashier desks are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy shop. \n Objectives: Detect automatic sliding door and aviod it. \n Conditions: The states of the agent, goal, the automatic sliding door are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_automatic_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_automatic_sliding door = calculate_distance_min(s_agent, s_automatic_door) \n    penalty_collision = -25 if (d_agent_automatic_sliding_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating shop open workshopperce. Objectives: It must avoid colliding with security gate. Conditions: States of the drone and the security gate are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_security_gate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_gate = calculate_distance_min(s_agent, s_security_gate) \n    penalty_collision = -25 if (d_agent_security_gate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a supermarket aisle, the drone must maneuver around cashier desk. All entity states (agent, goal, cashier desk) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -25 if (d_agent_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a supermarket aisle. Requirement: Detect the three checkout counters and do not collide with it. Given: The states for the drone and many checkout counters are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a shop. \n Objectives: So not collide with promo desk. \n Conditions: The states of the agent, goal, the promo desk are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_promo_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_promo_desk = calculate_distance_min(s_agent, s_promo_desk) \n    penalty_collision = -25 if (d_agent_promo_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate shop. Objectives: Do not collide hit with the clothing rack. Conditions: States of the agent, clothing rack are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_clothing_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clothing_rack = calculate_distance_min(s_agent, s_clothing_rack) \n    penalty_collision = -25 if (d_agent_clothing_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a supermarket aisle, the drone must steer clear of wall. All states (agent, goal, glass partition) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_glass_partition, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_partition = calculate_distance_min(s_agent, s_glass_partition) \n    penalty_collision = -25 if (d_agent_glass_partition < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: checkout area. Avoid: Detect mannequin and do not hitting with mannequin. Known: Agent, goal, mannequin states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_mannequin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mannequin = calculate_distance_min(s_agent, s_mannequin) \n    penalty_collision = -25 if (d_agent_mannequin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating shop. Objectives: It must avoid colliding with shopper. Conditions: The states of the drone, goal and shopper are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shopper, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shopper = calculate_distance_min(s_agent, s_shopper) \n    penalty_collision = -25 if (d_agent_shopper < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through shop. Objectives: Avoid collision with product rack, customers and freight elevator platform. Conditions: The states of the agent, goal, product rack, customers and freight elevator platform are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating shop. Objectives: It must avoid colliding with any mannequin, wa and computers. Conditions: Agent's, goal's mannequin, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through shop. Objectives: Do not collide with security gate. Conditions: The states of the drone, goal and the security gate are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_security_gate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_gate = calculate_distance_min(s_agent, s_security_gate) \n    penalty = -25 if (d_agent_security_gate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along shop and must avoid contact with the signage stand. The states of the drone, goal and the signage stand are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_signage_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signage_stand = calculate_distance_min(s_agent, s_signage_stand) \n    penalty = -25 if (d_agent_signage_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in shop. It must avoid colliding with the mannequin, automatic sliding doors and security shutters. The states of the agent, goal, potted plants near entrance, automatic sliding doors and security shutters are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in shop. It must avoid colliding with the glass display item and mannequin. The states of the drone, goal and the glass display item and mannequin are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in shop. It must avoid colliding with the PVC strip curtain. Agent's state, goal's state and PVC strip curtain's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -25 if (d_agent_curtain < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: It must avoid colliding with cloth. Assumptions: The states of the drone, goal and the cloth's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_cloth, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cloth = calculate_distance_min(s_agent, s_cloth) \n    penalty_collision = -25 if (d_agent_cloth < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: It must avoid colliding with shop's potted plants near entrance, back stockroom area and glass divider. Assumptions: The Agent's state, goal's state, potted plants near entrance, back stockroom area and glass divider's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: Detect wooden bench, automatic sliding door and security gate and do not collide. Assumptions: The states of the drone, goal, wooden bench, automatic sliding door and security gate state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with festival banner. The information of the drone, the goal, and festival banner are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_banner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banner = calculate_distance_min(s_agent, s_banner) \n    penalty_collision = -23 if (d_agent_banner < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with tent curtain. The information of the drone, the goal, and tent curtain are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -23 if (d_agent_curtain < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with souvenir stand. The information of the drone, the goal, and souvenir stand are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_souvenir_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_souvenir_stand = calculate_distance_min(s_agent, s_souvenir_stand) \n    penalty_collision = -23 if (d_agent_souvenir_stand < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with game booth. The information of the drone, the goal, and game booth are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_game_booth, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_game_booth = calculate_distance_min(s_agent, s_game_booth) \n    penalty_collision = -23 if (d_agent_game_booth < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with signpost. The information of the drone, the goal, and signpost are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_signpost, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signpost = calculate_distance_min(s_agent, s_signpost) \n    penalty_collision = -23 if (d_agent_signpost < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with parade float. The information of the drone, the goal, and parade float are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_parade_float, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_parade_float = calculate_distance_min(s_agent, s_parade_float) \n    penalty_collision = -23 if (d_agent_parade_float < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with food stall. The information of the drone, the goal, and food stall are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_food_stall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_food_stall = calculate_distance_min(s_agent, s_food_stall) \n    penalty_collision = -23 if (d_agent_food_stall < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with wooden fence. The information of the drone, the goal, and wooden fence are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_wooden_fence, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wooden_fence = calculate_distance_min(s_agent, s_wooden_fence) \n    penalty_collision = -23 if (d_agent_wooden_fence < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with rope divider. The information of the drone, the goal, and rope divider are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_rope_divider, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope_divider = calculate_distance_min(s_agent, s_rope_divider) \n    penalty_collision = -23 if (d_agent_rope_divider < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with festival lantern. The information of the drone, the goal, and festival lantern are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_lantern, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lantern = calculate_distance_min(s_agent, s_lantern) \n    penalty_collision = -23 if (d_agent_lantern < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with performer. The information of the drone, the goal, and performer are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_performer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_performer = calculate_distance_min(s_agent, s_performer) \n    penalty_collision = -23 if (d_agent_performer < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with festival archway. The information of the drone, the goal, and festival archway are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_archway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_archway = calculate_distance_min(s_agent, s_archway) \n    penalty_collision = -23 if (d_agent_archway < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with stage light. The information of the drone, the goal, and stage light are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_stage_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stage_light = calculate_distance_min(s_agent, s_stage_light) \n    penalty_collision = -23 if (d_agent_stage_light < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with tent pole. The information of the drone, the goal, and tent pole are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_tent_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tent_pole = calculate_distance_min(s_agent, s_tent_pole) \n    penalty_collision = -23 if (d_agent_tent_pole < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with crowd barrier. The information of the drone, the goal, and crowd barrier are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_crowd_barrier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crowd_barrier = calculate_distance_min(s_agent, s_crowd_barrier) \n    penalty_collision = -23 if (d_agent_crowd_barrier < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with decorative arch plants. The information of the drone, the goal, and decorative arch plants are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_arch_plants, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_arch_plants = calculate_distance_min(s_agent, s_arch_plants) \n    penalty_collision = -23 if (d_agent_arch_plants < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with stage platform. The information of the drone, the goal, and stage platform are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_stage_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stage_platform = calculate_distance_min(s_agent, s_stage_platform) \n    penalty_collision = -23 if (d_agent_stage_platform < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with festival-goer. The information of the drone, the goal, and festival-goer are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_festival_goer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_festival_goer = calculate_distance_min(s_agent, s_festival_goer) \n    penalty_collision = -23 if (d_agent_festival_goer < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with ticket counter. The information of the drone, the goal, and ticket counter are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_ticket_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_counter = calculate_distance_min(s_agent, s_ticket_counter) \n    penalty_collision = -23 if (d_agent_ticket_counter < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with music speaker. The information of the drone, the goal, and music speaker are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -23 if (d_agent_speaker < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with drum set. The information of the drone, the goal, and drum set are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_drum_set, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drum_set = calculate_distance_min(s_agent, s_drum_set) \n    penalty_collision = -23 if (d_agent_drum_set < 0.7) else 12 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with table using its own state, the table's state, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -22 if (d_agent_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with waiter using its own state, the waiter status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_waiter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_waiter = calculate_distance_min(s_agent, s_waiter) \n    penalty_collision = -22 if (d_agent_waiter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with kitchen counter using its own state, the kitchen counter status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_kitchen_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kitchen_counter = calculate_distance_min(s_agent, s_kitchen_counter) \n    penalty_collision = -22 if (d_agent_kitchen_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with Restaurant's dining table, waiter and serving cart using its own state, the multiple obstacle: Restaurant's dining table, waiter and serving cart status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with  Restaurant's kitchen counter and swinging door using its own state, the many obstacle: Restaurant's kitchen counter and swinging door status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacle_min < ob_threshold) else 5 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with snackbar using its own state, the snackbar status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_snackbar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snackbar = calculate_distance_min(s_agent, s_snackbar) \n    penalty_collision = -15 if (d_agent_snackbar < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with customer using its own state, the customer status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -15 if (d_agent_customer < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with wall using its own state, the wall status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with food trolley using its own state, the Detect ball polisher and food trolley status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_food_trolley, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_food_trolley = calculate_distance_min(s_agent, s_food_trolley) \n    penalty_collision = -22 if (d_agent_food_trolley < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with sauce station and napkin holder using its own state, the multiple obstacle: sauce station and napkin holder status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with shelf, bottle display and bar sink using its own state, the multiple obstacle: shelf, bottle display and bar sink status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with ice machine and water cooler using its own state, the bice machine and water cooler status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with soup kettle and bread warmer using its own state, the multiple item: soup kettle and bread warmer status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with ceiling fan and chandelier using its own state, the multiple obstacle: ceiling fan and chandelier status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with table divider screen and privacy curtain using its own state, the table divider screen and privacy curtain status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with POS terminal stand, poster stand and receipt printer using its own state, the multiple obstacle: POS terminal stand, poster stand and receipt printer status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with hand sanitizer stand and poster stand using its own state, the many obstacle: hand sanitizer stand and poster stand status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with chef using its own state, the chef status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_chef, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chef = calculate_distance_min(s_agent, s_chef) \n    penalty_collision = -15 if (d_agent_chef_min < 0.7) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with tresor using its own state, the tresor status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_tresor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tresor_min = calculate_distance_min(s_agent, s_tresor) \n    penalty_collision = -15 if (d_agent_tresor_min < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with frame using its own state, the frame status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_frame, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_frame_min = calculate_distance_min(s_agent, s_frame) \n    penalty_collision = -15 if (d_agent_frame_min < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, using its own state, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (rolling chair) and reach goal, and must avoid collisions by using its own state and the rolling chair’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_rolling_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rolling_chair = calculate_distance_min(s_agent, s_rolling_chair) \n    penalty_collision = -27 if (d_agent_rolling_chair < 0.6) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (paper shredder) and reach goal, and must avoid collisions by using its own state and the papper shredder’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_paper_shredder, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paper_shredder = calculate_distance_min(s_agent, s_paper_shredder) \n    penalty_collision = -27 if (d_agent_paper_shredder < 0.6) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (cubicle wall, rolling chair and glass partition) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (printer station and paper shredder) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (umbrella stand) and reach goal, and must avoid collisions by using its own state and the umbrella stand’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_umbrella_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_umbrella_stand = calculate_distance_min(s_agent, s_umbrella_stand) \n    penalty_collision = -27 if (d_agent_umbrella_stand < 0.6) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (conference table, projector screen and ceiling light) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (floor cable tray and power strip) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (coat rack and umbrella stand) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (potted plant and water cooler) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (filing cabinet and open drawer) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (whiteboard on wheels) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -27 if (d_agent_whiteboard < 0.6) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (recycling bin) and reach goal, and must avoid collisions by using its own state and the recycling bin’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_recycling_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_recycling_bin = calculate_distance_min(s_agent, s_recycling_bin) \n    penalty_collision = -27 if (d_agent_recycling_bin < 0.6) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (server rack and network cable bundle) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (sliding door and door closer arm) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (elevator, lobby pillar and queue stanchion) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (whiteboard on wheels, network cable bundle and marker stand) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (recycling bin, trash bin and cardboard box stack) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (stairwell handrail, whiteboard and wet floor sign) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (hand sanitizer stand and poster stand) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (standing desk and monitor arm) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (bookshelf, whiteboard and step ladder) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (meeting pod wall and acoustic panel) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (coffee cart and milk crate) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (mail cart and parcel trolley) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (floor outlet cover, cable management pole and rug edge) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.4) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the park bench. Agent's state, goal's state and park bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_park_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_park_bench = calculate_distance_min(s_agent, s_park_bench) \n    penalty_collision = -25 if (d_agent_park_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the trash can. Agent's state, goal's state and trash can's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_can, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_can) \n    penalty_collision = -25 if (d_agent_trash_can < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's  tree, park bench and glass partition. Assumptions: The Agent's state, goal's state and the states of the drone, goal, tree, park bench, and glass partition are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's bush and trash can. Assumptions: The Agent's state, goal's state and the states of the drone, goal, bush, and trash can are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the lamp post. Agent's state, goal's state and lamp post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lamp_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp_post = calculate_distance_min(s_agent, s_lamp_post) \n    penalty_collision = -25 if (d_agent_lamp_post < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's picknick table, lamp post and human. Assumptions: The Agent's state, goal's state and the states of the drone, goal, picknick table, lamp post, and human are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's visitor and slide. Assumptions: The Agent's state, goal's state and the states of the drone, goal, visitor, and slide are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's swing and lamp post. Assumptions: The Agent's state, goal's state and the states of the drone, goal, swing, and lamp post are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's apple tree and water cooler. Assumptions: The Agent's state, goal's state and the states of the drone, goal, apple tree, and water cooler are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's scooter and fountain. Assumptions: The Agent's state, goal's state and the states of the drone, goal, scooter, and fountain are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the information board. Agent's state, goal's state and information board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_information_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_information_board = calculate_distance_min(s_agent, s_information_board) \n    penalty_collision = -25 if (d_agent_information_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the picnic table. Agent's state, goal's state and picnic table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_picnic_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_picnic_table = calculate_distance_min(s_agent, s_picnic_table) \n    penalty_collision = -25 if (d_agent_picnic_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's scooter and bicycle. Assumptions: The Agent's state, goal's state and the states of the drone, goal, server rack, and bicycle are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's trash bin and fence. Assumptions: The Agent's state, goal's state and the states of the drone, goal, trash bin, and fence are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's fence, fountain and tree. Assumptions: The Agent's state, goal's state and the states of the drone, goal, fence fountain, and tree are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's information board, bicycle and railing. Assumptions: The Agent's state, goal's state and the states of the drone, goal, information board, bicycle and railing are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's picnic table, trash bin and children. Assumptions: The Agent's state, goal's state and the states of the drone, goal, picnic table, trash bin, and children are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's stairwell handrail, information board and signs. Assumptions: The Agent's state, goal's state and the states of the drone, goal, stairwell handrail, information board and signs are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's wheelchair and poster stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal, wheelchair, and poster stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's standing table and monkey bar. Assumptions: The Agent's state, goal's state and the states of the drone, goal, standing table, and monkey bar are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's monkey bar, information board and step ladder. Assumptions: The Agent's state, goal's state and the states of the drone, goal, monkey bar, information board and step ladder are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's meeting pod wall and steam. Assumptions: The Agent's state, goal's state and the states of the drone, goal, meeting pod wall, and steam are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's coffee cart and food truck. Assumptions: The Agent's state, goal's state and the states of the drone, goal, coffee cart, and food truck are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's food truck and vehicle. Assumptions: The Agent's state, goal's state and the states of the drone, goal, food truck, and vehicle are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's vehicle, rope and bridge. Assumptions: The Agent's state, goal's state and the states of the drone, goal, vehicle, cable management pole, and bridge are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along shop. \n Objectives: It must avoid colliding with concrete columns or cashier desks. \n Conditions: The states of the agent, goal, the columns and the cashier desks are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy shop. \n Objectives: Detect automatic sliding door and aviod it. \n Conditions: The states of the agent, goal, the automatic sliding door are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_automatic_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_automatic_sliding door = calculate_distance_min(s_agent, s_automatic_door) \n    penalty_collision = -25 if (d_agent_automatic_sliding_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating shop open workshopperce. Objectives: It must avoid colliding with security gate. Conditions: States of the drone and the security gate are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_security_gate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_gate = calculate_distance_min(s_agent, s_security_gate) \n    penalty_collision = -25 if (d_agent_security_gate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a supermarket aisle, the drone must maneuver around cashier desk. All entity states (agent, goal, cashier desk) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -25 if (d_agent_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a supermarket aisle. Requirement: Detect the three checkout counters and do not collide with it. Given: The states for the drone and many checkout counters are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a shop. \n Objectives: So not collide with promo desk. \n Conditions: The states of the agent, goal, the promo desk are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_promo_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_promo_desk = calculate_distance_min(s_agent, s_promo_desk) \n    penalty_collision = -25 if (d_agent_promo_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate shop. Objectives: Do not collide hit with the clothing rack. Conditions: States of the agent, clothing rack are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_clothing_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clothing_rack = calculate_distance_min(s_agent, s_clothing_rack) \n    penalty_collision = -25 if (d_agent_clothing_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a supermarket aisle, the drone must steer clear of wall. All states (agent, goal, glass partition) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_glass_partition, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_partition = calculate_distance_min(s_agent, s_glass_partition) \n    penalty_collision = -25 if (d_agent_glass_partition < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: checkout area. Avoid: Detect mannequin and do not hitting with mannequin. Known: Agent, goal, mannequin states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_mannequin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mannequin = calculate_distance_min(s_agent, s_mannequin) \n    penalty_collision = -25 if (d_agent_mannequin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating shop. Objectives: It must avoid colliding with shopper. Conditions: The states of the drone, goal and shopper are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shopper, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shopper = calculate_distance_min(s_agent, s_shopper) \n    penalty_collision = -25 if (d_agent_shopper < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through shop. Objectives: Avoid collision with product rack, customers and freight elevator platform. Conditions: The states of the agent, goal, product rack, customers and freight elevator platform are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating shop. Objectives: It must avoid colliding with any mannequin, wa and computers. Conditions: Agent's, goal's mannequin, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through shop. Objectives: Do not collide with security gate. Conditions: The states of the drone, goal and the security gate are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_security_gate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_gate = calculate_distance_min(s_agent, s_security_gate) \n    penalty = -25 if (d_agent_security_gate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along shop and must avoid contact with the signage stand. The states of the drone, goal and the signage stand are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_signage_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signage_stand = calculate_distance_min(s_agent, s_signage_stand) \n    penalty = -25 if (d_agent_signage_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in shop. It must avoid colliding with the mannequin, automatic sliding doors and security shutters. The states of the agent, goal, potted plants near entrance, automatic sliding doors and security shutters are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in shop. It must avoid colliding with the glass display item and mannequin. The states of the drone, goal and the glass display item and mannequin are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in shop. It must avoid colliding with the PVC strip curtain. Agent's state, goal's state and PVC strip curtain's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -25 if (d_agent_curtain < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: It must avoid colliding with cloth. Assumptions: The states of the drone, goal and the cloth's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_cloth, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cloth = calculate_distance_min(s_agent, s_cloth) \n    penalty_collision = -25 if (d_agent_cloth < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: It must avoid colliding with shop's potted plants near entrance, back stockroom area and glass divider. Assumptions: The Agent's state, goal's state, potted plants near entrance, back stockroom area and glass divider's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: Detect wooden bench, automatic sliding door and security gate and do not collide. Assumptions: The states of the drone, goal, wooden bench, automatic sliding door and security gate state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating shop. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with festival banner. The information of the drone, the goal, and festival banner are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_banner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banner = calculate_distance_min(s_agent, s_banner) \n    penalty_collision = -24 if (d_agent_banner < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with tent curtain. The information of the drone, the goal, and tent curtain are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -24 if (d_agent_curtain < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with souvenir stand. The information of the drone, the goal, and souvenir stand are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_souvenir_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_souvenir_stand = calculate_distance_min(s_agent, s_souvenir_stand) \n    penalty_collision = -24 if (d_agent_souvenir_stand < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with game booth. The information of the drone, the goal, and game booth are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_game_booth, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_game_booth = calculate_distance_min(s_agent, s_game_booth) \n    penalty_collision = -24 if (d_agent_game_booth < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with signpost. The information of the drone, the goal, and signpost are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_signpost, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signpost = calculate_distance_min(s_agent, s_signpost) \n    penalty_collision = -24 if (d_agent_signpost < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with parade float. The information of the drone, the goal, and parade float are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_parade_float, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_parade_float = calculate_distance_min(s_agent, s_parade_float) \n    penalty_collision = -24 if (d_agent_parade_float < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with food stall. The information of the drone, the goal, and food stall are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_food_stall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_food_stall = calculate_distance_min(s_agent, s_food_stall) \n    penalty_collision = -24 if (d_agent_food_stall < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with wooden fence. The information of the drone, the goal, and wooden fence are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_wooden_fence, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wooden_fence = calculate_distance_min(s_agent, s_wooden_fence) \n    penalty_collision = -24 if (d_agent_wooden_fence < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with rope divider. The information of the drone, the goal, and rope divider are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_rope_divider, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope_divider = calculate_distance_min(s_agent, s_rope_divider) \n    penalty_collision = -24 if (d_agent_rope_divider < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with festival lantern. The information of the drone, the goal, and festival lantern are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_lantern, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lantern = calculate_distance_min(s_agent, s_lantern) \n    penalty_collision = -24 if (d_agent_lantern < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with performer. The information of the drone, the goal, and performer are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_performer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_performer = calculate_distance_min(s_agent, s_performer) \n    penalty_collision = -24 if (d_agent_performer < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with festival archway. The information of the drone, the goal, and festival archway are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_archway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_archway = calculate_distance_min(s_agent, s_archway) \n    penalty_collision = -24 if (d_agent_archway < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with stage light. The information of the drone, the goal, and stage light are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_stage_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stage_light = calculate_distance_min(s_agent, s_stage_light) \n    penalty_collision = -24 if (d_agent_stage_light < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with tent pole. The information of the drone, the goal, and tent pole are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_tent_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tent_pole = calculate_distance_min(s_agent, s_tent_pole) \n    penalty_collision = -24 if (d_agent_tent_pole < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with crowd barrier. The information of the drone, the goal, and crowd barrier are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_crowd_barrier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crowd_barrier = calculate_distance_min(s_agent, s_crowd_barrier) \n    penalty_collision = -24 if (d_agent_crowd_barrier < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with decorative arch plants. The information of the drone, the goal, and decorative arch plants are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_arch_plants, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_arch_plants = calculate_distance_min(s_agent, s_arch_plants) \n    penalty_collision = -24 if (d_agent_arch_plants < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with stage platform. The information of the drone, the goal, and stage platform are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_stage_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stage_platform = calculate_distance_min(s_agent, s_stage_platform) \n    penalty_collision = -24 if (d_agent_stage_platform < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with festival-goer. The information of the drone, the goal, and festival-goer are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_festival_goer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_festival_goer = calculate_distance_min(s_agent, s_festival_goer) \n    penalty_collision = -24 if (d_agent_festival_goer < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with ticket counter. The information of the drone, the goal, and ticket counter are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_ticket_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ticket_counter = calculate_distance_min(s_agent, s_ticket_counter) \n    penalty_collision = -24 if (d_agent_ticket_counter < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with music speaker. The information of the drone, the goal, and music speaker are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -24 if (d_agent_speaker < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a festival, a drone navigates while avoiding collisions with drum set. The information of the drone, the goal, and drum set are available. Implement a Python reward function for this task.",
        "chosen": "def reward(s_agent, s_drum_set, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drum_set = calculate_distance_min(s_agent, s_drum_set) \n    penalty_collision = -24 if (d_agent_drum_set < 0.6) else 14 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.1) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with table using its own state, the table's state, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -22 if (d_agent_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with waiter using its own state, the waiter status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_waiter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_waiter = calculate_distance_min(s_agent, s_waiter) \n    penalty_collision = -22 if (d_agent_waiter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with kitchen counter using its own state, the kitchen counter status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_kitchen_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kitchen_counter = calculate_distance_min(s_agent, s_kitchen_counter) \n    penalty_collision = -22 if (d_agent_kitchen_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with Restaurant's dining table, waiter and serving cart using its own state, the multiple obstacle: Restaurant's dining table, waiter and serving cart status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with  Restaurant's kitchen counter and swinging door using its own state, the many obstacle: Restaurant's kitchen counter and swinging door status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacle_min < ob_threshold) else 5 \n    reward_reaching_goal = 19 if (d_agent_goal < goal_threshold) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with snackbar using its own state, the snackbar status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_snackbar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_snackbar = calculate_distance_min(s_agent, s_snackbar) \n    penalty_collision = -15 if (d_agent_snackbar < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with customer using its own state, the customer status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -15 if (d_agent_customer < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with wall using its own state, the wall status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with food trolley using its own state, the Detect ball polisher and food trolley status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_food_trolley, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_food_trolley = calculate_distance_min(s_agent, s_food_trolley) \n    penalty_collision = -22 if (d_agent_food_trolley < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with sauce station and napkin holder using its own state, the multiple obstacle: sauce station and napkin holder status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with shelf, bottle display and bar sink using its own state, the multiple obstacle: shelf, bottle display and bar sink status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with ice machine and water cooler using its own state, the bice machine and water cooler status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with soup kettle and bread warmer using its own state, the multiple item: soup kettle and bread warmer status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with ceiling fan and chandelier using its own state, the multiple obstacle: ceiling fan and chandelier status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with table divider screen and privacy curtain using its own state, the table divider screen and privacy curtain status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with POS terminal stand, poster stand and receipt printer using its own state, the multiple obstacle: POS terminal stand, poster stand and receipt printer status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with hand sanitizer stand and poster stand using its own state, the many obstacle: hand sanitizer stand and poster stand status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -15 if (d_agent_multiple_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with chef using its own state, the chef status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_chef, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chef = calculate_distance_min(s_agent, s_chef) \n    penalty_collision = -15 if (d_agent_chef_min < 0.7) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with tresor using its own state, the tresor status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_tresor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tresor_min = calculate_distance_min(s_agent, s_tresor) \n    penalty_collision = -15 if (d_agent_tresor_min < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with frame using its own state, the frame status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_frame, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_frame_min = calculate_distance_min(s_agent, s_frame) \n    penalty_collision = -15 if (d_agent_frame_min < ob_threshold) else 5 \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent flies inside a restaurant, aims to reach a goal, and must avoid collisions with chair using its own state, the chair status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 22 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (rolling chair) and reach goal, and must avoid collisions by using its own state and the rolling chair’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_rolling_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rolling_chair = calculate_distance_min(s_agent, s_rolling_chair) \n    penalty_collision = -25 if (d_agent_rolling_chair < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (paper shredder) and reach goal, and must avoid collisions by using its own state and the papper shredder’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_paper_shredder, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paper_shredder = calculate_distance_min(s_agent, s_paper_shredder) \n    penalty_collision = -25 if (d_agent_paper_shredder < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (cubicle wall, rolling chair and glass partition) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (printer station and paper shredder) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (umbrella stand) and reach goal, and must avoid collisions by using its own state and the umbrella stand’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_umbrella_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_umbrella_stand = calculate_distance_min(s_agent, s_umbrella_stand) \n    penalty_collision = -25 if (d_agent_umbrella_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (conference table, projector screen and ceiling light) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (floor cable tray and power strip) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (coat rack and umbrella stand) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (potted plant and water cooler) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (filing cabinet and open drawer) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (whiteboard on wheels) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -25 if (d_agent_whiteboard < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (recycling bin) and reach goal, and must avoid collisions by using its own state and the recycling bin’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_recycling_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_recycling_bin = calculate_distance_min(s_agent, s_recycling_bin) \n    penalty_collision = -25 if (d_agent_recycling_bin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (server rack and network cable bundle) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (sliding door and door closer arm) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (elevator, lobby pillar and queue stanchion) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (whiteboard on wheels, network cable bundle and marker stand) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (recycling bin, trash bin and cardboard box stack) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (stairwell handrail, whiteboard and wet floor sign) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (hand sanitizer stand and poster stand) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (standing desk and monitor arm) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (bookshelf, whiteboard and step ladder) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (meeting pod wall and acoustic panel) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (coffee cart and milk crate) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (mail cart and parcel trolley) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves inside a office, aims to detect a obstacle (floor outlet cover, cable management pole and rug edge) and reach goal, and must avoid collisions by using its own state and the multiple obstacle’s state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the park bench. Agent's state, goal's state and park bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_park_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_park_bench = calculate_distance_min(s_agent, s_park_bench) \n    penalty_collision = -25 if (d_agent_park_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the trash can. Agent's state, goal's state and trash can's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_can, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_can) \n    penalty_collision = -25 if (d_agent_trash_can < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's  tree, park bench and glass partition. Assumptions: The Agent's state, goal's state and the states of the drone, goal, tree, park bench, and glass partition are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's bush and trash can. Assumptions: The Agent's state, goal's state and the states of the drone, goal, bush, and trash can are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the lamp post. Agent's state, goal's state and lamp post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lamp_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp_post = calculate_distance_min(s_agent, s_lamp_post) \n    penalty_collision = -25 if (d_agent_lamp_post < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's picknick table, lamp post and human. Assumptions: The Agent's state, goal's state and the states of the drone, goal, picknick table, lamp post, and human are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's visitor and slide. Assumptions: The Agent's state, goal's state and the states of the drone, goal, visitor, and slide are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's swing and lamp post. Assumptions: The Agent's state, goal's state and the states of the drone, goal, swing, and lamp post are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's apple tree and water cooler. Assumptions: The Agent's state, goal's state and the states of the drone, goal, apple tree, and water cooler are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's scooter and fountain. Assumptions: The Agent's state, goal's state and the states of the drone, goal, scooter, and fountain are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the information board. Agent's state, goal's state and information board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_information_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_information_board = calculate_distance_min(s_agent, s_information_board) \n    penalty_collision = -25 if (d_agent_information_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the park. It must avoid colliding with the picnic table. Agent's state, goal's state and picnic table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_picnic_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_picnic_table = calculate_distance_min(s_agent, s_picnic_table) \n    penalty_collision = -25 if (d_agent_picnic_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's scooter and bicycle. Assumptions: The Agent's state, goal's state and the states of the drone, goal, server rack, and bicycle are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's trash bin and fence. Assumptions: The Agent's state, goal's state and the states of the drone, goal, trash bin, and fence are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's fence, fountain and tree. Assumptions: The Agent's state, goal's state and the states of the drone, goal, fence fountain, and tree are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's information board, bicycle and railing. Assumptions: The Agent's state, goal's state and the states of the drone, goal, information board, bicycle and railing are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's picnic table, trash bin and children. Assumptions: The Agent's state, goal's state and the states of the drone, goal, picnic table, trash bin, and children are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's stairwell handrail, information board and signs. Assumptions: The Agent's state, goal's state and the states of the drone, goal, stairwell handrail, information board and signs are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's wheelchair and poster stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal, wheelchair, and poster stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's standing table and monkey bar. Assumptions: The Agent's state, goal's state and the states of the drone, goal, standing table, and monkey bar are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's monkey bar, information board and step ladder. Assumptions: The Agent's state, goal's state and the states of the drone, goal, monkey bar, information board and step ladder are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's meeting pod wall and steam. Assumptions: The Agent's state, goal's state and the states of the drone, goal, meeting pod wall, and steam are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Park. Goal: It must avoid colliding with Park's coffee cart and food truck. Assumptions: The Agent's state, goal's state and the states of the drone, goal, coffee cart, and food truck are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Park. Goal: It must avoid colliding with Park's food truck and vehicle. Assumptions: The Agent's state, goal's state and the states of the drone, goal, food truck, and vehicle are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Park. Goal: It must avoid colliding with Park's vehicle, rope and bridge. Assumptions: The Agent's state, goal's state and the states of the drone, goal, vehicle, cable management pole, and bridge are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.7) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the School bench. Agent's state, goal's state and School bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_school_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_park_bench = calculate_distance_min(s_agent, s_school_desk) \n    penalty_collision = -25 if (d_agent_park_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the trash bin. Agent's state, goal's state and trash bin's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -25 if (d_agent_trash_can < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's  bookshelf, School bench and glass door. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bookshelf, School bench, and glass door are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's backpack rack and trash bin. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, backpack rack, and trash bin are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the hallway pillar. Agent's state, goal's state and hallway pillar's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_hallway_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_hallway_pillar = calculate_distance_min(s_agent, s_hallway_pillar) \n    penalty_collision = -25 if (d_agent_hallway_pillar < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria table, hallway pillar and student. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria table, hallway pillar, and student are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's teacher and slide. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, teacher, and slide are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's swing and hallway pillar. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, swing, and hallway pillar are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bookshelf and student. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bookshelf, and student are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bicycle and teachers. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bicycle, and teachers are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the bulletin board. Agent's state, goal's state and bulletin board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bulletin_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bulletin_board = calculate_distance_min(s_agent, s_bulletin_board) \n    penalty_collision = -25 if (d_agent_bulletin_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the cafeteria table. Agent's state, goal's state and cafeteria table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cafeteria_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cafeteria_table = calculate_distance_min(s_agent, s_cafeteria_table) \n    penalty_collision = -25 if (d_agent_cafeteria_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bicycle and bicycle rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bicycle, and bicycle rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's trash bin and hallway barrier. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, trash bin, and hallway barrier are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's hallway barrier, teachers and bookshelf. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, hallway barrier teachers, and bookshelf are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's bulletin board, bicycle rack and stairwell railing. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bulletin board, bicycle rack and stairwell railing are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria table, trash bin and students. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria table, trash bin, and students are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's stairwell handrail, bulletin board and hallway signs. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, stairwell handrail, bulletin board and hallway signs are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's wheelchair and poster stand. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, wheelchair, and poster stand are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's lab table and monkey bars. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, lab table, and monkey bars are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's monkey bars, bulletin board and step ladder. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, monkey bars, bulletin board and step ladder are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's classroom partition and AC. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, classroom partition, and AC are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria cart and chair. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria cart, and chair are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's chair and school bus. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, chair, and school bus are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's school bus, gym rope and fire extinguisher. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, school bus, gym rope, and fire extinguisher are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the Tennis court courtside bench. Agent's state, goal's state and Tennis court courtside bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_courtside_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_courtside_bench = calculate_distance_min(s_agent, s_courtside_bench) \n    penalty_collision = -25 if (d_agent_courtside_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the ball basket. Agent's state, goal's state and ball basket's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball_basket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball_basket = calculate_distance_min(s_agent, s_ball_basket) \n    penalty_collision = -25 if (d_agent_ball_basket < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's  equipment rack, Tennis court courtside bench and court gate. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment rack, Tennis court courtside bench, and court gate are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's gear rack and ball basket. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, gear rack, and ball basket are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the net post. Agent's state, goal's state and net post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_net_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net_post = calculate_distance_min(s_agent, s_net_post) \n    penalty_collision = -25 if (d_agent_net_post < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's umpire courtside chair, net post and ball kid. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, umpire courtside chair, net post, and ball kid are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's coach and practice wall. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, coach, and practice wall are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's ball basket and net post. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball basket, and net post are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's equipment rack and ball kid. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment rack, and ball kid are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's utility cart and coaches. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, utility cart, and coaches are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the scoreboard. Agent's state, goal's state and scoreboard's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -25 if (d_agent_scoreboard < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the umpire courtside chair. Agent's state, goal's state and umpire courtside chair's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_umpire_chair) \n    penalty_collision = -25 if (d_agent_chair < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's utility cart and equipment rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, utility cart, and equipment rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's ball basket and court divider net. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball basket, and court divider net are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's court divider net, coaches and equipment rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, court divider net coaches, and equipment rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's scoreboard, equipment rack and perimeter fence. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, scoreboard, equipment rack and perimeter fence are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's umpire courtside chair, ball basket and ball crew. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, umpire courtside chair, ball basket, and ball crew are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's perimeter fence, scoreboard and court signs. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, perimeter fence, scoreboard and court signs are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's equipment trolley and signboard. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment trolley, and signboard are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's stringing table and gate. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, stringing table, and gate are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's gate, scoreboard and step ladder. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, gate, scoreboard and step ladder are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's windscreen and misting fan. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, windscreen, and misting fan are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's ball machine and courtside chair. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball machine, and courtside chair are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's courtside chair and Tennis court bus. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, courtside chair, and Tennis court bus are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's Tennis court bus, net strap and hydration station. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, Tennis court bus, net strap, and hydration station are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Dental clinic. It must avoid colliding with enclosure X-ray stand or patients. The states of the agent, goal, the door, and the patients are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.5) else 15 \n    reward_reaching_goal = 25 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Dental clinic concourse. It must avoid colliding with instrument cart. The states of the agent, goal, the instrument cartare known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_instrument_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_instrument_cart = calculate_distance_min(s_agent, s_instrument_cart) \n    penalty_collision = -15 if (d_instrument_cart < 0.5) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic common room.\n Objectives: It must avoid colliding with supply box.\n Conditions: States of the agent and the supply box are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_supply_box, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_supply_box = calculate_distance_min(s_agent, s_supply_box) \n    penalty_collision = -15 if (d_agent_supply_box < 0.5) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Dental clinic corridor, the drone must maneuver around receptions. All entity states (agent, goal, reception) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_reception, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception = calculate_distance_min(s_agent, s_reception) \n    penalty_collision = -15 if (d_agent_reception < 0.5) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Dental clinic atrium.\nRequirement: Avoid collisions with instrument carts.\n Given: The states for the agent and many instrument carts are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.5) else 15 \n    reward_reaching_goal = 25 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Dental clinic entrance during an event. So not collide with X-ray stand. The states of the agent, goal, the X-ray stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_xray_stand, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_xray_stand = calculate_distance_min(s_agent, s_xray_stand) \n    penalty_collision = -15 if (d_agent_xray_stand < 0.5) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Dental clinic without.\n Objectives: Do not collide hit with privacy curtain, \n Conditions: States of the agent, privacy curtain are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_privacy_curtain, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_privacy_curtain = calculate_distance_min(s_agent, s_privacy_curtain) \n    penalty_collision = -15 if (d_privacy_curtain < 0.5) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Dental clinic atrium, the drone must steer clear of equipment towers. All states (agent, goal, ceiling fan) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -15 if (d_obs_min < 0.5) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Dental clinic lounge.\n Avoid: Hitting with Dental clinic worker.\n Known: Agent, goal, Dental clinic worker states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_dental_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dental_staff = calculate_distance_min(s_agent, s_dental_staff) \n    penalty_collision = -15 if (d_agent_dental_staff < 0.5) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic. \n Objectives: It must avoid colliding with sterilization units. \n Conditions: The states of the agent and the sterilization units are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sterilization_unit, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_sterilization_unit) \n    penalty_collision = -25 if (d_obs_min < 0.5) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Dental clinic. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic. \n Objectives: It must avoid colliding with any oxygen cylinder, supply rack and gate. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -25 if (d_obs_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Dental clinic. \n Objectives: Do not collide with any Dental clinic staff. \n Conditions: The states of the agent and the Dental clinic staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_clinic_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_clinic_staff = calculate_distance_min(s_agent, s_clinic_staff) \n    penalty = -25 if (d_clinic_staff < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Dental clinic and must avoid contact with any instrument cart. The states of the drone, goal and the instrument cart are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_instrument_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cart = calculate_distance_min(s_agent, s_instrument_cart) \n    penalty = -25 if (d_agent_cart < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Dental clinic. It must avoid colliding with storage cabinets and glass partitions placed in the exam area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Dental clinic. It must avoid colliding with queue stanchions and patients. The states of the drone, goal and the multiple clinic obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Dental clinic. It must avoid colliding with Dental clinic staff. Agent's state, goal's state and Dental clinic staff's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_clinic_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_clinic_staff) \n    penalty_collision = -25 if (d_agent_staff < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: It must avoid colliding with service elevator. \n Assumptions: The states of the agent and the elevator are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -25 if (dist_elevator < 0.5) else 15 \n    reward_reaching_goal = 25 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: It must avoid colliding with Dental clinic staff, patients and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Dental clinic staff's state, instrument cart's state and patients' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: Detect patients and pillars and avoid door corners. \n Assumptions: The states of the agent and doors, curtains and partitions state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_goal < 0.2) else -dist_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Kindergarten. It must avoid colliding with enclosure coat rack or children. The states of the agent, goal, the door, and the children are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 25 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Kindergarten hallway. It must avoid colliding with toy carts. The states of the agent, goal, the toy cart are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_toy_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_toy_cart = calculate_distance_min(s_agent, s_toy_cart) \n    penalty_collision = -15 if (d_toy_cart < 0.5) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten common room.\n Objectives: It must avoid colliding with toy box.\n Conditions: States of the agent and the toy box are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_toy_box, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tox_box = calculate_distance_min(s_agent, s_toy_box) \n    penalty_collision = -15 if (d_agent_tox_box < 0.5) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Kindergarten corridor, the drone must maneuver around cubby areas. All entity states (agent, goal, cubby area) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_cubby_area, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cubby_area = calculate_distance_min(s_agent, s_cubby_area) \n    penalty_collision = -15 if (d_agent_cubby_area < 0.5) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Kindergarten playroom.\nRequirement: Avoid collisions with toy carts.\n Given: The states for the agent and many toy carts are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 25 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Kindergarten entrance during an event. So not collide with coat rack. The states of the agent, goal, the coat rack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_coat_rack, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_rack = calculate_distance_min(s_agent, s_coat_rack) \n    penalty_collision = -15 if (d_agent_coat_rack < 0.5) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Kindergarten without.\n Objectives: Do not collide hit with room divider, \n Conditions: States of the agent, room divider are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_room_divider, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_room_divider = calculate_distance_min(s_agent, s_room_divider) \n    penalty_collision = -15 if (d_room_divider < 0.5) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Kindergarten playroom, the drone must steer clear of equipment towers. All states (agent, goal, ceiling fan) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ceiling_fan = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -15 if (d_agent_ceiling_fan < 0.5) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Kindergarten reading nook.\n Avoid: Hitting with Kindergarten worker.\n Known: Agent, goal, Kindergarten worker states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_teacher, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -15 if (d_agent_teacher < 0.5) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten. \n Objectives: It must avoid colliding with sanitizer station. \n Conditions: The states of the agent and the sanitizer station are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sanitizer_station, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sanitizer_station = calculate_distance_min(s_agent, s_sanitizer_station) \n    penalty_collision = -25 if (d_agent_sanitizer_station < 0.5) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Kindergarten. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten. \n Objectives: It must avoid colliding with any cleaning cart, toy shelf and safety gate. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -25 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Kindergarten. \n Objectives: Do not collide with any Kindergarten staff. \n Conditions: The states of the agent and the Kindergarten staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_staff = calculate_distance_min(s_agent, s_staff) \n    penalty = -25 if (d_staff < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Kindergarten and must avoid contact with any toy carts. The states of the drone, goal and the toy carts are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_toy_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toy_cart = calculate_distance_min(s_agent, s_toy_cart) \n    penalty = -25 if (d_agent_toy_cart < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Kindergarten. It must avoid colliding with storage cabinets and low partition placed in the play area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Kindergarten. It must avoid colliding with rope divider and children. The states of the drone, goal and the multiple kindergarten obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Kindergarten. It must avoid colliding with Kindergarten staff. Agent's state, goal's state and Kindergarten staff's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -25 if (d_agent_staff < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: It must avoid colliding with service elevator. \n Assumptions: The states of the agent and the elevator are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -25 if (dist_elevator < 0.5) else 15 \n    reward_reaching_goal = 25 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: It must avoid colliding with Kindergarten staff, children and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Kindergarten staff's state, toy carts's state and children' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: Detect children and pillar and avoid door corners. \n Assumptions: The states of the agent and doors, curtains and partitions state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_goal < 0.2) else -dist_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Ship. It must avoid colliding with enclosure pipe rack or passengers. The states of the agent, goal, the door, and the passengers are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 10 \n    reward_reaching_goal = 25 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Ship corridor. It must avoid colliding with equipment carts. The states of the agent, goal, the equipment carts are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_signal_flag, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_signal_flag = calculate_distance_min(s_agent, s_signal_flag) \n    penalty_collision = -15 if (d_signal_flag < 0.5) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship mess hall.\n Objectives: It must avoid colliding with cargo crate.\n Conditions: States of the agent and the cargo crate are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cargo_crate, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cargo_crate = calculate_distance_min(s_agent, s_cargo_crate) \n    penalty_collision = -15 if (d_agent_cargo_crate < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Ship corridor, the drone must maneuver around storage lockers. All entity states (agent, goal, storage lockers) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_storage_locker, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_locker = calculate_distance_min(s_agent, s_storage_locker) \n    penalty_collision = -15 if (d_agent_storage_locker < 0.5) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Ship deck.\nRequirement: Avoid collisions with containers.\n Given: The states for the agent and many containers are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 10 \n    reward_reaching_goal = 25 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Ship gangway during an event. So not collide with the contanier. The states of the agent, goal, the container are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_container, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_container = calculate_distance_min(s_agent, s_container) \n    penalty_collision = -15 if (d_agent_container < 0.5) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Ship without.\n Objectives: Do not collide hit with watertight door, \n Conditions: States of the agent, watertight door are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_watertight_door, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_watertight_door = calculate_distance_min(s_agent, s_watertight_door) \n    penalty_collision = -15 if (d_agent_watertight_door < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Ship deck, the drone must steer clear of ladders. All states (agent, goal, ladder) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ladder, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ladder = calculate_distance_min(s_agent, s_ladder) \n    penalty_collision = -15 if (d_agent_ladder < 0.5) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Ship crew lounge.\n Avoid: Hitting with crew member.\n Known: Agent, goal, crew member states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_crew_member, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crew_member = calculate_distance_min(s_agent, s_crew_member) \n    penalty_collision = -15 if (d_agent_crew_member < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship. \n Objectives: It must avoid colliding with anchor chain. \n Conditions: The states of the agent and the anchor chain are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_anchor_chain, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_anchor_chain = calculate_distance_min(s_agent, s_anchor_chain) \n    penalty_collision = -25 if (d_agent_anchor_chain < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Ship. \n Objectives: Avoid collision with mooring bollards and capstans. \n Conditions: The states of the agent, goal, mooring bollards and capstans are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship. \n Objectives: It must avoid colliding with any maintenance cart, storage shelf and safety chain. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -25 if (d_multiple_obstacles_min < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Ship. \n Objectives: Do not collide with any passenger. \n Conditions: The states of the agent and the passenger are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_passenger, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_passenger) \n    penalty = -25 if (d_agent_passenger < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Ship and must avoid contact with any signal flag. The states of the drone, goal and the signal flag are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_signal_flag, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signal_flag = calculate_distance_min(s_agent, s_signal_flag) \n    penalty = -25 if (d_agent_signal_flag < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Ship. It must avoid colliding with the multiple boxes in the work area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Ship. It must avoid colliding with mooring line and passengers. The states of the drone, goal and the mooring line and passengers are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Ship. It must avoid colliding with mast. Agent's state, goal's state and mast's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_mast, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mast = calculate_distance_min(s_agent, s_mast) \n    penalty_collision = -25 if (d_agent_mast < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: It must avoid colliding with halyard. \n Assumptions: The states of the agent and the halyard are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_halyard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_halyard = calculate_distance_min(s_agent, s_halyard) \n    penalty_collision = -25 if (dist_halyard < 0.5) else 10 \n    reward_reaching_goal = 25 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: It must avoid colliding with Ship crew, passengers and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Ship crew's state, equipment carts's state and passengers' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: Detect passengers and pillar and door corners and do not collide into them. \n Assumptions: The states of the agent and passengers and pillar and avoid door corner state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.5) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_goal < 0.2) else -dist_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Police station. It must avoid colliding with enclosure noticeboard or visitors. The states of the agent, goal, the door, and the visitors are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 19 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Police station hallway. It must avoid colliding with metal detector. The states of the agent, goal, the metal detector are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_metal_detector, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_metal_detector = calculate_distance_min(s_agent, s_metal_detector) \n    penalty_collision = -15 if (d_metal_detector < 0.5) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station common room.\n Objectives: It must avoid colliding with weapon's rack.\n Conditions: States of the agent and the weapon's rack are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weapon_rack, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tox_box = calculate_distance_min(s_agent, s_weapon_rack) \n    penalty_collision = -15 if (d_agent_tox_box < 0.5) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Police station corridor, the drone must maneuver around gear lockers. All entity states (agent, goal, gear lockers) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_gear_locker, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gear_locker = calculate_distance_min(s_agent, s_gear_locker) \n    penalty_collision = -15 if (d_agent_gear_locker < 0.5) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Police station lobby.\nRequirement: Avoid collisions with handcuff board.\n Given: The states for the agent and many handcuff board are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 19 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Police station entrance during an event. So not collide with noticeboard. The states of the agent, goal, the noticeboard are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_noticeboard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_noticeboard = calculate_distance_min(s_agent, s_noticeboard) \n    penalty_collision = -15 if (d_agent_noticeboard < 0.5) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Police station without.\n Objectives: Do not collide hit with security door, \n Conditions: States of the agent, security door are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_security_door, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_door = calculate_distance_min(s_agent, s_security_door) \n    penalty_collision = -15 if (d_agent_security_door < 0.5) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Police station lobby, the drone must steer clear of folder. All states (agent, goal, folder) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_folder, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_folder = calculate_distance_min(s_agent, s_folder) \n    penalty_collision = -15 if (d_agent_folder < 0.5) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Police station break room.\n Avoid: Hitting with officer.\n Known: Agent, goal, Police officer states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_officer, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_officer = calculate_distance_min(s_agent, s_officer) \n    penalty_collision = -15 if (d_agent_officer < 0.5) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station. \n Objectives: It must avoid colliding with counters. \n Conditions: The states of the agent and a counter are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -19 if (d_agent_counter < 0.5) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Police station. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station. \n Objectives: It must avoid colliding with any janitor cart, file shelf and barrier chain. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -19 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Police station. \n Objectives: Do not collide with any Police station staff. \n Conditions: The states of the agent and the Police station staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_staff = calculate_distance_min(s_agent, s_staff) \n    penalty = -19 if (d_staff < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Police station and must avoid contact with any handcuff board. The states of the drone, goal and the handcuff board are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_handcuff_board, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_handcuff_board = calculate_distance_min(s_agent, s_handcuff_board) \n    penalty = -19 if (d_agent_handcuff_board < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Police station. It must avoid colliding with gear lockers and visitors. The states of the drone, goal, gear lockers and visitor are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Police station. It must avoid colliding with barrier tape and visitors. The states of the drone, goal and the multiple Police station obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Police station. It must avoid colliding with pinboard. Agent's state, goal's state and pinboard's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_pinboard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pinboard = calculate_distance_min(s_agent, s_pinboard) \n    penalty_collision = -19 if (d_agent_pinboard < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: It must avoid colliding with training dummy. \n Assumptions: The states of the agent and the training dummy are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_training_dummy, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_training_dummyr = calculate_distance_min(s_agent, s_training_dummy) \n    penalty_collision = -19 if (dist_training_dummy < 0.5) else 15 \n    reward_reaching_goal = 19 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: It must avoid colliding with Police station staff, visitors and training dummy. \n Assumptions: The Agent's state, goal's state, Police station staff's state, handcuff board's state and visitors' states and training dummies state are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: Detect doors, curtains and door and do not collide with it. \n Assumptions: The states of the agent and doors, curtains and door state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.2) else -dist_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_goal < 0.2) else -dist_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the School bench. Agent's state, goal's state and School bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_school_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_park_bench = calculate_distance_min(s_agent, s_school_desk) \n    penalty_collision = -25 if (d_agent_park_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the trash bin. Agent's state, goal's state and trash bin's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -25 if (d_agent_trash_can < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's  bookshelf, School bench and glass door. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bookshelf, School bench, and glass door are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's backpack rack and trash bin. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, backpack rack, and trash bin are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the hallway pillar. Agent's state, goal's state and hallway pillar's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_hallway_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_hallway_pillar = calculate_distance_min(s_agent, s_hallway_pillar) \n    penalty_collision = -25 if (d_agent_hallway_pillar < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria table, hallway pillar and student. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria table, hallway pillar, and student are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's teacher and slide. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, teacher, and slide are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's swing and hallway pillar. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, swing, and hallway pillar are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bookshelf and student. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bookshelf, and student are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bicycle and teachers. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bicycle, and teachers are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the bulletin board. Agent's state, goal's state and bulletin board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bulletin_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bulletin_board = calculate_distance_min(s_agent, s_bulletin_board) \n    penalty_collision = -25 if (d_agent_bulletin_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the cafeteria table. Agent's state, goal's state and cafeteria table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cafeteria_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cafeteria_table = calculate_distance_min(s_agent, s_cafeteria_table) \n    penalty_collision = -25 if (d_agent_cafeteria_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bicycle and bicycle rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bicycle, and bicycle rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's trash bin and hallway barrier. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, trash bin, and hallway barrier are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's hallway barrier, teachers and bookshelf. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, hallway barrier teachers, and bookshelf are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's bulletin board, bicycle rack and stairwell railing. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bulletin board, bicycle rack and stairwell railing are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria table, trash bin and students. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria table, trash bin, and students are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's stairwell handrail, bulletin board and hallway signs. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, stairwell handrail, bulletin board and hallway signs are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's wheelchair and poster stand. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, wheelchair, and poster stand are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's lab table and monkey bars. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, lab table, and monkey bars are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's monkey bars, bulletin board and step ladder. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, monkey bars, bulletin board and step ladder are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's classroom partition and AC. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, classroom partition, and AC are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria cart and chair. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria cart, and chair are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's chair and school bus. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, chair, and school bus are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's school bus, gym rope and fire extinguisher. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, school bus, gym rope, and fire extinguisher are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the Tennis court courtside bench. Agent's state, goal's state and Tennis court courtside bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_courtside_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_courtside_bench = calculate_distance_min(s_agent, s_courtside_bench) \n    penalty_collision = -25 if (d_agent_courtside_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the ball basket. Agent's state, goal's state and ball basket's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball_basket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball_basket = calculate_distance_min(s_agent, s_ball_basket) \n    penalty_collision = -25 if (d_agent_ball_basket < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's  equipment rack, Tennis court courtside bench and court gate. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment rack, Tennis court courtside bench, and court gate are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's gear rack and ball basket. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, gear rack, and ball basket are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the net post. Agent's state, goal's state and net post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_net_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net_post = calculate_distance_min(s_agent, s_net_post) \n    penalty_collision = -25 if (d_agent_net_post < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's umpire courtside chair, net post and ball kid. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, umpire courtside chair, net post, and ball kid are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's coach and practice wall. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, coach, and practice wall are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's ball basket and net post. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball basket, and net post are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's equipment rack and ball kid. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment rack, and ball kid are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's utility cart and coaches. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, utility cart, and coaches are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the scoreboard. Agent's state, goal's state and scoreboard's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -25 if (d_agent_scoreboard < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the umpire courtside chair. Agent's state, goal's state and umpire courtside chair's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_umpire_chair) \n    penalty_collision = -25 if (d_agent_chair < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's utility cart and equipment rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, utility cart, and equipment rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's ball basket and court divider net. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball basket, and court divider net are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's court divider net, coaches and equipment rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, court divider net coaches, and equipment rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's scoreboard, equipment rack and perimeter fence. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, scoreboard, equipment rack and perimeter fence are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's umpire courtside chair, ball basket and ball crew. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, umpire courtside chair, ball basket, and ball crew are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's perimeter fence, scoreboard and court signs. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, perimeter fence, scoreboard and court signs are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's equipment trolley and signboard. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment trolley, and signboard are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's stringing table and gate. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, stringing table, and gate are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's gate, scoreboard and step ladder. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, gate, scoreboard and step ladder are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's windscreen and misting fan. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, windscreen, and misting fan are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's ball machine and courtside chair. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball machine, and courtside chair are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's courtside chair and Tennis court bus. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, courtside chair, and Tennis court bus are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's Tennis court bus, net strap and hydration station. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, Tennis court bus, net strap, and hydration station are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Dental clinic. It must avoid colliding with enclosure X-ray stand or patients. The states of the agent, goal, the door, and the patients are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 25 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Dental clinic concourse. It must avoid colliding with instrument cart. The states of the agent, goal, the instrument cartare known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_instrument_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_instrument_cart = calculate_distance_min(s_agent, s_instrument_cart) \n    penalty_collision = -15 if (d_instrument_cart < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic common room.\n Objectives: It must avoid colliding with supply box.\n Conditions: States of the agent and the supply box are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_supply_box, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_supply_box = calculate_distance_min(s_agent, s_supply_box) \n    penalty_collision = -15 if (d_agent_supply_box < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Dental clinic corridor, the drone must maneuver around receptions. All entity states (agent, goal, reception) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_reception, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception = calculate_distance_min(s_agent, s_reception) \n    penalty_collision = -15 if (d_agent_reception < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Dental clinic atrium.\nRequirement: Avoid collisions with instrument carts.\n Given: The states for the agent and many instrument carts are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 25 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Dental clinic entrance during an event. So not collide with X-ray stand. The states of the agent, goal, the X-ray stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_xray_stand, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_xray_stand = calculate_distance_min(s_agent, s_xray_stand) \n    penalty_collision = -15 if (d_agent_xray_stand < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Dental clinic without.\n Objectives: Do not collide hit with privacy curtain, \n Conditions: States of the agent, privacy curtain are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_privacy_curtain, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_privacy_curtain = calculate_distance_min(s_agent, s_privacy_curtain) \n    penalty_collision = -15 if (d_privacy_curtain < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Dental clinic atrium, the drone must steer clear of equipment towers. All states (agent, goal, ceiling fan) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -15 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Dental clinic lounge.\n Avoid: Hitting with Dental clinic worker.\n Known: Agent, goal, Dental clinic worker states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_dental_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dental_staff = calculate_distance_min(s_agent, s_dental_staff) \n    penalty_collision = -15 if (d_agent_dental_staff < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic. \n Objectives: It must avoid colliding with sterilization units. \n Conditions: The states of the agent and the sterilization units are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sterilization_unit, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_sterilization_unit) \n    penalty_collision = -25 if (d_obs_min < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Dental clinic. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic. \n Objectives: It must avoid colliding with any oxygen cylinder, supply rack and gate. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -25 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Dental clinic. \n Objectives: Do not collide with any Dental clinic staff. \n Conditions: The states of the agent and the Dental clinic staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_clinic_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_clinic_staff = calculate_distance_min(s_agent, s_clinic_staff) \n    penalty = -25 if (d_clinic_staff < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Dental clinic and must avoid contact with any instrument cart. The states of the drone, goal and the instrument cart are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_instrument_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cart = calculate_distance_min(s_agent, s_instrument_cart) \n    penalty = -25 if (d_agent_cart < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Dental clinic. It must avoid colliding with storage cabinets and glass partitions placed in the exam area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Dental clinic. It must avoid colliding with queue stanchions and patients. The states of the drone, goal and the multiple clinic obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Dental clinic. It must avoid colliding with Dental clinic staff. Agent's state, goal's state and Dental clinic staff's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_clinic_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_clinic_staff) \n    penalty_collision = -25 if (d_agent_staff < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: It must avoid colliding with service elevator. \n Assumptions: The states of the agent and the elevator are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -25 if (dist_elevator < 0.6) else 15 \n    reward_reaching_goal = 25 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: It must avoid colliding with Dental clinic staff, patients and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Dental clinic staff's state, instrument cart's state and patients' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: Detect patients and pillars and avoid door corners. \n Assumptions: The states of the agent and doors, curtains and partitions state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_goal < 0.3) else -3*dist_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Kindergarten. It must avoid colliding with enclosure coat rack or children. The states of the agent, goal, the door, and the children are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 25 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Kindergarten hallway. It must avoid colliding with toy carts. The states of the agent, goal, the toy cart are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_toy_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_toy_cart = calculate_distance_min(s_agent, s_toy_cart) \n    penalty_collision = -15 if (d_toy_cart < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten common room.\n Objectives: It must avoid colliding with toy box.\n Conditions: States of the agent and the toy box are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_toy_box, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tox_box = calculate_distance_min(s_agent, s_toy_box) \n    penalty_collision = -15 if (d_agent_tox_box < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Kindergarten corridor, the drone must maneuver around cubby areas. All entity states (agent, goal, cubby area) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_cubby_area, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cubby_area = calculate_distance_min(s_agent, s_cubby_area) \n    penalty_collision = -15 if (d_agent_cubby_area < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Kindergarten playroom.\nRequirement: Avoid collisions with toy carts.\n Given: The states for the agent and many toy carts are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 25 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Kindergarten entrance during an event. So not collide with coat rack. The states of the agent, goal, the coat rack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_coat_rack, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_rack = calculate_distance_min(s_agent, s_coat_rack) \n    penalty_collision = -15 if (d_agent_coat_rack < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Kindergarten without.\n Objectives: Do not collide hit with room divider, \n Conditions: States of the agent, room divider are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_room_divider, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_room_divider = calculate_distance_min(s_agent, s_room_divider) \n    penalty_collision = -15 if (d_room_divider < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Kindergarten playroom, the drone must steer clear of equipment towers. All states (agent, goal, ceiling fan) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ceiling_fan = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -15 if (d_agent_ceiling_fan < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Kindergarten reading nook.\n Avoid: Hitting with Kindergarten worker.\n Known: Agent, goal, Kindergarten worker states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_teacher, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -15 if (d_agent_teacher < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten. \n Objectives: It must avoid colliding with sanitizer station. \n Conditions: The states of the agent and the sanitizer station are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sanitizer_station, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sanitizer_station = calculate_distance_min(s_agent, s_sanitizer_station) \n    penalty_collision = -25 if (d_agent_sanitizer_station < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Kindergarten. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten. \n Objectives: It must avoid colliding with any cleaning cart, toy shelf and safety gate. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -25 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Kindergarten. \n Objectives: Do not collide with any Kindergarten staff. \n Conditions: The states of the agent and the Kindergarten staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_staff = calculate_distance_min(s_agent, s_staff) \n    penalty = -25 if (d_staff < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Kindergarten and must avoid contact with any toy carts. The states of the drone, goal and the toy carts are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_toy_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toy_cart = calculate_distance_min(s_agent, s_toy_cart) \n    penalty = -25 if (d_agent_toy_cart < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Kindergarten. It must avoid colliding with storage cabinets and low partition placed in the play area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Kindergarten. It must avoid colliding with rope divider and children. The states of the drone, goal and the multiple kindergarten obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Kindergarten. It must avoid colliding with Kindergarten staff. Agent's state, goal's state and Kindergarten staff's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -25 if (d_agent_staff < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: It must avoid colliding with service elevator. \n Assumptions: The states of the agent and the elevator are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -25 if (dist_elevator < 0.6) else 15 \n    reward_reaching_goal = 25 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: It must avoid colliding with Kindergarten staff, children and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Kindergarten staff's state, toy carts's state and children' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: Detect children and pillar and avoid door corners. \n Assumptions: The states of the agent and doors, curtains and partitions state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_goal < 0.3) else -3*dist_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Ship. It must avoid colliding with enclosure pipe rack or passengers. The states of the agent, goal, the door, and the passengers are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Ship corridor. It must avoid colliding with equipment carts. The states of the agent, goal, the equipment carts are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_signal_flag, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_signal_flag = calculate_distance_min(s_agent, s_signal_flag) \n    penalty_collision = -15 if (d_signal_flag < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship mess hall.\n Objectives: It must avoid colliding with cargo crate.\n Conditions: States of the agent and the cargo crate are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cargo_crate, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cargo_crate = calculate_distance_min(s_agent, s_cargo_crate) \n    penalty_collision = -15 if (d_agent_cargo_crate < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Ship corridor, the drone must maneuver around storage lockers. All entity states (agent, goal, storage lockers) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_storage_locker, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_locker = calculate_distance_min(s_agent, s_storage_locker) \n    penalty_collision = -15 if (d_agent_storage_locker < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Ship deck.\nRequirement: Avoid collisions with containers.\n Given: The states for the agent and many containers are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 25 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Ship gangway during an event. So not collide with the contanier. The states of the agent, goal, the container are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_container, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_container = calculate_distance_min(s_agent, s_container) \n    penalty_collision = -15 if (d_agent_container < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Ship without.\n Objectives: Do not collide hit with watertight door, \n Conditions: States of the agent, watertight door are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_watertight_door, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_watertight_door = calculate_distance_min(s_agent, s_watertight_door) \n    penalty_collision = -15 if (d_agent_watertight_door < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Ship deck, the drone must steer clear of ladders. All states (agent, goal, ladder) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ladder, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ladder = calculate_distance_min(s_agent, s_ladder) \n    penalty_collision = -15 if (d_agent_ladder < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Ship crew lounge.\n Avoid: Hitting with crew member.\n Known: Agent, goal, crew member states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_crew_member, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crew_member = calculate_distance_min(s_agent, s_crew_member) \n    penalty_collision = -15 if (d_agent_crew_member < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship. \n Objectives: It must avoid colliding with anchor chain. \n Conditions: The states of the agent and the anchor chain are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_anchor_chain, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_anchor_chain = calculate_distance_min(s_agent, s_anchor_chain) \n    penalty_collision = -25 if (d_agent_anchor_chain < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Ship. \n Objectives: Avoid collision with mooring bollards and capstans. \n Conditions: The states of the agent, goal, mooring bollards and capstans are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship. \n Objectives: It must avoid colliding with any maintenance cart, storage shelf and safety chain. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -25 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Ship. \n Objectives: Do not collide with any passenger. \n Conditions: The states of the agent and the passenger are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_passenger, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_passenger) \n    penalty = -25 if (d_agent_passenger < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Ship and must avoid contact with any signal flag. The states of the drone, goal and the signal flag are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_signal_flag, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signal_flag = calculate_distance_min(s_agent, s_signal_flag) \n    penalty = -25 if (d_agent_signal_flag < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Ship. It must avoid colliding with the multiple boxes in the work area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Ship. It must avoid colliding with mooring line and passengers. The states of the drone, goal and the mooring line and passengers are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Ship. It must avoid colliding with mast. Agent's state, goal's state and mast's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_mast, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mast = calculate_distance_min(s_agent, s_mast) \n    penalty_collision = -25 if (d_agent_mast < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: It must avoid colliding with halyard. \n Assumptions: The states of the agent and the halyard are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_halyard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_halyard = calculate_distance_min(s_agent, s_halyard) \n    penalty_collision = -25 if (dist_halyard < 0.6) else 10 \n    reward_reaching_goal = 25 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: It must avoid colliding with Ship crew, passengers and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Ship crew's state, equipment carts's state and passengers' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: Detect passengers and pillar and door corners and do not collide into them. \n Assumptions: The states of the agent and passengers and pillar and avoid door corner state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_goal < 0.3) else -3*dist_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Police station. It must avoid colliding with enclosure noticeboard or visitors. The states of the agent, goal, the door, and the visitors are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 19 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Police station hallway. It must avoid colliding with metal detector. The states of the agent, goal, the metal detector are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_metal_detector, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_metal_detector = calculate_distance_min(s_agent, s_metal_detector) \n    penalty_collision = -15 if (d_metal_detector < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station common room.\n Objectives: It must avoid colliding with weapon's rack.\n Conditions: States of the agent and the weapon's rack are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weapon_rack, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tox_box = calculate_distance_min(s_agent, s_weapon_rack) \n    penalty_collision = -15 if (d_agent_tox_box < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Police station corridor, the drone must maneuver around gear lockers. All entity states (agent, goal, gear lockers) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_gear_locker, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gear_locker = calculate_distance_min(s_agent, s_gear_locker) \n    penalty_collision = -15 if (d_agent_gear_locker < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Police station lobby.\nRequirement: Avoid collisions with handcuff board.\n Given: The states for the agent and many handcuff board are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 19 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Police station entrance during an event. So not collide with noticeboard. The states of the agent, goal, the noticeboard are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_noticeboard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_noticeboard = calculate_distance_min(s_agent, s_noticeboard) \n    penalty_collision = -15 if (d_agent_noticeboard < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Police station without.\n Objectives: Do not collide hit with security door, \n Conditions: States of the agent, security door are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_security_door, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_door = calculate_distance_min(s_agent, s_security_door) \n    penalty_collision = -15 if (d_agent_security_door < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Police station lobby, the drone must steer clear of folder. All states (agent, goal, folder) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_folder, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_folder = calculate_distance_min(s_agent, s_folder) \n    penalty_collision = -15 if (d_agent_folder < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Police station break room.\n Avoid: Hitting with officer.\n Known: Agent, goal, Police officer states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_officer, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_officer = calculate_distance_min(s_agent, s_officer) \n    penalty_collision = -15 if (d_agent_officer < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station. \n Objectives: It must avoid colliding with counters. \n Conditions: The states of the agent and a counter are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -19 if (d_agent_counter < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Police station. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station. \n Objectives: It must avoid colliding with any janitor cart, file shelf and barrier chain. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Police station. \n Objectives: Do not collide with any Police station staff. \n Conditions: The states of the agent and the Police station staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_staff = calculate_distance_min(s_agent, s_staff) \n    penalty = -19 if (d_staff < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Police station and must avoid contact with any handcuff board. The states of the drone, goal and the handcuff board are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_handcuff_board, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_handcuff_board = calculate_distance_min(s_agent, s_handcuff_board) \n    penalty = -19 if (d_agent_handcuff_board < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Police station. It must avoid colliding with gear lockers and visitors. The states of the drone, goal, gear lockers and visitor are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Police station. It must avoid colliding with barrier tape and visitors. The states of the drone, goal and the multiple Police station obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Police station. It must avoid colliding with pinboard. Agent's state, goal's state and pinboard's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_pinboard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pinboard = calculate_distance_min(s_agent, s_pinboard) \n    penalty_collision = -19 if (d_agent_pinboard < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: It must avoid colliding with training dummy. \n Assumptions: The states of the agent and the training dummy are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_training_dummy, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_training_dummyr = calculate_distance_min(s_agent, s_training_dummy) \n    penalty_collision = -19 if (dist_training_dummy < 0.6) else 15 \n    reward_reaching_goal = 19 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: It must avoid colliding with Police station staff, visitors and training dummy. \n Assumptions: The Agent's state, goal's state, Police station staff's state, handcuff board's state and visitors' states and training dummies state are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: Detect doors, curtains and door and do not collide with it. \n Assumptions: The states of the agent and doors, curtains and door state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -3*dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_goal < 0.3) else -3*dist_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the School bench. Agent's state, goal's state and School bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_school_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_park_bench = calculate_distance_min(s_agent, s_school_desk) \n    penalty_collision = -20 if (d_agent_park_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the trash bin. Agent's state, goal's state and trash bin's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -20 if (d_agent_trash_can < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's  bookshelf, School bench and glass door. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bookshelf, School bench, and glass door are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's backpack rack and trash bin. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, backpack rack, and trash bin are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the hallway pillar. Agent's state, goal's state and hallway pillar's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_hallway_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_hallway_pillar = calculate_distance_min(s_agent, s_hallway_pillar) \n    penalty_collision = -20 if (d_agent_hallway_pillar < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria table, hallway pillar and student. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria table, hallway pillar, and student are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's teacher and slide. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, teacher, and slide are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's swing and hallway pillar. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, swing, and hallway pillar are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bookshelf and student. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bookshelf, and student are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bicycle and teachers. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bicycle, and teachers are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the bulletin board. Agent's state, goal's state and bulletin board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bulletin_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bulletin_board = calculate_distance_min(s_agent, s_bulletin_board) \n    penalty_collision = -20 if (d_agent_bulletin_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the cafeteria table. Agent's state, goal's state and cafeteria table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cafeteria_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cafeteria_table = calculate_distance_min(s_agent, s_cafeteria_table) \n    penalty_collision = -20 if (d_agent_cafeteria_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bicycle and bicycle rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bicycle, and bicycle rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's trash bin and hallway barrier. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, trash bin, and hallway barrier are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's hallway barrier, teachers and bookshelf. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, hallway barrier teachers, and bookshelf are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's bulletin board, bicycle rack and stairwell railing. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bulletin board, bicycle rack and stairwell railing are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria table, trash bin and students. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria table, trash bin, and students are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's stairwell handrail, bulletin board and hallway signs. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, stairwell handrail, bulletin board and hallway signs are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's wheelchair and poster stand. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, wheelchair, and poster stand are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's lab table and monkey bars. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, lab table, and monkey bars are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's monkey bars, bulletin board and step ladder. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, monkey bars, bulletin board and step ladder are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's classroom partition and AC. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, classroom partition, and AC are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria cart and chair. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria cart, and chair are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's chair and school bus. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, chair, and school bus are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's school bus, gym rope and fire extinguisher. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, school bus, gym rope, and fire extinguisher are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the Tennis court courtside bench. Agent's state, goal's state and Tennis court courtside bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_courtside_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_courtside_bench = calculate_distance_min(s_agent, s_courtside_bench) \n    penalty_collision = -20 if (d_agent_courtside_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the ball basket. Agent's state, goal's state and ball basket's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball_basket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball_basket = calculate_distance_min(s_agent, s_ball_basket) \n    penalty_collision = -20 if (d_agent_ball_basket < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's  equipment rack, Tennis court courtside bench and court gate. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment rack, Tennis court courtside bench, and court gate are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's gear rack and ball basket. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, gear rack, and ball basket are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the net post. Agent's state, goal's state and net post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_net_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net_post = calculate_distance_min(s_agent, s_net_post) \n    penalty_collision = -20 if (d_agent_net_post < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's umpire courtside chair, net post and ball kid. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, umpire courtside chair, net post, and ball kid are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's coach and practice wall. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, coach, and practice wall are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's ball basket and net post. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball basket, and net post are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's equipment rack and ball kid. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment rack, and ball kid are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's utility cart and coaches. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, utility cart, and coaches are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the scoreboard. Agent's state, goal's state and scoreboard's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -20 if (d_agent_scoreboard < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the umpire courtside chair. Agent's state, goal's state and umpire courtside chair's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_umpire_chair) \n    penalty_collision = -20 if (d_agent_chair < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's utility cart and equipment rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, utility cart, and equipment rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's ball basket and court divider net. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball basket, and court divider net are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's court divider net, coaches and equipment rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, court divider net coaches, and equipment rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's scoreboard, equipment rack and perimeter fence. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, scoreboard, equipment rack and perimeter fence are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's umpire courtside chair, ball basket and ball crew. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, umpire courtside chair, ball basket, and ball crew are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's perimeter fence, scoreboard and court signs. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, perimeter fence, scoreboard and court signs are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's equipment trolley and signboard. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment trolley, and signboard are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's stringing table and gate. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, stringing table, and gate are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's gate, scoreboard and step ladder. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, gate, scoreboard and step ladder are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's windscreen and misting fan. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, windscreen, and misting fan are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's ball machine and courtside chair. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball machine, and courtside chair are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's courtside chair and Tennis court bus. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, courtside chair, and Tennis court bus are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's Tennis court bus, net strap and hydration station. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, Tennis court bus, net strap, and hydration station are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Dental clinic. It must avoid colliding with enclosure X-ray stand or patients. The states of the agent, goal, the door, and the patients are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Dental clinic concourse. It must avoid colliding with instrument cart. The states of the agent, goal, the instrument cartare known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_instrument_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_instrument_cart = calculate_distance_min(s_agent, s_instrument_cart) \n    penalty_collision = -15 if (d_instrument_cart < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic common room.\n Objectives: It must avoid colliding with supply box.\n Conditions: States of the agent and the supply box are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_supply_box, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_supply_box = calculate_distance_min(s_agent, s_supply_box) \n    penalty_collision = -15 if (d_agent_supply_box < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Dental clinic corridor, the drone must maneuver around receptions. All entity states (agent, goal, reception) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_reception, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception = calculate_distance_min(s_agent, s_reception) \n    penalty_collision = -15 if (d_agent_reception < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Dental clinic atrium.\nRequirement: Avoid collisions with instrument carts.\n Given: The states for the agent and many instrument carts are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Dental clinic entrance during an event. So not collide with X-ray stand. The states of the agent, goal, the X-ray stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_xray_stand, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_xray_stand = calculate_distance_min(s_agent, s_xray_stand) \n    penalty_collision = -15 if (d_agent_xray_stand < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Dental clinic without.\n Objectives: Do not collide hit with privacy curtain, \n Conditions: States of the agent, privacy curtain are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_privacy_curtain, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_privacy_curtain = calculate_distance_min(s_agent, s_privacy_curtain) \n    penalty_collision = -15 if (d_privacy_curtain < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Dental clinic atrium, the drone must steer clear of equipment towers. All states (agent, goal, ceiling fan) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -15 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Dental clinic lounge.\n Avoid: Hitting with Dental clinic worker.\n Known: Agent, goal, Dental clinic worker states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_dental_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dental_staff = calculate_distance_min(s_agent, s_dental_staff) \n    penalty_collision = -15 if (d_agent_dental_staff < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic. \n Objectives: It must avoid colliding with sterilization units. \n Conditions: The states of the agent and the sterilization units are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sterilization_unit, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_sterilization_unit) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Dental clinic. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic. \n Objectives: It must avoid colliding with any oxygen cylinder, supply rack and gate. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -20 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Dental clinic. \n Objectives: Do not collide with any Dental clinic staff. \n Conditions: The states of the agent and the Dental clinic staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_clinic_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_clinic_staff = calculate_distance_min(s_agent, s_clinic_staff) \n    penalty = -20 if (d_clinic_staff < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Dental clinic and must avoid contact with any instrument cart. The states of the drone, goal and the instrument cart are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_instrument_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cart = calculate_distance_min(s_agent, s_instrument_cart) \n    penalty = -20 if (d_agent_cart < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Dental clinic. It must avoid colliding with storage cabinets and glass partitions placed in the exam area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Dental clinic. It must avoid colliding with queue stanchions and patients. The states of the drone, goal and the multiple clinic obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Dental clinic. It must avoid colliding with Dental clinic staff. Agent's state, goal's state and Dental clinic staff's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_clinic_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_clinic_staff) \n    penalty_collision = -20 if (d_agent_staff < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: It must avoid colliding with service elevator. \n Assumptions: The states of the agent and the elevator are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -20 if (dist_elevator < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: It must avoid colliding with Dental clinic staff, patients and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Dental clinic staff's state, instrument cart's state and patients' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: Detect patients and pillars and avoid door corners. \n Assumptions: The states of the agent and doors, curtains and partitions state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_goal < 0.3) else -math.exp(dist_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Kindergarten. It must avoid colliding with enclosure coat rack or children. The states of the agent, goal, the door, and the children are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Kindergarten hallway. It must avoid colliding with toy carts. The states of the agent, goal, the toy cart are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_toy_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_toy_cart = calculate_distance_min(s_agent, s_toy_cart) \n    penalty_collision = -15 if (d_toy_cart < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten common room.\n Objectives: It must avoid colliding with toy box.\n Conditions: States of the agent and the toy box are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_toy_box, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tox_box = calculate_distance_min(s_agent, s_toy_box) \n    penalty_collision = -15 if (d_agent_tox_box < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Kindergarten corridor, the drone must maneuver around cubby areas. All entity states (agent, goal, cubby area) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_cubby_area, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cubby_area = calculate_distance_min(s_agent, s_cubby_area) \n    penalty_collision = -15 if (d_agent_cubby_area < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Kindergarten playroom.\nRequirement: Avoid collisions with toy carts.\n Given: The states for the agent and many toy carts are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Kindergarten entrance during an event. So not collide with coat rack. The states of the agent, goal, the coat rack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_coat_rack, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_rack = calculate_distance_min(s_agent, s_coat_rack) \n    penalty_collision = -15 if (d_agent_coat_rack < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Kindergarten without.\n Objectives: Do not collide hit with room divider, \n Conditions: States of the agent, room divider are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_room_divider, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_room_divider = calculate_distance_min(s_agent, s_room_divider) \n    penalty_collision = -15 if (d_room_divider < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Kindergarten playroom, the drone must steer clear of equipment towers. All states (agent, goal, ceiling fan) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ceiling_fan = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -15 if (d_agent_ceiling_fan < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Kindergarten reading nook.\n Avoid: Hitting with Kindergarten worker.\n Known: Agent, goal, Kindergarten worker states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_teacher, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -15 if (d_agent_teacher < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten. \n Objectives: It must avoid colliding with sanitizer station. \n Conditions: The states of the agent and the sanitizer station are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sanitizer_station, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sanitizer_station = calculate_distance_min(s_agent, s_sanitizer_station) \n    penalty_collision = -20 if (d_agent_sanitizer_station < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Kindergarten. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten. \n Objectives: It must avoid colliding with any cleaning cart, toy shelf and safety gate. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -20 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Kindergarten. \n Objectives: Do not collide with any Kindergarten staff. \n Conditions: The states of the agent and the Kindergarten staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_staff = calculate_distance_min(s_agent, s_staff) \n    penalty = -20 if (d_staff < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Kindergarten and must avoid contact with any toy carts. The states of the drone, goal and the toy carts are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_toy_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toy_cart = calculate_distance_min(s_agent, s_toy_cart) \n    penalty = -20 if (d_agent_toy_cart < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Kindergarten. It must avoid colliding with storage cabinets and low partition placed in the play area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Kindergarten. It must avoid colliding with rope divider and children. The states of the drone, goal and the multiple kindergarten obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Kindergarten. It must avoid colliding with Kindergarten staff. Agent's state, goal's state and Kindergarten staff's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -20 if (d_agent_staff < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: It must avoid colliding with service elevator. \n Assumptions: The states of the agent and the elevator are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -20 if (dist_elevator < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: It must avoid colliding with Kindergarten staff, children and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Kindergarten staff's state, toy carts's state and children' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: Detect children and pillar and avoid door corners. \n Assumptions: The states of the agent and doors, curtains and partitions state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_goal < 0.3) else -math.exp(dist_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Ship. It must avoid colliding with enclosure pipe rack or passengers. The states of the agent, goal, the door, and the passengers are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Ship corridor. It must avoid colliding with equipment carts. The states of the agent, goal, the equipment carts are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_signal_flag, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_signal_flag = calculate_distance_min(s_agent, s_signal_flag) \n    penalty_collision = -15 if (d_signal_flag < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship mess hall.\n Objectives: It must avoid colliding with cargo crate.\n Conditions: States of the agent and the cargo crate are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cargo_crate, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cargo_crate = calculate_distance_min(s_agent, s_cargo_crate) \n    penalty_collision = -15 if (d_agent_cargo_crate < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Ship corridor, the drone must maneuver around storage lockers. All entity states (agent, goal, storage lockers) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_storage_locker, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_locker = calculate_distance_min(s_agent, s_storage_locker) \n    penalty_collision = -15 if (d_agent_storage_locker < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Ship deck.\nRequirement: Avoid collisions with containers.\n Given: The states for the agent and many containers are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Ship gangway during an event. So not collide with the contanier. The states of the agent, goal, the container are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_container, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_container = calculate_distance_min(s_agent, s_container) \n    penalty_collision = -15 if (d_agent_container < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Ship without.\n Objectives: Do not collide hit with watertight door, \n Conditions: States of the agent, watertight door are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_watertight_door, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_watertight_door = calculate_distance_min(s_agent, s_watertight_door) \n    penalty_collision = -15 if (d_agent_watertight_door < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Ship deck, the drone must steer clear of ladders. All states (agent, goal, ladder) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ladder, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ladder = calculate_distance_min(s_agent, s_ladder) \n    penalty_collision = -15 if (d_agent_ladder < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Ship crew lounge.\n Avoid: Hitting with crew member.\n Known: Agent, goal, crew member states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_crew_member, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crew_member = calculate_distance_min(s_agent, s_crew_member) \n    penalty_collision = -15 if (d_agent_crew_member < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship. \n Objectives: It must avoid colliding with anchor chain. \n Conditions: The states of the agent and the anchor chain are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_anchor_chain, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_anchor_chain = calculate_distance_min(s_agent, s_anchor_chain) \n    penalty_collision = -20 if (d_agent_anchor_chain < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Ship. \n Objectives: Avoid collision with mooring bollards and capstans. \n Conditions: The states of the agent, goal, mooring bollards and capstans are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship. \n Objectives: It must avoid colliding with any maintenance cart, storage shelf and safety chain. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Ship. \n Objectives: Do not collide with any passenger. \n Conditions: The states of the agent and the passenger are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_passenger, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_passenger) \n    penalty = -20 if (d_agent_passenger < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Ship and must avoid contact with any signal flag. The states of the drone, goal and the signal flag are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_signal_flag, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signal_flag = calculate_distance_min(s_agent, s_signal_flag) \n    penalty = -20 if (d_agent_signal_flag < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Ship. It must avoid colliding with the multiple boxes in the work area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Ship. It must avoid colliding with mooring line and passengers. The states of the drone, goal and the mooring line and passengers are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Ship. It must avoid colliding with mast. Agent's state, goal's state and mast's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_mast, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mast = calculate_distance_min(s_agent, s_mast) \n    penalty_collision = -20 if (d_agent_mast < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: It must avoid colliding with halyard. \n Assumptions: The states of the agent and the halyard are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_halyard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_halyard = calculate_distance_min(s_agent, s_halyard) \n    penalty_collision = -20 if (dist_halyard < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: It must avoid colliding with Ship crew, passengers and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Ship crew's state, equipment carts's state and passengers' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: Detect passengers and pillar and door corners and do not collide into them. \n Assumptions: The states of the agent and passengers and pillar and avoid door corner state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_goal < 0.3) else -math.exp(dist_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Police station. It must avoid colliding with enclosure noticeboard or visitors. The states of the agent, goal, the door, and the visitors are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 19 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Police station hallway. It must avoid colliding with metal detector. The states of the agent, goal, the metal detector are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_metal_detector, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_metal_detector = calculate_distance_min(s_agent, s_metal_detector) \n    penalty_collision = -15 if (d_metal_detector < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station common room.\n Objectives: It must avoid colliding with weapon's rack.\n Conditions: States of the agent and the weapon's rack are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weapon_rack, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tox_box = calculate_distance_min(s_agent, s_weapon_rack) \n    penalty_collision = -15 if (d_agent_tox_box < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Police station corridor, the drone must maneuver around gear lockers. All entity states (agent, goal, gear lockers) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_gear_locker, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gear_locker = calculate_distance_min(s_agent, s_gear_locker) \n    penalty_collision = -15 if (d_agent_gear_locker < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Police station lobby.\nRequirement: Avoid collisions with handcuff board.\n Given: The states for the agent and many handcuff board are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 19 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Police station entrance during an event. So not collide with noticeboard. The states of the agent, goal, the noticeboard are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_noticeboard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_noticeboard = calculate_distance_min(s_agent, s_noticeboard) \n    penalty_collision = -15 if (d_agent_noticeboard < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Police station without.\n Objectives: Do not collide hit with security door, \n Conditions: States of the agent, security door are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_security_door, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_door = calculate_distance_min(s_agent, s_security_door) \n    penalty_collision = -15 if (d_agent_security_door < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Police station lobby, the drone must steer clear of folder. All states (agent, goal, folder) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_folder, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_folder = calculate_distance_min(s_agent, s_folder) \n    penalty_collision = -15 if (d_agent_folder < 0.6) else 15 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Police station break room.\n Avoid: Hitting with officer.\n Known: Agent, goal, Police officer states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_officer, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_officer = calculate_distance_min(s_agent, s_officer) \n    penalty_collision = -15 if (d_agent_officer < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station. \n Objectives: It must avoid colliding with counters. \n Conditions: The states of the agent and a counter are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -19 if (d_agent_counter < 0.6) else 4 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Police station. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station. \n Objectives: It must avoid colliding with any janitor cart, file shelf and barrier chain. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Police station. \n Objectives: Do not collide with any Police station staff. \n Conditions: The states of the agent and the Police station staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_staff = calculate_distance_min(s_agent, s_staff) \n    penalty = -19 if (d_staff < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Police station and must avoid contact with any handcuff board. The states of the drone, goal and the handcuff board are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_handcuff_board, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_handcuff_board = calculate_distance_min(s_agent, s_handcuff_board) \n    penalty = -19 if (d_agent_handcuff_board < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Police station. It must avoid colliding with gear lockers and visitors. The states of the drone, goal, gear lockers and visitor are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Police station. It must avoid colliding with barrier tape and visitors. The states of the drone, goal and the multiple Police station obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Police station. It must avoid colliding with pinboard. Agent's state, goal's state and pinboard's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_pinboard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pinboard = calculate_distance_min(s_agent, s_pinboard) \n    penalty_collision = -19 if (d_agent_pinboard < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: It must avoid colliding with training dummy. \n Assumptions: The states of the agent and the training dummy are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_training_dummy, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_training_dummyr = calculate_distance_min(s_agent, s_training_dummy) \n    penalty_collision = -19 if (dist_training_dummy < 0.6) else 15 \n    reward_reaching_goal = 19 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: It must avoid colliding with Police station staff, visitors and training dummy. \n Assumptions: The Agent's state, goal's state, Police station staff's state, handcuff board's state and visitors' states and training dummies state are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: Detect doors, curtains and door and do not collide with it. \n Assumptions: The states of the agent and doors, curtains and door state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 15 \n    reward_reaching_goal = 15 if (dist_goal < 0.3) else -math.exp(dist_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 15 if (d_goal < 0.3) else -math.exp(dist_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the School bench. Agent's state, goal's state and School bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_school_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_park_bench = calculate_distance_min(s_agent, s_school_desk) \n    penalty_collision = -20 if (d_agent_park_bench < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the trash bin. Agent's state, goal's state and trash bin's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -20 if (d_agent_trash_can < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's  bookshelf, School bench and glass door. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bookshelf, School bench, and glass door are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's backpack rack and trash bin. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, backpack rack, and trash bin are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the hallway pillar. Agent's state, goal's state and hallway pillar's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_hallway_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_hallway_pillar = calculate_distance_min(s_agent, s_hallway_pillar) \n    penalty_collision = -20 if (d_agent_hallway_pillar < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria table, hallway pillar and student. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria table, hallway pillar, and student are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's teacher and slide. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, teacher, and slide are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's swing and hallway pillar. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, swing, and hallway pillar are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bookshelf and student. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bookshelf, and student are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bicycle and teachers. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bicycle, and teachers are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the bulletin board. Agent's state, goal's state and bulletin board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bulletin_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bulletin_board = calculate_distance_min(s_agent, s_bulletin_board) \n    penalty_collision = -20 if (d_agent_bulletin_board < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the cafeteria table. Agent's state, goal's state and cafeteria table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cafeteria_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cafeteria_table = calculate_distance_min(s_agent, s_cafeteria_table) \n    penalty_collision = -20 if (d_agent_cafeteria_table < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bicycle and bicycle rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bicycle, and bicycle rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's trash bin and hallway barrier. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, trash bin, and hallway barrier are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's hallway barrier, teachers and bookshelf. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, hallway barrier teachers, and bookshelf are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's bulletin board, bicycle rack and stairwell railing. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bulletin board, bicycle rack and stairwell railing are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria table, trash bin and students. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria table, trash bin, and students are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's stairwell handrail, bulletin board and hallway signs. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, stairwell handrail, bulletin board and hallway signs are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's wheelchair and poster stand. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, wheelchair, and poster stand are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's lab table and monkey bars. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, lab table, and monkey bars are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's monkey bars, bulletin board and step ladder. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, monkey bars, bulletin board and step ladder are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's classroom partition and AC. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, classroom partition, and AC are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria cart and chair. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria cart, and chair are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's chair and school bus. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, chair, and school bus are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's school bus, gym rope and fire extinguisher. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, school bus, gym rope, and fire extinguisher are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the Tennis court courtside bench. Agent's state, goal's state and Tennis court courtside bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_courtside_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_courtside_bench = calculate_distance_min(s_agent, s_courtside_bench) \n    penalty_collision = -20 if (d_agent_courtside_bench < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the ball basket. Agent's state, goal's state and ball basket's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball_basket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball_basket = calculate_distance_min(s_agent, s_ball_basket) \n    penalty_collision = -20 if (d_agent_ball_basket < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's  equipment rack, Tennis court courtside bench and court gate. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment rack, Tennis court courtside bench, and court gate are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's gear rack and ball basket. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, gear rack, and ball basket are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the net post. Agent's state, goal's state and net post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_net_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net_post = calculate_distance_min(s_agent, s_net_post) \n    penalty_collision = -20 if (d_agent_net_post < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's umpire courtside chair, net post and ball kid. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, umpire courtside chair, net post, and ball kid are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's coach and practice wall. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, coach, and practice wall are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's ball basket and net post. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball basket, and net post are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's equipment rack and ball kid. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment rack, and ball kid are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's utility cart and coaches. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, utility cart, and coaches are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the scoreboard. Agent's state, goal's state and scoreboard's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -20 if (d_agent_scoreboard < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the umpire courtside chair. Agent's state, goal's state and umpire courtside chair's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_umpire_chair) \n    penalty_collision = -20 if (d_agent_chair < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's utility cart and equipment rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, utility cart, and equipment rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's ball basket and court divider net. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball basket, and court divider net are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's court divider net, coaches and equipment rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, court divider net coaches, and equipment rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's scoreboard, equipment rack and perimeter fence. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, scoreboard, equipment rack and perimeter fence are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's umpire courtside chair, ball basket and ball crew. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, umpire courtside chair, ball basket, and ball crew are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's perimeter fence, scoreboard and court signs. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, perimeter fence, scoreboard and court signs are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's equipment trolley and signboard. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment trolley, and signboard are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's stringing table and gate. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, stringing table, and gate are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's gate, scoreboard and step ladder. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, gate, scoreboard and step ladder are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's windscreen and misting fan. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, windscreen, and misting fan are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's ball machine and courtside chair. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball machine, and courtside chair are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's courtside chair and Tennis court bus. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, courtside chair, and Tennis court bus are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's Tennis court bus, net strap and hydration station. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, Tennis court bus, net strap, and hydration station are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -3**d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Dental clinic. It must avoid colliding with enclosure X-ray stand or patients. The states of the agent, goal, the door, and the patients are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Dental clinic concourse. It must avoid colliding with instrument cart. The states of the agent, goal, the instrument cartare known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_instrument_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_instrument_cart = calculate_distance_min(s_agent, s_instrument_cart) \n    penalty_collision = -10 if (d_instrument_cart < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic common room.\n Objectives: It must avoid colliding with supply box.\n Conditions: States of the agent and the supply box are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_supply_box, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_supply_box = calculate_distance_min(s_agent, s_supply_box) \n    penalty_collision = -10 if (d_agent_supply_box < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Dental clinic corridor, the drone must maneuver around receptions. All entity states (agent, goal, reception) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_reception, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception = calculate_distance_min(s_agent, s_reception) \n    penalty_collision = -10 if (d_agent_reception < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Dental clinic atrium.\nRequirement: Avoid collisions with instrument carts.\n Given: The states for the agent and many instrument carts are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Dental clinic entrance during an event. So not collide with X-ray stand. The states of the agent, goal, the X-ray stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_xray_stand, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_xray_stand = calculate_distance_min(s_agent, s_xray_stand) \n    penalty_collision = -10 if (d_agent_xray_stand < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Dental clinic without.\n Objectives: Do not collide hit with privacy curtain, \n Conditions: States of the agent, privacy curtain are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_privacy_curtain, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_privacy_curtain = calculate_distance_min(s_agent, s_privacy_curtain) \n    penalty_collision = -10 if (d_privacy_curtain < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Dental clinic atrium, the drone must steer clear of equipment towers. All states (agent, goal, ceiling fan) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -10 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Dental clinic lounge.\n Avoid: Hitting with Dental clinic worker.\n Known: Agent, goal, Dental clinic worker states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_dental_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dental_staff = calculate_distance_min(s_agent, s_dental_staff) \n    penalty_collision = -10 if (d_agent_dental_staff < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic. \n Objectives: It must avoid colliding with sterilization units. \n Conditions: The states of the agent and the sterilization units are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sterilization_unit, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_sterilization_unit) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Dental clinic. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic. \n Objectives: It must avoid colliding with any oxygen cylinder, supply rack and gate. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Dental clinic. \n Objectives: Do not collide with any Dental clinic staff. \n Conditions: The states of the agent and the Dental clinic staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_clinic_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_clinic_staff = calculate_distance_min(s_agent, s_clinic_staff) \n    penalty = -20 if (d_clinic_staff < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Dental clinic and must avoid contact with any instrument cart. The states of the drone, goal and the instrument cart are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_instrument_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cart = calculate_distance_min(s_agent, s_instrument_cart) \n    penalty = -20 if (d_agent_cart < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Dental clinic. It must avoid colliding with storage cabinets and glass partitions placed in the exam area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Dental clinic. It must avoid colliding with queue stanchions and patients. The states of the drone, goal and the multiple clinic obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Dental clinic. It must avoid colliding with Dental clinic staff. Agent's state, goal's state and Dental clinic staff's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_clinic_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_clinic_staff) \n    penalty_collision = -20 if (d_agent_staff < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: It must avoid colliding with service elevator. \n Assumptions: The states of the agent and the elevator are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -20 if (dist_elevator < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: It must avoid colliding with Dental clinic staff, patients and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Dental clinic staff's state, instrument cart's state and patients' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: Detect patients and pillars and avoid door corners. \n Assumptions: The states of the agent and doors, curtains and partitions state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_goal < 0.3) else -3**dist_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Kindergarten. It must avoid colliding with enclosure coat rack or children. The states of the agent, goal, the door, and the children are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Kindergarten hallway. It must avoid colliding with toy carts. The states of the agent, goal, the toy cart are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_toy_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_toy_cart = calculate_distance_min(s_agent, s_toy_cart) \n    penalty_collision = -10 if (d_toy_cart < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten common room.\n Objectives: It must avoid colliding with toy box.\n Conditions: States of the agent and the toy box are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_toy_box, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tox_box = calculate_distance_min(s_agent, s_toy_box) \n    penalty_collision = -10 if (d_agent_tox_box < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Kindergarten corridor, the drone must maneuver around cubby areas. All entity states (agent, goal, cubby area) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_cubby_area, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cubby_area = calculate_distance_min(s_agent, s_cubby_area) \n    penalty_collision = -10 if (d_agent_cubby_area < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Kindergarten playroom.\nRequirement: Avoid collisions with toy carts.\n Given: The states for the agent and many toy carts are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Kindergarten entrance during an event. So not collide with coat rack. The states of the agent, goal, the coat rack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_coat_rack, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_rack = calculate_distance_min(s_agent, s_coat_rack) \n    penalty_collision = -10 if (d_agent_coat_rack < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Kindergarten without.\n Objectives: Do not collide hit with room divider, \n Conditions: States of the agent, room divider are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_room_divider, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_room_divider = calculate_distance_min(s_agent, s_room_divider) \n    penalty_collision = -10 if (d_room_divider < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Kindergarten playroom, the drone must steer clear of equipment towers. All states (agent, goal, ceiling fan) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ceiling_fan = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -10 if (d_agent_ceiling_fan < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Kindergarten reading nook.\n Avoid: Hitting with Kindergarten worker.\n Known: Agent, goal, Kindergarten worker states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_teacher, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -10 if (d_agent_teacher < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten. \n Objectives: It must avoid colliding with sanitizer station. \n Conditions: The states of the agent and the sanitizer station are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sanitizer_station, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sanitizer_station = calculate_distance_min(s_agent, s_sanitizer_station) \n    penalty_collision = -20 if (d_agent_sanitizer_station < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Kindergarten. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten. \n Objectives: It must avoid colliding with any cleaning cart, toy shelf and safety gate. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Kindergarten. \n Objectives: Do not collide with any Kindergarten staff. \n Conditions: The states of the agent and the Kindergarten staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_staff = calculate_distance_min(s_agent, s_staff) \n    penalty = -20 if (d_staff < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Kindergarten and must avoid contact with any toy carts. The states of the drone, goal and the toy carts are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_toy_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toy_cart = calculate_distance_min(s_agent, s_toy_cart) \n    penalty = -20 if (d_agent_toy_cart < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Kindergarten. It must avoid colliding with storage cabinets and low partition placed in the play area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Kindergarten. It must avoid colliding with rope divider and children. The states of the drone, goal and the multiple kindergarten obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Kindergarten. It must avoid colliding with Kindergarten staff. Agent's state, goal's state and Kindergarten staff's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -20 if (d_agent_staff < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: It must avoid colliding with service elevator. \n Assumptions: The states of the agent and the elevator are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -20 if (dist_elevator < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: It must avoid colliding with Kindergarten staff, children and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Kindergarten staff's state, toy carts's state and children' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: Detect children and pillar and avoid door corners. \n Assumptions: The states of the agent and doors, curtains and partitions state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_goal < 0.3) else -3**dist_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Ship. It must avoid colliding with enclosure pipe rack or passengers. The states of the agent, goal, the door, and the passengers are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Ship corridor. It must avoid colliding with equipment carts. The states of the agent, goal, the equipment carts are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_signal_flag, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_signal_flag = calculate_distance_min(s_agent, s_signal_flag) \n    penalty_collision = -10 if (d_signal_flag < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship mess hall.\n Objectives: It must avoid colliding with cargo crate.\n Conditions: States of the agent and the cargo crate are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cargo_crate, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cargo_crate = calculate_distance_min(s_agent, s_cargo_crate) \n    penalty_collision = -10 if (d_agent_cargo_crate < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Ship corridor, the drone must maneuver around storage lockers. All entity states (agent, goal, storage lockers) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_storage_locker, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_locker = calculate_distance_min(s_agent, s_storage_locker) \n    penalty_collision = -10 if (d_agent_storage_locker < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Ship deck.\nRequirement: Avoid collisions with containers.\n Given: The states for the agent and many containers are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Ship gangway during an event. So not collide with the contanier. The states of the agent, goal, the container are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_container, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_container = calculate_distance_min(s_agent, s_container) \n    penalty_collision = -10 if (d_agent_container < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Ship without.\n Objectives: Do not collide hit with watertight door, \n Conditions: States of the agent, watertight door are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_watertight_door, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_watertight_door = calculate_distance_min(s_agent, s_watertight_door) \n    penalty_collision = -10 if (d_agent_watertight_door < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Ship deck, the drone must steer clear of ladders. All states (agent, goal, ladder) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ladder, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ladder = calculate_distance_min(s_agent, s_ladder) \n    penalty_collision = -10 if (d_agent_ladder < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Ship crew lounge.\n Avoid: Hitting with crew member.\n Known: Agent, goal, crew member states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_crew_member, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crew_member = calculate_distance_min(s_agent, s_crew_member) \n    penalty_collision = -10 if (d_agent_crew_member < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship. \n Objectives: It must avoid colliding with anchor chain. \n Conditions: The states of the agent and the anchor chain are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_anchor_chain, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_anchor_chain = calculate_distance_min(s_agent, s_anchor_chain) \n    penalty_collision = -20 if (d_agent_anchor_chain < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Ship. \n Objectives: Avoid collision with mooring bollards and capstans. \n Conditions: The states of the agent, goal, mooring bollards and capstans are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship. \n Objectives: It must avoid colliding with any maintenance cart, storage shelf and safety chain. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Ship. \n Objectives: Do not collide with any passenger. \n Conditions: The states of the agent and the passenger are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_passenger, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_passenger) \n    penalty = -20 if (d_agent_passenger < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Ship and must avoid contact with any signal flag. The states of the drone, goal and the signal flag are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_signal_flag, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signal_flag = calculate_distance_min(s_agent, s_signal_flag) \n    penalty = -20 if (d_agent_signal_flag < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Ship. It must avoid colliding with the multiple boxes in the work area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Ship. It must avoid colliding with mooring line and passengers. The states of the drone, goal and the mooring line and passengers are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Ship. It must avoid colliding with mast. Agent's state, goal's state and mast's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_mast, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mast = calculate_distance_min(s_agent, s_mast) \n    penalty_collision = -20 if (d_agent_mast < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: It must avoid colliding with halyard. \n Assumptions: The states of the agent and the halyard are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_halyard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_halyard = calculate_distance_min(s_agent, s_halyard) \n    penalty_collision = -20 if (dist_halyard < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: It must avoid colliding with Ship crew, passengers and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Ship crew's state, equipment carts's state and passengers' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: Detect passengers and pillar and door corners and do not collide into them. \n Assumptions: The states of the agent and passengers and pillar and avoid door corner state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_goal < 0.3) else -3**dist_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Police station. It must avoid colliding with enclosure noticeboard or visitors. The states of the agent, goal, the door, and the visitors are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 19 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Police station hallway. It must avoid colliding with metal detector. The states of the agent, goal, the metal detector are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_metal_detector, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_metal_detector = calculate_distance_min(s_agent, s_metal_detector) \n    penalty_collision = -10 if (d_metal_detector < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station common room.\n Objectives: It must avoid colliding with weapon's rack.\n Conditions: States of the agent and the weapon's rack are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weapon_rack, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tox_box = calculate_distance_min(s_agent, s_weapon_rack) \n    penalty_collision = -10 if (d_agent_tox_box < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Police station corridor, the drone must maneuver around gear lockers. All entity states (agent, goal, gear lockers) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_gear_locker, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gear_locker = calculate_distance_min(s_agent, s_gear_locker) \n    penalty_collision = -10 if (d_agent_gear_locker < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Police station lobby.\nRequirement: Avoid collisions with handcuff board.\n Given: The states for the agent and many handcuff board are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 19 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Police station entrance during an event. So not collide with noticeboard. The states of the agent, goal, the noticeboard are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_noticeboard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_noticeboard = calculate_distance_min(s_agent, s_noticeboard) \n    penalty_collision = -10 if (d_agent_noticeboard < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Police station without.\n Objectives: Do not collide hit with security door, \n Conditions: States of the agent, security door are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_security_door, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_door = calculate_distance_min(s_agent, s_security_door) \n    penalty_collision = -10 if (d_agent_security_door < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Police station lobby, the drone must steer clear of folder. All states (agent, goal, folder) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_folder, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_folder = calculate_distance_min(s_agent, s_folder) \n    penalty_collision = -10 if (d_agent_folder < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Police station break room.\n Avoid: Hitting with officer.\n Known: Agent, goal, Police officer states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_officer, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_officer = calculate_distance_min(s_agent, s_officer) \n    penalty_collision = -10 if (d_agent_officer < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station. \n Objectives: It must avoid colliding with counters. \n Conditions: The states of the agent and a counter are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -19 if (d_agent_counter < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Police station. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station. \n Objectives: It must avoid colliding with any janitor cart, file shelf and barrier chain. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Police station. \n Objectives: Do not collide with any Police station staff. \n Conditions: The states of the agent and the Police station staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_staff = calculate_distance_min(s_agent, s_staff) \n    penalty = -19 if (d_staff < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Police station and must avoid contact with any handcuff board. The states of the drone, goal and the handcuff board are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_handcuff_board, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_handcuff_board = calculate_distance_min(s_agent, s_handcuff_board) \n    penalty = -19 if (d_agent_handcuff_board < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Police station. It must avoid colliding with gear lockers and visitors. The states of the drone, goal, gear lockers and visitor are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Police station. It must avoid colliding with barrier tape and visitors. The states of the drone, goal and the multiple Police station obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Police station. It must avoid colliding with pinboard. Agent's state, goal's state and pinboard's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_pinboard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pinboard = calculate_distance_min(s_agent, s_pinboard) \n    penalty_collision = -19 if (d_agent_pinboard < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: It must avoid colliding with training dummy. \n Assumptions: The states of the agent and the training dummy are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_training_dummy, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_training_dummyr = calculate_distance_min(s_agent, s_training_dummy) \n    penalty_collision = -19 if (dist_training_dummy < 0.6) else 10 \n    reward_reaching_goal = 19 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: It must avoid colliding with Police station staff, visitors and training dummy. \n Assumptions: The Agent's state, goal's state, Police station staff's state, handcuff board's state and visitors' states and training dummies state are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: Detect doors, curtains and door and do not collide with it. \n Assumptions: The states of the agent and doors, curtains and door state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -3**dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_goal < 0.3) else -3**dist_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the School bench. Agent's state, goal's state and School bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_school_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_park_bench = calculate_distance_min(s_agent, s_school_desk) \n    penalty_collision = -20 if (d_agent_park_bench < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the trash bin. Agent's state, goal's state and trash bin's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -20 if (d_agent_trash_can < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's  bookshelf, School bench and glass door. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bookshelf, School bench, and glass door are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's backpack rack and trash bin. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, backpack rack, and trash bin are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the hallway pillar. Agent's state, goal's state and hallway pillar's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_hallway_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_hallway_pillar = calculate_distance_min(s_agent, s_hallway_pillar) \n    penalty_collision = -20 if (d_agent_hallway_pillar < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria table, hallway pillar and student. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria table, hallway pillar, and student are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's teacher and slide. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, teacher, and slide are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's swing and hallway pillar. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, swing, and hallway pillar are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bookshelf and student. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bookshelf, and student are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bicycle and teachers. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bicycle, and teachers are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the bulletin board. Agent's state, goal's state and bulletin board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bulletin_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bulletin_board = calculate_distance_min(s_agent, s_bulletin_board) \n    penalty_collision = -20 if (d_agent_bulletin_board < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the School. It must avoid colliding with the cafeteria table. Agent's state, goal's state and cafeteria table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cafeteria_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cafeteria_table = calculate_distance_min(s_agent, s_cafeteria_table) \n    penalty_collision = -20 if (d_agent_cafeteria_table < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's bicycle and bicycle rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bicycle, and bicycle rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's trash bin and hallway barrier. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, trash bin, and hallway barrier are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's hallway barrier, teachers and bookshelf. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, hallway barrier teachers, and bookshelf are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's bulletin board, bicycle rack and stairwell railing. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, bulletin board, bicycle rack and stairwell railing are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria table, trash bin and students. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria table, trash bin, and students are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's stairwell handrail, bulletin board and hallway signs. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, stairwell handrail, bulletin board and hallway signs are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's wheelchair and poster stand. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, wheelchair, and poster stand are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's lab table and monkey bars. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, lab table, and monkey bars are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's monkey bars, bulletin board and step ladder. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, monkey bars, bulletin board and step ladder are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's classroom partition and AC. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, classroom partition, and AC are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through School. \n Goal: It must avoid colliding with School's cafeteria cart and chair. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, cafeteria cart, and chair are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the School. \n Goal: It must avoid colliding with School's chair and school bus. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, chair, and school bus are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving School. \n Goal: It must avoid colliding with School's school bus, gym rope and fire extinguisher. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, school bus, gym rope, and fire extinguisher are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the Tennis court courtside bench. Agent's state, goal's state and Tennis court courtside bench's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_courtside_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_courtside_bench = calculate_distance_min(s_agent, s_courtside_bench) \n    penalty_collision = -20 if (d_agent_courtside_bench < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the ball basket. Agent's state, goal's state and ball basket's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball_basket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball_basket = calculate_distance_min(s_agent, s_ball_basket) \n    penalty_collision = -20 if (d_agent_ball_basket < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's  equipment rack, Tennis court courtside bench and court gate. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment rack, Tennis court courtside bench, and court gate are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's gear rack and ball basket. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, gear rack, and ball basket are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the net post. Agent's state, goal's state and net post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_net_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net_post = calculate_distance_min(s_agent, s_net_post) \n    penalty_collision = -20 if (d_agent_net_post < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's umpire courtside chair, net post and ball kid. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, umpire courtside chair, net post, and ball kid are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's coach and practice wall. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, coach, and practice wall are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's ball basket and net post. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball basket, and net post are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's equipment rack and ball kid. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment rack, and ball kid are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's utility cart and coaches. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, utility cart, and coaches are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the scoreboard. Agent's state, goal's state and scoreboard's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -20 if (d_agent_scoreboard < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in the Tennis court. It must avoid colliding with the umpire courtside chair. Agent's state, goal's state and umpire courtside chair's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_umpire_chair) \n    penalty_collision = -20 if (d_agent_chair < 0.7) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's utility cart and equipment rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, utility cart, and equipment rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's ball basket and court divider net. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball basket, and court divider net are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's court divider net, coaches and equipment rack. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, court divider net coaches, and equipment rack are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's scoreboard, equipment rack and perimeter fence. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, scoreboard, equipment rack and perimeter fence are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's umpire courtside chair, ball basket and ball crew. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, umpire courtside chair, ball basket, and ball crew are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's perimeter fence, scoreboard and court signs. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, perimeter fence, scoreboard and court signs are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's equipment trolley and signboard. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, equipment trolley, and signboard are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's stringing table and gate. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, stringing table, and gate are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's gate, scoreboard and step ladder. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, gate, scoreboard and step ladder are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's windscreen and misting fan. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, windscreen, and misting fan are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating through Tennis court. \n Goal: It must avoid colliding with Tennis court's ball machine and courtside chair. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, ball machine, and courtside chair are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is flying in the Tennis court. \n Goal: It must avoid colliding with Tennis court's courtside chair and Tennis court bus. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, courtside chair, and Tennis court bus are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is moving Tennis court. \n Goal: It must avoid colliding with Tennis court's Tennis court bus, net strap and hydration station. \n Assumptions: The Agent's state, goal's state and the states of the drone, goal, Tennis court bus, net strap, and hydration station are available. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Dental clinic. It must avoid colliding with enclosure X-ray stand or patients. The states of the agent, goal, the door, and the patients are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Dental clinic concourse. It must avoid colliding with instrument cart. The states of the agent, goal, the instrument cartare known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_instrument_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_instrument_cart = calculate_distance_min(s_agent, s_instrument_cart) \n    penalty_collision = -10 if (d_instrument_cart < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic common room.\n Objectives: It must avoid colliding with supply box.\n Conditions: States of the agent and the supply box are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_supply_box, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_supply_box = calculate_distance_min(s_agent, s_supply_box) \n    penalty_collision = -10 if (d_agent_supply_box < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Dental clinic corridor, the drone must maneuver around receptions. All entity states (agent, goal, reception) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_reception, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception = calculate_distance_min(s_agent, s_reception) \n    penalty_collision = -10 if (d_agent_reception < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Dental clinic atrium.\nRequirement: Avoid collisions with instrument carts.\n Given: The states for the agent and many instrument carts are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Dental clinic entrance during an event. So not collide with X-ray stand. The states of the agent, goal, the X-ray stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_xray_stand, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_xray_stand = calculate_distance_min(s_agent, s_xray_stand) \n    penalty_collision = -10 if (d_agent_xray_stand < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Dental clinic without.\n Objectives: Do not collide hit with privacy curtain, \n Conditions: States of the agent, privacy curtain are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_privacy_curtain, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_privacy_curtain = calculate_distance_min(s_agent, s_privacy_curtain) \n    penalty_collision = -10 if (d_privacy_curtain < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Dental clinic atrium, the drone must steer clear of equipment towers. All states (agent, goal, ceiling fan) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -10 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Dental clinic lounge.\n Avoid: Hitting with Dental clinic worker.\n Known: Agent, goal, Dental clinic worker states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_dental_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dental_staff = calculate_distance_min(s_agent, s_dental_staff) \n    penalty_collision = -10 if (d_agent_dental_staff < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic. \n Objectives: It must avoid colliding with sterilization units. \n Conditions: The states of the agent and the sterilization units are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sterilization_unit, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_sterilization_unit) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Dental clinic. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Dental clinic. \n Objectives: It must avoid colliding with any oxygen cylinder, supply rack and gate. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Dental clinic. \n Objectives: Do not collide with any Dental clinic staff. \n Conditions: The states of the agent and the Dental clinic staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_clinic_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_clinic_staff = calculate_distance_min(s_agent, s_clinic_staff) \n    penalty = -20 if (d_clinic_staff < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Dental clinic and must avoid contact with any instrument cart. The states of the drone, goal and the instrument cart are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_instrument_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cart = calculate_distance_min(s_agent, s_instrument_cart) \n    penalty = -20 if (d_agent_cart < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Dental clinic. It must avoid colliding with storage cabinets and glass partitions placed in the exam area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Dental clinic. It must avoid colliding with queue stanchions and patients. The states of the drone, goal and the multiple clinic obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Dental clinic. It must avoid colliding with Dental clinic staff. Agent's state, goal's state and Dental clinic staff's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_clinic_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_clinic_staff) \n    penalty_collision = -20 if (d_agent_staff < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: It must avoid colliding with service elevator. \n Assumptions: The states of the agent and the elevator are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -20 if (dist_elevator < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: It must avoid colliding with Dental clinic staff, patients and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Dental clinic staff's state, instrument cart's state and patients' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: Detect patients and pillars and avoid door corners. \n Assumptions: The states of the agent and doors, curtains and partitions state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_obs_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_obs_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Dental clinic. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_goal < 0.3) else -dist_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Kindergarten. It must avoid colliding with enclosure coat rack or children. The states of the agent, goal, the door, and the children are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Kindergarten hallway. It must avoid colliding with toy carts. The states of the agent, goal, the toy cart are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_toy_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_toy_cart = calculate_distance_min(s_agent, s_toy_cart) \n    penalty_collision = -10 if (d_toy_cart < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten common room.\n Objectives: It must avoid colliding with toy box.\n Conditions: States of the agent and the toy box are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_toy_box, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tox_box = calculate_distance_min(s_agent, s_toy_box) \n    penalty_collision = -10 if (d_agent_tox_box < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Kindergarten corridor, the drone must maneuver around cubby areas. All entity states (agent, goal, cubby area) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_cubby_area, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cubby_area = calculate_distance_min(s_agent, s_cubby_area) \n    penalty_collision = -10 if (d_agent_cubby_area < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Kindergarten playroom.\nRequirement: Avoid collisions with toy carts.\n Given: The states for the agent and many toy carts are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Kindergarten entrance during an event. So not collide with coat rack. The states of the agent, goal, the coat rack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_coat_rack, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_rack = calculate_distance_min(s_agent, s_coat_rack) \n    penalty_collision = -10 if (d_agent_coat_rack < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Kindergarten without.\n Objectives: Do not collide hit with room divider, \n Conditions: States of the agent, room divider are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_room_divider, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_room_divider = calculate_distance_min(s_agent, s_room_divider) \n    penalty_collision = -10 if (d_room_divider < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Kindergarten playroom, the drone must steer clear of equipment towers. All states (agent, goal, ceiling fan) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ceiling_fan = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -10 if (d_agent_ceiling_fan < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Kindergarten reading nook.\n Avoid: Hitting with Kindergarten worker.\n Known: Agent, goal, Kindergarten worker states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_teacher, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -10 if (d_agent_teacher < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten. \n Objectives: It must avoid colliding with sanitizer station. \n Conditions: The states of the agent and the sanitizer station are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sanitizer_station, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sanitizer_station = calculate_distance_min(s_agent, s_sanitizer_station) \n    penalty_collision = -20 if (d_agent_sanitizer_station < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Kindergarten. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Kindergarten. \n Objectives: It must avoid colliding with any cleaning cart, toy shelf and safety gate. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Kindergarten. \n Objectives: Do not collide with any Kindergarten staff. \n Conditions: The states of the agent and the Kindergarten staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_staff = calculate_distance_min(s_agent, s_staff) \n    penalty = -20 if (d_staff < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Kindergarten and must avoid contact with any toy carts. The states of the drone, goal and the toy carts are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_toy_cart, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toy_cart = calculate_distance_min(s_agent, s_toy_cart) \n    penalty = -20 if (d_agent_toy_cart < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Kindergarten. It must avoid colliding with storage cabinets and low partition placed in the play area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Kindergarten. It must avoid colliding with rope divider and children. The states of the drone, goal and the multiple kindergarten obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Kindergarten. It must avoid colliding with Kindergarten staff. Agent's state, goal's state and Kindergarten staff's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -20 if (d_agent_staff < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: It must avoid colliding with service elevator. \n Assumptions: The states of the agent and the elevator are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -20 if (dist_elevator < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: It must avoid colliding with Kindergarten staff, children and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Kindergarten staff's state, toy carts's state and children' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: Detect children and pillar and avoid door corners. \n Assumptions: The states of the agent and doors, curtains and partitions state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Kindergarten. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_goal < 0.3) else -dist_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Ship. It must avoid colliding with enclosure pipe rack or passengers. The states of the agent, goal, the door, and the passengers are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Ship corridor. It must avoid colliding with equipment carts. The states of the agent, goal, the equipment carts are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_signal_flag, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_signal_flag = calculate_distance_min(s_agent, s_signal_flag) \n    penalty_collision = -10 if (d_signal_flag < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship mess hall.\n Objectives: It must avoid colliding with cargo crate.\n Conditions: States of the agent and the cargo crate are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cargo_crate, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cargo_crate = calculate_distance_min(s_agent, s_cargo_crate) \n    penalty_collision = -10 if (d_agent_cargo_crate < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Ship corridor, the drone must maneuver around storage lockers. All entity states (agent, goal, storage lockers) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_storage_locker, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_locker = calculate_distance_min(s_agent, s_storage_locker) \n    penalty_collision = -10 if (d_agent_storage_locker < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Ship deck.\nRequirement: Avoid collisions with containers.\n Given: The states for the agent and many containers are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Ship gangway during an event. So not collide with the contanier. The states of the agent, goal, the container are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_container, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_container = calculate_distance_min(s_agent, s_container) \n    penalty_collision = -10 if (d_agent_container < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Ship without.\n Objectives: Do not collide hit with watertight door, \n Conditions: States of the agent, watertight door are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_watertight_door, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_watertight_door = calculate_distance_min(s_agent, s_watertight_door) \n    penalty_collision = -10 if (d_agent_watertight_door < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Ship deck, the drone must steer clear of ladders. All states (agent, goal, ladder) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_ladder, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ladder = calculate_distance_min(s_agent, s_ladder) \n    penalty_collision = -10 if (d_agent_ladder < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Ship crew lounge.\n Avoid: Hitting with crew member.\n Known: Agent, goal, crew member states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_crew_member, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crew_member = calculate_distance_min(s_agent, s_crew_member) \n    penalty_collision = -10 if (d_agent_crew_member < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship. \n Objectives: It must avoid colliding with anchor chain. \n Conditions: The states of the agent and the anchor chain are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_anchor_chain, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_anchor_chain = calculate_distance_min(s_agent, s_anchor_chain) \n    penalty_collision = -20 if (d_agent_anchor_chain < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Ship. \n Objectives: Avoid collision with mooring bollards and capstans. \n Conditions: The states of the agent, goal, mooring bollards and capstans are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Ship. \n Objectives: It must avoid colliding with any maintenance cart, storage shelf and safety chain. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Ship. \n Objectives: Do not collide with any passenger. \n Conditions: The states of the agent and the passenger are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_passenger, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_passenger) \n    penalty = -20 if (d_agent_passenger < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Ship and must avoid contact with any signal flag. The states of the drone, goal and the signal flag are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_signal_flag, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_signal_flag = calculate_distance_min(s_agent, s_signal_flag) \n    penalty = -20 if (d_agent_signal_flag < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Ship. It must avoid colliding with the multiple boxes in the work area. The states of the drone, goal and multiple boxes are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Ship. It must avoid colliding with mooring line and passengers. The states of the drone, goal and the mooring line and passengers are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Ship. It must avoid colliding with mast. Agent's state, goal's state and mast's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_mast, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mast = calculate_distance_min(s_agent, s_mast) \n    penalty_collision = -20 if (d_agent_mast < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: It must avoid colliding with halyard. \n Assumptions: The states of the agent and the halyard are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_halyard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_halyard = calculate_distance_min(s_agent, s_halyard) \n    penalty_collision = -20 if (dist_halyard < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: It must avoid colliding with Ship crew, passengers and RA maintenance carts. \n Assumptions: The Agent's state, goal's state, Ship crew's state, equipment carts's state and passengers' states are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: Detect passengers and pillar and door corners and do not collide into them. \n Assumptions: The states of the agent and passengers and pillar and avoid door corner state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Ship. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_goal < 0.3) else -dist_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Police station. It must avoid colliding with enclosure noticeboard or visitors. The states of the agent, goal, the door, and the visitors are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 19 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a busy Police station hallway. It must avoid colliding with metal detector. The states of the agent, goal, the metal detector are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_metal_detector, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_metal_detector = calculate_distance_min(s_agent, s_metal_detector) \n    penalty_collision = -10 if (d_metal_detector < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station common room.\n Objectives: It must avoid colliding with weapon's rack.\n Conditions: States of the agent and the weapon's rack are known.\n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weapon_rack, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tox_box = calculate_distance_min(s_agent, s_weapon_rack) \n    penalty_collision = -10 if (d_agent_tox_box < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Police station corridor, the drone must maneuver around gear lockers. All entity states (agent, goal, gear lockers) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_gear_locker, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gear_locker = calculate_distance_min(s_agent, s_gear_locker) \n    penalty_collision = -10 if (d_agent_gear_locker < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a Police station lobby.\nRequirement: Avoid collisions with handcuff board.\n Given: The states for the agent and many handcuff board are known.\n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 19 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone operates near a Police station entrance during an event. So not collide with noticeboard. The states of the agent, goal, the noticeboard are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_noticeboard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_noticeboard = calculate_distance_min(s_agent, s_noticeboard) \n    penalty_collision = -10 if (d_agent_noticeboard < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate a Police station without.\n Objectives: Do not collide hit with security door, \n Conditions: States of the agent, security door are available.\n Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_security_door, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_door = calculate_distance_min(s_agent, s_security_door) \n    penalty_collision = -10 if (d_agent_security_door < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Police station lobby, the drone must steer clear of folder. All states (agent, goal, folder) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_folder, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_folder = calculate_distance_min(s_agent, s_folder) \n    penalty_collision = -10 if (d_agent_folder < 0.6) else 10 \n    reward_reaching_goal = 20 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: \n Environment: Police station break room.\n Avoid: Hitting with officer.\n Known: Agent, goal, Police officer states.\n Create the Python reward function.",
        "chosen": "def reward(s_agent, s_officer, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_officer = calculate_distance_min(s_agent, s_officer) \n    penalty_collision = -10 if (d_agent_officer < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station. \n Objectives: It must avoid colliding with counters. \n Conditions: The states of the agent and a counter are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -19 if (d_agent_counter < 0.6) else 4 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Police station. \n Objectives: Avoid collision with swing door and cable cover. \n Conditions: The states of the agent, goal, swing door and cable cover are known. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacless_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Police station. \n Objectives: It must avoid colliding with any janitor cart, file shelf and barrier chain. \n Conditions: Agent's and all obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Police station. \n Objectives: Do not collide with any Police station staff. \n Conditions: The states of the agent and the Police station staff are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_staff = calculate_distance_min(s_agent, s_staff) \n    penalty = -19 if (d_staff < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating inside a Police station and must avoid contact with any handcuff board. The states of the drone, goal and the handcuff board are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_handcuff_board, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_handcuff_board = calculate_distance_min(s_agent, s_handcuff_board) \n    penalty = -19 if (d_agent_handcuff_board < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Police station. It must avoid colliding with gear lockers and visitors. The states of the drone, goal, gear lockers and visitor are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a Police station. It must avoid colliding with barrier tape and visitors. The states of the drone, goal and the multiple Police station obstacles are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a Police station. It must avoid colliding with pinboard. Agent's state, goal's state and pinboard's state are accessible. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_pinboard, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pinboard = calculate_distance_min(s_agent, s_pinboard) \n    penalty_collision = -19 if (d_agent_pinboard < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: It must avoid colliding with training dummy. \n Assumptions: The states of the agent and the training dummy are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_training_dummy, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    dist_training_dummyr = calculate_distance_min(s_agent, s_training_dummy) \n    penalty_collision = -19 if (dist_training_dummy < 0.6) else 10 \n    reward_reaching_goal = 19 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: It must avoid colliding with Police station staff, visitors and training dummy. \n Assumptions: The Agent's state, goal's state, Police station staff's state, handcuff board's state and visitors' states and training dummies state are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: Detect doors, curtains and door and do not collide with it. \n Assumptions: The states of the agent and doors, curtains and door state are availalbe. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    dist_goal = calculate_distance(s_agent, s_goal) \n    d_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_multiple_obstacles_min < 0.6) else 10 \n    reward_reaching_goal = 10 if (dist_goal < 0.3) else -dist_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Police station. \n Goal: Drone goal is to reach the goal. \n Assumptions: The states of the agent and the goal are known. \n Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_goal < 0.3) else -dist_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along play room. \n Objectives: It must avoid colliding with toy shelf or play room island. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the toy shelf and the play room island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy play room. \n Objectives: Detect train set and aviod it. \n Conditions: The states of the agent, goal, the train set are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_train_set, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_train_set  = calculate_distance_min(s_agent, s_train_set) \n    penalty_collision = -25 if (d_agent_automatic_train_set  < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a play room. Objectives: It must avoid colliding with slide. Conditions: States of the drone and the slide are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_slide, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_slide = calculate_distance_min(s_agent, s_slide) \n    penalty_collision = -25 if (d_agent_slide < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a play room, the drone must maneuver around play room island. All entity states (agent, goal, play room island) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_play_mat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_play_mst = calculate_distance_min(s_agent, s_play_mat) \n    penalty_collision = -25 if (d_agent_play_mst < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a play room. Requirement: Detect the three lego table and do not collide with it. Given: The states for the drone and multiple lego table are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a play room. \n Objectives: So not collide with toy shelf. \n Conditions: The states of the agent, goal, the toy shelf are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_toy_shelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toy_shelf = calculate_distance_min(s_agent, s_toy_shelf) \n    penalty_collision = -25 if (d_agent_toy_shelf < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate play room. Objectives: Do not collide hit with the game shelf. Conditions: States of the agent, game shelf are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_game_shelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_game_shelf = calculate_distance_min(s_agent, s_game_shelf) \n    penalty_collision = -25 if (d_agent_game_shelf < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a play room, the drone must steer clear of bean bag. All states (agent, goal, bean bag) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_bean_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bean_bag = calculate_distance_min(s_agent, s_bean_bag) \n    penalty_collision = -25 if (d_agent_bean_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: play room. Avoid: Detect bar rocking horse and do not hitting with bar rocking horse. Known: Agent, goal, bar rocking horse states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_rocking_horse, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rocking_horse = calculate_distance_min(s_agent, s_rocking_horse) \n    penalty_collision = -25 if (d_agent_rocking_horse < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating play room. Objectives: It must avoid colliding with child rocking_horse. Conditions: The states of the drone, goal and child rocking_horse are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_child_rocking_horse, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    dchild_rocking_horse_agent_child_rocking_horse = calculate_distance_min(s_agent, s_child_rocking_horse) \n    penalty_collision = -25 if (d_agent_child_rocking_horse < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through play room. Objectives: Avoid collision with game shelf, child rocking_horse and play room island. Conditions: The states of the agent and of the multiple obstacles: game shelf, child rocking_horse and play room island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating play room. Objectives: It must avoid colliding with any bar rocking horse, chalkboard. Conditions: Agent's and of the multiple obstacle: bar rocking horse, chalkboard states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through play room. Objectives: Do not collide with slide. Conditions: The states of the drone, goal and the stuffed animal are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stuffed_animal, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stuffed_animal = calculate_distance_min(s_agent, s_stuffed_animal) \n    penalty = -25 if (d_agent_stuffed_animal < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along play room and must avoid contact with the ball pit. The states of the drone, goal and the ball pit are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_ball_pit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball_pit = calculate_distance_min(s_agent, s_ball_pit) \n    penalty = -25 if (d_agent_ball_pit < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in play room. It must avoid colliding with the bar rocking horse, appliance front and toy robot. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and toy robot are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in play room. It must avoid colliding with the glass play room island and bar rocking horse. The states of the drone, goal and of the multiple obstacle: the glass play room island and bar rocking horse are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in play room. It must avoid colliding with the ceiling mobile. Agent's state, goal's state and ceiling mobile's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ceiling_mobile, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ceiling_mobile = calculate_distance_min(s_agent, s_ceiling_mobile) \n    penalty_collision = -25 if (d_agent_ceiling_mobile < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating play room. Goal: It must avoid colliding with ceiling mobile. Assumptions: The states of the drone, goal and the toy robot's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_toy_robot, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toy_robot = calculate_distance_min(s_agent, s_toy_robot) \n    penalty_collision = -25 if (d_agent_toy_robot < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating play room. Goal: It must avoid colliding with play room's building blocks, tent and glass bean bag. Assumptions: The Agent's state, goal's state and multiple obstacle's state: building blocks, fridge nook and glass bean bag are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating play room. Goal: Detect train set, train set and slide and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: children, train set and slide state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating play room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  A drone is operating along living room. \n Objectives:  It must avoid colliding with sofas or coffee tables. \n Conditions:  The states of the agent and the multiple obstacles are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  A drone is operating inside a busy living room. \n Objectives:  Detect sliding balcony door and aviod it. \n Conditions:  The states of the agent, goal, the sliding balcony door are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sliding_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sliding_door = calculate_distance_min(s_agent, s_sliding_door) \n    penalty_collision = -25 if (d_agent_sliding_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating living room open workoccupantce. Objectives: It must avoid colliding with doorway. Conditions: States of the drone and the doorway are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_doorway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doorway = calculate_distance_min(s_agent, s_doorway) \n    penalty_collision = -25 if (d_agent_doorway < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a living room, the drone must maneuver around coffee tables. All entity states (agent, goal, coffee tables) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_coffee_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_table = calculate_distance_min(s_agent, s_coffee_table) \n    penalty_collision = -25 if (d_agent_coffee_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a living room. Requirement: Detect the three side tables and do not collide with it. Given: The states for the drone and mmultiple tables are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  A drone operates near a living room. \n Objectives:  So not collide with TV stand. \n Conditions:  The states of the agent, goal, the TV stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_tv_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tv_stand = calculate_distance_min(s_agent, s_tv_stand) \n    penalty_collision = -25 if (d_agent_tv_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate living room. Objectives: Do not collide hit with the bookshelf. Conditions: States of the agent, bookshelf are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_bookshelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelf = calculate_distance_min(s_agent, s_bookshelf) \n    penalty_collision = -25 if (d_agent_bookshelf < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a living room, the drone must steer clear of wall. All states (agent, goal, glass cabinet) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_glass_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_cabinet = calculate_distance_min(s_agent, s_glass_cabinet) \n    penalty_collision = -25 if (d_agent_glass_cabinet < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: living room. Avoid: Detect floor lamp and do not hitting with floor lamp. Known: Agent, goal, floor lamp states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_floor_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_floor_lamp = calculate_distance_min(s_agent, s_floor_lamp) \n    penalty_collision = -25 if (d_agent_floor_lamp < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating living room. Objectives: It must avoid colliding with occupant. Conditions: The states of the drone, goal and occupant are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_occupant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_occupant = calculate_distance_min(s_agent, s_occupant) \n    penalty_collision = -25 if (d_agent_occupant < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through living room. Objectives: Avoid collision with bookshelf, occupants and staircase. Conditions: The states of the agent, goal, and multiple obstacles such as the bookshelf, occupants and staircase are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating living room. Objectives: It must avoid colliding with any floor lamp, wall unit and TV. Conditions: Agent's and of the multiple obstacles such as the floor lamp's, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through living room. Objectives: Do not collide with doorway. Conditions: The states of the drone, goal and the doorway are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_doorway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doorway = calculate_distance_min(s_agent, s_doorway) \n    penalty = -25 if (d_agent_doorway < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along living room and must avoid contact with the coat rack. The states of the drone, goal and the coat rack are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_coat_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_rack = calculate_distance_min(s_agent, s_coat_rack) \n    penalty = -25 if (d_agent_coat_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in living room. It must avoid colliding with the floor lamp, sliding balcony doors and window shutters. The states of the agent, goal, and multiple obstacles such as the potted plants near entrance, sliding balcony doors and window shutters are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in living room. It must avoid colliding with the glass coffee table and floor lamp. The states of the drone, goal and multiple obstacles such as the  the glass coffee table and floor lamp are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in living room. It must avoid colliding with the curtains. Agent's state, goal's state and curtains's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -25 if (d_agent_curtain < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: It must avoid colliding with drapery. Assumptions: The states of the drone, goal and the drapery's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_drapery, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drapery = calculate_distance_min(s_agent, s_drapery) \n    penalty_collision = -25 if (d_agent_drapery < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: It must avoid colliding with living room's potted plant, hallway entrance and glass room divider. Assumptions: The Agent's state, goal's state, potted plant, hallway entrance and glass room divider's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: Detect ottoman, sliding balcony door and doorway and do not collide. Assumptions: The states of the drone, goal, ottoman, sliding balcony door and doorway state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating along kitchen. Objectives: \n It must avoid colliding with refrigerator or kitchen island. Conditions: \n The states of the agent, goal, and of the other multiple obstacöes e.g. the refrigerator and the kitchen island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating inside a busy kitchen. Objectives: \n Detect oven and aviod it. Conditions: \n The states of the agent, goal, the oven are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_oven, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_oven = calculate_distance_min(s_agent, s_oven) \n    penalty_collision = -25 if (d_agent_automatic_oven < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a kitchen. Objectives: It must avoid colliding with sink. Conditions: States of the drone and the sink are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sink, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sink = calculate_distance_min(s_agent, s_sink) \n    penalty_collision = -25 if (d_agent_sink < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a kitchen, the drone must maneuver around kitchen island. All entity states (agent, goal, kitchen island) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_kitchen_island, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kitchen_island = calculate_distance_min(s_agent, s_kitchen_island) \n    penalty_collision = -25 if (d_agent_kitchen_island < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a kitchen. Requirement: Detect the three countertop edge and do not collide with it. Given: The states for the drone and multiple countertop edge are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone operates near a kitchen. Objectives: \n So not collide with dishwasher. Conditions: \n The states of the agent, goal, the dishwasher are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_dishwasher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dishwasher = calculate_distance_min(s_agent, s_dishwasher) \n    penalty_collision = -25 if (d_agent_dishwasher < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate kitchen. Objectives: Do not collide hit with the pantry cabinet. Conditions: States of the agent, pantry cabinet are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_pantry_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pantry_cabinet = calculate_distance_min(s_agent, s_pantry_cabinet) \n    penalty_collision = -25 if (d_agent_pantry_cabinet < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a kitchen, the drone must steer clear of backsplash. All states (agent, goal, backsplash) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_backsplash, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backsplash = calculate_distance_min(s_agent, s_backsplash) \n    penalty_collision = -25 if (d_agent_backsplash < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: kitchen. Avoid: Detect bar stool and do not hitting with bar stool. Known: Agent, goal, bar stool states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_stool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stool = calculate_distance_min(s_agent, s_stool) \n    penalty_collision = -25 if (d_agent_stool < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating kitchen. Objectives: It must avoid colliding with dining chair. Conditions: The states of the drone, goal and dining chair are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dining_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_chair = calculate_distance_min(s_agent, s_dining_chair) \n    penalty_collision = -25 if (d_agent_dining_chair < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through kitchen. Objectives: Avoid collision with pantry cabinet, dining chair and kitchen island. Conditions: The states of the agent and of the multiple obstacles: pantry cabinet, dining chair and kitchen island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating kitchen. Objectives: It must avoid colliding with any bar stool, range and hood. Conditions: Agent's and of the multiple obstacle: bar stool, range and hood states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through kitchen. Objectives: Do not collide with sink. Conditions: The states of the drone, goal and the blender are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_blender, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blender = calculate_distance_min(s_agent, s_blender) \n    penalty = -25 if (d_agent_blender < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along kitchen and must avoid contact with the trash bin. The states of the drone, goal and the trash bin are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty = -25 if (d_agent_trash_bin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in kitchen. It must avoid colliding with the bar stool, appliance front and microwave. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and microwave are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in kitchen. It must avoid colliding with the glass kitchen island and bar stool. The states of the drone, goal and of the multiple obstacle: the glass kitchen island and bar stool are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in kitchen. It must avoid colliding with the pendant light. Agent's state, goal's state and pendant light's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_pendant_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pendant_light = calculate_distance_min(s_agent, s_pendant_light) \n    penalty_collision = -25 if (d_agent_pendant_light < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: It must avoid colliding with pendant light. Assumptions: The states of the drone, goal and the microwave's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_microwave, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microwave = calculate_distance_min(s_agent, s_microwave) \n    penalty_collision = -25 if (d_agent_microwave < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: It must avoid colliding with kitchen's pet bowl, breakfast nook and glass backsplash. Assumptions: The Agent's state, goal's state and multiple obstacle's state: pet bowl, fridge nook and glass backsplash are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: Detect rolling cart, oven and sink and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: stove, oven and sink state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating along dining area. Objectives: \n It must avoid colliding with dining table or dining area island. Conditions: \n The states of the agent, goal, and of the other multiple obstaces e.g. the dining table and the dining area island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating inside a dining area. Objectives: \n Detect serving trolley and aviod it. Conditions: \n The states of the agent, goal, the serving trolley are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_serving_trolley, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_serving_trolley = calculate_distance_min(s_agent, s_serving_trolley) \n    penalty_collision = -25 if (d_agent_serving_trolley < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a dining area. Objectives: It must avoid colliding with fireplace. Conditions: States of the drone and the fireplace are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fireplace, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fireplace = calculate_distance_min(s_agent, s_fireplace) \n    penalty_collision = -25 if (d_agent_fireplace < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a dining area, the drone must maneuver around dining area island. All entity states (agent, goal, dining area island) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_island, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_island = calculate_distance_min(s_agent, s_island) \n    penalty_collision = -25 if (d_agent_island < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a dining area. Requirement: Detect the three buffet cabinet and do not collide with it. Given: The states for the drone and multiple obstacle state such as buffet cabinet are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone operates near a dining area. Objectives: \n So not collide with wine rack. Conditions: \n The states of the agent, goal, the wine rack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_wine_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wine_rack = calculate_distance_min(s_agent, s_wine_rack) \n    penalty_collision = -25 if (d_agent_wine_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate dining area. Objectives: Do not collide hit with the china cabinet. Conditions: States of the agent, cabinet are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabinet = calculate_distance_min(s_agent, s_cabinet) \n    penalty_collision = -25 if (d_agent_cabinet < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a dining area, the drone must steer clear of mirror. All states (agent, goal, mirror) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_mirror, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mirror = calculate_distance_min(s_agent, s_mirror) \n    penalty_collision = -25 if (d_agent_mirror < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: dining area. Avoid: Detect bar armchair and do not hitting with bar armchair. Known: Agent, goal, bar armchair states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_armchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_armchair = calculate_distance_min(s_agent, s_armchair) \n    penalty_collision = -25 if (d_agent_armchair < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating dining area. Objectives: It must avoid colliding with high chair. Conditions: The states of the drone, goal and high chair are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_high_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_high_chair = calculate_distance_min(s_agent, s_high_chair) \n    penalty_collision = -25 if (d_agent_high_chair < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through dining area. Objectives: Avoid collision with china cabinet, high chair and dining area island. Conditions: The states of the agent and of the multiple obstacles: china cabinet, high chair and dining area island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating dining area. Objectives: It must avoid colliding with any bar armchair, wall painting. Conditions: Agent's and of the multiple obstacle: bar armchair, wall painting states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through dining area. Objectives: Do not collide with fireplace. Conditions: The states of the drone, goal and the picture are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_picture, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_picture = calculate_distance_min(s_agent, s_picture) \n    penalty = -25 if (d_agent_picture < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along dining area and must avoid contact with the vase. The states of the drone, goal and the vase are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_vase, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vase = calculate_distance_min(s_agent, s_vase) \n    penalty = -25 if (d_agent_vase < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in dining area. It must avoid colliding with the bar armchair, appliance front and candelabra. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and candelabra are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in dining area. It must avoid colliding with the glass dining area island and bar armchair. The states of the drone, goal and of the multiple obstacle: the glass dining area island and bar armchair are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in dining area. It must avoid colliding with the chandelier. Agent's state, goal's state and chandelier's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chandelier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chandelier = calculate_distance_min(s_agent, s_chandelier) \n    penalty_collision = -25 if (d_agent_chandelier < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: It must avoid colliding with chandelier. Assumptions: The states of the drone, goal and the candelabra's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_candelabra, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_candelabra = calculate_distance_min(s_agent, s_candelabra) \n    penalty_collision = -25 if (d_agent_candelabra < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: It must avoid colliding with dining area's centerpiece, alcove seating and glass mirror. Assumptions: The Agent's state, goal's state and multiple obstacle's state: centerpiece, fridge nook and glass mirror are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: Detect serving trolley, serving trolley and fireplace and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: stove, serving trolley and fireplace state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along gaming room. \n Objectives: It must avoid colliding with gaming footrest or gaming table. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the gaming footrest and the gaming table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy gaming room. \n Objectives: Detect controller dock and aviod it. \n Conditions: The states of the agent, goal, the controller dock are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_controller_dock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_controller_dock = calculate_distance_min(s_agent, s_controller_dock) \n    penalty_collision = -25 if (d_agent_automatic_controller_dock < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a gaming room. Objectives: It must avoid colliding with speaker tower. Conditions: States of the drone and the speaker tower are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_speaker_tower, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker_tower = calculate_distance_min(s_agent, s_speaker_tower) \n    penalty_collision = -25 if (d_agent_speaker_tower < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a gaming room, the drone must maneuver around console stand. All entity states (agent, goal, console stand) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_console_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_console_stand = calculate_distance_min(s_agent, s_console_stand) \n    penalty_collision = -25 if (d_agent_console_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a gaming room. Requirement: Detect the three arcade machine and do not collide with it. Given: The states for the drone and multiple arcade machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a gaming room. \n Objectives: So not collide with VR headset stand. \n Conditions: The states of the agent, goal, the VR headset stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_vr_headset_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vr_headset_stand = calculate_distance_min(s_agent, s_vr_headset_stand) \n    penalty_collision = -25 if (d_agent_vr_headset_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate gaming room. Objectives: Do not collide hit with the gaming PC. Conditions: States of the agent, gaming PC are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_gaming_pc, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gaming_pc = calculate_distance_min(s_agent, s_gaming_pc) \n    penalty_collision = -25 if (d_agent_gaming_pc < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a gaming room, the drone must steer clear of monitor stand. All states (agent, goal, monitor stand) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_monitor_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_monitor_stand = calculate_distance_min(s_agent, s_monitor_stand) \n    penalty_collision = -25 if (d_agent_monitor_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: gaming room. Avoid: Detect bar cable bundle and do not hitting with bar cable bundle. Known: Agent, goal, bar cable bundle states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cable_bundle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable_bundle = calculate_distance_min(s_agent, s_cable_bundle) \n    penalty_collision = -25 if (d_agent_cable_bundle < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating gaming room. Objectives: It must avoid colliding with footrest. Conditions: The states of the drone, goal and footrest are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_footrest, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_footrest = calculate_distance_min(s_agent, s_footrest) \n    penalty_collision = -25 if (d_agent_dining_footrest < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through gaming room. Objectives: Avoid collision with gaming PC, footrest and gaming table. Conditions: The states of the agent and of the multiple obstacles: gaming PC, footrest and gaming table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating gaming room. Objectives: It must avoid colliding with any bar cable bundle, projector screen. Conditions: Agent's and of the multiple obstacle: bar cable bundle, projector screen states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through gaming room. Objectives: Do not collide with speaker tower. Conditions: The states of the drone, goal and the speaker tower are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_speaker_tower, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker_tower = calculate_distance_min(s_agent, s_speaker_tower) \n    penalty = -25 if (d_agent_speaker_tower < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along gaming room and must avoid contact with the subwoofer. The states of the drone, goal and the subwoofer are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_subwoofer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_subwoofer = calculate_distance_min(s_agent, s_subwoofer) \n    penalty = -25 if (d_agent_subwoofer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in gaming room. It must avoid colliding with the bar cable bundle, appliance front and LED light strip. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and LED light strip are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in gaming room. It must avoid colliding with the glass gaming table and bar cable bundle. The states of the drone, goal and of the multiple obstacle: the glass gaming table and bar cable bundle are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in gaming room. It must avoid colliding with the ceiling fan. Agent's state, goal's state and ceiling fan's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ceiling_fan = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -25 if (d_agent_ceiling_fan < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: It must avoid colliding with ceiling fan. Assumptions: The states of the drone, goal and the LED light strip's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_led_light_strip, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_led_light_strip = calculate_distance_min(s_agent, s_led_light_strip) \n    penalty_collision = -25 if (d_agent_led_light_strip < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: It must avoid colliding with gaming room's game controller, gaming desk and glass monitor stand. Assumptions: The Agent's state, goal's state and multiple obstacle's state: game controller, computer nook and monitor stand are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: Detect controller dock, controller dock and speaker tower and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: plant, controller dock and speaker tower state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along garage. \n Objectives: It must avoid colliding with gaming jack stand or work table. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the gaming jack stand and the work table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy garage. \n Objectives: Detect oil can and aviod it. \n Conditions: The states of the agent, goal, the oil can are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_oil_can, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_oil_can = calculate_distance_min(s_agent, s_oil_can) \n    penalty_collision = -25 if (d_agent_automatic_oil_can < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a garage. Objectives: It must avoid colliding with air compressor. Conditions: States of the drone and the air compressor are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_air_compressor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_air_compressor = calculate_distance_min(s_agent, s_air_compressor) \n    penalty_collision = -25 if (d_agent_air_compressor < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a garage, the drone must maneuver around workbench. All entity states (agent, goal, workbench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_workbench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_workbench = calculate_distance_min(s_agent, s_workbench) \n    penalty_collision = -25 if (d_agent_workbench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a garage. Requirement: Detect the three tool chest and do not collide with it. Given: The states for the drone and multiple tool chest are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a garage. \n Objectives: So not collide with ladder. \n Conditions: The states of the agent, goal, the ladder are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_ladder, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ladder = calculate_distance_min(s_agent, s_ladder) \n    penalty_collision = -25 if (d_agent_ladder < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate garage. Objectives: Do not collide hit with the generator. Conditions: States of the agent, generator are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_generator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_generator = calculate_distance_min(s_agent, s_generator) \n    penalty_collision = -25 if (d_agent_generator < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a garage, the drone must steer clear of bike. All states (agent, goal, bike) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_bike, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bike = calculate_distance_min(s_agent, s_bike) \n    penalty_collision = -25 if (d_agent_bike < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: garage. Avoid: Detect bar extension cord and do not hitting with bar extension cord. Known: Agent, goal, bar extension cord states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_extension_cord, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_extension_cord = calculate_distance_min(s_agent, s_extension_cord) \n    penalty_collision = -25 if (d_agent_extension_cord < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating garage. Objectives: It must avoid colliding with jack stand. Conditions: The states of the drone, goal and jack stand are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_jack_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_jack_stand = calculate_distance_min(s_agent, s_jack_stand) \n    penalty_collision = -25 if (d_agent_jack_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through garage. Objectives: Avoid collision with generator, jack stand and work table. Conditions: The states of the agent and of the multiple obstacles: generator, jack stand and work table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating garage. Objectives: It must avoid colliding with any bar extension cord, garage door motor. Conditions: Agent's and of the multiple obstacle: bar extension cord, garage door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through garage. Objectives: Do not collide with air compressor. Conditions: The states of the drone, goal and the air compressor are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_air_compressor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_air_compressor = calculate_distance_min(s_agent, s_air_compressor) \n    penalty = -25 if (d_agent_air_compressor < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along garage and must avoid contact with the storage box. The states of the drone, goal and the storage box are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_storage_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_box = calculate_distance_min(s_agent, s_storage_box) \n    penalty = -25 if (d_agent_storage_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in garage. It must avoid colliding with the bar extension cord, appliance front and spare tire. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and spare tire are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in garage. It must avoid colliding with the glass work table and bar extension cord. The states of the drone, goal and of the multiple obstacle: the glass work table and bar extension cord are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in garage. It must avoid colliding with the overhead light. Agent's state, goal's state and overhead light's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_overhead_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_overhead_light = calculate_distance_min(s_agent, s_overhead_light) \n    penalty_collision = -25 if (d_agent_overhead_light < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: It must avoid colliding with overhead light. Assumptions: The states of the drone, goal and the spare tire's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_spare_tire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spare_tire = calculate_distance_min(s_agent, s_spare_tire) \n    penalty_collision = -25 if (d_agent_spare_tire < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: It must avoid colliding with garage's paint cans, sawhorse and glass bike. Assumptions: The Agent's state, goal's state and multiple obstacle's state: paint cans, computer nook and bike are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: Detect oil can, oil can and air compressor and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: plant, oil can and air compressor state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  A drone is operating along living room. \n Objectives:  It must avoid colliding with sofas or coffee tables. \n Conditions:  The states of the agent and the multiple obstacles are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  A drone is operating inside a busy living room. \n Objectives:  Detect sliding balcony door and aviod it. \n Conditions:  The states of the agent, goal, the sliding balcony door are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sliding_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sliding_door = calculate_distance_min(s_agent, s_sliding_door) \n    penalty_collision = -20 if (d_agent_sliding_door < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating living room open workoccupantce. Objectives: It must avoid colliding with doorway. Conditions: States of the drone and the doorway are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_doorway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doorway = calculate_distance_min(s_agent, s_doorway) \n    penalty_collision = -20 if (d_agent_doorway < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a living room, the drone must maneuver around coffee tables. All entity states (agent, goal, coffee tables) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_coffee_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_table = calculate_distance_min(s_agent, s_coffee_table) \n    penalty_collision = -20 if (d_agent_coffee_table < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a living room. Requirement: Detect the three side tables and do not collide with it. Given: The states for the drone and mmultiple tables are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  A drone operates near a living room. \n Objectives:  So not collide with TV stand. \n Conditions:  The states of the agent, goal, the TV stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_tv_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tv_stand = calculate_distance_min(s_agent, s_tv_stand) \n    penalty_collision = -20 if (d_agent_tv_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate living room. Objectives: Do not collide hit with the bookshelf. Conditions: States of the agent, bookshelf are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_bookshelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelf = calculate_distance_min(s_agent, s_bookshelf) \n    penalty_collision = -20 if (d_agent_bookshelf < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a living room, the drone must steer clear of wall. All states (agent, goal, glass cabinet) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_glass_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_cabinet = calculate_distance_min(s_agent, s_glass_cabinet) \n    penalty_collision = -20 if (d_agent_glass_cabinet < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: living room. Avoid: Detect floor lamp and do not hitting with floor lamp. Known: Agent, goal, floor lamp states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_floor_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_floor_lamp = calculate_distance_min(s_agent, s_floor_lamp) \n    penalty_collision = -20 if (d_agent_floor_lamp < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating living room. Objectives: It must avoid colliding with occupant. Conditions: The states of the drone, goal and occupant are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_occupant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_occupant = calculate_distance_min(s_agent, s_occupant) \n    penalty_collision = -20 if (d_agent_occupant < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through living room. Objectives: Avoid collision with bookshelf, occupants and staircase. Conditions: The states of the agent, goal, and multiple obstacles such as the bookshelf, occupants and staircase are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating living room. Objectives: It must avoid colliding with any floor lamp, wall unit and TV. Conditions: Agent's and of the multiple obstacles such as the floor lamp's, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through living room. Objectives: Do not collide with doorway. Conditions: The states of the drone, goal and the doorway are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_doorway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doorway = calculate_distance_min(s_agent, s_doorway) \n    penalty = -20 if (d_agent_doorway < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along living room and must avoid contact with the coat rack. The states of the drone, goal and the coat rack are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_coat_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_rack = calculate_distance_min(s_agent, s_coat_rack) \n    penalty = -20 if (d_agent_coat_rack < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in living room. It must avoid colliding with the floor lamp, sliding balcony doors and window shutters. The states of the agent, goal, and multiple obstacles such as the potted plants near entrance, sliding balcony doors and window shutters are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in living room. It must avoid colliding with the glass coffee table and floor lamp. The states of the drone, goal and multiple obstacles such as the  the glass coffee table and floor lamp are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in living room. It must avoid colliding with the curtains. Agent's state, goal's state and curtains's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -20 if (d_agent_curtain < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: It must avoid colliding with drapery. Assumptions: The states of the drone, goal and the drapery's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_drapery, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drapery = calculate_distance_min(s_agent, s_drapery) \n    penalty_collision = -20 if (d_agent_drapery < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: It must avoid colliding with living room's potted plant, hallway entrance and glass room divider. Assumptions: The Agent's state, goal's state, potted plant, hallway entrance and glass room divider's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: Detect ottoman, sliding balcony door and doorway and do not collide. Assumptions: The states of the drone, goal, ottoman, sliding balcony door and doorway state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating along kitchen. Objectives: \n It must avoid colliding with refrigerator or kitchen island. Conditions: \n The states of the agent, goal, and of the other multiple obstacöes e.g. the refrigerator and the kitchen island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating inside a busy kitchen. Objectives: \n Detect oven and aviod it. Conditions: \n The states of the agent, goal, the oven are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_oven, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_oven = calculate_distance_min(s_agent, s_oven) \n    penalty_collision = -20 if (d_agent_automatic_oven < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a kitchen. Objectives: It must avoid colliding with sink. Conditions: States of the drone and the sink are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sink, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sink = calculate_distance_min(s_agent, s_sink) \n    penalty_collision = -20 if (d_agent_sink < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a kitchen, the drone must maneuver around kitchen island. All entity states (agent, goal, kitchen island) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_kitchen_island, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kitchen_island = calculate_distance_min(s_agent, s_kitchen_island) \n    penalty_collision = -20 if (d_agent_kitchen_island < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a kitchen. Requirement: Detect the three countertop edge and do not collide with it. Given: The states for the drone and multiple countertop edge are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone operates near a kitchen. Objectives: \n So not collide with dishwasher. Conditions: \n The states of the agent, goal, the dishwasher are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_dishwasher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dishwasher = calculate_distance_min(s_agent, s_dishwasher) \n    penalty_collision = -20 if (d_agent_dishwasher < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate kitchen. Objectives: Do not collide hit with the pantry cabinet. Conditions: States of the agent, pantry cabinet are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_pantry_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pantry_cabinet = calculate_distance_min(s_agent, s_pantry_cabinet) \n    penalty_collision = -20 if (d_agent_pantry_cabinet < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a kitchen, the drone must steer clear of backsplash. All states (agent, goal, backsplash) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_backsplash, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backsplash = calculate_distance_min(s_agent, s_backsplash) \n    penalty_collision = -20 if (d_agent_backsplash < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: kitchen. Avoid: Detect bar stool and do not hitting with bar stool. Known: Agent, goal, bar stool states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_stool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stool = calculate_distance_min(s_agent, s_stool) \n    penalty_collision = -20 if (d_agent_stool < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating kitchen. Objectives: It must avoid colliding with dining chair. Conditions: The states of the drone, goal and dining chair are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dining_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_chair = calculate_distance_min(s_agent, s_dining_chair) \n    penalty_collision = -20 if (d_agent_dining_chair < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through kitchen. Objectives: Avoid collision with pantry cabinet, dining chair and kitchen island. Conditions: The states of the agent and of the multiple obstacles: pantry cabinet, dining chair and kitchen island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating kitchen. Objectives: It must avoid colliding with any bar stool, range and hood. Conditions: Agent's and of the multiple obstacle: bar stool, range and hood states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through kitchen. Objectives: Do not collide with sink. Conditions: The states of the drone, goal and the blender are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_blender, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blender = calculate_distance_min(s_agent, s_blender) \n    penalty = -20 if (d_agent_blender < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along kitchen and must avoid contact with the trash bin. The states of the drone, goal and the trash bin are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty = -20 if (d_agent_trash_bin < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in kitchen. It must avoid colliding with the bar stool, appliance front and microwave. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and microwave are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in kitchen. It must avoid colliding with the glass kitchen island and bar stool. The states of the drone, goal and of the multiple obstacle: the glass kitchen island and bar stool are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in kitchen. It must avoid colliding with the pendant light. Agent's state, goal's state and pendant light's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_pendant_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pendant_light = calculate_distance_min(s_agent, s_pendant_light) \n    penalty_collision = -20 if (d_agent_pendant_light < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: It must avoid colliding with pendant light. Assumptions: The states of the drone, goal and the microwave's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_microwave, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microwave = calculate_distance_min(s_agent, s_microwave) \n    penalty_collision = -20 if (d_agent_microwave < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: It must avoid colliding with kitchen's pet bowl, breakfast nook and glass backsplash. Assumptions: The Agent's state, goal's state and multiple obstacle's state: pet bowl, fridge nook and glass backsplash are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: Detect rolling cart, oven and sink and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: stove, oven and sink state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating along dining area. Objectives: \n It must avoid colliding with dining table or dining area island. Conditions: \n The states of the agent, goal, and of the other multiple obstaces e.g. the dining table and the dining area island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating inside a dining area. Objectives: \n Detect serving trolley and aviod it. Conditions: \n The states of the agent, goal, the serving trolley are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_serving_trolley, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_serving_trolley = calculate_distance_min(s_agent, s_serving_trolley) \n    penalty_collision = -20 if (d_agent_serving_trolley < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a dining area. Objectives: It must avoid colliding with fireplace. Conditions: States of the drone and the fireplace are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fireplace, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fireplace = calculate_distance_min(s_agent, s_fireplace) \n    penalty_collision = -20 if (d_agent_fireplace < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a dining area, the drone must maneuver around dining area island. All entity states (agent, goal, dining area island) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_island, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_island = calculate_distance_min(s_agent, s_island) \n    penalty_collision = -20 if (d_agent_island < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a dining area. Requirement: Detect the three buffet cabinet and do not collide with it. Given: The states for the drone and multiple obstacle state such as buffet cabinet are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone operates near a dining area. Objectives: \n So not collide with wine rack. Conditions: \n The states of the agent, goal, the wine rack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_wine_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wine_rack = calculate_distance_min(s_agent, s_wine_rack) \n    penalty_collision = -20 if (d_agent_wine_rack < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate dining area. Objectives: Do not collide hit with the china cabinet. Conditions: States of the agent, cabinet are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabinet = calculate_distance_min(s_agent, s_cabinet) \n    penalty_collision = -20 if (d_agent_cabinet < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a dining area, the drone must steer clear of mirror. All states (agent, goal, mirror) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_mirror, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mirror = calculate_distance_min(s_agent, s_mirror) \n    penalty_collision = -20 if (d_agent_mirror < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: dining area. Avoid: Detect bar armchair and do not hitting with bar armchair. Known: Agent, goal, bar armchair states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_armchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_armchair = calculate_distance_min(s_agent, s_armchair) \n    penalty_collision = -20 if (d_agent_armchair < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating dining area. Objectives: It must avoid colliding with high chair. Conditions: The states of the drone, goal and high chair are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_high_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_high_chair = calculate_distance_min(s_agent, s_high_chair) \n    penalty_collision = -20 if (d_agent_high_chair < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through dining area. Objectives: Avoid collision with china cabinet, high chair and dining area island. Conditions: The states of the agent and of the multiple obstacles: china cabinet, high chair and dining area island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating dining area. Objectives: It must avoid colliding with any bar armchair, wall painting. Conditions: Agent's and of the multiple obstacle: bar armchair, wall painting states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through dining area. Objectives: Do not collide with fireplace. Conditions: The states of the drone, goal and the picture are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_picture, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_picture = calculate_distance_min(s_agent, s_picture) \n    penalty = -20 if (d_agent_picture < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along dining area and must avoid contact with the vase. The states of the drone, goal and the vase are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_vase, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vase = calculate_distance_min(s_agent, s_vase) \n    penalty = -20 if (d_agent_vase < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in dining area. It must avoid colliding with the bar armchair, appliance front and candelabra. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and candelabra are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in dining area. It must avoid colliding with the glass dining area island and bar armchair. The states of the drone, goal and of the multiple obstacle: the glass dining area island and bar armchair are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in dining area. It must avoid colliding with the chandelier. Agent's state, goal's state and chandelier's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chandelier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chandelier = calculate_distance_min(s_agent, s_chandelier) \n    penalty_collision = -20 if (d_agent_chandelier < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: It must avoid colliding with chandelier. Assumptions: The states of the drone, goal and the candelabra's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_candelabra, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_candelabra = calculate_distance_min(s_agent, s_candelabra) \n    penalty_collision = -20 if (d_agent_candelabra < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: It must avoid colliding with dining area's centerpiece, alcove seating and glass mirror. Assumptions: The Agent's state, goal's state and multiple obstacle's state: centerpiece, fridge nook and glass mirror are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: Detect serving trolley, serving trolley and fireplace and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: stove, serving trolley and fireplace state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along gaming room. \n Objectives: It must avoid colliding with gaming footrest or gaming table. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the gaming footrest and the gaming table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy gaming room. \n Objectives: Detect controller dock and aviod it. \n Conditions: The states of the agent, goal, the controller dock are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_controller_dock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_controller_dock = calculate_distance_min(s_agent, s_controller_dock) \n    penalty_collision = -20 if (d_agent_automatic_controller_dock < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a gaming room. Objectives: It must avoid colliding with speaker tower. Conditions: States of the drone and the speaker tower are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_speaker_tower, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker_tower = calculate_distance_min(s_agent, s_speaker_tower) \n    penalty_collision = -20 if (d_agent_speaker_tower < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a gaming room, the drone must maneuver around console stand. All entity states (agent, goal, console stand) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_console_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_console_stand = calculate_distance_min(s_agent, s_console_stand) \n    penalty_collision = -20 if (d_agent_console_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a gaming room. Requirement: Detect the three arcade machine and do not collide with it. Given: The states for the drone and multiple arcade machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a gaming room. \n Objectives: So not collide with VR headset stand. \n Conditions: The states of the agent, goal, the VR headset stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_vr_headset_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vr_headset_stand = calculate_distance_min(s_agent, s_vr_headset_stand) \n    penalty_collision = -20 if (d_agent_vr_headset_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate gaming room. Objectives: Do not collide hit with the gaming PC. Conditions: States of the agent, gaming PC are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_gaming_pc, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gaming_pc = calculate_distance_min(s_agent, s_gaming_pc) \n    penalty_collision = -20 if (d_agent_gaming_pc < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a gaming room, the drone must steer clear of monitor stand. All states (agent, goal, monitor stand) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_monitor_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_monitor_stand = calculate_distance_min(s_agent, s_monitor_stand) \n    penalty_collision = -20 if (d_agent_monitor_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: gaming room. Avoid: Detect bar cable bundle and do not hitting with bar cable bundle. Known: Agent, goal, bar cable bundle states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cable_bundle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable_bundle = calculate_distance_min(s_agent, s_cable_bundle) \n    penalty_collision = -20 if (d_agent_cable_bundle < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating gaming room. Objectives: It must avoid colliding with footrest. Conditions: The states of the drone, goal and footrest are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_footrest, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_footrest = calculate_distance_min(s_agent, s_footrest) \n    penalty_collision = -20 if (d_agent_dining_footrest < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through gaming room. Objectives: Avoid collision with gaming PC, footrest and gaming table. Conditions: The states of the agent and of the multiple obstacles: gaming PC, footrest and gaming table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating gaming room. Objectives: It must avoid colliding with any bar cable bundle, projector screen. Conditions: Agent's and of the multiple obstacle: bar cable bundle, projector screen states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through gaming room. Objectives: Do not collide with speaker tower. Conditions: The states of the drone, goal and the speaker tower are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_speaker_tower, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker_tower = calculate_distance_min(s_agent, s_speaker_tower) \n    penalty = -20 if (d_agent_speaker_tower < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along gaming room and must avoid contact with the subwoofer. The states of the drone, goal and the subwoofer are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_subwoofer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_subwoofer = calculate_distance_min(s_agent, s_subwoofer) \n    penalty = -20 if (d_agent_subwoofer < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in gaming room. It must avoid colliding with the bar cable bundle, appliance front and LED light strip. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and LED light strip are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in gaming room. It must avoid colliding with the glass gaming table and bar cable bundle. The states of the drone, goal and of the multiple obstacle: the glass gaming table and bar cable bundle are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in gaming room. It must avoid colliding with the ceiling fan. Agent's state, goal's state and ceiling fan's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ceiling_fan = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -20 if (d_agent_ceiling_fan < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: It must avoid colliding with ceiling fan. Assumptions: The states of the drone, goal and the LED light strip's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_led_light_strip, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_led_light_strip = calculate_distance_min(s_agent, s_led_light_strip) \n    penalty_collision = -20 if (d_agent_led_light_strip < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: It must avoid colliding with gaming room's game controller, gaming desk and glass monitor stand. Assumptions: The Agent's state, goal's state and multiple obstacle's state: game controller, computer nook and monitor stand are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: Detect controller dock, controller dock and speaker tower and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: plant, controller dock and speaker tower state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along garage. \n Objectives: It must avoid colliding with gaming jack stand or work table. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the gaming jack stand and the work table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy garage. \n Objectives: Detect oil can and aviod it. \n Conditions: The states of the agent, goal, the oil can are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_oil_can, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_oil_can = calculate_distance_min(s_agent, s_oil_can) \n    penalty_collision = -20 if (d_agent_automatic_oil_can < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a garage. Objectives: It must avoid colliding with air compressor. Conditions: States of the drone and the air compressor are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_air_compressor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_air_compressor = calculate_distance_min(s_agent, s_air_compressor) \n    penalty_collision = -20 if (d_agent_air_compressor < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a garage, the drone must maneuver around workbench. All entity states (agent, goal, workbench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_workbench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_workbench = calculate_distance_min(s_agent, s_workbench) \n    penalty_collision = -20 if (d_agent_workbench < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a garage. Requirement: Detect the three tool chest and do not collide with it. Given: The states for the drone and multiple tool chest are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a garage. \n Objectives: So not collide with ladder. \n Conditions: The states of the agent, goal, the ladder are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_ladder, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ladder = calculate_distance_min(s_agent, s_ladder) \n    penalty_collision = -20 if (d_agent_ladder < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate garage. Objectives: Do not collide hit with the generator. Conditions: States of the agent, generator are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_generator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_generator = calculate_distance_min(s_agent, s_generator) \n    penalty_collision = -20 if (d_agent_generator < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a garage, the drone must steer clear of bike. All states (agent, goal, bike) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_bike, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bike = calculate_distance_min(s_agent, s_bike) \n    penalty_collision = -20 if (d_agent_bike < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: garage. Avoid: Detect bar extension cord and do not hitting with bar extension cord. Known: Agent, goal, bar extension cord states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_extension_cord, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_extension_cord = calculate_distance_min(s_agent, s_extension_cord) \n    penalty_collision = -20 if (d_agent_extension_cord < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating garage. Objectives: It must avoid colliding with jack stand. Conditions: The states of the drone, goal and jack stand are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_jack_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_jack_stand = calculate_distance_min(s_agent, s_jack_stand) \n    penalty_collision = -20 if (d_agent_jack_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through garage. Objectives: Avoid collision with generator, jack stand and work table. Conditions: The states of the agent and of the multiple obstacles: generator, jack stand and work table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating garage. Objectives: It must avoid colliding with any bar extension cord, garage door motor. Conditions: Agent's and of the multiple obstacle: bar extension cord, garage door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through garage. Objectives: Do not collide with air compressor. Conditions: The states of the drone, goal and the air compressor are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_air_compressor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_air_compressor = calculate_distance_min(s_agent, s_air_compressor) \n    penalty = -20 if (d_agent_air_compressor < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along garage and must avoid contact with the storage box. The states of the drone, goal and the storage box are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_storage_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_box = calculate_distance_min(s_agent, s_storage_box) \n    penalty = -20 if (d_agent_storage_box < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in garage. It must avoid colliding with the bar extension cord, appliance front and spare tire. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and spare tire are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in garage. It must avoid colliding with the glass work table and bar extension cord. The states of the drone, goal and of the multiple obstacle: the glass work table and bar extension cord are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in garage. It must avoid colliding with the overhead light. Agent's state, goal's state and overhead light's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_overhead_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_overhead_light = calculate_distance_min(s_agent, s_overhead_light) \n    penalty_collision = -20 if (d_agent_overhead_light < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: It must avoid colliding with overhead light. Assumptions: The states of the drone, goal and the spare tire's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_spare_tire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spare_tire = calculate_distance_min(s_agent, s_spare_tire) \n    penalty_collision = -20 if (d_agent_spare_tire < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: It must avoid colliding with garage's paint cans, sawhorse and glass bike. Assumptions: The Agent's state, goal's state and multiple obstacle's state: paint cans, computer nook and bike are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: Detect oil can, oil can and air compressor and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: plant, oil can and air compressor state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  A drone is operating along living room. \n Objectives:  It must avoid colliding with sofas or coffee tables. \n Conditions:  The states of the agent and the multiple obstacles are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  A drone is operating inside a busy living room. \n Objectives:  Detect sliding balcony door and aviod it. \n Conditions:  The states of the agent, goal, the sliding balcony door are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sliding_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sliding_door = calculate_distance_min(s_agent, s_sliding_door) \n    penalty_collision = -20 if (d_agent_sliding_door < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating living room open workoccupantce. Objectives: It must avoid colliding with doorway. Conditions: States of the drone and the doorway are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_doorway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doorway = calculate_distance_min(s_agent, s_doorway) \n    penalty_collision = -20 if (d_agent_doorway < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a living room, the drone must maneuver around coffee tables. All entity states (agent, goal, coffee tables) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_coffee_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_table = calculate_distance_min(s_agent, s_coffee_table) \n    penalty_collision = -20 if (d_agent_coffee_table < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a living room. Requirement: Detect the three side tables and do not collide with it. Given: The states for the drone and mmultiple tables are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  A drone operates near a living room. \n Objectives:  So not collide with TV stand. \n Conditions:  The states of the agent, goal, the TV stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_tv_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tv_stand = calculate_distance_min(s_agent, s_tv_stand) \n    penalty_collision = -20 if (d_agent_tv_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate living room. Objectives: Do not collide hit with the bookshelf. Conditions: States of the agent, bookshelf are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_bookshelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelf = calculate_distance_min(s_agent, s_bookshelf) \n    penalty_collision = -20 if (d_agent_bookshelf < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a living room, the drone must steer clear of wall. All states (agent, goal, glass cabinet) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_glass_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_cabinet = calculate_distance_min(s_agent, s_glass_cabinet) \n    penalty_collision = -20 if (d_agent_glass_cabinet < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: living room. Avoid: Detect floor lamp and do not hitting with floor lamp. Known: Agent, goal, floor lamp states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_floor_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_floor_lamp = calculate_distance_min(s_agent, s_floor_lamp) \n    penalty_collision = -20 if (d_agent_floor_lamp < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating living room. Objectives: It must avoid colliding with occupant. Conditions: The states of the drone, goal and occupant are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_occupant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_occupant = calculate_distance_min(s_agent, s_occupant) \n    penalty_collision = -20 if (d_agent_occupant < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through living room. Objectives: Avoid collision with bookshelf, occupants and staircase. Conditions: The states of the agent, goal, and multiple obstacles such as the bookshelf, occupants and staircase are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating living room. Objectives: It must avoid colliding with any floor lamp, wall unit and TV. Conditions: Agent's and of the multiple obstacles such as the floor lamp's, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through living room. Objectives: Do not collide with doorway. Conditions: The states of the drone, goal and the doorway are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_doorway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doorway = calculate_distance_min(s_agent, s_doorway) \n    penalty = -20 if (d_agent_doorway < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along living room and must avoid contact with the coat rack. The states of the drone, goal and the coat rack are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_coat_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_rack = calculate_distance_min(s_agent, s_coat_rack) \n    penalty = -20 if (d_agent_coat_rack < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in living room. It must avoid colliding with the floor lamp, sliding balcony doors and window shutters. The states of the agent, goal, and multiple obstacles such as the potted plants near entrance, sliding balcony doors and window shutters are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in living room. It must avoid colliding with the glass coffee table and floor lamp. The states of the drone, goal and multiple obstacles such as the  the glass coffee table and floor lamp are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in living room. It must avoid colliding with the curtains. Agent's state, goal's state and curtains's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -20 if (d_agent_curtain < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: It must avoid colliding with drapery. Assumptions: The states of the drone, goal and the drapery's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_drapery, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drapery = calculate_distance_min(s_agent, s_drapery) \n    penalty_collision = -20 if (d_agent_drapery < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: It must avoid colliding with living room's potted plant, hallway entrance and glass room divider. Assumptions: The Agent's state, goal's state, potted plant, hallway entrance and glass room divider's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: Detect ottoman, sliding balcony door and doorway and do not collide. Assumptions: The states of the drone, goal, ottoman, sliding balcony door and doorway state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating along kitchen. Objectives: \n It must avoid colliding with refrigerator or kitchen island. Conditions: \n The states of the agent, goal, and of the other multiple obstacöes e.g. the refrigerator and the kitchen island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating inside a busy kitchen. Objectives: \n Detect oven and aviod it. Conditions: \n The states of the agent, goal, the oven are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_oven, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_oven = calculate_distance_min(s_agent, s_oven) \n    penalty_collision = -20 if (d_agent_automatic_oven < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a kitchen. Objectives: It must avoid colliding with sink. Conditions: States of the drone and the sink are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sink, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sink = calculate_distance_min(s_agent, s_sink) \n    penalty_collision = -20 if (d_agent_sink < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a kitchen, the drone must maneuver around kitchen island. All entity states (agent, goal, kitchen island) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_kitchen_island, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kitchen_island = calculate_distance_min(s_agent, s_kitchen_island) \n    penalty_collision = -20 if (d_agent_kitchen_island < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a kitchen. Requirement: Detect the three countertop edge and do not collide with it. Given: The states for the drone and multiple countertop edge are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone operates near a kitchen. Objectives: \n So not collide with dishwasher. Conditions: \n The states of the agent, goal, the dishwasher are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_dishwasher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dishwasher = calculate_distance_min(s_agent, s_dishwasher) \n    penalty_collision = -20 if (d_agent_dishwasher < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate kitchen. Objectives: Do not collide hit with the pantry cabinet. Conditions: States of the agent, pantry cabinet are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_pantry_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pantry_cabinet = calculate_distance_min(s_agent, s_pantry_cabinet) \n    penalty_collision = -20 if (d_agent_pantry_cabinet < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a kitchen, the drone must steer clear of backsplash. All states (agent, goal, backsplash) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_backsplash, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backsplash = calculate_distance_min(s_agent, s_backsplash) \n    penalty_collision = -20 if (d_agent_backsplash < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: kitchen. Avoid: Detect bar stool and do not hitting with bar stool. Known: Agent, goal, bar stool states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_stool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stool = calculate_distance_min(s_agent, s_stool) \n    penalty_collision = -20 if (d_agent_stool < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating kitchen. Objectives: It must avoid colliding with dining chair. Conditions: The states of the drone, goal and dining chair are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dining_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_chair = calculate_distance_min(s_agent, s_dining_chair) \n    penalty_collision = -20 if (d_agent_dining_chair < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through kitchen. Objectives: Avoid collision with pantry cabinet, dining chair and kitchen island. Conditions: The states of the agent and of the multiple obstacles: pantry cabinet, dining chair and kitchen island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating kitchen. Objectives: It must avoid colliding with any bar stool, range and hood. Conditions: Agent's and of the multiple obstacle: bar stool, range and hood states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through kitchen. Objectives: Do not collide with sink. Conditions: The states of the drone, goal and the blender are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_blender, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blender = calculate_distance_min(s_agent, s_blender) \n    penalty = -20 if (d_agent_blender < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along kitchen and must avoid contact with the trash bin. The states of the drone, goal and the trash bin are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty = -20 if (d_agent_trash_bin < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in kitchen. It must avoid colliding with the bar stool, appliance front and microwave. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and microwave are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in kitchen. It must avoid colliding with the glass kitchen island and bar stool. The states of the drone, goal and of the multiple obstacle: the glass kitchen island and bar stool are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in kitchen. It must avoid colliding with the pendant light. Agent's state, goal's state and pendant light's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_pendant_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pendant_light = calculate_distance_min(s_agent, s_pendant_light) \n    penalty_collision = -20 if (d_agent_pendant_light < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: It must avoid colliding with pendant light. Assumptions: The states of the drone, goal and the microwave's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_microwave, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microwave = calculate_distance_min(s_agent, s_microwave) \n    penalty_collision = -20 if (d_agent_microwave < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: It must avoid colliding with kitchen's pet bowl, breakfast nook and glass backsplash. Assumptions: The Agent's state, goal's state and multiple obstacle's state: pet bowl, fridge nook and glass backsplash are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: Detect rolling cart, oven and sink and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: stove, oven and sink state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating along dining area. Objectives: \n It must avoid colliding with dining table or dining area island. Conditions: \n The states of the agent, goal, and of the other multiple obstaces e.g. the dining table and the dining area island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating inside a dining area. Objectives: \n Detect serving trolley and aviod it. Conditions: \n The states of the agent, goal, the serving trolley are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_serving_trolley, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_serving_trolley = calculate_distance_min(s_agent, s_serving_trolley) \n    penalty_collision = -20 if (d_agent_serving_trolley < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a dining area. Objectives: It must avoid colliding with fireplace. Conditions: States of the drone and the fireplace are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fireplace, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fireplace = calculate_distance_min(s_agent, s_fireplace) \n    penalty_collision = -20 if (d_agent_fireplace < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a dining area, the drone must maneuver around dining area island. All entity states (agent, goal, dining area island) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_island, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_island = calculate_distance_min(s_agent, s_island) \n    penalty_collision = -20 if (d_agent_island < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a dining area. Requirement: Detect the three buffet cabinet and do not collide with it. Given: The states for the drone and multiple obstacle state such as buffet cabinet are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone operates near a dining area. Objectives: \n So not collide with wine rack. Conditions: \n The states of the agent, goal, the wine rack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_wine_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wine_rack = calculate_distance_min(s_agent, s_wine_rack) \n    penalty_collision = -20 if (d_agent_wine_rack < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate dining area. Objectives: Do not collide hit with the china cabinet. Conditions: States of the agent, cabinet are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabinet = calculate_distance_min(s_agent, s_cabinet) \n    penalty_collision = -20 if (d_agent_cabinet < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a dining area, the drone must steer clear of mirror. All states (agent, goal, mirror) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_mirror, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mirror = calculate_distance_min(s_agent, s_mirror) \n    penalty_collision = -20 if (d_agent_mirror < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: dining area. Avoid: Detect bar armchair and do not hitting with bar armchair. Known: Agent, goal, bar armchair states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_armchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_armchair = calculate_distance_min(s_agent, s_armchair) \n    penalty_collision = -20 if (d_agent_armchair < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating dining area. Objectives: It must avoid colliding with high chair. Conditions: The states of the drone, goal and high chair are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_high_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_high_chair = calculate_distance_min(s_agent, s_high_chair) \n    penalty_collision = -20 if (d_agent_high_chair < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through dining area. Objectives: Avoid collision with china cabinet, high chair and dining area island. Conditions: The states of the agent and of the multiple obstacles: china cabinet, high chair and dining area island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating dining area. Objectives: It must avoid colliding with any bar armchair, wall painting. Conditions: Agent's and of the multiple obstacle: bar armchair, wall painting states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through dining area. Objectives: Do not collide with fireplace. Conditions: The states of the drone, goal and the picture are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_picture, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_picture = calculate_distance_min(s_agent, s_picture) \n    penalty = -20 if (d_agent_picture < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along dining area and must avoid contact with the vase. The states of the drone, goal and the vase are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_vase, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vase = calculate_distance_min(s_agent, s_vase) \n    penalty = -20 if (d_agent_vase < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in dining area. It must avoid colliding with the bar armchair, appliance front and candelabra. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and candelabra are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in dining area. It must avoid colliding with the glass dining area island and bar armchair. The states of the drone, goal and of the multiple obstacle: the glass dining area island and bar armchair are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in dining area. It must avoid colliding with the chandelier. Agent's state, goal's state and chandelier's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chandelier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chandelier = calculate_distance_min(s_agent, s_chandelier) \n    penalty_collision = -20 if (d_agent_chandelier < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: It must avoid colliding with chandelier. Assumptions: The states of the drone, goal and the candelabra's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_candelabra, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_candelabra = calculate_distance_min(s_agent, s_candelabra) \n    penalty_collision = -20 if (d_agent_candelabra < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: It must avoid colliding with dining area's centerpiece, alcove seating and glass mirror. Assumptions: The Agent's state, goal's state and multiple obstacle's state: centerpiece, fridge nook and glass mirror are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: Detect serving trolley, serving trolley and fireplace and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: stove, serving trolley and fireplace state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along gaming room. \n Objectives: It must avoid colliding with gaming footrest or gaming table. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the gaming footrest and the gaming table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy gaming room. \n Objectives: Detect controller dock and aviod it. \n Conditions: The states of the agent, goal, the controller dock are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_controller_dock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_controller_dock = calculate_distance_min(s_agent, s_controller_dock) \n    penalty_collision = -20 if (d_agent_automatic_controller_dock < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a gaming room. Objectives: It must avoid colliding with speaker tower. Conditions: States of the drone and the speaker tower are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_speaker_tower, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker_tower = calculate_distance_min(s_agent, s_speaker_tower) \n    penalty_collision = -20 if (d_agent_speaker_tower < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a gaming room, the drone must maneuver around console stand. All entity states (agent, goal, console stand) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_console_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_console_stand = calculate_distance_min(s_agent, s_console_stand) \n    penalty_collision = -20 if (d_agent_console_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a gaming room. Requirement: Detect the three arcade machine and do not collide with it. Given: The states for the drone and multiple arcade machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a gaming room. \n Objectives: So not collide with VR headset stand. \n Conditions: The states of the agent, goal, the VR headset stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_vr_headset_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vr_headset_stand = calculate_distance_min(s_agent, s_vr_headset_stand) \n    penalty_collision = -20 if (d_agent_vr_headset_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate gaming room. Objectives: Do not collide hit with the gaming PC. Conditions: States of the agent, gaming PC are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_gaming_pc, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gaming_pc = calculate_distance_min(s_agent, s_gaming_pc) \n    penalty_collision = -20 if (d_agent_gaming_pc < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a gaming room, the drone must steer clear of monitor stand. All states (agent, goal, monitor stand) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_monitor_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_monitor_stand = calculate_distance_min(s_agent, s_monitor_stand) \n    penalty_collision = -20 if (d_agent_monitor_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: gaming room. Avoid: Detect bar cable bundle and do not hitting with bar cable bundle. Known: Agent, goal, bar cable bundle states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cable_bundle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable_bundle = calculate_distance_min(s_agent, s_cable_bundle) \n    penalty_collision = -20 if (d_agent_cable_bundle < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating gaming room. Objectives: It must avoid colliding with footrest. Conditions: The states of the drone, goal and footrest are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_footrest, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_footrest = calculate_distance_min(s_agent, s_footrest) \n    penalty_collision = -20 if (d_agent_dining_footrest < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through gaming room. Objectives: Avoid collision with gaming PC, footrest and gaming table. Conditions: The states of the agent and of the multiple obstacles: gaming PC, footrest and gaming table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating gaming room. Objectives: It must avoid colliding with any bar cable bundle, projector screen. Conditions: Agent's and of the multiple obstacle: bar cable bundle, projector screen states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through gaming room. Objectives: Do not collide with speaker tower. Conditions: The states of the drone, goal and the speaker tower are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_speaker_tower, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker_tower = calculate_distance_min(s_agent, s_speaker_tower) \n    penalty = -20 if (d_agent_speaker_tower < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along gaming room and must avoid contact with the subwoofer. The states of the drone, goal and the subwoofer are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_subwoofer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_subwoofer = calculate_distance_min(s_agent, s_subwoofer) \n    penalty = -20 if (d_agent_subwoofer < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in gaming room. It must avoid colliding with the bar cable bundle, appliance front and LED light strip. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and LED light strip are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in gaming room. It must avoid colliding with the glass gaming table and bar cable bundle. The states of the drone, goal and of the multiple obstacle: the glass gaming table and bar cable bundle are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in gaming room. It must avoid colliding with the ceiling fan. Agent's state, goal's state and ceiling fan's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ceiling_fan = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -20 if (d_agent_ceiling_fan < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: It must avoid colliding with ceiling fan. Assumptions: The states of the drone, goal and the LED light strip's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_led_light_strip, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_led_light_strip = calculate_distance_min(s_agent, s_led_light_strip) \n    penalty_collision = -20 if (d_agent_led_light_strip < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: It must avoid colliding with gaming room's game controller, gaming desk and glass monitor stand. Assumptions: The Agent's state, goal's state and multiple obstacle's state: game controller, computer nook and monitor stand are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: Detect controller dock, controller dock and speaker tower and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: plant, controller dock and speaker tower state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along garage. \n Objectives: It must avoid colliding with gaming jack stand or work table. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the gaming jack stand and the work table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy garage. \n Objectives: Detect oil can and aviod it. \n Conditions: The states of the agent, goal, the oil can are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_oil_can, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_oil_can = calculate_distance_min(s_agent, s_oil_can) \n    penalty_collision = -20 if (d_agent_automatic_oil_can < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a garage. Objectives: It must avoid colliding with air compressor. Conditions: States of the drone and the air compressor are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_air_compressor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_air_compressor = calculate_distance_min(s_agent, s_air_compressor) \n    penalty_collision = -20 if (d_agent_air_compressor < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a garage, the drone must maneuver around workbench. All entity states (agent, goal, workbench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_workbench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_workbench = calculate_distance_min(s_agent, s_workbench) \n    penalty_collision = -20 if (d_agent_workbench < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a garage. Requirement: Detect the three tool chest and do not collide with it. Given: The states for the drone and multiple tool chest are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a garage. \n Objectives: So not collide with ladder. \n Conditions: The states of the agent, goal, the ladder are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_ladder, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ladder = calculate_distance_min(s_agent, s_ladder) \n    penalty_collision = -20 if (d_agent_ladder < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate garage. Objectives: Do not collide hit with the generator. Conditions: States of the agent, generator are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_generator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_generator = calculate_distance_min(s_agent, s_generator) \n    penalty_collision = -20 if (d_agent_generator < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a garage, the drone must steer clear of bike. All states (agent, goal, bike) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_bike, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bike = calculate_distance_min(s_agent, s_bike) \n    penalty_collision = -20 if (d_agent_bike < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: garage. Avoid: Detect bar extension cord and do not hitting with bar extension cord. Known: Agent, goal, bar extension cord states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_extension_cord, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_extension_cord = calculate_distance_min(s_agent, s_extension_cord) \n    penalty_collision = -20 if (d_agent_extension_cord < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating garage. Objectives: It must avoid colliding with jack stand. Conditions: The states of the drone, goal and jack stand are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_jack_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_jack_stand = calculate_distance_min(s_agent, s_jack_stand) \n    penalty_collision = -20 if (d_agent_jack_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through garage. Objectives: Avoid collision with generator, jack stand and work table. Conditions: The states of the agent and of the multiple obstacles: generator, jack stand and work table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating garage. Objectives: It must avoid colliding with any bar extension cord, garage door motor. Conditions: Agent's and of the multiple obstacle: bar extension cord, garage door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through garage. Objectives: Do not collide with air compressor. Conditions: The states of the drone, goal and the air compressor are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_air_compressor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_air_compressor = calculate_distance_min(s_agent, s_air_compressor) \n    penalty = -20 if (d_agent_air_compressor < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along garage and must avoid contact with the storage box. The states of the drone, goal and the storage box are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_storage_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_box = calculate_distance_min(s_agent, s_storage_box) \n    penalty = -20 if (d_agent_storage_box < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in garage. It must avoid colliding with the bar extension cord, appliance front and spare tire. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and spare tire are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in garage. It must avoid colliding with the glass work table and bar extension cord. The states of the drone, goal and of the multiple obstacle: the glass work table and bar extension cord are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in garage. It must avoid colliding with the overhead light. Agent's state, goal's state and overhead light's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_overhead_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_overhead_light = calculate_distance_min(s_agent, s_overhead_light) \n    penalty_collision = -20 if (d_agent_overhead_light < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: It must avoid colliding with overhead light. Assumptions: The states of the drone, goal and the spare tire's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_spare_tire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spare_tire = calculate_distance_min(s_agent, s_spare_tire) \n    penalty_collision = -20 if (d_agent_spare_tire < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: It must avoid colliding with garage's paint cans, sawhorse and glass bike. Assumptions: The Agent's state, goal's state and multiple obstacle's state: paint cans, computer nook and bike are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: Detect oil can, oil can and air compressor and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: plant, oil can and air compressor state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -2**d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  A drone is operating along living room. \n Objectives:  It must avoid colliding with sofas or coffee tables. \n Conditions:  The states of the agent and the multiple obstacles are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  A drone is operating inside a busy living room. \n Objectives:  Detect sliding balcony door and aviod it. \n Conditions:  The states of the agent, goal, the sliding balcony door are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sliding_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sliding_door = calculate_distance_min(s_agent, s_sliding_door) \n    penalty_collision = -20 if (d_agent_sliding_door < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating living room open workoccupantce. Objectives: It must avoid colliding with doorway. Conditions: States of the drone and the doorway are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_doorway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doorway = calculate_distance_min(s_agent, s_doorway) \n    penalty_collision = -20 if (d_agent_doorway < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a living room, the drone must maneuver around coffee tables. All entity states (agent, goal, coffee tables) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_coffee_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_table = calculate_distance_min(s_agent, s_coffee_table) \n    penalty_collision = -20 if (d_agent_coffee_table < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a living room. Requirement: Detect the three side tables and do not collide with it. Given: The states for the drone and mmultiple tables are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  A drone operates near a living room. \n Objectives:  So not collide with TV stand. \n Conditions:  The states of the agent, goal, the TV stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_tv_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tv_stand = calculate_distance_min(s_agent, s_tv_stand) \n    penalty_collision = -20 if (d_agent_tv_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate living room. Objectives: Do not collide hit with the bookshelf. Conditions: States of the agent, bookshelf are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_bookshelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelf = calculate_distance_min(s_agent, s_bookshelf) \n    penalty_collision = -20 if (d_agent_bookshelf < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a living room, the drone must steer clear of wall. All states (agent, goal, glass cabinet) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_glass_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_cabinet = calculate_distance_min(s_agent, s_glass_cabinet) \n    penalty_collision = -20 if (d_agent_glass_cabinet < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: living room. Avoid: Detect floor lamp and do not hitting with floor lamp. Known: Agent, goal, floor lamp states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_floor_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_floor_lamp = calculate_distance_min(s_agent, s_floor_lamp) \n    penalty_collision = -20 if (d_agent_floor_lamp < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating living room. Objectives: It must avoid colliding with occupant. Conditions: The states of the drone, goal and occupant are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_occupant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_occupant = calculate_distance_min(s_agent, s_occupant) \n    penalty_collision = -20 if (d_agent_occupant < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through living room. Objectives: Avoid collision with bookshelf, occupants and staircase. Conditions: The states of the agent, goal, and multiple obstacles such as the bookshelf, occupants and staircase are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating living room. Objectives: It must avoid colliding with any floor lamp, wall unit and TV. Conditions: Agent's and of the multiple obstacles such as the floor lamp's, units and computers states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through living room. Objectives: Do not collide with doorway. Conditions: The states of the drone, goal and the doorway are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_doorway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doorway = calculate_distance_min(s_agent, s_doorway) \n    penalty = -20 if (d_agent_doorway < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along living room and must avoid contact with the coat rack. The states of the drone, goal and the coat rack are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_coat_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_rack = calculate_distance_min(s_agent, s_coat_rack) \n    penalty = -20 if (d_agent_coat_rack < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in living room. It must avoid colliding with the floor lamp, sliding balcony doors and window shutters. The states of the agent, goal, and multiple obstacles such as the potted plants near entrance, sliding balcony doors and window shutters are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in living room. It must avoid colliding with the glass coffee table and floor lamp. The states of the drone, goal and multiple obstacles such as the  the glass coffee table and floor lamp are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in living room. It must avoid colliding with the curtains. Agent's state, goal's state and curtains's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -20 if (d_agent_curtain < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: It must avoid colliding with drapery. Assumptions: The states of the drone, goal and the drapery's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_drapery, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drapery = calculate_distance_min(s_agent, s_drapery) \n    penalty_collision = -20 if (d_agent_drapery < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: It must avoid colliding with living room's potted plant, hallway entrance and glass room divider. Assumptions: The Agent's state, goal's state, potted plant, hallway entrance and glass room divider's states are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: Detect ottoman, sliding balcony door and doorway and do not collide. Assumptions: The states of the drone, goal, ottoman, sliding balcony door and doorway state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating living room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating along kitchen. Objectives: \n It must avoid colliding with refrigerator or kitchen island. Conditions: \n The states of the agent, goal, and of the other multiple obstacöes e.g. the refrigerator and the kitchen island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating inside a busy kitchen. Objectives: \n Detect oven and aviod it. Conditions: \n The states of the agent, goal, the oven are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_oven, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_oven = calculate_distance_min(s_agent, s_oven) \n    penalty_collision = -20 if (d_agent_automatic_oven < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a kitchen. Objectives: It must avoid colliding with sink. Conditions: States of the drone and the sink are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sink, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sink = calculate_distance_min(s_agent, s_sink) \n    penalty_collision = -20 if (d_agent_sink < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a kitchen, the drone must maneuver around kitchen island. All entity states (agent, goal, kitchen island) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_kitchen_island, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kitchen_island = calculate_distance_min(s_agent, s_kitchen_island) \n    penalty_collision = -20 if (d_agent_kitchen_island < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a kitchen. Requirement: Detect the three countertop edge and do not collide with it. Given: The states for the drone and multiple countertop edge are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone operates near a kitchen. Objectives: \n So not collide with dishwasher. Conditions: \n The states of the agent, goal, the dishwasher are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_dishwasher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dishwasher = calculate_distance_min(s_agent, s_dishwasher) \n    penalty_collision = -20 if (d_agent_dishwasher < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate kitchen. Objectives: Do not collide hit with the pantry cabinet. Conditions: States of the agent, pantry cabinet are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_pantry_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pantry_cabinet = calculate_distance_min(s_agent, s_pantry_cabinet) \n    penalty_collision = -20 if (d_agent_pantry_cabinet < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a kitchen, the drone must steer clear of backsplash. All states (agent, goal, backsplash) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_backsplash, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backsplash = calculate_distance_min(s_agent, s_backsplash) \n    penalty_collision = -20 if (d_agent_backsplash < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: kitchen. Avoid: Detect bar stool and do not hitting with bar stool. Known: Agent, goal, bar stool states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_stool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stool = calculate_distance_min(s_agent, s_stool) \n    penalty_collision = -20 if (d_agent_stool < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating kitchen. Objectives: It must avoid colliding with dining chair. Conditions: The states of the drone, goal and dining chair are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dining_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_chair = calculate_distance_min(s_agent, s_dining_chair) \n    penalty_collision = -20 if (d_agent_dining_chair < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through kitchen. Objectives: Avoid collision with pantry cabinet, dining chair and kitchen island. Conditions: The states of the agent and of the multiple obstacles: pantry cabinet, dining chair and kitchen island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating kitchen. Objectives: It must avoid colliding with any bar stool, range and hood. Conditions: Agent's and of the multiple obstacle: bar stool, range and hood states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through kitchen. Objectives: Do not collide with sink. Conditions: The states of the drone, goal and the blender are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_blender, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blender = calculate_distance_min(s_agent, s_blender) \n    penalty = -20 if (d_agent_blender < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along kitchen and must avoid contact with the trash bin. The states of the drone, goal and the trash bin are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty = -20 if (d_agent_trash_bin < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in kitchen. It must avoid colliding with the bar stool, appliance front and microwave. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and microwave are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in kitchen. It must avoid colliding with the glass kitchen island and bar stool. The states of the drone, goal and of the multiple obstacle: the glass kitchen island and bar stool are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in kitchen. It must avoid colliding with the pendant light. Agent's state, goal's state and pendant light's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_pendant_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pendant_light = calculate_distance_min(s_agent, s_pendant_light) \n    penalty_collision = -20 if (d_agent_pendant_light < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: It must avoid colliding with pendant light. Assumptions: The states of the drone, goal and the microwave's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_microwave, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microwave = calculate_distance_min(s_agent, s_microwave) \n    penalty_collision = -20 if (d_agent_microwave < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: It must avoid colliding with kitchen's pet bowl, breakfast nook and glass backsplash. Assumptions: The Agent's state, goal's state and multiple obstacle's state: pet bowl, fridge nook and glass backsplash are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: Detect rolling cart, oven and sink and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: stove, oven and sink state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating kitchen. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating along dining area. Objectives: \n It must avoid colliding with dining table or dining area island. Conditions: \n The states of the agent, goal, and of the other multiple obstaces e.g. the dining table and the dining area island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone is operating inside a dining area. Objectives: \n Detect serving trolley and aviod it. Conditions: \n The states of the agent, goal, the serving trolley are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_serving_trolley, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_serving_trolley = calculate_distance_min(s_agent, s_serving_trolley) \n    penalty_collision = -20 if (d_agent_serving_trolley < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a dining area. Objectives: It must avoid colliding with fireplace. Conditions: States of the drone and the fireplace are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fireplace, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fireplace = calculate_distance_min(s_agent, s_fireplace) \n    penalty_collision = -20 if (d_agent_fireplace < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a dining area, the drone must maneuver around dining area island. All entity states (agent, goal, dining area island) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_island, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_island = calculate_distance_min(s_agent, s_island) \n    penalty_collision = -20 if (d_agent_island < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a dining area. Requirement: Detect the three buffet cabinet and do not collide with it. Given: The states for the drone and multiple obstacle state such as buffet cabinet are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: \n A drone operates near a dining area. Objectives: \n So not collide with wine rack. Conditions: \n The states of the agent, goal, the wine rack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_wine_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wine_rack = calculate_distance_min(s_agent, s_wine_rack) \n    penalty_collision = -20 if (d_agent_wine_rack < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate dining area. Objectives: Do not collide hit with the china cabinet. Conditions: States of the agent, cabinet are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabinet = calculate_distance_min(s_agent, s_cabinet) \n    penalty_collision = -20 if (d_agent_cabinet < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a dining area, the drone must steer clear of mirror. All states (agent, goal, mirror) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_mirror, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mirror = calculate_distance_min(s_agent, s_mirror) \n    penalty_collision = -20 if (d_agent_mirror < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: dining area. Avoid: Detect bar armchair and do not hitting with bar armchair. Known: Agent, goal, bar armchair states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_armchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_armchair = calculate_distance_min(s_agent, s_armchair) \n    penalty_collision = -20 if (d_agent_armchair < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating dining area. Objectives: It must avoid colliding with high chair. Conditions: The states of the drone, goal and high chair are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_high_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_high_chair = calculate_distance_min(s_agent, s_high_chair) \n    penalty_collision = -20 if (d_agent_high_chair < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through dining area. Objectives: Avoid collision with china cabinet, high chair and dining area island. Conditions: The states of the agent and of the multiple obstacles: china cabinet, high chair and dining area island are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating dining area. Objectives: It must avoid colliding with any bar armchair, wall painting. Conditions: Agent's and of the multiple obstacle: bar armchair, wall painting states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through dining area. Objectives: Do not collide with fireplace. Conditions: The states of the drone, goal and the picture are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_picture, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_picture = calculate_distance_min(s_agent, s_picture) \n    penalty = -20 if (d_agent_picture < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along dining area and must avoid contact with the vase. The states of the drone, goal and the vase are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_vase, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vase = calculate_distance_min(s_agent, s_vase) \n    penalty = -20 if (d_agent_vase < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in dining area. It must avoid colliding with the bar armchair, appliance front and candelabra. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and candelabra are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in dining area. It must avoid colliding with the glass dining area island and bar armchair. The states of the drone, goal and of the multiple obstacle: the glass dining area island and bar armchair are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in dining area. It must avoid colliding with the chandelier. Agent's state, goal's state and chandelier's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chandelier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chandelier = calculate_distance_min(s_agent, s_chandelier) \n    penalty_collision = -20 if (d_agent_chandelier < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: It must avoid colliding with chandelier. Assumptions: The states of the drone, goal and the candelabra's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_candelabra, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_candelabra = calculate_distance_min(s_agent, s_candelabra) \n    penalty_collision = -20 if (d_agent_candelabra < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: It must avoid colliding with dining area's centerpiece, alcove seating and glass mirror. Assumptions: The Agent's state, goal's state and multiple obstacle's state: centerpiece, fridge nook and glass mirror are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: Detect serving trolley, serving trolley and fireplace and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: stove, serving trolley and fireplace state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating dining area. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along gaming room. \n Objectives: It must avoid colliding with gaming footrest or gaming table. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the gaming footrest and the gaming table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy gaming room. \n Objectives: Detect controller dock and aviod it. \n Conditions: The states of the agent, goal, the controller dock are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_controller_dock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_controller_dock = calculate_distance_min(s_agent, s_controller_dock) \n    penalty_collision = -20 if (d_agent_automatic_controller_dock < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a gaming room. Objectives: It must avoid colliding with speaker tower. Conditions: States of the drone and the speaker tower are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_speaker_tower, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker_tower = calculate_distance_min(s_agent, s_speaker_tower) \n    penalty_collision = -20 if (d_agent_speaker_tower < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a gaming room, the drone must maneuver around console stand. All entity states (agent, goal, console stand) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_console_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_console_stand = calculate_distance_min(s_agent, s_console_stand) \n    penalty_collision = -20 if (d_agent_console_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a gaming room. Requirement: Detect the three arcade machine and do not collide with it. Given: The states for the drone and multiple arcade machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a gaming room. \n Objectives: So not collide with VR headset stand. \n Conditions: The states of the agent, goal, the VR headset stand are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_vr_headset_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vr_headset_stand = calculate_distance_min(s_agent, s_vr_headset_stand) \n    penalty_collision = -20 if (d_agent_vr_headset_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate gaming room. Objectives: Do not collide hit with the gaming PC. Conditions: States of the agent, gaming PC are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_gaming_pc, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gaming_pc = calculate_distance_min(s_agent, s_gaming_pc) \n    penalty_collision = -20 if (d_agent_gaming_pc < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a gaming room, the drone must steer clear of monitor stand. All states (agent, goal, monitor stand) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_monitor_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_monitor_stand = calculate_distance_min(s_agent, s_monitor_stand) \n    penalty_collision = -20 if (d_agent_monitor_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: gaming room. Avoid: Detect bar cable bundle and do not hitting with bar cable bundle. Known: Agent, goal, bar cable bundle states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cable_bundle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable_bundle = calculate_distance_min(s_agent, s_cable_bundle) \n    penalty_collision = -20 if (d_agent_cable_bundle < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating gaming room. Objectives: It must avoid colliding with footrest. Conditions: The states of the drone, goal and footrest are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_footrest, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_footrest = calculate_distance_min(s_agent, s_footrest) \n    penalty_collision = -20 if (d_agent_dining_footrest < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through gaming room. Objectives: Avoid collision with gaming PC, footrest and gaming table. Conditions: The states of the agent and of the multiple obstacles: gaming PC, footrest and gaming table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating gaming room. Objectives: It must avoid colliding with any bar cable bundle, projector screen. Conditions: Agent's and of the multiple obstacle: bar cable bundle, projector screen states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through gaming room. Objectives: Do not collide with speaker tower. Conditions: The states of the drone, goal and the speaker tower are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_speaker_tower, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker_tower = calculate_distance_min(s_agent, s_speaker_tower) \n    penalty = -20 if (d_agent_speaker_tower < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along gaming room and must avoid contact with the subwoofer. The states of the drone, goal and the subwoofer are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_subwoofer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_subwoofer = calculate_distance_min(s_agent, s_subwoofer) \n    penalty = -20 if (d_agent_subwoofer < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in gaming room. It must avoid colliding with the bar cable bundle, appliance front and LED light strip. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and LED light strip are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in gaming room. It must avoid colliding with the glass gaming table and bar cable bundle. The states of the drone, goal and of the multiple obstacle: the glass gaming table and bar cable bundle are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in gaming room. It must avoid colliding with the ceiling fan. Agent's state, goal's state and ceiling fan's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ceiling_fan, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ceiling_fan = calculate_distance_min(s_agent, s_ceiling_fan) \n    penalty_collision = -20 if (d_agent_ceiling_fan < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: It must avoid colliding with ceiling fan. Assumptions: The states of the drone, goal and the LED light strip's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_led_light_strip, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_led_light_strip = calculate_distance_min(s_agent, s_led_light_strip) \n    penalty_collision = -20 if (d_agent_led_light_strip < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: It must avoid colliding with gaming room's game controller, gaming desk and glass monitor stand. Assumptions: The Agent's state, goal's state and multiple obstacle's state: game controller, computer nook and monitor stand are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: Detect controller dock, controller dock and speaker tower and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: plant, controller dock and speaker tower state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating gaming room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along garage. \n Objectives: It must avoid colliding with gaming jack stand or work table. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the gaming jack stand and the work table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy garage. \n Objectives: Detect oil can and aviod it. \n Conditions: The states of the agent, goal, the oil can are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_oil_can, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_oil_can = calculate_distance_min(s_agent, s_oil_can) \n    penalty_collision = -20 if (d_agent_automatic_oil_can < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a garage. Objectives: It must avoid colliding with air compressor. Conditions: States of the drone and the air compressor are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_air_compressor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_air_compressor = calculate_distance_min(s_agent, s_air_compressor) \n    penalty_collision = -20 if (d_agent_air_compressor < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a garage, the drone must maneuver around workbench. All entity states (agent, goal, workbench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_workbench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_workbench = calculate_distance_min(s_agent, s_workbench) \n    penalty_collision = -20 if (d_agent_workbench < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a garage. Requirement: Detect the three tool chest and do not collide with it. Given: The states for the drone and multiple tool chest are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacle_min < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a garage. \n Objectives: So not collide with ladder. \n Conditions: The states of the agent, goal, the ladder are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_ladder, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ladder = calculate_distance_min(s_agent, s_ladder) \n    penalty_collision = -20 if (d_agent_ladder < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate garage. Objectives: Do not collide hit with the generator. Conditions: States of the agent, generator are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_generator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_generator = calculate_distance_min(s_agent, s_generator) \n    penalty_collision = -20 if (d_agent_generator < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a garage, the drone must steer clear of bike. All states (agent, goal, bike) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_bike, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bike = calculate_distance_min(s_agent, s_bike) \n    penalty_collision = -20 if (d_agent_bike < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: garage. Avoid: Detect bar extension cord and do not hitting with bar extension cord. Known: Agent, goal, bar extension cord states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_extension_cord, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_extension_cord = calculate_distance_min(s_agent, s_extension_cord) \n    penalty_collision = -20 if (d_agent_extension_cord < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating garage. Objectives: It must avoid colliding with jack stand. Conditions: The states of the drone, goal and jack stand are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_jack_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_jack_stand = calculate_distance_min(s_agent, s_jack_stand) \n    penalty_collision = -20 if (d_agent_jack_stand < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through garage. Objectives: Avoid collision with generator, jack stand and work table. Conditions: The states of the agent and of the multiple obstacles: generator, jack stand and work table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating garage. Objectives: It must avoid colliding with any bar extension cord, garage door motor. Conditions: Agent's and of the multiple obstacle: bar extension cord, garage door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through garage. Objectives: Do not collide with air compressor. Conditions: The states of the drone, goal and the air compressor are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_air_compressor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_air_compressor = calculate_distance_min(s_agent, s_air_compressor) \n    penalty = -20 if (d_agent_air_compressor < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along garage and must avoid contact with the storage box. The states of the drone, goal and the storage box are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_storage_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_box = calculate_distance_min(s_agent, s_storage_box) \n    penalty = -20 if (d_agent_storage_box < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in garage. It must avoid colliding with the bar extension cord, appliance front and spare tire. The states of the agent and of the multiple obstacle: potted plants near entrance, sliding balcony appliance front and spare tire are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in garage. It must avoid colliding with the glass work table and bar extension cord. The states of the drone, goal and of the multiple obstacle: the glass work table and bar extension cord are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in garage. It must avoid colliding with the overhead light. Agent's state, goal's state and overhead light's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_overhead_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_overhead_light = calculate_distance_min(s_agent, s_overhead_light) \n    penalty_collision = -20 if (d_agent_overhead_light < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: It must avoid colliding with overhead light. Assumptions: The states of the drone, goal and the spare tire's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_spare_tire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spare_tire = calculate_distance_min(s_agent, s_spare_tire) \n    penalty_collision = -20 if (d_agent_spare_tire < 1) else 19 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: It must avoid colliding with garage's paint cans, sawhorse and glass bike. Assumptions: The Agent's state, goal's state and multiple obstacle's state: paint cans, computer nook and bike are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: Detect oil can, oil can and air compressor and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: plant, oil can and air compressor state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < 1) else 19 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating garage. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.5) else -math.exp(d_agent_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is performing indoor exploration in a room and needs to reach the goal. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is performing indoor exploration in a library and needs to reach the goal. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is performing indoor exploration in a forest and needs to reach the goal. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is performing indoor exploration in a mensa and needs to reach the goal. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is performing indoor exploration in a classroom and needs to reach the goal. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is performing indoor exploration in a conference room and needs to reach the goal. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is performing indoor exploration in a warehouse and needs to reach the goal. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is performing indoor exploration in a theater and needs to reach the goal. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is performing indoor exploration in a sport halls and needs to reach the goal. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is performing indoor exploration in a hospital and needs to reach the goal. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting wind turbines along the coast and must reach its target position. Both the agent’s state and the goal’s state are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying across a factory floor and needs to reach its target location. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying across a train staion and needs to reach its target location. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying across a airport terminal and needs to reach its target location. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying across a shopping mall and needs to reach its target location. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "MiA drone is flying across a supermarket and needs to reach its target location. The agent’s state and the goal’s state are available. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a swimming pool area. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a busy construction site. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a dormitory atrium. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a farmland. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a zoo. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a zoo. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "n a public plaza, a drone is navigating toward a specified goal. The system provides access to both the drone’s state and the goal’s state. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "n a soundstage, a drone is navigating toward a specified goal. The system provides access to both the drone’s state and the goal’s state. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "n a cliff terrance, a drone is navigating toward a specified goal. The system provides access to both the drone’s state and the goal’s state. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "n a gymnasium, a drone is navigating toward a specified goal. The system provides access to both the drone’s state and the goal’s state. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "n a amusement park, a drone is navigating toward a specified goal. The system provides access to both the drone’s state and the goal’s state. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A agent is navigating Greenhouse. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Film Studio. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating Gymnasium common room. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying through a central plaza. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent is flying through Greenhouse. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Parking Garage. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying through a forest trail. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "While operating in a science lab environment, a drone must travel to the goal position. Details of the agent’s current state and the goal’s state are provided. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "While operating in a Church environment, a drone must travel to the goal position. Details of the agent’s current state and the goal’s state are provided. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "While operating in a Art museum environment, a drone must travel to the goal position. Details of the agent’s current state and the goal’s state are provided. Write the reward function in Python..",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "While operating in a parking garage environment, a drone must travel to the goal position. Details of the agent’s current state and the goal’s state are provided. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "While operating in a rainforest environment, a drone must travel to the goal position. Details of the agent’s current state and the goal’s state are provided. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "While operating in a Kindergarten playground environment, a drone must travel to the goal position. Details of the agent’s current state and the goal’s state are provided. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "While operating in a University campus environment, a drone must travel to the goal position. Details of the agent’s current state and the goal’s state are provided. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "While operating in a Fire station environment, a drone must travel to the goal position. Details of the agent’s current state and the goal’s state are provided. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through Recycling Facility. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through Botanical Garden. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Hotel. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along Data Center. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating in a yoga hall. The function should encourage target-reaching, and use the available agent, target Information.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating in a baking area area. The function should encourage target-reaching, and use the available agent, target Information.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for an outdoor drone navigating in a Stadium. The function should encourage target-reaching, and use the available agent, target Information.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for an outdoor drone navigating in a skatepark. The function should encourage target-reaching, and use the available agent, target Information.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating in a mosque. The function should encourage target-reaching, and use the available agent, target Information.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating in a music hall. The function should encourage target-reaching, and use the available agent, target Information.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating in a hair salon. The function should encourage target-reaching, and use the available agent, target Information.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating in a spa resort. The function should encourage target-reaching, and use the available agent, target Information.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating in a tennis court. The function should encourage target-reaching, and use the available agent, target Information.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a Tennis Court. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a store floor, the drone must reach the goal. All states (drone, goal,) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a circus, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a pet store, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a newsroom, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bowling alley, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a castle, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a shop, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a festival, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a garage, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a gaming room, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a dining room, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a kitchen, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a living room, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a restaurant, the drone must reach the goal. All states (drone, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying inside a room and needs to reach the assigned destination. Data on the agent’s position and the goal’s position is available. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying inside a library and needs to reach the assigned destination. Data on the agent’s position and the goal’s position is available. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying inside a forest and needs to reach the assigned destination. Data on the agent’s position and the goal’s position is available. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying inside a mensa and needs to reach the assigned destination. Data on the agent’s position and the goal’s position is available. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying inside a classroom and needs to reach the assigned destination. Data on the agent’s position and the goal’s position is available. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying inside a conference room and needs to reach the assigned destination. Data on the agent’s position and the goal’s position is available. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying inside a warehouse and needs to reach the assigned destination. Data on the agent’s position and the goal’s position is available. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying inside a theater and needs to reach the assigned destination. Data on the agent’s position and the goal’s position is available. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying inside a sport hall and needs to reach the assigned destination. Data on the agent’s position and the goal’s position is available. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying inside a hospital and needs to reach the assigned destination. Data on the agent’s position and the goal’s position is available. Write the reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves through an open wind farm with the objective of arriving at the goal point. Information about the agent’s state and the goal’s state is known. Create a Python reward function..",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves through an factory floor with the objective of arriving at the goal point. Information about the agent’s state and the goal’s state is known. Create a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves through an trian station with the objective of arriving at the goal point. Information about the agent’s state and the goal’s state is known. Create a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves through an airport with the objective of arriving at the goal point. Information about the agent’s state and the goal’s state is known. Create a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves through an open shopping place with the objective of arriving at the goal point. Information about the agent’s state and the goal’s state is known. Create a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone moves through an open supermarket with the objective of arriving at the goal point. Information about the agent’s state and the goal’s state is known. Create a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a swmming pool area. The drone needs reach Goal and use drone's Information and goal's Information for it.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating in a construction site. The drone needs reach Goal and use drone's Information and goal's Information for it.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a dormitory. The drone needs reach Goal and use drone's Information and goal's Information for it.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating in a farmland. The drone needs reach Goal and use drone's Information and goal's Information for it.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "TWrite a Python reward function for a drone navigating inside a zoo. The drone needs reach Goal and use drone's Information and goal's Information for it.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a zoo. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a street plaza. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a soundstage. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a cliff terrace. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is navigating Gymnasium. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating along Amusement Park. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: a drone moves through a greenhouse. It should reach target and rely on the Agent, goal. Develop a reward function in Python. ",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: a drone moves through a film studio. It should reach target and rely on the Agent, goal. Develop a reward function in Python. ",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: a drone moves through a common room. It should reach target and rely on the Agent, goal. Develop a reward function in Python. ",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: a drone moves through a central plaza. It should reach target and rely on the Agent, goal. Develop a reward function in Python. ",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent is flying through Greenhouse. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Parking Garage. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying through a forest trail. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a science laboratory, a drone is flying and needs to land on its goal position. There are no obstacles in the environment. The agent’s state and the goal’s state are available. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a church, a drone is flying and needs to land on its goal position. There are no obstacles in the environment. The agent’s state and the goal’s state are available. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a art museum, a drone is flying and needs to land on its goal position. There are no obstacles in the environment. The agent’s state and the goal’s state are available. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a parking garage, a drone is flying and needs to land on its goal position. There are no obstacles in the environment. The agent’s state and the goal’s state are available. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a rainforest, a drone is flying and needs to land on its goal position. There are no obstacles in the environment. The agent’s state and the goal’s state are available. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a kindergarten, a drone is flying and needs to land on its goal position. There are no obstacles in the environment. The agent’s state and the goal’s state are available. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a university campus, a drone is flying and needs to land on its goal position. There are no obstacles in the environment. The agent’s state and the goal’s state are available. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a fire station, a drone is flying and needs to land on its goal position. There are no obstacles in the environment. The agent’s state and the goal’s state are available. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a recycling factory, a drone is flying and needs to land on its goal position. There are no obstacles in the environment. The agent’s state and the goal’s state are available. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a botentical garden, a drone is flying and needs to land on its goal position. There are no obstacles in the environment. The agent’s state and the goal’s state are available. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Inside a hotel, a drone is flying and needs to land on its goal position. There are no obstacles in the environment. The agent’s state and the goal’s state are available. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a data center. The drone must head toward a goal. You are provided with the agent’s state, the target’s state.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a yoga hall. The drone must head toward a goal. You are provided with the agent’s state, the target’s state..",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a baking area. The drone must head toward a goal. You are provided with the agent’s state, the target’s state.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a stadium. The drone must head toward a goal. You are provided with the agent’s state, the target’s state.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a skatepark. The drone must head toward a goal. You are provided with the agent’s state, the target’s state.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a mosque. The drone must head toward a goal. You are provided with the agent’s state, the target’s state.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a hall. The drone must head toward a goal. You are provided with the agent’s state, the target’s state.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a hairsalon. The drone must head toward a goal. You are provided with the agent’s state, the target’s state.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a spa resort. The drone must head toward a goal. You are provided with the agent’s state, the target’s state.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a Tennis Court. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: a drone moves through a tennis court. It should reach target and rely on the Agent's and goal's information. Develop a reward function in Python. ",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a store floor, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a circus, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a pet store, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a newsroom, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bowling alley, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a castle, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a shop, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a festival, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a garage, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a gaming room, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a dining room, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a kitchen, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a living room, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a restaurant, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -20 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone drives in a mensa. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  Drone in-door navigation in a classroom. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone moves in a theater. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Coastal wind-farm drone inspecting turbines. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a factory floor. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a train station. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a airport terminal. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a shopping mall. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a supermarket. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a swimming pool area. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a busy construction site. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a dormitory atrium. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a farmland. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a zoo. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a zoo. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a street plaza. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a soundstage. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a cliff terrace. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is navigating Gymnasium. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating along Amusement Park. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A agent is navigating Greenhouse. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Film Studio. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating Gymnasium common room. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying through a central plaza. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent is flying through Greenhouse. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Parking Garage. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying through a forest trail. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Science Lab. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating Church. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating Art Museum open workspace. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating Parking Garage. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through Rainforest. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through Kindergarten Playground. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through University Campus. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through Fire Station. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through Recycling Facility. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through Botanical Garden. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Hotel. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along Data Center. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Within a yoga hall, the drone moves. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Within a baking area, the drone moves. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Within a Stadium, the drone moves. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Within a Skatepark, the drone moves. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a mosque. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a Music Hall. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a Hair Salon. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a Spa Resort. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a Tennis Court. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a Tennis Court. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a store floor, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a circus, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a pet store, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a newsroom, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bowling alley, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a castle, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a shop, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a festival, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a garage, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a gaming room, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a dining room, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a kitchen, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a living room, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a restaurant, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone drives in a mensa. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:  Drone in-door navigation in a classroom. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone moves in a theater. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Reaach goal. \n Conditions: Agent's state, goal's state and goal's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Coastal wind-farm drone inspecting turbines. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a factory floor. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a train station. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a airport terminal. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a shopping mall. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a supermarket. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a swimming pool area. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a busy construction site. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a dormitory atrium. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a farmland. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a zoo. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating inside a zoo. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a street plaza. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a soundstage. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a cliff terrace. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is navigating Gymnasium. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating along Amusement Park. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A agent is navigating Greenhouse. \n Requirement: Reaach the goal. \n Given: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Film Studio. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating Gymnasium common room. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying through a central plaza. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A agent is flying through Greenhouse. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Parking Garage. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is flying through a forest trail. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Science Lab. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating Church. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating Art Museum open workspace. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is navigating Parking Garage. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through Rainforest. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through Kindergarten Playground. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through University Campus. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through Fire Station. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through Recycling Facility. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "An agent is flying through Botanical Garden. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along Hotel. It must land on goal and there are no obstacles. The states of the agent and goals are known. Write a reward function in Python for this scenario.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along Data Center. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Within a yoga hall, the drone moves. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Within a baking area, the drone moves. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Within a Stadium, the drone moves. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Within a Skatepark, the drone moves. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a mosque. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a Music Hall. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a Hair Salon. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a Spa Resort. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a Tennis Court. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission:A drone is flying through a Tennis Court. \n Objectives: Reaach the goal. \n Conditions: Agent's state, goal's state and goal's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a store floor, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a circus, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a pet store, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a newsroom, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bowling alley, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a castle, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a shop, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a festival, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a garage, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a gaming room, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a dining room, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a kitchen, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a living room, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a restaurant, the drone must reach the goal. All states (agent, goal) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bus terminal. \n Objectives: It must avoid colliding with luggage cart or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the luggage cart and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bus terminal. \n Objectives: Detect trash bin and aviod it. \n Conditions: The states of the agent, goal, the trash bin are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -25 if (d_agent_trash_bin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bus terminal. Objectives: It must avoid colliding with platform pillar. Conditions: States of the drone and the platform pillar are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform_pillar = calculate_distance_min(s_agent, s_platform_pillar) \n    penalty_collision = -25 if (d_agent_platform_pillar < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bus terminal, the drone must maneuver around bench. All entity states (agent, goal, bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -25 if (d_agent_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bus terminal. Requirement: Detect the three vending machine and do not collide with it. Given: The states for the drone and multiple vending machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bus terminal. \n Objectives: So not collide with escalator. \n Conditions: The states of the agent, goal, the escalator are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_escalator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_escalator = calculate_distance_min(s_agent, s_escalator) \n    penalty_collision = -25 if (d_agent_escalator < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bus terminal. Objectives: Do not collide hit with the bus door. Conditions: States of the agent, bus door are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_bus_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bus_door = calculate_distance_min(s_agent, s_bus_door) \n    penalty_collision = -25 if (d_agent_bus_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bus terminal, the drone must steer clear of passenger. All states (agent, goal, passenger) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_passenger, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_passenger) \n    penalty_collision = -25 if (d_agent_passenger < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bus terminal. Avoid: Detect queue stanchion belt and do not hitting with queue stanchion belt. Known: Agent, goal, queue stanchion belt states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_queue_stanchion_belt, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_queue_stanchion_belt = calculate_distance_min(s_agent, s_queue_stanchion_belt) \n    penalty_collision = -25 if (d_agent_queue_stanchion_belt < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bus terminal. Objectives: It must avoid colliding with luggage cart. Conditions: The states of the drone, goal and luggage cart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_luggage_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_luggage_cart = calculate_distance_min(s_agent, s_luggage_cart) \n    penalty_collision = -25 if (d_agent_luggage_cart < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bus terminal. Objectives: Avoid collision with bus door, luggage cart and ticket kiosk. Conditions: The states of the agent and of the multiple obstacles: bus door, luggage cart and ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bus terminal. Objectives: It must avoid colliding with any queue stanchion belt, bus terminal door motor. Conditions: Agent's and of the multiple obstacle: queue stanchion belt, bus terminal door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bus terminal. Objectives: Do not collide with platform pillar. Conditions: The states of the drone, goal and the platform pillar are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform_pillar = calculate_distance_min(s_agent, s_platform_pillar) \n    penalty = -25 if (d_agent_platform_pillar < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bus terminal and must avoid contact with the luggage pile. The states of the drone, goal and the luggage pile are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_luggage_pile, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_luggage_pile = calculate_distance_min(s_agent, s_luggage_pile) \n    penalty = -25 if (d_agent_luggage_pile < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bus terminal. It must avoid colliding with the queue stanchion belt, platform gate and rolling suitcase. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony platform gate and rolling suitcase are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bus terminal. It must avoid colliding with the glass ticket booth and queue stanchion belt. The states of the drone, goal and of the multiple obstacle: the glass ticket booth and queue stanchion belt are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bus terminal. It must avoid colliding with the overhead signboard. Agent's state, goal's state and overhead signboard's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_overhead_signboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_overhead_signboard = calculate_distance_min(s_agent, s_overhead_signboard) \n    penalty_collision = -25 if (d_agent_overhead_signboard < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: It must avoid colliding with overhead signboard. Assumptions: The states of the drone, goal and the rolling suitcase's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_rolling_suitcase, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rolling_suitcase = calculate_distance_min(s_agent, s_rolling_suitcase) \n    penalty_collision = -25 if (d_agent_rolling_suitcase < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: It must avoid colliding with bus terminal's platform pillars, bench row and glass wall. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, information kiosk and passenger are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: Detect trash bin, trash bin and platform pillar and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, trash bin and platform pillar state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along coffee shop. \n Objectives: It must avoid colliding with pastry display or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the pastry display and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy coffee shop. \n Objectives: Detect trash can and aviod it. \n Conditions: The states of the agent, goal, the trash can are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_can, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_can) \n    penalty_collision = -25 if (d_agent_trash_can < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a coffee shop. Objectives: It must avoid colliding with bar stool. Conditions: States of the drone and the bar stool are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bar_stool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bar_stool = calculate_distance_min(s_agent, s_bar_stool) \n    penalty_collision = -25 if (d_agent_bar_stool < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a coffee shop, the drone must maneuver around couch. All entity states (agent, goal, couch) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_couch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_couch = calculate_distance_min(s_agent, s_couch) \n    penalty_collision = -25 if (d_agent_couch < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a coffee shop. Requirement: Detect the three fridge display and do not collide with it. Given: The states for the drone and multiple fridge display are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a coffee shop. \n Objectives: So not collide with stairway. \n Conditions: The states of the agent, goal, the stairway are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_stairway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stairway = calculate_distance_min(s_agent, s_stairway) \n    penalty_collision = -25 if (d_agent_stairway < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate coffee shop. Objectives: Do not collide hit with the coffee counter door. Conditions: States of the agent, coffee counter door are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_glass_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_door = calculate_distance_min(s_agent, s_glass_door) \n    penalty_collision = -25 if (d_agent_glass_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a coffee shop, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -25 if (d_agent_customer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: coffee shop. Avoid: Detect rope barrier and do not hitting with rope barrier. Known: Agent, goal, rope barrier states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_rope_barrier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope_barrier = calculate_distance_min(s_agent, s_rope_barrier) \n    penalty_collision = -25 if (d_agent_rope_barrier < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating coffee shop. Objectives: It must avoid colliding with pastry display. Conditions: The states of the drone, goal and pastry display are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_pastry_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pastry_display = calculate_distance_min(s_agent, s_pastry_display) \n    penalty_collision = -25 if (d_agent_pastry_display < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through coffee shop. Objectives: Avoid collision with coffee counter door, pastry display and ticket kiosk. Conditions: The states of the agent and of the multiple obstacles: coffee counter door, pastry display and ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating coffee shop. Objectives: It must avoid colliding with any rope barrier, coffee shop door motor. Conditions: Agent's and of the multiple obstacle: rope barrier, coffee shop door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through coffee shop. Objectives: Do not collide with platform coffee table. Conditions: The states of the drone, goal and the platform coffee table are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_table = calculate_distance_min(s_agent, s_coffee_table) \n    penalty = -25 if (d_agent_coffee_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along coffee shop and must avoid contact with the sack of coffee beans. The states of the drone, goal and the sack of coffee beans are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_coffee_bean_sack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_bean_sack = calculate_distance_min(s_agent, s_coffee_bean_sack) \n    penalty = -25 if (d_agent_coffee_bean_sack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in coffee shop. It must avoid colliding with the rope barrier, swinging door and serving tray. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony swinging door and serving tray are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in coffee shop. It must avoid colliding with the glass pastry case and rope barrier. The states of the drone, goal and of the multiple obstacle: the glass pastry case and rope barrier are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in coffee shop. It must avoid colliding with the menu sign. Agent's state, goal's state and menu sign's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_menu_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_menu_sign = calculate_distance_min(s_agent, s_menu_sign) \n    penalty_collision = -25 if (d_agent_menu_sign < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: It must avoid colliding with menu sign. Assumptions: The states of the drone, goal and the serving tray's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_serving_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_serving_tray = calculate_distance_min(s_agent, s_serving_tray) \n    penalty_collision = -25 if (d_agent_serving_tray < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: It must avoid colliding with coffee shop's platform pillars, couch row and glass partition. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, menu board and customer are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: Detect trash can, trash can and platform coffee table and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, trash can and platform coffee table state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along pharmacy. \n Objectives: It must avoid colliding with medicine fridge or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the medicine fridge and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy pharmacy. \n Objectives: Detect biohazard bin and aviod it. \n Conditions: The states of the agent, goal, the biohazard bin are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_biohazard_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_biohazard_bin = calculate_distance_min(s_agent, s_biohazard_bin) \n    penalty_collision = -25 if (d_agent_biohazard_bin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a pharmacy. Objectives: It must avoid colliding with platform consultation desk. Conditions: States of the drone and the platform consultation desk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weighing_scale, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_weighing_scale = calculate_distance_min(s_agent, s_weighing_scale) \n    penalty_collision = -25 if (d_agent_weighing_scale < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a pharmacy, the drone must maneuver around waiting bench. All entity states (agent, goal, waiting bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_waiting_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_waiting_bench = calculate_distance_min(s_agent, s_waiting_bench) \n    penalty_collision = -25 if (d_agent_waiting_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a pharmacy. Requirement: Detect the three refrigerated cabinet and do not collide with it. Given: The states for the drone and multiple refrigerated cabinet are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a pharmacy. \n Objectives: So not collide with emergency exit. \n Conditions: The states of the agent, goal, the emergency exit are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_emergency_exit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_emergency_exit = calculate_distance_min(s_agent, s_emergency_exit) \n    penalty_collision = -25 if (d_agent_emergency_exit < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate pharmacy. Objectives: Do not collide hit with the prescription counter door. Conditions: States of the agent, prescription counter door are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_sliding_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sliding_door = calculate_distance_min(s_agent, s_sliding_door) \n    penalty_collision = -25 if (d_agent_sliding_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a pharmacy, the drone must steer clear of patient. All states (agent, goal, patient) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -25 if (d_agent_patient < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: pharmacy. Avoid: Detect safety barrier and do not hitting with safety barrier. Known: Agent, goal, safety barrier states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_safety_barrier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_safety_barrier = calculate_distance_min(s_agent, s_safety_barrier) \n    penalty_collision = -25 if (d_agent_safety_barrier < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating pharmacy. Objectives: It must avoid colliding with medicine fridge. Conditions: The states of the drone, goal and medicine fridge are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_medicine_fridge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_medicine_fridge = calculate_distance_min(s_agent, s_medicine_fridge) \n    penalty_collision = -25 if (d_agent_medicine_fridge < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through pharmacy. Objectives: Avoid collision with prescription counter door, medicine fridge and customers. Conditions: The states of the agent and of the multiple obstacles: prescription counter door, medicine fridge and customers are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating pharmacy. Objectives: It must avoid colliding with any safety barrier, pharmacy door motor. Conditions: Agent's and of the multiple obstacle: safety barrier, pharmacy door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through pharmacy. Objectives: Do not collide with platform consultation desk. Conditions: The states of the drone, goal and the platform consultation desk are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weighing_scale, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_weighing_scale = calculate_distance_min(s_agent, s_weighing_scale) \n    penalty = -25 if (d_agent_weighing_scale < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along pharmacy and must avoid contact with the sack of medicine supplies. The states of the drone, goal and the sack of medicine supplies are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_medicine_supplies_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_medicine_supplies_box = calculate_distance_min(s_agent, s_medicine_supplies_box) \n    penalty = -25 if (d_agent_medicine_supplies_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in pharmacy. It must avoid colliding with the safety barrier, staff door and medicine tray. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony staff door and medicine tray are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in pharmacy. It must avoid colliding with the locked medicine cabinet and safety barrier. The states of the drone, goal and of the multiple obstacle: the locked medicine cabinet and safety barrier are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in pharmacy. It must avoid colliding with the drug information poster. Agent's state, goal's state and drug information poster's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drug_information_poster, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drug_information_poster = calculate_distance_min(s_agent, s_drug_information_poster) \n    penalty_collision = -25 if (d_agent_drug_information_poster < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: It must avoid colliding with drug information poster. Assumptions: The states of the drone, goal and the medicine tray's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_medicine_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_medicine_tray = calculate_distance_min(s_agent, s_medicine_tray) \n    penalty_collision = -25 if (d_agent_medicine_tray < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: It must avoid colliding with pharmacy's platform pillars, waiting bench row and protective glass panel. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, digital prescription screen and patient are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: Detect biohazard bin, biohazard bin and platform consultation desk and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, biohazard bin and platform consultation desk state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bakery. \n Objectives: It must avoid colliding with cake display fridge or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the cake display fridge and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bakery. \n Objectives: Detect trash bin and aviod it. \n Conditions: The states of the agent, goal, the trash bin are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -25 if (d_agent_trash_bin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bakery. Objectives: It must avoid colliding with sign. Conditions: States of the drone and the sign are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -25 if (d_agent_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bakery, the drone must maneuver around bench. All entity states (agent, goal, bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -25 if (d_agent_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bakery. Requirement: Detect the three refrigerated display and do not collide with it. Given: The states for the drone and multiple refrigerated display are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bakery. \n Objectives: So not collide with displayas case. \n Conditions: The states of the agent, goal, the display case are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_display_case, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_escalator = calculate_distance_min(s_agent, s_display_case) \n    penalty_collision = -25 if (d_agent_display_case < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bakery. Objectives: Do not collide hit with the bowl stand. Conditions: States of the agent, bowl stand are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_bowl_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bowl_stand = calculate_distance_min(s_agent, s_bowl_stand) \n    penalty_collision = -25 if (d_agent_bowl_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bakery, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -25 if (d_agent_passenger < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bakery. Avoid: Detect cabinet and do not hitting with cabinet. Known: Agent, goal, cabinet states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabinet = calculate_distance_min(s_agent, s_cabinet) \n    penalty_collision = -25 if (d_agent_cabinet < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bakery. Objectives: It must avoid colliding with cake display fridge. Conditions: The states of the drone, goal and cake display fridge are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fridge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fridge = calculate_distance_min(s_agent, s_fridge) \n    penalty_collision = -25 if (d_agent_fridge < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bakery. Objectives: Avoid collision with bread counter door, cake display fridge and queue. Conditions: The states of the agent and of the multiple obstacles: bread counter door, cake display fridge and queue are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bakery. Objectives: It must avoid colliding with any customers, bakery door. Conditions: Agent's and of the multiple obstacle: customers, bakery door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bakery. Objectives: Do not collide with sign. Conditions: The states of the drone, goal and the sign are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sign = calculate_distance_min(s_agent, s_sign) \n    penalty = -25 if (d_agent_sign < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bakery and must avoid contact with the sack of flour sacks. The states of the drone, goal and the sack of flour sacks are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_flour_sacks, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flour_sacks = calculate_distance_min(s_agent, s_flour_sacks) \n    penalty = -25 if (d_agent_flour_sacks < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bakery. It must avoid colliding with the plants, swinging door and baking tray. The states of the agent and of the multiple obstacle: plants, sliding balcony door and baking tray are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bakery. It must avoid colliding with the pastry case and plants. The states of the drone, goal and of the multiple obstacle: the pastry case and plants are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bakery. It must avoid colliding with the daily specials board. Agent's state, goal's state and daily specials board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_board = calculate_distance_min(s_agent, s_board) \n    penalty_collision = -25 if (d_agent_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: It must avoid colliding with daily specials board. Assumptions: The states of the drone, goal and the baking tray's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_baking_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_baking_tray = calculate_distance_min(s_agent, s_baking_tray) \n    penalty_collision = -25 if (d_agent_baking_tray < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: It must avoid colliding with bakery's platform pillars, bench row and sneeze guard. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, digital menu board and customer are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: Detect trash bin, trash bin and sign and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, trash bin and sign state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bookstore. \n Objectives: It must avoid colliding with display table or book shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the display table and the book shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bookstore. \n Objectives: Detect book stack and aviod it. \n Conditions: The states of the agent, goal, the book stack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_stack = calculate_distance_min(s_agent, s_book_stack) \n    penalty_collision = -25 if (d_agent_book_stack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bookstore. Objectives: It must avoid colliding with book stack. Conditions: States of the drone and the book stack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goacustomerl) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -25 if (d_agent_customer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bookstore, the drone must maneuver around reading bench. All entity states (agent, goal, reading bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_reading_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_reading_bench) \n    penalty_collision = -25 if (d_agent_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bookstore. Requirement: Detect the three magazine rack and do not collide with it. Given: The states for the drone and multiple magazine rack are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bookstore. \n Objectives: So not collide with box. \n Conditions: The states of the agent, goal, the box are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -25 if (d_agent_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bookstore. Objectives: Do not collide hit with the cashier counter. Conditions: States of the agent, cashier counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -25 if (d_agent_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bookstore, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -25 if (d_agent_customer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bookstore. Avoid: Detect book and do not hitting with book. Known: Agent, goal, book states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -25 if (d_agent_book < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bookstore. Objectives: It must avoid colliding with display table. Conditions: The states of the drone, goal and display table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_display_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display_table = calculate_distance_min(s_agent, s_display_table) \n    penalty_collision = -25 if (d_agent_display_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bookstore. Objectives: Avoid collision with cashier counter door, display table and book shelf. Conditions: The states of the agent and of the multiple obstacles: cashier counter door, display table and book shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bookstore. Objectives: It must avoid colliding with any book, bookstore door. Conditions: Agent's and of the multiple obstacle: book, bookstore door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bookstore. Objectives: Do not collide with book stack. Conditions: The states of the drone, goal and the book stack are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_stack = calculate_distance_min(s_agent, s_book_stack) \n    penalty = -25 if (d_agent_book_stack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bookstore and must avoid contact with the sack of book shipment boxes. The states of the drone, goal and the sack of book shipment boxes are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_book_shipment_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_shipment_box = calculate_distance_min(s_agent, s_book_shipment_box) \n    penalty = -25 if (d_agent_book_shipment_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bookstore. It must avoid colliding with the book, staff door and book cart. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony staff door and book cart are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bookstore. It must avoid colliding with the glass display case and book. The states of the drone, goal and of the multiple obstacle: the glass display case and book are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bookstore. It must avoid colliding with the event poster board. Agent's state, goal's state and event poster board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_event_poster_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_event_poster_board = calculate_distance_min(s_agent, s_event_poster_board) \n    penalty_collision = -25 if (d_agent_event_poster_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: It must avoid colliding with event poster board. Assumptions: The states of the drone, goal and the book cart's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_cart = calculate_distance_min(s_agent, s_book_cart) \n    penalty_collision = -25 if (d_agent_book_cart < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: It must avoid colliding with bookstore's platform pillars, reading bench row and protective glass panel. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, digital catalog screen and customer are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: Detect book stack, book stack and book stack and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, book stack and book stack state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bus terminal. \n Objectives: It must avoid colliding with luggage cart or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the luggage cart and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bus terminal. \n Objectives: Detect trash bin and aviod it. \n Conditions: The states of the agent, goal, the trash bin are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -25 if (d_agent_trash_bin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bus terminal. Objectives: It must avoid colliding with platform pillar. Conditions: States of the drone and the platform pillar are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform_pillar = calculate_distance_min(s_agent, s_platform_pillar) \n    penalty_collision = -25 if (d_agent_platform_pillar < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bus terminal, the drone must maneuver around bench. All entity states (agent, goal, bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -25 if (d_agent_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bus terminal. Requirement: Detect the three vending machine and do not collide with it. Given: The states for the drone and multiple vending machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bus terminal. \n Objectives: So not collide with escalator. \n Conditions: The states of the agent, goal, the escalator are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_escalator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_escalator = calculate_distance_min(s_agent, s_escalator) \n    penalty_collision = -25 if (d_agent_escalator < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bus terminal. Objectives: Do not collide hit with the bus door. Conditions: States of the agent, bus door are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_bus_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bus_door = calculate_distance_min(s_agent, s_bus_door) \n    penalty_collision = -25 if (d_agent_bus_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bus terminal, the drone must steer clear of passenger. All states (agent, goal, passenger) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_passenger, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_passenger) \n    penalty_collision = -25 if (d_agent_passenger < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bus terminal. Avoid: Detect queue stanchion belt and do not hitting with queue stanchion belt. Known: Agent, goal, queue stanchion belt states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_queue_stanchion_belt, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_queue_stanchion_belt = calculate_distance_min(s_agent, s_queue_stanchion_belt) \n    penalty_collision = -25 if (d_agent_queue_stanchion_belt < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bus terminal. Objectives: It must avoid colliding with luggage cart. Conditions: The states of the drone, goal and luggage cart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_luggage_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_luggage_cart = calculate_distance_min(s_agent, s_luggage_cart) \n    penalty_collision = -25 if (d_agent_luggage_cart < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bus terminal. Objectives: Avoid collision with bus door, luggage cart and ticket kiosk. Conditions: The states of the agent and of the multiple obstacles: bus door, luggage cart and ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bus terminal. Objectives: It must avoid colliding with any queue stanchion belt, bus terminal door motor. Conditions: Agent's and of the multiple obstacle: queue stanchion belt, bus terminal door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bus terminal. Objectives: Do not collide with platform pillar. Conditions: The states of the drone, goal and the platform pillar are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform_pillar = calculate_distance_min(s_agent, s_platform_pillar) \n    penalty = -25 if (d_agent_platform_pillar < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bus terminal and must avoid contact with the luggage pile. The states of the drone, goal and the luggage pile are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_luggage_pile, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_luggage_pile = calculate_distance_min(s_agent, s_luggage_pile) \n    penalty = -25 if (d_agent_luggage_pile < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bus terminal. It must avoid colliding with the queue stanchion belt, platform gate and rolling suitcase. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony platform gate and rolling suitcase are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bus terminal. It must avoid colliding with the glass ticket booth and queue stanchion belt. The states of the drone, goal and of the multiple obstacle: the glass ticket booth and queue stanchion belt are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bus terminal. It must avoid colliding with the overhead signboard. Agent's state, goal's state and overhead signboard's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_overhead_signboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_overhead_signboard = calculate_distance_min(s_agent, s_overhead_signboard) \n    penalty_collision = -25 if (d_agent_overhead_signboard < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: It must avoid colliding with overhead signboard. Assumptions: The states of the drone, goal and the rolling suitcase's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_rolling_suitcase, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rolling_suitcase = calculate_distance_min(s_agent, s_rolling_suitcase) \n    penalty_collision = -25 if (d_agent_rolling_suitcase < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: It must avoid colliding with bus terminal's platform pillars, bench row and glass wall. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, information kiosk and passenger are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: Detect trash bin, trash bin and platform pillar and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, trash bin and platform pillar state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along coffee shop. \n Objectives: It must avoid colliding with pastry display or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the pastry display and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy coffee shop. \n Objectives: Detect trash can and aviod it. \n Conditions: The states of the agent, goal, the trash can are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_can, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_can) \n    penalty_collision = -25 if (d_agent_trash_can < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a coffee shop. Objectives: It must avoid colliding with bar stool. Conditions: States of the drone and the bar stool are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bar_stool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bar_stool = calculate_distance_min(s_agent, s_bar_stool) \n    penalty_collision = -25 if (d_agent_bar_stool < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a coffee shop, the drone must maneuver around couch. All entity states (agent, goal, couch) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_couch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_couch = calculate_distance_min(s_agent, s_couch) \n    penalty_collision = -25 if (d_agent_couch < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a coffee shop. Requirement: Detect the three fridge display and do not collide with it. Given: The states for the drone and multiple fridge display are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a coffee shop. \n Objectives: So not collide with stairway. \n Conditions: The states of the agent, goal, the stairway are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_stairway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stairway = calculate_distance_min(s_agent, s_stairway) \n    penalty_collision = -25 if (d_agent_stairway < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate coffee shop. Objectives: Do not collide hit with the coffee counter door. Conditions: States of the agent, coffee counter door are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_glass_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_door = calculate_distance_min(s_agent, s_glass_door) \n    penalty_collision = -25 if (d_agent_glass_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a coffee shop, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -25 if (d_agent_customer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: coffee shop. Avoid: Detect rope barrier and do not hitting with rope barrier. Known: Agent, goal, rope barrier states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_rope_barrier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope_barrier = calculate_distance_min(s_agent, s_rope_barrier) \n    penalty_collision = -25 if (d_agent_rope_barrier < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating coffee shop. Objectives: It must avoid colliding with pastry display. Conditions: The states of the drone, goal and pastry display are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_pastry_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pastry_display = calculate_distance_min(s_agent, s_pastry_display) \n    penalty_collision = -25 if (d_agent_pastry_display < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through coffee shop. Objectives: Avoid collision with coffee counter door, pastry display and ticket kiosk. Conditions: The states of the agent and of the multiple obstacles: coffee counter door, pastry display and ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating coffee shop. Objectives: It must avoid colliding with any rope barrier, coffee shop door motor. Conditions: Agent's and of the multiple obstacle: rope barrier, coffee shop door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through coffee shop. Objectives: Do not collide with platform coffee table. Conditions: The states of the drone, goal and the platform coffee table are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_table = calculate_distance_min(s_agent, s_coffee_table) \n    penalty = -25 if (d_agent_coffee_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along coffee shop and must avoid contact with the sack of coffee beans. The states of the drone, goal and the sack of coffee beans are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_coffee_bean_sack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_bean_sack = calculate_distance_min(s_agent, s_coffee_bean_sack) \n    penalty = -25 if (d_agent_coffee_bean_sack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in coffee shop. It must avoid colliding with the rope barrier, swinging door and serving tray. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony swinging door and serving tray are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in coffee shop. It must avoid colliding with the glass pastry case and rope barrier. The states of the drone, goal and of the multiple obstacle: the glass pastry case and rope barrier are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in coffee shop. It must avoid colliding with the menu sign. Agent's state, goal's state and menu sign's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_menu_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_menu_sign = calculate_distance_min(s_agent, s_menu_sign) \n    penalty_collision = -25 if (d_agent_menu_sign < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: It must avoid colliding with menu sign. Assumptions: The states of the drone, goal and the serving tray's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_serving_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_serving_tray = calculate_distance_min(s_agent, s_serving_tray) \n    penalty_collision = -25 if (d_agent_serving_tray < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: It must avoid colliding with coffee shop's platform pillars, couch row and glass partition. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, menu board and customer are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: Detect trash can, trash can and platform coffee table and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, trash can and platform coffee table state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along pharmacy. \n Objectives: It must avoid colliding with medicine fridge or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the medicine fridge and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy pharmacy. \n Objectives: Detect biohazard bin and aviod it. \n Conditions: The states of the agent, goal, the biohazard bin are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_biohazard_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_biohazard_bin = calculate_distance_min(s_agent, s_biohazard_bin) \n    penalty_collision = -25 if (d_agent_biohazard_bin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a pharmacy. Objectives: It must avoid colliding with platform consultation desk. Conditions: States of the drone and the platform consultation desk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weighing_scale, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_weighing_scale = calculate_distance_min(s_agent, s_weighing_scale) \n    penalty_collision = -25 if (d_agent_weighing_scale < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a pharmacy, the drone must maneuver around waiting bench. All entity states (agent, goal, waiting bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_waiting_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_waiting_bench = calculate_distance_min(s_agent, s_waiting_bench) \n    penalty_collision = -25 if (d_agent_waiting_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a pharmacy. Requirement: Detect the three refrigerated cabinet and do not collide with it. Given: The states for the drone and multiple refrigerated cabinet are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a pharmacy. \n Objectives: So not collide with emergency exit. \n Conditions: The states of the agent, goal, the emergency exit are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_emergency_exit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_emergency_exit = calculate_distance_min(s_agent, s_emergency_exit) \n    penalty_collision = -25 if (d_agent_emergency_exit < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate pharmacy. Objectives: Do not collide hit with the prescription counter door. Conditions: States of the agent, prescription counter door are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_sliding_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sliding_door = calculate_distance_min(s_agent, s_sliding_door) \n    penalty_collision = -25 if (d_agent_sliding_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a pharmacy, the drone must steer clear of patient. All states (agent, goal, patient) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -25 if (d_agent_patient < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: pharmacy. Avoid: Detect safety barrier and do not hitting with safety barrier. Known: Agent, goal, safety barrier states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_safety_barrier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_safety_barrier = calculate_distance_min(s_agent, s_safety_barrier) \n    penalty_collision = -25 if (d_agent_safety_barrier < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating pharmacy. Objectives: It must avoid colliding with medicine fridge. Conditions: The states of the drone, goal and medicine fridge are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_medicine_fridge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_medicine_fridge = calculate_distance_min(s_agent, s_medicine_fridge) \n    penalty_collision = -25 if (d_agent_medicine_fridge < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through pharmacy. Objectives: Avoid collision with prescription counter door, medicine fridge and customers. Conditions: The states of the agent and of the multiple obstacles: prescription counter door, medicine fridge and customers are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating pharmacy. Objectives: It must avoid colliding with any safety barrier, pharmacy door motor. Conditions: Agent's and of the multiple obstacle: safety barrier, pharmacy door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through pharmacy. Objectives: Do not collide with platform consultation desk. Conditions: The states of the drone, goal and the platform consultation desk are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weighing_scale, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_weighing_scale = calculate_distance_min(s_agent, s_weighing_scale) \n    penalty = -25 if (d_agent_weighing_scale < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along pharmacy and must avoid contact with the sack of medicine supplies. The states of the drone, goal and the sack of medicine supplies are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_medicine_supplies_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_medicine_supplies_box = calculate_distance_min(s_agent, s_medicine_supplies_box) \n    penalty = -25 if (d_agent_medicine_supplies_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in pharmacy. It must avoid colliding with the safety barrier, staff door and medicine tray. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony staff door and medicine tray are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in pharmacy. It must avoid colliding with the locked medicine cabinet and safety barrier. The states of the drone, goal and of the multiple obstacle: the locked medicine cabinet and safety barrier are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in pharmacy. It must avoid colliding with the drug information poster. Agent's state, goal's state and drug information poster's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drug_information_poster, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drug_information_poster = calculate_distance_min(s_agent, s_drug_information_poster) \n    penalty_collision = -25 if (d_agent_drug_information_poster < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: It must avoid colliding with drug information poster. Assumptions: The states of the drone, goal and the medicine tray's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_medicine_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_medicine_tray = calculate_distance_min(s_agent, s_medicine_tray) \n    penalty_collision = -25 if (d_agent_medicine_tray < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: It must avoid colliding with pharmacy's platform pillars, waiting bench row and protective glass panel. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, digital prescription screen and patient are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: Detect biohazard bin, biohazard bin and platform consultation desk and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, biohazard bin and platform consultation desk state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bakery. \n Objectives: It must avoid colliding with cake display fridge or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the cake display fridge and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bakery. \n Objectives: Detect trash bin and aviod it. \n Conditions: The states of the agent, goal, the trash bin are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -25 if (d_agent_trash_bin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bakery. Objectives: It must avoid colliding with sign. Conditions: States of the drone and the sign are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -25 if (d_agent_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bakery, the drone must maneuver around bench. All entity states (agent, goal, bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -25 if (d_agent_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bakery. Requirement: Detect the three refrigerated display and do not collide with it. Given: The states for the drone and multiple refrigerated display are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bakery. \n Objectives: So not collide with displayas case. \n Conditions: The states of the agent, goal, the display case are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_display_case, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_escalator = calculate_distance_min(s_agent, s_display_case) \n    penalty_collision = -25 if (d_agent_display_case < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bakery. Objectives: Do not collide hit with the bowl stand. Conditions: States of the agent, bowl stand are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_bowl_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bowl_stand = calculate_distance_min(s_agent, s_bowl_stand) \n    penalty_collision = -25 if (d_agent_bowl_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bakery, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -25 if (d_agent_passenger < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bakery. Avoid: Detect cabinet and do not hitting with cabinet. Known: Agent, goal, cabinet states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabinet = calculate_distance_min(s_agent, s_cabinet) \n    penalty_collision = -25 if (d_agent_cabinet < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bakery. Objectives: It must avoid colliding with cake display fridge. Conditions: The states of the drone, goal and cake display fridge are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fridge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fridge = calculate_distance_min(s_agent, s_fridge) \n    penalty_collision = -25 if (d_agent_fridge < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bakery. Objectives: Avoid collision with bread counter door, cake display fridge and queue. Conditions: The states of the agent and of the multiple obstacles: bread counter door, cake display fridge and queue are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bakery. Objectives: It must avoid colliding with any customers, bakery door. Conditions: Agent's and of the multiple obstacle: customers, bakery door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bakery. Objectives: Do not collide with sign. Conditions: The states of the drone, goal and the sign are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sign = calculate_distance_min(s_agent, s_sign) \n    penalty = -25 if (d_agent_sign < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bakery and must avoid contact with the sack of flour sacks. The states of the drone, goal and the sack of flour sacks are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_flour_sacks, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flour_sacks = calculate_distance_min(s_agent, s_flour_sacks) \n    penalty = -25 if (d_agent_flour_sacks < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bakery. It must avoid colliding with the plants, swinging door and baking tray. The states of the agent and of the multiple obstacle: plants, sliding balcony door and baking tray are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bakery. It must avoid colliding with the pastry case and plants. The states of the drone, goal and of the multiple obstacle: the pastry case and plants are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bakery. It must avoid colliding with the daily specials board. Agent's state, goal's state and daily specials board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_board = calculate_distance_min(s_agent, s_board) \n    penalty_collision = -25 if (d_agent_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: It must avoid colliding with daily specials board. Assumptions: The states of the drone, goal and the baking tray's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_baking_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_baking_tray = calculate_distance_min(s_agent, s_baking_tray) \n    penalty_collision = -25 if (d_agent_baking_tray < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: It must avoid colliding with bakery's platform pillars, bench row and sneeze guard. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, digital menu board and customer are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: Detect trash bin, trash bin and sign and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, trash bin and sign state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bookstore. \n Objectives: It must avoid colliding with display table or book shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the display table and the book shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bookstore. \n Objectives: Detect book stack and aviod it. \n Conditions: The states of the agent, goal, the book stack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_stack = calculate_distance_min(s_agent, s_book_stack) \n    penalty_collision = -25 if (d_agent_book_stack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bookstore. Objectives: It must avoid colliding with book stack. Conditions: States of the drone and the book stack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goacustomerl) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -25 if (d_agent_customer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bookstore, the drone must maneuver around reading bench. All entity states (agent, goal, reading bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_reading_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_reading_bench) \n    penalty_collision = -25 if (d_agent_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bookstore. Requirement: Detect the three magazine rack and do not collide with it. Given: The states for the drone and multiple magazine rack are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bookstore. \n Objectives: So not collide with box. \n Conditions: The states of the agent, goal, the box are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -25 if (d_agent_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bookstore. Objectives: Do not collide hit with the cashier counter. Conditions: States of the agent, cashier counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -25 if (d_agent_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bookstore, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -25 if (d_agent_customer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bookstore. Avoid: Detect book and do not hitting with book. Known: Agent, goal, book states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -25 if (d_agent_book < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bookstore. Objectives: It must avoid colliding with display table. Conditions: The states of the drone, goal and display table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_display_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display_table = calculate_distance_min(s_agent, s_display_table) \n    penalty_collision = -25 if (d_agent_display_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bookstore. Objectives: Avoid collision with cashier counter door, display table and book shelf. Conditions: The states of the agent and of the multiple obstacles: cashier counter door, display table and book shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bookstore. Objectives: It must avoid colliding with any book, bookstore door. Conditions: Agent's and of the multiple obstacle: book, bookstore door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bookstore. Objectives: Do not collide with book stack. Conditions: The states of the drone, goal and the book stack are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_stack = calculate_distance_min(s_agent, s_book_stack) \n    penalty = -25 if (d_agent_book_stack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bookstore and must avoid contact with the sack of book shipment boxes. The states of the drone, goal and the sack of book shipment boxes are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_book_shipment_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_shipment_box = calculate_distance_min(s_agent, s_book_shipment_box) \n    penalty = -25 if (d_agent_book_shipment_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bookstore. It must avoid colliding with the book, staff door and book cart. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony staff door and book cart are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bookstore. It must avoid colliding with the glass display case and book. The states of the drone, goal and of the multiple obstacle: the glass display case and book are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bookstore. It must avoid colliding with the event poster board. Agent's state, goal's state and event poster board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_event_poster_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_event_poster_board = calculate_distance_min(s_agent, s_event_poster_board) \n    penalty_collision = -25 if (d_agent_event_poster_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: It must avoid colliding with event poster board. Assumptions: The states of the drone, goal and the book cart's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_cart = calculate_distance_min(s_agent, s_book_cart) \n    penalty_collision = -25 if (d_agent_book_cart < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: It must avoid colliding with bookstore's platform pillars, reading bench row and protective glass panel. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, digital catalog screen and customer are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: Detect book stack, book stack and book stack and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, book stack and book stack state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*3 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bus terminal. \n Objectives: It must avoid colliding with luggage cart or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the luggage cart and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bus terminal. \n Objectives: Detect trash bin and aviod it. \n Conditions: The states of the agent, goal, the trash bin are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -29 if (d_agent_trash_bin < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bus terminal. Objectives: It must avoid colliding with platform pillar. Conditions: States of the drone and the platform pillar are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform_pillar = calculate_distance_min(s_agent, s_platform_pillar) \n    penalty_collision = -29 if (d_agent_platform_pillar < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bus terminal, the drone must maneuver around bench. All entity states (agent, goal, bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -29 if (d_agent_bench < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bus terminal. Requirement: Detect the three vending machine and do not collide with it. Given: The states for the drone and multiple vending machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bus terminal. \n Objectives: So not collide with escalator. \n Conditions: The states of the agent, goal, the escalator are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_escalator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_escalator = calculate_distance_min(s_agent, s_escalator) \n    penalty_collision = -29 if (d_agent_escalator < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bus terminal. Objectives: Do not collide hit with the bus door. Conditions: States of the agent, bus door are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_bus_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bus_door = calculate_distance_min(s_agent, s_bus_door) \n    penalty_collision = -29 if (d_agent_bus_door < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bus terminal, the drone must steer clear of passenger. All states (agent, goal, passenger) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_passenger, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_passenger) \n    penalty_collision = -29 if (d_agent_passenger < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bus terminal. Avoid: Detect queue stanchion belt and do not hitting with queue stanchion belt. Known: Agent, goal, queue stanchion belt states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_queue_stanchion_belt, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_queue_stanchion_belt = calculate_distance_min(s_agent, s_queue_stanchion_belt) \n    penalty_collision = -29 if (d_agent_queue_stanchion_belt < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bus terminal. Objectives: It must avoid colliding with luggage cart. Conditions: The states of the drone, goal and luggage cart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_luggage_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_luggage_cart = calculate_distance_min(s_agent, s_luggage_cart) \n    penalty_collision = -29 if (d_agent_luggage_cart < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bus terminal. Objectives: Avoid collision with bus door, luggage cart and ticket kiosk. Conditions: The states of the agent and of the multiple obstacles: bus door, luggage cart and ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bus terminal. Objectives: It must avoid colliding with any queue stanchion belt, bus terminal door motor. Conditions: Agent's and of the multiple obstacle: queue stanchion belt, bus terminal door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bus terminal. Objectives: Do not collide with platform pillar. Conditions: The states of the drone, goal and the platform pillar are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform_pillar = calculate_distance_min(s_agent, s_platform_pillar) \n    penalty = -29 if (d_agent_platform_pillar < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bus terminal and must avoid contact with the luggage pile. The states of the drone, goal and the luggage pile are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_luggage_pile, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_luggage_pile = calculate_distance_min(s_agent, s_luggage_pile) \n    penalty = -29 if (d_agent_luggage_pile < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bus terminal. It must avoid colliding with the queue stanchion belt, platform gate and rolling suitcase. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony platform gate and rolling suitcase are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bus terminal. It must avoid colliding with the glass ticket booth and queue stanchion belt. The states of the drone, goal and of the multiple obstacle: the glass ticket booth and queue stanchion belt are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bus terminal. It must avoid colliding with the overhead signboard. Agent's state, goal's state and overhead signboard's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_overhead_signboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_overhead_signboard = calculate_distance_min(s_agent, s_overhead_signboard) \n    penalty_collision = -29 if (d_agent_overhead_signboard < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: It must avoid colliding with overhead signboard. Assumptions: The states of the drone, goal and the rolling suitcase's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_rolling_suitcase, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rolling_suitcase = calculate_distance_min(s_agent, s_rolling_suitcase) \n    penalty_collision = -29 if (d_agent_rolling_suitcase < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: It must avoid colliding with bus terminal's platform pillars, bench row and glass wall. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, information kiosk and passenger are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: Detect trash bin, trash bin and platform pillar and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, trash bin and platform pillar state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along coffee shop. \n Objectives: It must avoid colliding with pastry display or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the pastry display and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy coffee shop. \n Objectives: Detect trash can and aviod it. \n Conditions: The states of the agent, goal, the trash can are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_can, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_can) \n    penalty_collision = -29 if (d_agent_trash_can < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a coffee shop. Objectives: It must avoid colliding with bar stool. Conditions: States of the drone and the bar stool are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bar_stool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bar_stool = calculate_distance_min(s_agent, s_bar_stool) \n    penalty_collision = -29 if (d_agent_bar_stool < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a coffee shop, the drone must maneuver around couch. All entity states (agent, goal, couch) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_couch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_couch = calculate_distance_min(s_agent, s_couch) \n    penalty_collision = -29 if (d_agent_couch < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a coffee shop. Requirement: Detect the three fridge display and do not collide with it. Given: The states for the drone and multiple fridge display are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a coffee shop. \n Objectives: So not collide with stairway. \n Conditions: The states of the agent, goal, the stairway are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_stairway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stairway = calculate_distance_min(s_agent, s_stairway) \n    penalty_collision = -29 if (d_agent_stairway < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate coffee shop. Objectives: Do not collide hit with the coffee counter door. Conditions: States of the agent, coffee counter door are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_glass_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_door = calculate_distance_min(s_agent, s_glass_door) \n    penalty_collision = -29 if (d_agent_glass_door < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a coffee shop, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -29 if (d_agent_customer < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: coffee shop. Avoid: Detect rope barrier and do not hitting with rope barrier. Known: Agent, goal, rope barrier states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_rope_barrier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope_barrier = calculate_distance_min(s_agent, s_rope_barrier) \n    penalty_collision = -29 if (d_agent_rope_barrier < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating coffee shop. Objectives: It must avoid colliding with pastry display. Conditions: The states of the drone, goal and pastry display are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_pastry_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pastry_display = calculate_distance_min(s_agent, s_pastry_display) \n    penalty_collision = -29 if (d_agent_pastry_display < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through coffee shop. Objectives: Avoid collision with coffee counter door, pastry display and ticket kiosk. Conditions: The states of the agent and of the multiple obstacles: coffee counter door, pastry display and ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating coffee shop. Objectives: It must avoid colliding with any rope barrier, coffee shop door motor. Conditions: Agent's and of the multiple obstacle: rope barrier, coffee shop door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through coffee shop. Objectives: Do not collide with platform coffee table. Conditions: The states of the drone, goal and the platform coffee table are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_table = calculate_distance_min(s_agent, s_coffee_table) \n    penalty = -29 if (d_agent_coffee_table < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along coffee shop and must avoid contact with the sack of coffee beans. The states of the drone, goal and the sack of coffee beans are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_coffee_bean_sack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_bean_sack = calculate_distance_min(s_agent, s_coffee_bean_sack) \n    penalty = -29 if (d_agent_coffee_bean_sack < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in coffee shop. It must avoid colliding with the rope barrier, swinging door and serving tray. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony swinging door and serving tray are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in coffee shop. It must avoid colliding with the glass pastry case and rope barrier. The states of the drone, goal and of the multiple obstacle: the glass pastry case and rope barrier are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in coffee shop. It must avoid colliding with the menu sign. Agent's state, goal's state and menu sign's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_menu_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_menu_sign = calculate_distance_min(s_agent, s_menu_sign) \n    penalty_collision = -29 if (d_agent_menu_sign < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: It must avoid colliding with menu sign. Assumptions: The states of the drone, goal and the serving tray's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_serving_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_serving_tray = calculate_distance_min(s_agent, s_serving_tray) \n    penalty_collision = -29 if (d_agent_serving_tray < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: It must avoid colliding with coffee shop's platform pillars, couch row and glass partition. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, menu board and customer are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: Detect trash can, trash can and platform coffee table and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, trash can and platform coffee table state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along pharmacy. \n Objectives: It must avoid colliding with medicine fridge or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the medicine fridge and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy pharmacy. \n Objectives: Detect biohazard bin and aviod it. \n Conditions: The states of the agent, goal, the biohazard bin are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_biohazard_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_biohazard_bin = calculate_distance_min(s_agent, s_biohazard_bin) \n    penalty_collision = -29 if (d_agent_biohazard_bin < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a pharmacy. Objectives: It must avoid colliding with platform consultation desk. Conditions: States of the drone and the platform consultation desk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weighing_scale, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_weighing_scale = calculate_distance_min(s_agent, s_weighing_scale) \n    penalty_collision = -29 if (d_agent_weighing_scale < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a pharmacy, the drone must maneuver around waiting bench. All entity states (agent, goal, waiting bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_waiting_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_waiting_bench = calculate_distance_min(s_agent, s_waiting_bench) \n    penalty_collision = -29 if (d_agent_waiting_bench < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a pharmacy. Requirement: Detect the three refrigerated cabinet and do not collide with it. Given: The states for the drone and multiple refrigerated cabinet are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a pharmacy. \n Objectives: So not collide with emergency exit. \n Conditions: The states of the agent, goal, the emergency exit are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_emergency_exit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_emergency_exit = calculate_distance_min(s_agent, s_emergency_exit) \n    penalty_collision = -29 if (d_agent_emergency_exit < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate pharmacy. Objectives: Do not collide hit with the prescription counter door. Conditions: States of the agent, prescription counter door are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_sliding_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sliding_door = calculate_distance_min(s_agent, s_sliding_door) \n    penalty_collision = -29 if (d_agent_sliding_door < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a pharmacy, the drone must steer clear of patient. All states (agent, goal, patient) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -29 if (d_agent_patient < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: pharmacy. Avoid: Detect safety barrier and do not hitting with safety barrier. Known: Agent, goal, safety barrier states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_safety_barrier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_safety_barrier = calculate_distance_min(s_agent, s_safety_barrier) \n    penalty_collision = -29 if (d_agent_safety_barrier < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating pharmacy. Objectives: It must avoid colliding with medicine fridge. Conditions: The states of the drone, goal and medicine fridge are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_medicine_fridge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_medicine_fridge = calculate_distance_min(s_agent, s_medicine_fridge) \n    penalty_collision = -29 if (d_agent_medicine_fridge < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through pharmacy. Objectives: Avoid collision with prescription counter door, medicine fridge and customers. Conditions: The states of the agent and of the multiple obstacles: prescription counter door, medicine fridge and customers are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating pharmacy. Objectives: It must avoid colliding with any safety barrier, pharmacy door motor. Conditions: Agent's and of the multiple obstacle: safety barrier, pharmacy door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through pharmacy. Objectives: Do not collide with platform consultation desk. Conditions: The states of the drone, goal and the platform consultation desk are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weighing_scale, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_weighing_scale = calculate_distance_min(s_agent, s_weighing_scale) \n    penalty = -29 if (d_agent_weighing_scale < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along pharmacy and must avoid contact with the sack of medicine supplies. The states of the drone, goal and the sack of medicine supplies are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_medicine_supplies_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_medicine_supplies_box = calculate_distance_min(s_agent, s_medicine_supplies_box) \n    penalty = -29 if (d_agent_medicine_supplies_box < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in pharmacy. It must avoid colliding with the safety barrier, staff door and medicine tray. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony staff door and medicine tray are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in pharmacy. It must avoid colliding with the locked medicine cabinet and safety barrier. The states of the drone, goal and of the multiple obstacle: the locked medicine cabinet and safety barrier are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in pharmacy. It must avoid colliding with the drug information poster. Agent's state, goal's state and drug information poster's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drug_information_poster, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drug_information_poster = calculate_distance_min(s_agent, s_drug_information_poster) \n    penalty_collision = -29 if (d_agent_drug_information_poster < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: It must avoid colliding with drug information poster. Assumptions: The states of the drone, goal and the medicine tray's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_medicine_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_medicine_tray = calculate_distance_min(s_agent, s_medicine_tray) \n    penalty_collision = -29 if (d_agent_medicine_tray < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: It must avoid colliding with pharmacy's platform pillars, waiting bench row and protective glass panel. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, digital prescription screen and patient are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: Detect biohazard bin, biohazard bin and platform consultation desk and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, biohazard bin and platform consultation desk state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bakery. \n Objectives: It must avoid colliding with cake display fridge or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the cake display fridge and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bakery. \n Objectives: Detect trash bin and aviod it. \n Conditions: The states of the agent, goal, the trash bin are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -29 if (d_agent_trash_bin < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bakery. Objectives: It must avoid colliding with sign. Conditions: States of the drone and the sign are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -29 if (d_agent_table < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bakery, the drone must maneuver around bench. All entity states (agent, goal, bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -29 if (d_agent_bench < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bakery. Requirement: Detect the three refrigerated display and do not collide with it. Given: The states for the drone and multiple refrigerated display are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bakery. \n Objectives: So not collide with displayas case. \n Conditions: The states of the agent, goal, the display case are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_display_case, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_escalator = calculate_distance_min(s_agent, s_display_case) \n    penalty_collision = -29 if (d_agent_display_case < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bakery. Objectives: Do not collide hit with the bowl stand. Conditions: States of the agent, bowl stand are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_bowl_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bowl_stand = calculate_distance_min(s_agent, s_bowl_stand) \n    penalty_collision = -29 if (d_agent_bowl_stand < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bakery, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -29 if (d_agent_passenger < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bakery. Avoid: Detect cabinet and do not hitting with cabinet. Known: Agent, goal, cabinet states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabinet = calculate_distance_min(s_agent, s_cabinet) \n    penalty_collision = -29 if (d_agent_cabinet < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bakery. Objectives: It must avoid colliding with cake display fridge. Conditions: The states of the drone, goal and cake display fridge are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fridge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fridge = calculate_distance_min(s_agent, s_fridge) \n    penalty_collision = -29 if (d_agent_fridge < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bakery. Objectives: Avoid collision with bread counter door, cake display fridge and queue. Conditions: The states of the agent and of the multiple obstacles: bread counter door, cake display fridge and queue are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bakery. Objectives: It must avoid colliding with any customers, bakery door. Conditions: Agent's and of the multiple obstacle: customers, bakery door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bakery. Objectives: Do not collide with sign. Conditions: The states of the drone, goal and the sign are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sign = calculate_distance_min(s_agent, s_sign) \n    penalty = -29 if (d_agent_sign < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bakery and must avoid contact with the sack of flour sacks. The states of the drone, goal and the sack of flour sacks are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_flour_sacks, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flour_sacks = calculate_distance_min(s_agent, s_flour_sacks) \n    penalty = -29 if (d_agent_flour_sacks < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bakery. It must avoid colliding with the plants, swinging door and baking tray. The states of the agent and of the multiple obstacle: plants, sliding balcony door and baking tray are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bakery. It must avoid colliding with the pastry case and plants. The states of the drone, goal and of the multiple obstacle: the pastry case and plants are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bakery. It must avoid colliding with the daily specials board. Agent's state, goal's state and daily specials board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_board = calculate_distance_min(s_agent, s_board) \n    penalty_collision = -29 if (d_agent_board < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: It must avoid colliding with daily specials board. Assumptions: The states of the drone, goal and the baking tray's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_baking_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_baking_tray = calculate_distance_min(s_agent, s_baking_tray) \n    penalty_collision = -29 if (d_agent_baking_tray < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: It must avoid colliding with bakery's platform pillars, bench row and sneeze guard. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, digital menu board and customer are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: Detect trash bin, trash bin and sign and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, trash bin and sign state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bookstore. \n Objectives: It must avoid colliding with display table or book shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the display table and the book shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bookstore. \n Objectives: Detect book stack and aviod it. \n Conditions: The states of the agent, goal, the book stack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_stack = calculate_distance_min(s_agent, s_book_stack) \n    penalty_collision = -29 if (d_agent_book_stack < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bookstore. Objectives: It must avoid colliding with book stack. Conditions: States of the drone and the book stack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goacustomerl) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -29 if (d_agent_customer < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bookstore, the drone must maneuver around reading bench. All entity states (agent, goal, reading bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_reading_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_reading_bench) \n    penalty_collision = -29 if (d_agent_bench < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bookstore. Requirement: Detect the three magazine rack and do not collide with it. Given: The states for the drone and multiple magazine rack are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bookstore. \n Objectives: So not collide with box. \n Conditions: The states of the agent, goal, the box are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -29 if (d_agent_box < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bookstore. Objectives: Do not collide hit with the cashier counter. Conditions: States of the agent, cashier counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -29 if (d_agent_counter < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bookstore, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -29 if (d_agent_customer < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bookstore. Avoid: Detect book and do not hitting with book. Known: Agent, goal, book states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -29 if (d_agent_book < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bookstore. Objectives: It must avoid colliding with display table. Conditions: The states of the drone, goal and display table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_display_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display_table = calculate_distance_min(s_agent, s_display_table) \n    penalty_collision = -29 if (d_agent_display_table < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bookstore. Objectives: Avoid collision with cashier counter door, display table and book shelf. Conditions: The states of the agent and of the multiple obstacles: cashier counter door, display table and book shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bookstore. Objectives: It must avoid colliding with any book, bookstore door. Conditions: Agent's and of the multiple obstacle: book, bookstore door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bookstore. Objectives: Do not collide with book stack. Conditions: The states of the drone, goal and the book stack are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_stack = calculate_distance_min(s_agent, s_book_stack) \n    penalty = -29 if (d_agent_book_stack < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bookstore and must avoid contact with the sack of book shipment boxes. The states of the drone, goal and the sack of book shipment boxes are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_book_shipment_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_shipment_box = calculate_distance_min(s_agent, s_book_shipment_box) \n    penalty = -29 if (d_agent_book_shipment_box < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bookstore. It must avoid colliding with the book, staff door and book cart. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony staff door and book cart are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bookstore. It must avoid colliding with the glass display case and book. The states of the drone, goal and of the multiple obstacle: the glass display case and book are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bookstore. It must avoid colliding with the event poster board. Agent's state, goal's state and event poster board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_event_poster_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_event_poster_board = calculate_distance_min(s_agent, s_event_poster_board) \n    penalty_collision = -29 if (d_agent_event_poster_board < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: It must avoid colliding with event poster board. Assumptions: The states of the drone, goal and the book cart's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_cart = calculate_distance_min(s_agent, s_book_cart) \n    penalty_collision = -29 if (d_agent_book_cart < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: It must avoid colliding with bookstore's platform pillars, reading bench row and protective glass panel. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, digital catalog screen and customer are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: Detect book stack, book stack and book stack and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, book stack and book stack state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*4 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bus terminal. \n Objectives: It must avoid colliding with luggage cart or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the luggage cart and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bus terminal. \n Objectives: Detect trash bin and aviod it. \n Conditions: The states of the agent, goal, the trash bin are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -29 if (d_agent_trash_bin < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bus terminal. Objectives: It must avoid colliding with platform pillar. Conditions: States of the drone and the platform pillar are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform_pillar = calculate_distance_min(s_agent, s_platform_pillar) \n    penalty_collision = -29 if (d_agent_platform_pillar < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bus terminal, the drone must maneuver around bench. All entity states (agent, goal, bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -29 if (d_agent_bench < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bus terminal. Requirement: Detect the three vending machine and do not collide with it. Given: The states for the drone and multiple vending machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bus terminal. \n Objectives: So not collide with escalator. \n Conditions: The states of the agent, goal, the escalator are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_escalator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_escalator = calculate_distance_min(s_agent, s_escalator) \n    penalty_collision = -29 if (d_agent_escalator < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bus terminal. Objectives: Do not collide hit with the bus door. Conditions: States of the agent, bus door are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_bus_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bus_door = calculate_distance_min(s_agent, s_bus_door) \n    penalty_collision = -29 if (d_agent_bus_door < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bus terminal, the drone must steer clear of passenger. All states (agent, goal, passenger) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_passenger, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_passenger) \n    penalty_collision = -29 if (d_agent_passenger < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bus terminal. Avoid: Detect queue stanchion belt and do not hitting with queue stanchion belt. Known: Agent, goal, queue stanchion belt states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_queue_stanchion_belt, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_queue_stanchion_belt = calculate_distance_min(s_agent, s_queue_stanchion_belt) \n    penalty_collision = -29 if (d_agent_queue_stanchion_belt < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bus terminal. Objectives: It must avoid colliding with luggage cart. Conditions: The states of the drone, goal and luggage cart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_luggage_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_luggage_cart = calculate_distance_min(s_agent, s_luggage_cart) \n    penalty_collision = -29 if (d_agent_luggage_cart < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bus terminal. Objectives: Avoid collision with bus door, luggage cart and ticket kiosk. Conditions: The states of the agent and of the multiple obstacles: bus door, luggage cart and ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bus terminal. Objectives: It must avoid colliding with any queue stanchion belt, bus terminal door motor. Conditions: Agent's and of the multiple obstacle: queue stanchion belt, bus terminal door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bus terminal. Objectives: Do not collide with platform pillar. Conditions: The states of the drone, goal and the platform pillar are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform_pillar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform_pillar = calculate_distance_min(s_agent, s_platform_pillar) \n    penalty = -29 if (d_agent_platform_pillar < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bus terminal and must avoid contact with the luggage pile. The states of the drone, goal and the luggage pile are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_luggage_pile, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_luggage_pile = calculate_distance_min(s_agent, s_luggage_pile) \n    penalty = -29 if (d_agent_luggage_pile < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bus terminal. It must avoid colliding with the queue stanchion belt, platform gate and rolling suitcase. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony platform gate and rolling suitcase are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bus terminal. It must avoid colliding with the glass ticket booth and queue stanchion belt. The states of the drone, goal and of the multiple obstacle: the glass ticket booth and queue stanchion belt are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bus terminal. It must avoid colliding with the overhead signboard. Agent's state, goal's state and overhead signboard's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_overhead_signboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_overhead_signboard = calculate_distance_min(s_agent, s_overhead_signboard) \n    penalty_collision = -29 if (d_agent_overhead_signboard < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: It must avoid colliding with overhead signboard. Assumptions: The states of the drone, goal and the rolling suitcase's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_rolling_suitcase, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rolling_suitcase = calculate_distance_min(s_agent, s_rolling_suitcase) \n    penalty_collision = -29 if (d_agent_rolling_suitcase < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: It must avoid colliding with bus terminal's platform pillars, bench row and glass wall. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, information kiosk and passenger are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: Detect trash bin, trash bin and platform pillar and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, trash bin and platform pillar state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bus terminal. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along coffee shop. \n Objectives: It must avoid colliding with pastry display or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the pastry display and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy coffee shop. \n Objectives: Detect trash can and aviod it. \n Conditions: The states of the agent, goal, the trash can are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_can, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_can = calculate_distance_min(s_agent, s_trash_can) \n    penalty_collision = -29 if (d_agent_trash_can < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a coffee shop. Objectives: It must avoid colliding with bar stool. Conditions: States of the drone and the bar stool are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bar_stool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bar_stool = calculate_distance_min(s_agent, s_bar_stool) \n    penalty_collision = -29 if (d_agent_bar_stool < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a coffee shop, the drone must maneuver around couch. All entity states (agent, goal, couch) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_couch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_couch = calculate_distance_min(s_agent, s_couch) \n    penalty_collision = -29 if (d_agent_couch < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a coffee shop. Requirement: Detect the three fridge display and do not collide with it. Given: The states for the drone and multiple fridge display are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a coffee shop. \n Objectives: So not collide with stairway. \n Conditions: The states of the agent, goal, the stairway are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_stairway, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stairway = calculate_distance_min(s_agent, s_stairway) \n    penalty_collision = -29 if (d_agent_stairway < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate coffee shop. Objectives: Do not collide hit with the coffee counter door. Conditions: States of the agent, coffee counter door are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_glass_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_door = calculate_distance_min(s_agent, s_glass_door) \n    penalty_collision = -29 if (d_agent_glass_door < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a coffee shop, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -29 if (d_agent_customer < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: coffee shop. Avoid: Detect rope barrier and do not hitting with rope barrier. Known: Agent, goal, rope barrier states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_rope_barrier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope_barrier = calculate_distance_min(s_agent, s_rope_barrier) \n    penalty_collision = -29 if (d_agent_rope_barrier < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating coffee shop. Objectives: It must avoid colliding with pastry display. Conditions: The states of the drone, goal and pastry display are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_pastry_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pastry_display = calculate_distance_min(s_agent, s_pastry_display) \n    penalty_collision = -29 if (d_agent_pastry_display < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through coffee shop. Objectives: Avoid collision with coffee counter door, pastry display and ticket kiosk. Conditions: The states of the agent and of the multiple obstacles: coffee counter door, pastry display and ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating coffee shop. Objectives: It must avoid colliding with any rope barrier, coffee shop door motor. Conditions: Agent's and of the multiple obstacle: rope barrier, coffee shop door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through coffee shop. Objectives: Do not collide with platform coffee table. Conditions: The states of the drone, goal and the platform coffee table are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_table = calculate_distance_min(s_agent, s_coffee_table) \n    penalty = -29 if (d_agent_coffee_table < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along coffee shop and must avoid contact with the sack of coffee beans. The states of the drone, goal and the sack of coffee beans are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_coffee_bean_sack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_bean_sack = calculate_distance_min(s_agent, s_coffee_bean_sack) \n    penalty = -29 if (d_agent_coffee_bean_sack < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in coffee shop. It must avoid colliding with the rope barrier, swinging door and serving tray. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony swinging door and serving tray are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in coffee shop. It must avoid colliding with the glass pastry case and rope barrier. The states of the drone, goal and of the multiple obstacle: the glass pastry case and rope barrier are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in coffee shop. It must avoid colliding with the menu sign. Agent's state, goal's state and menu sign's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_menu_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_menu_sign = calculate_distance_min(s_agent, s_menu_sign) \n    penalty_collision = -29 if (d_agent_menu_sign < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: It must avoid colliding with menu sign. Assumptions: The states of the drone, goal and the serving tray's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_serving_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_serving_tray = calculate_distance_min(s_agent, s_serving_tray) \n    penalty_collision = -29 if (d_agent_serving_tray < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: It must avoid colliding with coffee shop's platform pillars, couch row and glass partition. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, menu board and customer are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: Detect trash can, trash can and platform coffee table and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, trash can and platform coffee table state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating coffee shop. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along pharmacy. \n Objectives: It must avoid colliding with medicine fridge or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the medicine fridge and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy pharmacy. \n Objectives: Detect biohazard bin and aviod it. \n Conditions: The states of the agent, goal, the biohazard bin are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_biohazard_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_biohazard_bin = calculate_distance_min(s_agent, s_biohazard_bin) \n    penalty_collision = -29 if (d_agent_biohazard_bin < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a pharmacy. Objectives: It must avoid colliding with platform consultation desk. Conditions: States of the drone and the platform consultation desk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weighing_scale, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_weighing_scale = calculate_distance_min(s_agent, s_weighing_scale) \n    penalty_collision = -29 if (d_agent_weighing_scale < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a pharmacy, the drone must maneuver around waiting bench. All entity states (agent, goal, waiting bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_waiting_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_waiting_bench = calculate_distance_min(s_agent, s_waiting_bench) \n    penalty_collision = -29 if (d_agent_waiting_bench < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a pharmacy. Requirement: Detect the three refrigerated cabinet and do not collide with it. Given: The states for the drone and multiple refrigerated cabinet are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a pharmacy. \n Objectives: So not collide with emergency exit. \n Conditions: The states of the agent, goal, the emergency exit are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_emergency_exit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_emergency_exit = calculate_distance_min(s_agent, s_emergency_exit) \n    penalty_collision = -29 if (d_agent_emergency_exit < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate pharmacy. Objectives: Do not collide hit with the prescription counter door. Conditions: States of the agent, prescription counter door are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_sliding_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sliding_door = calculate_distance_min(s_agent, s_sliding_door) \n    penalty_collision = -29 if (d_agent_sliding_door < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a pharmacy, the drone must steer clear of patient. All states (agent, goal, patient) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -29 if (d_agent_patient < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: pharmacy. Avoid: Detect safety barrier and do not hitting with safety barrier. Known: Agent, goal, safety barrier states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_safety_barrier, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_safety_barrier = calculate_distance_min(s_agent, s_safety_barrier) \n    penalty_collision = -29 if (d_agent_safety_barrier < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating pharmacy. Objectives: It must avoid colliding with medicine fridge. Conditions: The states of the drone, goal and medicine fridge are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_medicine_fridge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_medicine_fridge = calculate_distance_min(s_agent, s_medicine_fridge) \n    penalty_collision = -29 if (d_agent_medicine_fridge < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through pharmacy. Objectives: Avoid collision with prescription counter door, medicine fridge and customers. Conditions: The states of the agent and of the multiple obstacles: prescription counter door, medicine fridge and customers are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating pharmacy. Objectives: It must avoid colliding with any safety barrier, pharmacy door motor. Conditions: Agent's and of the multiple obstacle: safety barrier, pharmacy door motor states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through pharmacy. Objectives: Do not collide with platform consultation desk. Conditions: The states of the drone, goal and the platform consultation desk are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_weighing_scale, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_weighing_scale = calculate_distance_min(s_agent, s_weighing_scale) \n    penalty = -29 if (d_agent_weighing_scale < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along pharmacy and must avoid contact with the sack of medicine supplies. The states of the drone, goal and the sack of medicine supplies are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_medicine_supplies_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_medicine_supplies_box = calculate_distance_min(s_agent, s_medicine_supplies_box) \n    penalty = -29 if (d_agent_medicine_supplies_box < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in pharmacy. It must avoid colliding with the safety barrier, staff door and medicine tray. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony staff door and medicine tray are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in pharmacy. It must avoid colliding with the locked medicine cabinet and safety barrier. The states of the drone, goal and of the multiple obstacle: the locked medicine cabinet and safety barrier are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in pharmacy. It must avoid colliding with the drug information poster. Agent's state, goal's state and drug information poster's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drug_information_poster, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drug_information_poster = calculate_distance_min(s_agent, s_drug_information_poster) \n    penalty_collision = -29 if (d_agent_drug_information_poster < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: It must avoid colliding with drug information poster. Assumptions: The states of the drone, goal and the medicine tray's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_medicine_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_medicine_tray = calculate_distance_min(s_agent, s_medicine_tray) \n    penalty_collision = -29 if (d_agent_medicine_tray < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: It must avoid colliding with pharmacy's platform pillars, waiting bench row and protective glass panel. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, digital prescription screen and patient are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: Detect biohazard bin, biohazard bin and platform consultation desk and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, biohazard bin and platform consultation desk state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating pharmacy. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bakery. \n Objectives: It must avoid colliding with cake display fridge or ticket kiosk. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the cake display fridge and the ticket kiosk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bakery. \n Objectives: Detect trash bin and aviod it. \n Conditions: The states of the agent, goal, the trash bin are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -29 if (d_agent_trash_bin < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bakery. Objectives: It must avoid colliding with sign. Conditions: States of the drone and the sign are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -29 if (d_agent_table < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bakery, the drone must maneuver around bench. All entity states (agent, goal, bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -29 if (d_agent_bench < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bakery. Requirement: Detect the three refrigerated display and do not collide with it. Given: The states for the drone and multiple refrigerated display are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bakery. \n Objectives: So not collide with displayas case. \n Conditions: The states of the agent, goal, the display case are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_display_case, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_escalator = calculate_distance_min(s_agent, s_display_case) \n    penalty_collision = -29 if (d_agent_display_case < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bakery. Objectives: Do not collide hit with the bowl stand. Conditions: States of the agent, bowl stand are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_bowl_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bowl_stand = calculate_distance_min(s_agent, s_bowl_stand) \n    penalty_collision = -29 if (d_agent_bowl_stand < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bakery, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_passenger = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -29 if (d_agent_passenger < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bakery. Avoid: Detect cabinet and do not hitting with cabinet. Known: Agent, goal, cabinet states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabinet = calculate_distance_min(s_agent, s_cabinet) \n    penalty_collision = -29 if (d_agent_cabinet < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bakery. Objectives: It must avoid colliding with cake display fridge. Conditions: The states of the drone, goal and cake display fridge are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fridge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fridge = calculate_distance_min(s_agent, s_fridge) \n    penalty_collision = -29 if (d_agent_fridge < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bakery. Objectives: Avoid collision with bread counter door, cake display fridge and queue. Conditions: The states of the agent and of the multiple obstacles: bread counter door, cake display fridge and queue are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bakery. Objectives: It must avoid colliding with any customers, bakery door. Conditions: Agent's and of the multiple obstacle: customers, bakery door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bakery. Objectives: Do not collide with sign. Conditions: The states of the drone, goal and the sign are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sign = calculate_distance_min(s_agent, s_sign) \n    penalty = -29 if (d_agent_sign < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bakery and must avoid contact with the sack of flour sacks. The states of the drone, goal and the sack of flour sacks are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_flour_sacks, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flour_sacks = calculate_distance_min(s_agent, s_flour_sacks) \n    penalty = -29 if (d_agent_flour_sacks < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bakery. It must avoid colliding with the plants, swinging door and baking tray. The states of the agent and of the multiple obstacle: plants, sliding balcony door and baking tray are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bakery. It must avoid colliding with the pastry case and plants. The states of the drone, goal and of the multiple obstacle: the pastry case and plants are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bakery. It must avoid colliding with the daily specials board. Agent's state, goal's state and daily specials board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_board = calculate_distance_min(s_agent, s_board) \n    penalty_collision = -29 if (d_agent_board < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: It must avoid colliding with daily specials board. Assumptions: The states of the drone, goal and the baking tray's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_baking_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_baking_tray = calculate_distance_min(s_agent, s_baking_tray) \n    penalty_collision = -29 if (d_agent_baking_tray < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: It must avoid colliding with bakery's platform pillars, bench row and sneeze guard. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, digital menu board and customer are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: Detect trash bin, trash bin and sign and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, trash bin and sign state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bakery. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bookstore. \n Objectives: It must avoid colliding with display table or book shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the display table and the book shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bookstore. \n Objectives: Detect book stack and aviod it. \n Conditions: The states of the agent, goal, the book stack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_stack = calculate_distance_min(s_agent, s_book_stack) \n    penalty_collision = -29 if (d_agent_book_stack < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bookstore. Objectives: It must avoid colliding with book stack. Conditions: States of the drone and the book stack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goacustomerl) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -29 if (d_agent_customer < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bookstore, the drone must maneuver around reading bench. All entity states (agent, goal, reading bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_reading_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_reading_bench) \n    penalty_collision = -29 if (d_agent_bench < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bookstore. Requirement: Detect the three magazine rack and do not collide with it. Given: The states for the drone and multiple magazine rack are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacle_min < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bookstore. \n Objectives: So not collide with box. \n Conditions: The states of the agent, goal, the box are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -29 if (d_agent_box < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bookstore. Objectives: Do not collide hit with the cashier counter. Conditions: States of the agent, cashier counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -29 if (d_agent_counter < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bookstore, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -29 if (d_agent_customer < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bookstore. Avoid: Detect book and do not hitting with book. Known: Agent, goal, book states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -29 if (d_agent_book < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bookstore. Objectives: It must avoid colliding with display table. Conditions: The states of the drone, goal and display table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_display_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display_table = calculate_distance_min(s_agent, s_display_table) \n    penalty_collision = -29 if (d_agent_display_table < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bookstore. Objectives: Avoid collision with cashier counter door, display table and book shelf. Conditions: The states of the agent and of the multiple obstacles: cashier counter door, display table and book shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bookstore. Objectives: It must avoid colliding with any book, bookstore door. Conditions: Agent's and of the multiple obstacle: book, bookstore door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bookstore. Objectives: Do not collide with book stack. Conditions: The states of the drone, goal and the book stack are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_stack = calculate_distance_min(s_agent, s_book_stack) \n    penalty = -29 if (d_agent_book_stack < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bookstore and must avoid contact with the sack of book shipment boxes. The states of the drone, goal and the sack of book shipment boxes are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_book_shipment_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_shipment_box = calculate_distance_min(s_agent, s_book_shipment_box) \n    penalty = -29 if (d_agent_book_shipment_box < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bookstore. It must avoid colliding with the book, staff door and book cart. The states of the agent and of the multiple obstacle: potted potted plants near entrance, sliding balcony staff door and book cart are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bookstore. It must avoid colliding with the glass display case and book. The states of the drone, goal and of the multiple obstacle: the glass display case and book are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bookstore. It must avoid colliding with the event poster board. Agent's state, goal's state and event poster board's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_event_poster_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_event_poster_board = calculate_distance_min(s_agent, s_event_poster_board) \n    penalty_collision = -29 if (d_agent_event_poster_board < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: It must avoid colliding with event poster board. Assumptions: The states of the drone, goal and the book cart's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_cart = calculate_distance_min(s_agent, s_book_cart) \n    penalty_collision = -29 if (d_agent_book_cart < 0.7) else 13 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: It must avoid colliding with bookstore's platform pillars, reading bench row and protective glass panel. Assumptions: The Agent's state, goal's state and multiple obstacle's state: platform pillars, digital catalog screen and customer are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: Detect book stack, book stack and book stack and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, book stack and book stack state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -29 if (d_agent_multiple_obstacles_min < 0.7) else 13 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bookstore. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -d_agent_goal*c_1 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along print shop. \n Objectives: It must avoid colliding with printing table or poster roll shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the printing table and the poster roll shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy print shop. \n Objectives: Detect paper stack and aviod it. \n Conditions: The states of the agent, goal, the paper stack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_paper_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paper_stack = calculate_distance_min(s_agent, s_paper_stack) \n    penalty_collision = -25 if (d_agent_paper_stack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a print shop. Objectives: It must avoid colliding with counter. Conditions: States of the drone and the counter are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -25 if (d_agent_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a print shop, the drone must maneuver around cutting station. All entity states (agent, goal, cutting station) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_cutting_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cutting_station = calculate_distance_min(s_agent, s_cutting_station) \n    penalty_collision = -25 if (d_agent_cutting_station < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a print shop. Requirement: Detect the three ink cabinet and do not collide with it. Given: The states for the drone and multiple ink cabinet are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a print shop. \n Objectives: So not collide with box. \n Conditions: The states of the agent, goal, the box are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -25 if (d_agent_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate print shop. Objectives: Do not collide hit with the checkout counter. Conditions: States of the agent, checkout counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_checkout_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_checkout_counter = calculate_distance_min(s_agent, s_checkout_counter) \n    penalty_collision = -25 if (d_agent_checkout_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a print shop, the drone must steer clear of staff worker. All states (agent, goal, staff worker) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_staff_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff_worker = calculate_distance_min(s_agent, s_staff_worker) \n    penalty_collision = -25 if (d_agent_staff_worker < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: print shop. Avoid: Detect poster roll and do not hitting with poster roll. Known: Agent, goal, poster roll states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_poster_roll, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_poster_roll = calculate_distance_min(s_agent, s_poster_roll) \n    penalty_collision = -25 if (d_agent_poster_roll < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating print shop. Objectives: It must avoid colliding with printing table. Conditions: The states of the drone, goal and printing table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_printing_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_printing_table = calculate_distance_min(s_agent, s_printing_table) \n    penalty_collision = -25 if (d_agent_printing_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through print shop. Objectives: Avoid collision with checkout loading bay door, printing table and poster roll shelf. Conditions: The states of the agent and of the multiple obstacles: checkout loading bay door, printing table and poster roll shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating print shop. Objectives: It must avoid colliding with any poster roll, print shop door. Conditions: Agent's and of the multiple obstacle: poster roll, print shop door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through print shop. Objectives: Do not collide with paper stack. Conditions: The states of the drone, goal and the paper stack are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_paper_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paper_stack = calculate_distance_min(s_agent, s_paper_stack) \n    penalty = -25 if (d_agent_paper_stack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along print shop and must avoid contact with the sack of poster roll shipment boxes. The states of the drone, goal and the sack of poster roll shipment boxes are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_shipment_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shipment_box = calculate_distance_min(s_agent, s_shipment_box) \n    penalty = -25 if (d_agent_shipment_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in print shop. It must avoid colliding with the poster roll, checkout counter and poster roll cart. The states of the agent and of the multiple obstacle: plants, checkout counter door and poster roll cart are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in print shop. It must avoid colliding with the lamination machine and poster roll. The states of the drone, goal and of the multiple obstacle: the lamination machine and poster roll are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in print shop. It must avoid colliding with the printing banner stand. Agent's state, goal's state and printing banner stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_printing_banner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_printing_banner = calculate_distance_min(s_agent, s_printing_banner) \n    penalty_collision = -25 if (d_agent_printing_banner < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating print shop. Goal: It must avoid colliding with book cart. Assumptions: The states of the drone, goal and the book cart's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_cart = calculate_distance_min(s_agent, s_book_cart) \n    penalty_collision = -25 if (d_agent_book_cart < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating print shop. Goal: It must avoid colliding with print shop's support columns, cutting station and customers. Assumptions: The Agent's state, goal's state and multiple obstacle's state: support columns, cutting station and customers are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating print shop. Goal: Detect paper stack, paper stack and paper stack and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, paper stack and paper stack state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating print shop. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bank lobby. \n Objectives: It must avoid colliding with teller counter or cash bag shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the teller counter and the cash bag shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bank lobby. \n Objectives: Detect brochure stand and aviod it. \n Conditions: The states of the agent, goal, the brochure stand are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_brochure_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_brochure_stand = calculate_distance_min(s_agent, s_brochure_stand) \n    penalty_collision = -25 if (d_agent_brochure_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bank lobby. Objectives: It must avoid colliding with visitor. Conditions: States of the drone and the visitor are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_visitor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_visitor = calculate_distance_min(s_agent, s_visitor) \n    penalty_collision = -25 if (d_agent_visitor < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bank lobby, the drone must maneuver around security desk. All entity states (agent, goal, security desk) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_security_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_desk = calculate_distance_min(s_agent, s_security_desk) \n    penalty_collision = -25 if (d_agent_security_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bank lobby. Requirement: Detect the three coin counting machine and do not collide with it. Given: The states for the drone and multiple coin counting machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bank lobby. \n Objectives: So not collide with package. \n Conditions: The states of the agent, goal, the package are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = -25 if (d_agent_package < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bank lobby. Objectives: Do not collide hit with the information desk. Conditions: States of the agent, information desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_information_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_information_desk = calculate_distance_min(s_agent, s_information_desk) \n    penalty_collision = -25 if (d_agent_information_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bank lobby, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -25 if (d_agent_customer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bank lobby. Avoid: Detect cash bag and do not hitting with cash bag. Known: Agent, goal, cash bag states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cash_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cash_bag = calculate_distance_min(s_agent, s_cash_bag) \n    penalty_collision = -25 if (d_agent_cash_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bank lobby. Objectives: It must avoid colliding with teller counter. Conditions: The states of the drone, goal and teller counter are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_teller_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teller_counter = calculate_distance_min(s_agent, s_teller_counter) \n    penalty_collision = -25 if (d_agent_teller_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bank lobby. Objectives: Avoid collision with checkout revolving door, teller counter and cash bag shelf. Conditions: The states of the agent and of the multiple obstacles: checkout revolving door, teller counter and cash bag shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bank lobby. Objectives: It must avoid colliding with any cash bag, bank lobby door. Conditions: Agent's and of the multiple obstacle: cash bag, bank lobby door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bank lobby. Objectives: Do not collide with brochure stand. Conditions: The states of the drone, goal and the brochure stand are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_brochure_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_brochure_stand = calculate_distance_min(s_agent, s_brochure_stand) \n    penalty = -25 if (d_agent_brochure_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bank lobby and must avoid contact with the ATM maschine. The states of the drone, goal and the ATM maschine are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_ATM_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ATM_maschine = calculate_distance_min(s_agent, s_ATM_maschine) \n    penalty = -25 if (d_agent_ATM_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bank lobby. It must avoid colliding with the cash bag, ATM maschine and staff. The states of the agent and of the multiple obstacle: cash bag, ATM maschine and staff are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bank lobby. It must avoid colliding with the ATM and cash bag. The states of the drone, goal and of the multiple obstacle: the ATM and cash bag are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bank lobby. It must avoid colliding with the vault door. Agent's state, goal's state and vault doorn's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_vault_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vault_door = calculate_distance_min(s_agent, s_vault_door) \n    penalty_collision = -25 if (d_agent_vault_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bank lobby. Goal: It must avoid colliding with alarm system. Assumptions: The states of the drone, goal and the alarm system's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_alarm_system, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_alarm_system = calculate_distance_min(s_agent, s_alarm_system) \n    penalty_collision = -25 if (d_agent_alarm_system < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bank lobby. Goal: It must avoid colliding with information counter, deposit box and staff. Assumptions: The Agent's state, goal's state and multiple obstacle's state: information counter, deposit box and staff are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bank lobby. Goal: Detect door, brochure stand and seiling light and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: door, brochure stand and seiling light state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bank lobby. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along daycare. \n Objectives: It must avoid colliding with toy shelf or stuffed toy. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the toy shelf and the stuffed toy are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy daycare. \n Objectives: Detect play mat and aviod it. \n Conditions: The states of the agent, goal, the play mat are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_play_mat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_play_mat = calculate_distance_min(s_agent, s_play_mat) \n    penalty_collision = -25 if (d_agent_play_mat < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a daycare. Objectives: It must avoid colliding with visitor. Conditions: States of the drone and the visitor are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_visitor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_visitor = calculate_distance_min(s_agent, s_visitor) \n    penalty_collision = -25 if (d_agent_visitor < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a daycare, the drone must maneuver around teacher's desk. All entity states (agent, goal, teacher's desk) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_teachers_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teachers_desk = calculate_distance_min(s_agent, s_teachers_desk) \n    penalty_collision = -25 if (d_agent_teachers_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a daycare. Requirement: Detect the three lego table and do not collide with it. Given: The states for the drone and multiple lego table are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a daycare. \n Objectives: So not collide with backpack. \n Conditions: The states of the agent, goal, the backpack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -25 if (d_agent_backpack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate daycare. Objectives: Do not collide hit with the activity table. Conditions: States of the agent, activity table are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_activity_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_activity_table = calculate_distance_min(s_agent, s_activity_table) \n    penalty_collision = -25 if (d_agent_activity_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a daycare, the drone must steer clear of child. All states (agent, goal, child) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_child, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_child = calculate_distance_min(s_agent, s_child) \n    penalty_collision = -25 if (d_agent_child < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: daycare. Avoid: Detect stuffed toy and do not hitting with stuffed toy. Known: Agent, goal, stuffed toy states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_stuffed_toy, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stuffed_toy = calculate_distance_min(s_agent, s_stuffed_toy) \n    penalty_collision = -25 if (d_agent_stuffed_toy < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating daycare. Objectives: It must avoid colliding with toy shelf. Conditions: The states of the drone, goal and toy shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_toy_shelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toy_shelf = calculate_distance_min(s_agent, s_toy_shelf) \n    penalty_collision = -25 if (d_agent_toy_shelf < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through daycare. Objectives: Avoid collision with checkout safety gate, toy shelf and stuffed toy shelf. Conditions: The states of the agent and of the multiple obstacles: checkout safety gate, toy shelf and stuffed toy are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating daycare. Objectives: It must avoid colliding with any stuffed toy, daycare safety gate. Conditions: Agent's and of the multiple obstacle: stuffed toy, daycare safety gate states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through daycare. Objectives: Do not collide with play mat. Conditions: The states of the drone, goal and the play mat are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_play_mat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_play_mat = calculate_distance_min(s_agent, s_play_mat) \n    penalty = -25 if (d_agent_play_mat < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along daycare and must avoid contact with the cubby storage. The states of the drone, goal and the cubby storage are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_cubby_storage, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cubby_storage = calculate_distance_min(s_agent, s_cubby_storage) \n    penalty = -25 if (d_agent_cubby_storage < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in daycare. It must avoid colliding with the stuffed toy, cubby storage and teacher. The states of the agent and of the multiple obstacle: stuffed toy, cubby storage and teacher are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in daycare. It must avoid colliding with the cubby storage and stuffed toy. The states of the drone, goal and of the multiple obstacle: the cubby storage and stuffed toy are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in daycare. It must avoid colliding with the storage door. Agent's state, goal's state and storage door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_storage_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_door = calculate_distance_min(s_agent, s_storage_door) \n    penalty_collision = -25 if (d_agent_storage_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating daycare. Goal: It must avoid colliding with baby monitor. Assumptions: The states of the drone, goal and the baby monitor's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_baby_monitor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_baby_monitor = calculate_distance_min(s_agent, s_baby_monitor) \n    penalty_collision = -25 if (d_agent_baby_monitor < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating daycare. Goal: It must avoid colliding with activity table, toy container and teacher. Assumptions: The Agent's state, goal's state and multiple obstacle's state: activity table, toy container and teacher are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating daycare. Goal: Detect safety gate, play mat and ceiling light and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: safety gate, play mat and ceiling light state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating daycare. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along a barbershop. \n Objectives: It must avoid colliding with barber chair or rolling cart. \n Conditions: The states of the agent, goal, and of the other multiple obstacles e.g. the barber chair and the rolling cart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy barbershop. \n Objectives: Detect hair dryer and avoid it. \n Conditions: The states of the agent, goal, the hair dryer are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_hair_dryer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_hair_dryer = calculate_distance_min(s_agent, s_hair_dryer) \n    penalty_collision = -25 if (d_agent_hair_dryer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a barbershop. Objectives: It must avoid colliding with customer. Conditions: States of the drone and the customer are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -25 if (d_agent_customer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a barbershop, the drone must maneuver around stylist station. All entity states (agent, goal, stylist station) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_stylist_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stylist_station = calculate_distance_min(s_agent, s_stylist_station) \n    penalty_collision = -25 if (d_agent_stylist_station < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a barbershop. Requirement: Detect the three barber chairs and do not collide with them. Given: The states for the drone and multiple barber chairs are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a barbershop. \n Objectives: Do not collide with tool bag. \n Conditions: The states of the agent, goal, the tool bag are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_tool_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool_bag = calculate_distance_min(s_agent, s_tool_bag) \n    penalty_collision = -25 if (d_agent_tool_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate barbershop. Objectives: Do not collide with the waiting bench. Conditions: States of the agent, waiting bench are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_waiting_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_waiting_bench = calculate_distance_min(s_agent, s_waiting_bench) \n    penalty_collision = -25 if (d_agent_waiting_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a barbershop, the drone must steer clear of toddler. All states (agent, goal, toddler) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_toddler, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toddler = calculate_distance_min(s_agent, s_toddler) \n    penalty_collision = -25 if (d_agent_toddler < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: barbershop. Avoid: Detect clipper case and do not hit it. Known: Agent, goal, clipper case states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_clipper_case, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clipper_case = calculate_distance_min(s_agent, s_clipper_case) \n    penalty_collision = -25 if (d_agent_clipper_case < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a barbershop. Objectives: It must avoid colliding with product display shelf. Conditions: The states of the drone, goal and product display shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_product_display_shelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_product_display_shelf = calculate_distance_min(s_agent, s_product_display_shelf) \n    penalty_collision = -25 if (d_agent_product_display_shelf < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a barbershop. Objectives: Avoid collision with front door, product display shelf and rolling cart. Conditions: The states of the agent and of the multiple obstacles: front door, product display shelf and rolling cart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a barbershop. Objectives: It must avoid colliding with any clipper case, cape rack. Conditions: Agent's and of the multiple obstacles: clipper case, cape rack states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a barbershop. Objectives: Do not collide with wet floor sign. Conditions: The states of the drone, goal and the wet floor sign are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wet_floor_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wet_floor_sign = calculate_distance_min(s_agent, s_wet_floor_sign) \n    penalty = -25 if (d_agent_wet_floor_sign < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along a barbershop and must avoid contact with the coat rack. The states of the drone, goal and the coat rack are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_coat_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_rack = calculate_distance_min(s_agent, s_coat_rack) \n    penalty = -25 if (d_agent_coat_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a barbershop. It must avoid colliding with the clipper case, coat rack and barber. The states of the agent and of the multiple obstacles: clipper case, coat rack and barber are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a barbershop. It must avoid colliding with the coat rack and clipper case. The states of the drone, goal and of the multiple obstacles: the coat rack and clipper case are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a barbershop. It must avoid colliding with the backroom door. Agent's state, goal's state and backroom door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_backroom_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backroom_door = calculate_distance_min(s_agent, s_backroom_door) \n    penalty_collision = -25 if (d_agent_backroom_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a barbershop. Goal: It must avoid colliding with CCTV camera. Assumptions: The states of the drone, goal and the CCTV camera's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_cctv_camera, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cctv_camera = calculate_distance_min(s_agent, s_cctv_camera) \n    penalty_collision = -25 if (d_agent_cctv_camera < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a barbershop. Goal: It must avoid colliding with stylist chair, mixing bowl and hairstylist. Assumptions: The Agent's state, goal's state and multiple obstacles' state: stylist chair, mixing bowl and hairstylist are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a barbershop. Goal: Detect mirror wall, power cord and ceiling fan and do not collide. Assumptions: The states of the drone, goal and multiple obstacles: mirror wall, power cord and ceiling fan state are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a barbershop. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside an apartment. \n Objectives: It must avoid colliding with coffee table or floor lamp. \n Conditions: The states of the agent, goal, and of the other multiple items (e.g., the coffee table and the floor lamp) are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -25 if (d_agent_items_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy apartment. \n Objectives: Detect stair rail and avoid it. \n Conditions: The states of the agent and the stair rail are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stair_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stair_rail = calculate_distance_min(s_agent, s_stair_rail) \n    penalty_collision = -25 if (d_agent_stair_rail < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in an apartment. Objectives: It must avoid colliding with resident. Conditions: States of the drone and the resident are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_resident, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_resident = calculate_distance_min(s_agent, s_resident) \n    penalty_collision = -25 if (d_agent_resident < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside an apartment, the drone must maneuver around the dining table. All entity states (agent, goal, dining table) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_dining_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_table = calculate_distance_min(s_agent, s_dining_table) \n    penalty_collision = -25 if (d_agent_dining_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through an apartment. Requirement: Detect the three items and do not collide with them. Given: The states for the drone and multiple items are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -25 if (d_agent_items_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates in an apartment. \n Objectives: Do not collide with tool bag. \n Conditions: The states of the agent and the tool bag are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_tool_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool_bag = calculate_distance_min(s_agent, s_tool_bag) \n    penalty_collision = -25 if (d_agent_tool_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate apartment. Objectives: Do not collide with the sofa. Conditions: States of the agent and sofa are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_sofa, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sofa = calculate_distance_min(s_agent, s_sofa) \n    penalty_collision = -25 if (d_agent_sofa < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within an apartment, the drone must steer clear of toddler. All states (agent, goal, toddler) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_toddler, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toddler = calculate_distance_min(s_agent, s_toddler) \n    penalty_collision = -25 if (d_agent_toddler < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: apartment. Avoid: Detect toy box and do not hit it. Known: Agent and toy box states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_toy_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toy_box = calculate_distance_min(s_agent, s_toy_box) \n    penalty_collision = -25 if (d_agent_toy_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating an apartment. Objectives: It must avoid colliding with potted plant. Conditions: The states of the drone, goal and potted plant are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_potted_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_potted_plant = calculate_distance_min(s_agent, s_potted_plant) \n    penalty_collision = -25 if (d_agent_potted_plant < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through an apartment. Objectives: Avoid collision with robot vacuum, potted plant and floor lamp. Conditions: The states of the agent and of the multiple items: robot vacuum, potted plant and floor lamp are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -25 if (d_agent_items_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating an apartment. Objectives: It must avoid colliding with any toy box and yoga mat. Conditions: Agent's and the multiple items' states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -25 if (d_agent_items_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through an apartment. Objectives: Do not collide with water spill. Conditions: The states of the drone, goal and the water spill are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_water_spill, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_water_spill = calculate_distance_min(s_agent, s_water_spill) \n    penalty = -25 if (d_agent_water_spill < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in an apartment and must avoid contact with an open suitcase. The states of the drone, goal and the suitcase are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_suitcase, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_suitcase = calculate_distance_min(s_agent, s_suitcase) \n    penalty = -25 if (d_agent_suitcase < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in an apartment. It must avoid colliding with the toy box, open suitcase and resident. The states of the agent and of the multiple items: toy box, open suitcase and resident are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -25 if (d_agent_items_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in an apartment. It must avoid colliding with the open suitcase and toy box. The states of the drone, goal and of the multiple items: the open suitcase and moving box are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -25 if (d_agent_items_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting an apartment. It must avoid colliding with the standing fan. Agent's state, goal's state and standing fan's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_standing_fan, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_standing_fan = calculate_distance_min(s_agent, s_standing_fan) \n    penalty_collision = -25 if (d_agent_standing_fan < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating an apartment. Goal: It must avoid colliding with smoke detector. Assumptions: The states of the drone, goal and the smoke detector are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detector = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = -25 if (d_agent_smoke_detector < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating an apartment. Goal: It must avoid colliding with dining chair, mixing bowl and roommate. Assumptions: The Agent's state, goal's state and the state of these items are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -25 if (d_agent_items_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating an apartment. Goal: Detect wall mirror, power cord and ceiling fan and do not collide. Assumptions: The states of the drone, goal and multiple items are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -25 if (d_agent_items_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating an apartment. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along print shop. \n Objectives: It must avoid colliding with printing table or poster roll shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the printing table and the poster roll shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacle_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy print shop. \n Objectives: Detect paper stack and aviod it. \n Conditions: The states of the agent, goal, the paper stack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_paper_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paper_stack = calculate_distance_min(s_agent, s_paper_stack) \n    penalty_collision = -24 if (d_agent_paper_stack < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a print shop. Objectives: It must avoid colliding with counter. Conditions: States of the drone and the counter are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -24 if (d_agent_counter < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a print shop, the drone must maneuver around cutting station. All entity states (agent, goal, cutting station) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_cutting_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cutting_station = calculate_distance_min(s_agent, s_cutting_station) \n    penalty_collision = -24 if (d_agent_cutting_station < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a print shop. Requirement: Detect the three ink cabinet and do not collide with it. Given: The states for the drone and multiple ink cabinet are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacle_min < 0.5) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a print shop. \n Objectives: So not collide with box. \n Conditions: The states of the agent, goal, the box are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -24 if (d_agent_box < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate print shop. Objectives: Do not collide hit with the checkout counter. Conditions: States of the agent, checkout counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_checkout_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_checkout_counter = calculate_distance_min(s_agent, s_checkout_counter) \n    penalty_collision = -24 if (d_agent_checkout_counter < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a print shop, the drone must steer clear of staff worker. All states (agent, goal, staff worker) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_staff_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff_worker = calculate_distance_min(s_agent, s_staff_worker) \n    penalty_collision = -24 if (d_agent_staff_worker < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: print shop. Avoid: Detect poster roll and do not hitting with poster roll. Known: Agent, goal, poster roll states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_poster_roll, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_poster_roll = calculate_distance_min(s_agent, s_poster_roll) \n    penalty_collision = -24 if (d_agent_poster_roll < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating print shop. Objectives: It must avoid colliding with printing table. Conditions: The states of the drone, goal and printing table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_printing_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_printing_table = calculate_distance_min(s_agent, s_printing_table) \n    penalty_collision = -24 if (d_agent_printing_table < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through print shop. Objectives: Avoid collision with checkout loading bay door, printing table and poster roll shelf. Conditions: The states of the agent and of the multiple obstacles: checkout loading bay door, printing table and poster roll shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating print shop. Objectives: It must avoid colliding with any poster roll, print shop door. Conditions: Agent's and of the multiple obstacle: poster roll, print shop door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through print shop. Objectives: Do not collide with paper stack. Conditions: The states of the drone, goal and the paper stack are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_paper_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paper_stack = calculate_distance_min(s_agent, s_paper_stack) \n    penalty = -24 if (d_agent_paper_stack < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along print shop and must avoid contact with the sack of poster roll shipment boxes. The states of the drone, goal and the sack of poster roll shipment boxes are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_shipment_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shipment_box = calculate_distance_min(s_agent, s_shipment_box) \n    penalty = -24 if (d_agent_shipment_box < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in print shop. It must avoid colliding with the poster roll, checkout counter and poster roll cart. The states of the agent and of the multiple obstacle: plants, checkout counter door and poster roll cart are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in print shop. It must avoid colliding with the lamination machine and poster roll. The states of the drone, goal and of the multiple obstacle: the lamination machine and poster roll are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in print shop. It must avoid colliding with the printing banner stand. Agent's state, goal's state and printing banner stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_printing_banner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_printing_banner = calculate_distance_min(s_agent, s_printing_banner) \n    penalty_collision = -24 if (d_agent_printing_banner < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating print shop. Goal: It must avoid colliding with book cart. Assumptions: The states of the drone, goal and the book cart's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_book_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book_cart = calculate_distance_min(s_agent, s_book_cart) \n    penalty_collision = -24 if (d_agent_book_cart < 0.5) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating print shop. Goal: It must avoid colliding with print shop's support columns, cutting station and customers. Assumptions: The Agent's state, goal's state and multiple obstacle's state: support columns, cutting station and customers are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating print shop. Goal: Detect paper stack, paper stack and paper stack and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: potted plant, paper stack and paper stack state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating print shop. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along bank lobby. \n Objectives: It must avoid colliding with teller counter or cash bag shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the teller counter and the cash bag shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacle_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy bank lobby. \n Objectives: Detect brochure stand and aviod it. \n Conditions: The states of the agent, goal, the brochure stand are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_brochure_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_brochure_stand = calculate_distance_min(s_agent, s_brochure_stand) \n    penalty_collision = -24 if (d_agent_brochure_stand < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a bank lobby. Objectives: It must avoid colliding with visitor. Conditions: States of the drone and the visitor are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_visitor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_visitor = calculate_distance_min(s_agent, s_visitor) \n    penalty_collision = -24 if (d_agent_visitor < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a bank lobby, the drone must maneuver around security desk. All entity states (agent, goal, security desk) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_security_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security_desk = calculate_distance_min(s_agent, s_security_desk) \n    penalty_collision = -24 if (d_agent_security_desk < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a bank lobby. Requirement: Detect the three coin counting machine and do not collide with it. Given: The states for the drone and multiple coin counting machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacle_min < 0.5) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a bank lobby. \n Objectives: So not collide with package. \n Conditions: The states of the agent, goal, the package are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = -24 if (d_agent_package < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate bank lobby. Objectives: Do not collide hit with the information desk. Conditions: States of the agent, information desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_information_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_information_desk = calculate_distance_min(s_agent, s_information_desk) \n    penalty_collision = -24 if (d_agent_information_desk < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a bank lobby, the drone must steer clear of customer. All states (agent, goal, customer) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -24 if (d_agent_customer < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: bank lobby. Avoid: Detect cash bag and do not hitting with cash bag. Known: Agent, goal, cash bag states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cash_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cash_bag = calculate_distance_min(s_agent, s_cash_bag) \n    penalty_collision = -24 if (d_agent_cash_bag < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bank lobby. Objectives: It must avoid colliding with teller counter. Conditions: The states of the drone, goal and teller counter are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_teller_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teller_counter = calculate_distance_min(s_agent, s_teller_counter) \n    penalty_collision = -24 if (d_agent_teller_counter < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bank lobby. Objectives: Avoid collision with checkout revolving door, teller counter and cash bag shelf. Conditions: The states of the agent and of the multiple obstacles: checkout revolving door, teller counter and cash bag shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating bank lobby. Objectives: It must avoid colliding with any cash bag, bank lobby door. Conditions: Agent's and of the multiple obstacle: cash bag, bank lobby door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through bank lobby. Objectives: Do not collide with brochure stand. Conditions: The states of the drone, goal and the brochure stand are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_brochure_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_brochure_stand = calculate_distance_min(s_agent, s_brochure_stand) \n    penalty = -24 if (d_agent_brochure_stand < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along bank lobby and must avoid contact with the ATM maschine. The states of the drone, goal and the ATM maschine are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_ATM_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ATM_maschine = calculate_distance_min(s_agent, s_ATM_maschine) \n    penalty = -24 if (d_agent_ATM_maschine < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bank lobby. It must avoid colliding with the cash bag, ATM maschine and staff. The states of the agent and of the multiple obstacle: cash bag, ATM maschine and staff are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in bank lobby. It must avoid colliding with the ATM and cash bag. The states of the drone, goal and of the multiple obstacle: the ATM and cash bag are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in bank lobby. It must avoid colliding with the vault door. Agent's state, goal's state and vault doorn's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_vault_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vault_door = calculate_distance_min(s_agent, s_vault_door) \n    penalty_collision = -24 if (d_agent_vault_door < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bank lobby. Goal: It must avoid colliding with alarm system. Assumptions: The states of the drone, goal and the alarm system's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_alarm_system, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_alarm_system = calculate_distance_min(s_agent, s_alarm_system) \n    penalty_collision = -24 if (d_agent_alarm_system < 0.5) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bank lobby. Goal: It must avoid colliding with information counter, deposit box and staff. Assumptions: The Agent's state, goal's state and multiple obstacle's state: information counter, deposit box and staff are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bank lobby. Goal: Detect door, brochure stand and seiling light and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: door, brochure stand and seiling light state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating bank lobby. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along daycare. \n Objectives: It must avoid colliding with toy shelf or stuffed toy. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the toy shelf and the stuffed toy are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacle_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy daycare. \n Objectives: Detect play mat and aviod it. \n Conditions: The states of the agent, goal, the play mat are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_play_mat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_play_mat = calculate_distance_min(s_agent, s_play_mat) \n    penalty_collision = -24 if (d_agent_play_mat < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a daycare. Objectives: It must avoid colliding with visitor. Conditions: States of the drone and the visitor are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_visitor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_visitor = calculate_distance_min(s_agent, s_visitor) \n    penalty_collision = -24 if (d_agent_visitor < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a daycare, the drone must maneuver around teacher's desk. All entity states (agent, goal, teacher's desk) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_teachers_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teachers_desk = calculate_distance_min(s_agent, s_teachers_desk) \n    penalty_collision = -24 if (d_agent_teachers_desk < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a daycare. Requirement: Detect the three lego table and do not collide with it. Given: The states for the drone and multiple lego table are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacle_min < 0.5) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a daycare. \n Objectives: So not collide with backpack. \n Conditions: The states of the agent, goal, the backpack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -24 if (d_agent_backpack < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate daycare. Objectives: Do not collide hit with the activity table. Conditions: States of the agent, activity table are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_activity_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_activity_table = calculate_distance_min(s_agent, s_activity_table) \n    penalty_collision = -24 if (d_agent_activity_table < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a daycare, the drone must steer clear of child. All states (agent, goal, child) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_child, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_child = calculate_distance_min(s_agent, s_child) \n    penalty_collision = -24 if (d_agent_child < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: daycare. Avoid: Detect stuffed toy and do not hitting with stuffed toy. Known: Agent, goal, stuffed toy states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_stuffed_toy, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stuffed_toy = calculate_distance_min(s_agent, s_stuffed_toy) \n    penalty_collision = -24 if (d_agent_stuffed_toy < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating daycare. Objectives: It must avoid colliding with toy shelf. Conditions: The states of the drone, goal and toy shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_toy_shelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toy_shelf = calculate_distance_min(s_agent, s_toy_shelf) \n    penalty_collision = -24 if (d_agent_toy_shelf < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through daycare. Objectives: Avoid collision with checkout safety gate, toy shelf and stuffed toy shelf. Conditions: The states of the agent and of the multiple obstacles: checkout safety gate, toy shelf and stuffed toy are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating daycare. Objectives: It must avoid colliding with any stuffed toy, daycare safety gate. Conditions: Agent's and of the multiple obstacle: stuffed toy, daycare safety gate states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through daycare. Objectives: Do not collide with play mat. Conditions: The states of the drone, goal and the play mat are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_play_mat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_play_mat = calculate_distance_min(s_agent, s_play_mat) \n    penalty = -24 if (d_agent_play_mat < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along daycare and must avoid contact with the cubby storage. The states of the drone, goal and the cubby storage are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_cubby_storage, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cubby_storage = calculate_distance_min(s_agent, s_cubby_storage) \n    penalty = -24 if (d_agent_cubby_storage < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in daycare. It must avoid colliding with the stuffed toy, cubby storage and teacher. The states of the agent and of the multiple obstacle: stuffed toy, cubby storage and teacher are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in daycare. It must avoid colliding with the cubby storage and stuffed toy. The states of the drone, goal and of the multiple obstacle: the cubby storage and stuffed toy are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in daycare. It must avoid colliding with the storage door. Agent's state, goal's state and storage door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_storage_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_door = calculate_distance_min(s_agent, s_storage_door) \n    penalty_collision = -24 if (d_agent_storage_door < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating daycare. Goal: It must avoid colliding with baby monitor. Assumptions: The states of the drone, goal and the baby monitor's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_baby_monitor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_baby_monitor = calculate_distance_min(s_agent, s_baby_monitor) \n    penalty_collision = -24 if (d_agent_baby_monitor < 0.5) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating daycare. Goal: It must avoid colliding with activity table, toy container and teacher. Assumptions: The Agent's state, goal's state and multiple obstacle's state: activity table, toy container and teacher are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating daycare. Goal: Detect safety gate, play mat and ceiling light and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: safety gate, play mat and ceiling light state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating daycare. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along a barbershop. \n Objectives: It must avoid colliding with barber chair or rolling cart. \n Conditions: The states of the agent, goal, and of the other multiple obstacles e.g. the barber chair and the rolling cart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacle_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy barbershop. \n Objectives: Detect hair dryer and avoid it. \n Conditions: The states of the agent, goal, the hair dryer are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_hair_dryer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_hair_dryer = calculate_distance_min(s_agent, s_hair_dryer) \n    penalty_collision = -24 if (d_agent_hair_dryer < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a barbershop. Objectives: It must avoid colliding with customer. Conditions: States of the drone and the customer are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_customer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -24 if (d_agent_customer < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a barbershop, the drone must maneuver around stylist station. All entity states (agent, goal, stylist station) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_stylist_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stylist_station = calculate_distance_min(s_agent, s_stylist_station) \n    penalty_collision = -24 if (d_agent_stylist_station < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a barbershop. Requirement: Detect the three barber chairs and do not collide with them. Given: The states for the drone and multiple barber chairs are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacle_min < 0.5) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a barbershop. \n Objectives: Do not collide with tool bag. \n Conditions: The states of the agent, goal, the tool bag are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_tool_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool_bag = calculate_distance_min(s_agent, s_tool_bag) \n    penalty_collision = -24 if (d_agent_tool_bag < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate barbershop. Objectives: Do not collide with the waiting bench. Conditions: States of the agent, waiting bench are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_waiting_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_waiting_bench = calculate_distance_min(s_agent, s_waiting_bench) \n    penalty_collision = -24 if (d_agent_waiting_bench < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a barbershop, the drone must steer clear of toddler. All states (agent, goal, toddler) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_toddler, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toddler = calculate_distance_min(s_agent, s_toddler) \n    penalty_collision = -24 if (d_agent_toddler < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: barbershop. Avoid: Detect clipper case and do not hit it. Known: Agent, goal, clipper case states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_clipper_case, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clipper_case = calculate_distance_min(s_agent, s_clipper_case) \n    penalty_collision = -24 if (d_agent_clipper_case < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a barbershop. Objectives: It must avoid colliding with product display shelf. Conditions: The states of the drone, goal and product display shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_product_display_shelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_product_display_shelf = calculate_distance_min(s_agent, s_product_display_shelf) \n    penalty_collision = -24 if (d_agent_product_display_shelf < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a barbershop. Objectives: Avoid collision with front door, product display shelf and rolling cart. Conditions: The states of the agent and of the multiple obstacles: front door, product display shelf and rolling cart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a barbershop. Objectives: It must avoid colliding with any clipper case, cape rack. Conditions: Agent's and of the multiple obstacles: clipper case, cape rack states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a barbershop. Objectives: Do not collide with wet floor sign. Conditions: The states of the drone, goal and the wet floor sign are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wet_floor_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wet_floor_sign = calculate_distance_min(s_agent, s_wet_floor_sign) \n    penalty = -24 if (d_agent_wet_floor_sign < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along a barbershop and must avoid contact with the coat rack. The states of the drone, goal and the coat rack are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_coat_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_rack = calculate_distance_min(s_agent, s_coat_rack) \n    penalty = -24 if (d_agent_coat_rack < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a barbershop. It must avoid colliding with the clipper case, coat rack and barber. The states of the agent and of the multiple obstacles: clipper case, coat rack and barber are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in a barbershop. It must avoid colliding with the coat rack and clipper case. The states of the drone, goal and of the multiple obstacles: the coat rack and clipper case are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in a barbershop. It must avoid colliding with the backroom door. Agent's state, goal's state and backroom door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_backroom_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backroom_door = calculate_distance_min(s_agent, s_backroom_door) \n    penalty_collision = -24 if (d_agent_backroom_door < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a barbershop. Goal: It must avoid colliding with CCTV camera. Assumptions: The states of the drone, goal and the CCTV camera's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_cctv_camera, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cctv_camera = calculate_distance_min(s_agent, s_cctv_camera) \n    penalty_collision = -24 if (d_agent_cctv_camera < 0.5) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a barbershop. Goal: It must avoid colliding with stylist chair, mixing bowl and hairstylist. Assumptions: The Agent's state, goal's state and multiple obstacles' state: stylist chair, mixing bowl and hairstylist are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a barbershop. Goal: Detect mirror wall, power cord and ceiling fan and do not collide. Assumptions: The states of the drone, goal and multiple obstacles: mirror wall, power cord and ceiling fan state are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -24 if (d_agent_multiple_obstacles_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a barbershop. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside an apartment. \n Objectives: It must avoid colliding with coffee table or floor lamp. \n Conditions: The states of the agent, goal, and of the other multiple items (e.g., the coffee table and the floor lamp) are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -24 if (d_agent_items_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy apartment. \n Objectives: Detect stair rail and avoid it. \n Conditions: The states of the agent and the stair rail are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stair_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stair_rail = calculate_distance_min(s_agent, s_stair_rail) \n    penalty_collision = -24 if (d_agent_stair_rail < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in an apartment. Objectives: It must avoid colliding with resident. Conditions: States of the drone and the resident are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_resident, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_resident = calculate_distance_min(s_agent, s_resident) \n    penalty_collision = -24 if (d_agent_resident < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside an apartment, the drone must maneuver around the dining table. All entity states (agent, goal, dining table) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_dining_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_table = calculate_distance_min(s_agent, s_dining_table) \n    penalty_collision = -24 if (d_agent_dining_table < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through an apartment. Requirement: Detect the three items and do not collide with them. Given: The states for the drone and multiple items are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -24 if (d_agent_items_min < 0.5) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates in an apartment. \n Objectives: Do not collide with tool bag. \n Conditions: The states of the agent and the tool bag are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_tool_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool_bag = calculate_distance_min(s_agent, s_tool_bag) \n    penalty_collision = -24 if (d_agent_tool_bag < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate apartment. Objectives: Do not collide with the sofa. Conditions: States of the agent and sofa are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_sofa, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sofa = calculate_distance_min(s_agent, s_sofa) \n    penalty_collision = -24 if (d_agent_sofa < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within an apartment, the drone must steer clear of toddler. All states (agent, goal, toddler) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_toddler, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toddler = calculate_distance_min(s_agent, s_toddler) \n    penalty_collision = -24 if (d_agent_toddler < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: apartment. Avoid: Detect toy box and do not hit it. Known: Agent and toy box states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_toy_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toy_box = calculate_distance_min(s_agent, s_toy_box) \n    penalty_collision = -24 if (d_agent_toy_box < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating an apartment. Objectives: It must avoid colliding with potted plant. Conditions: The states of the drone, goal and potted plant are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_potted_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_potted_plant = calculate_distance_min(s_agent, s_potted_plant) \n    penalty_collision = -24 if (d_agent_potted_plant < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through an apartment. Objectives: Avoid collision with robot vacuum, potted plant and floor lamp. Conditions: The states of the agent and of the multiple items: robot vacuum, potted plant and floor lamp are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -24 if (d_agent_items_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating an apartment. Objectives: It must avoid colliding with any toy box and yoga mat. Conditions: Agent's and the multiple items' states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -24 if (d_agent_items_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through an apartment. Objectives: Do not collide with water spill. Conditions: The states of the drone, goal and the water spill are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_water_spill, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_water_spill = calculate_distance_min(s_agent, s_water_spill) \n    penalty = -24 if (d_agent_water_spill < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in an apartment and must avoid contact with an open suitcase. The states of the drone, goal and the suitcase are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_suitcase, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_suitcase = calculate_distance_min(s_agent, s_suitcase) \n    penalty = -24 if (d_agent_suitcase < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in an apartment. It must avoid colliding with the toy box, open suitcase and resident. The states of the agent and of the multiple items: toy box, open suitcase and resident are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -24 if (d_agent_items_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in an apartment. It must avoid colliding with the open suitcase and toy box. The states of the drone, goal and of the multiple items: the open suitcase and moving box are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -24 if (d_agent_items_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting an apartment. It must avoid colliding with the standing fan. Agent's state, goal's state and standing fan's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_standing_fan, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_standing_fan = calculate_distance_min(s_agent, s_standing_fan) \n    penalty_collision = -24 if (d_agent_standing_fan < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating an apartment. Goal: It must avoid colliding with smoke detector. Assumptions: The states of the drone, goal and the smoke detector are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detector = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = -24 if (d_agent_smoke_detector < 0.5) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating an apartment. Goal: It must avoid colliding with dining chair, mixing bowl and roommate. Assumptions: The Agent's state, goal's state and the state of these items are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -24 if (d_agent_items_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating an apartment. Goal: Detect wall mirror, power cord and ceiling fan and do not collide. Assumptions: The states of the drone, goal and multiple items are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_items, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_items_min = calculate_distance_min(s_agent, s_items) \n    penalty_collision = -24 if (d_agent_items_min < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating an apartment. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 29 if (d_agent_goal < 0.1) else -d_agent_goal*5 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a Science Museum.\n Objectives: It must avoid colliding with a glass display case.\n Conditions: The states of the agent and the glass display case are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_glass_display_case, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_display_case = calculate_distance_min(s_agent, s_glass_display_case) \n    penalty_collision = -25 if (d_agent_glass_display_case < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating the atrium of a Science Museum.\n Objectives: Avoid the Foucault pendulum.\n Conditions: States of the drone and pendulum bob are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_pendulum, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pendulum = calculate_distance_min(s_agent, s_pendulum) \n    penalty_collision = -30 if (d_agent_pendulum < 1.0) else 15 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through the technology wing of a Science Museum.\nRequirement: Detect the interactive kiosk and do not collide with it.\n Given: The states for the drone and the kiosk are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_kiosk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kiosk = calculate_distance_min(s_agent, s_kiosk) \n    penalty_collision = -25 if (d_agent_kiosk < 0.7) else 15 \n    reward_reaching_goal = 26 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Science Museum gallery, the drone must steer clear of rope stanchions used for crowd control.\n All states (agent, goal, rope) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -22 if (d_agent_rope < 0.6) else 12 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Science Museum.\n Objectives: It must avoid colliding with the suspended aircraft exhibit wing.\n Conditions: The states of the drone, goal and the aircraft wing are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_aircraft_wing, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_aircraft_wingg = calculate_distance_min(s_agent, s_aircraft_wing) \n    penalty_collision = -35 if (d_agent_aircraft_wingg < 0.9) else 15 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating near the planetarium entrance of a Science Museum.\n Objectives: Do not enter the projector beam path.\n Conditions: The states of the agent and the projector beam volume are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_projector_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_projector_beam) \n    penalty_collision = -28 if (d_agent_beam < 0.8) else 10\n    reward_reaching_goal = 27 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is inspecting a Science Museum lab demo area.\n Goal: Avoid the Tesla coil safety cage.\n Assumptions: The states of the drone, goal and the Tesla coil cage are known. Implement a Python reward function.",
        "chosen": "def reward(s_agent, s_cage, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cage = calculate_distance_min(s_agent, s_cage) \n    penalty_collision = -30 if (d_agent_cage < 0.8) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: Science Museum. Avoid: Detect the rotating solar system model and do not collide with it.\n Known: Agent and rotating model states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_rotating_model, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rotating_model = calculate_distance_min(s_agent, s_rotating_model) \n    penalty_collision = -27 if (d_agent_rotating_model < 0.8) else 14\n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Science Museum hallway.\n Objectives: It must avoid colliding with the autonomous floor scrubber robot.\n Conditions: The states of the drone, goal and the scrubber are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_floor_scrubber_robot, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_robot = calculate_distance_min(s_agent, s_floor_scrubber_robot) \n    penalty_collision = -25 if (d_agent_robot < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Science Museum space.\n Objectives: Avoid collision with multiple 3D printer enclosures.\n Conditions: The states of the agent and of the multiple obstacles (3D printer enclosures) are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 24 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Science Museum, the drone must maneuver around the hologram display pedestal.\n All entity states (agent, goal, hologram pedestal) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_hologram_pedestal, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pedestal = calculate_distance_min(s_agent, s_hologram_pedestal) \n    penalty_collision = -23 if (d_agent_pedestal < 0.6) else 12 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Science Museum stairwell.\n Goal: Do not collide with the escalator handrail region.\n Assumptions: The Agent's state, goal's state and the escalator handrail volume state are known. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_escalator_handrail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_handrail = calculate_distance_min(s_agent, s_escalator_handrail) \n    penalty_collision = -26 if (d_agent_handrail < 0.7) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates inside a Science Museum ocean hall.\n Objectives: Do not collide with the suspended whale skeleton.\n Conditions: The states of the agent and the whale skeleton are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_whale_skeleton, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_skeleton = calculate_distance_min(s_agent, s_whale_skeleton) \n    penalty_collision = -34 if (d_agent_skeleton < 0.9) else 15 \n    reward_reaching_goal = 31 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying near the VR demo zone in a Science Museum.\nRequirement: Detect the tethered headset cable and avoid it.\n Given: The states for the drone and the cable are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -21 if (d_agent_cable < 0.5) else 10\n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating the Science Museum innovation gallery.\n Goal: It must avoid colliding with the magnetic levitation track.\n Assumptions: The states of the drone, goal and the maglev track are available. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_maglev_track, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_track = calculate_distance_min(s_agent, s_maglev_track) \n    penalty_collision = -24 if (d_agent_track < 0.7) else 14\n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is exploring the Science Museum fossil hall.\n Objective: Avoid collision with the large dinosaur skeleton tail.\n Conditions: The states of the drone, goal and the skeleton are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_skeleton, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_skeleton = calculate_distance_min(s_agent, s_skeleton) \n    penalty_collision = -33 if (d_agent_skeleton < 0.8) else 15\n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -d_agent_goal**2\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating the Science Museum optics exhibit.\n Objective: Avoid the rotating mirror array.\n Conditions: Agent and mirror states are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_mirror, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mirror = calculate_distance_min(s_agent, s_mirror) \n    penalty_collision = -28 if (d_agent_mirror < 0.7) else 12\n    reward_reaching_goal = 27 if (d_agent_goal < 0.2) else -d_agent_goal**2\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying inside the Science Museum energy gallery.\n Requirement: Avoid colliding with the spinning wind turbine model.\n Given: States for the drone and the turbine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_turbine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_turbine = calculate_distance_min(s_agent, s_turbine) \n    penalty_collision = -32 if (d_agent_turbine < 1.0) else 14\n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: A drone is operating in the Science Museum chemistry wing.\n Goal: It must avoid flying into the mist zone of the liquid nitrogen demo.\n Assumptions: The states of the drone, goal and mist cloud are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_mist_zone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mist = calculate_distance_min(s_agent, s_mist_zone) \n    penalty_collision = -20 if (d_agent_mist < 0.6) else 10\n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal**2\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Science Museum.\n Goal: Drone goal is to reach the charging dock goal.\n Assumptions: The states of the drone, goal and the charging dock are known. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along cellar. \n Objectives: It must avoid colliding with wine rack or barrel. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the wine rack and the barrel are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy cellar. \n Objectives: Detect support beam and aviod it. \n Conditions: The states of the agent, goal, the beam are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -25 if (d_agent_beam < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a cellar. Objectives: It must avoid colliding with cellar worker. Conditions: States of the drone and the cellar worker are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cellar_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cellar_worker = calculate_distance_min(s_agent, s_cellar_worker) \n    penalty_collision = -25 if (d_agent_cellar_worker < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a cellar, the drone must maneuver around tool bench. All entity states (agent, goal, tool bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_tool_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool_bench = calculate_distance_min(s_agent, s_tool_bench) \n    penalty_collision = -25 if (d_agent_tool_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a cellar. Requirement: Detect the three old machinery and do not collide with it. Given: The states for the drone and multiple old machinery are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a cellar. \n Objectives: So not collide with wooden crate. \n Conditions: The states of the agent, goal, the wooden crate are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_wooden_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wooden_crate = calculate_distance_min(s_agent, s_wooden_crate) \n    penalty_collision = -25 if (d_agent_wooden_crate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate cellar. Objectives: Do not collide hit with the storage table. Conditions: States of the agent, storage table are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_storage_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_table = calculate_distance_min(s_agent, s_storage_table) \n    penalty_collision = -25 if (d_agent_storage_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a cellar, the drone must steer clear of cellar worker. All states (agent, goal, cellar worker) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_cellar_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cellar_worker = calculate_distance_min(s_agent, s_cellar_worker) \n    penalty_collision = -25 if (d_agent_cellar_worker < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: cellar. Avoid: Detect wooden crate and do not hitting with wooden crate. Known: Agent, goal, wooden crate states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_wooden_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wooden_crate = calculate_distance_min(s_agent, s_wooden_crate) \n    penalty_collision = -25 if (d_agent_wooden_crate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating cellar. Objectives: It must avoid colliding with wine rack. Conditions: The states of the drone, goal and wine rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wine_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wine_rack = calculate_distance_min(s_agent, s_wine_rack) \n    penalty_collision = -25 if (d_agent_wine_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through cellar. Objectives: Avoid collision with checkout revolving cellar door, wine rack and barrel. Conditions: The states of the agent and of the multiple obstacles: cellar door, wine rack and barrel are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating cellar. Objectives: It must avoid colliding with any wooden crate, cellar cellar door. Conditions: Agent's and of the multiple obstacle: wooden crate, cellar cellar door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through cellar. Objectives: Do not collide with support beam. Conditions: The states of the drone, goal and the support beam are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_beam) \n    penalty = -25 if (d_agent_beam < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along cellar and must avoid contact with the wine press. The states of the drone, goal and the wine press are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_wine_press, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wine_press = calculate_distance_min(s_agent, s_wine_press) \n    penalty = -25 if (d_agent_wine_press < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in cellar. It must avoid colliding with the wooden crate, wine press and cellar worker. The states of the agent and of the multiple obstacle: wooden crate, wine press and cellar worker are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in cellar. It must avoid colliding with the wine press and wooden crate. The states of the drone, goal and of the multiple obstacle: the wine press and wooden crate are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in cellar. It must avoid colliding with the cellar door. Agent's state, goal's state and cellar door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cellar_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cellar_door = calculate_distance_min(s_agent, s_cellar_door) \n    penalty_collision = -25 if (d_agent_cellar_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: It must avoid colliding with moisture sensor. Assumptions: The states of the drone, goal and the moisture sensor's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_sensor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sensor = calculate_distance_min(s_agent, s_sensor) \n    penalty_collision = -25 if (d_agent_sensor < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: It must avoid colliding with storage table, storage box and cellar worker. Assumptions: The Agent's state, goal's state and multiple obstacle's state: storage table, storage box and cellar worker are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: Detect cellar door, support beam and hanging lamp and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: cellar door, support beam and hanging lamp state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along university. \n Objectives: It must avoid colliding with reception desk or supply shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the reception desk and the supply shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy university. \n Objectives: Detect notice board and aviod it. \n Conditions: The states of the agent, goal, the notice board are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_notice_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_notice_board = calculate_distance_min(s_agent, s_notice_board) \n    penalty_collision = -25 if (d_agent_notice_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a university. Objectives: It must avoid colliding with student. Conditions: States of the drone and the student are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -25 if (d_agent_student < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a university, the drone must maneuver around projector. All entity states (agent, goal, projector) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -25 if (d_agent_projector < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a university. Requirement: Detect the three kiosk and do not collide with it. Given: The states for the drone and multiple kiosks are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a university. \n Objectives: So not collide with backpack. \n Conditions: The states of the agent, goal, the backpack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -25 if (d_agent_backpack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate university. Objectives: Do not collide hit with the help desk. Conditions: States of the agent, help desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_help_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_help_desk = calculate_distance_min(s_agent, s_help_desk) \n    penalty_collision = -25 if (d_agent_help_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a university, the drone must steer clear of professor. All states (agent, goal, professor) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_professor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_professor = calculate_distance_min(s_agent, s_professor) \n    penalty_collision = -25 if (d_agent_professor < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: university. Avoid: Detect pipe and do not hitting with pipe. Known: Agent, goal, pipe states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -25 if (d_agent_pipe < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating university. Objectives: It must avoid colliding with reception desk. Conditions: The states of the drone, goal and reception desk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_reception_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception_desk = calculate_distance_min(s_agent, s_reception_desk) \n    penalty_collision = -25 if (d_agent_reception_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through university. Objectives: Avoid collision with entrance door, reception desk and shelf. Conditions: The states of the agent and of the multiple obstacles: entrance door, reception desk and shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating university. Objectives: It must avoid colliding with any backpack, university entrance. Conditions: Agent's and of the multiple obstacle: backpack, university entrance states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through university. Objectives: Do not collide with notice board. Conditions: The states of the drone, goal and the notice board are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_notice_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_notice_board = calculate_distance_min(s_agent, s_notice_board) \n    penalty = -25 if (d_agent_notice_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along university and must avoid contact with the vending machine. The states of the drone, goal and the vending machine are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_vending machine_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vending machine_maschine = calculate_distance_min(s_agent, s_vending machine_maschine) \n    penalty = -25 if (d_agent_vending machine_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in university. It must avoid colliding with the backpack, vending machine and faculty member. The states of the agent and of the multiple obstacle: backpack, vending machine and faculty member are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in university. It must avoid colliding with the vending machine and backpack. The states of the drone, goal and of the multiple obstacle: the vending machine and backpack are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in university. It must avoid colliding with the vault building entrance. Agent's state, goal's state and vault building entrancen's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_entrance, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_entrance = calculate_distance_min(s_agent, s_entrance) \n    penalty_collision = -25 if (d_agent_entrance < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: It must avoid colliding with fire alarm panel. Assumptions: The states of the drone, goal and the fire alarm panel's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_alarm_system, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_alarm_system = calculate_distance_min(s_agent, s_alarm_system) \n    penalty_collision = -25 if (d_agent_alarm_system < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: It must avoid colliding with help desk, assignment drop box and faculty member. Assumptions: The Agent's state, goal's state and multiple obstacle's state: help desk, assignment drop box and faculty member are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: Detect building entrance, notice board and overhead light and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: building entrance, notice board and overhead light state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along supply store. \n Objectives: It must avoid colliding with checkout counter or storage shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the checkout counter and the storage shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy supply store. \n Objectives: Detect promo display and aviod it. \n Conditions: The states of the agent, goal, the promo display are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display = calculate_distance_min(s_agent, s_display) \n    penalty_collision = -25 if (d_agent_display < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a supply store. Objectives: It must avoid colliding with shopper. Conditions: States of the drone and the shopper are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shopper, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shopper = calculate_distance_min(s_agent, s_shopper) \n    penalty_collision = -25 if (d_agent_shopper < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a supply store, the drone must maneuver around cash register. All entity states (agent, goal, cash register) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_cash_register, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cash_register = calculate_distance_min(s_agent, s_cash_register) \n    penalty_collision = -25 if (d_agent_cash_register < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a supply store. Requirement: Detect the three price scanner and do not collide with it. Given: The states for the drone and multiple price scanner are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a supply store. \n Objectives: So not collide with supply box. \n Conditions: The states of the agent, goal, the supply box are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_supply_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_supply_box = calculate_distance_min(s_agent, s_supply_box) \n    penalty_collision = -25 if (d_agent_supply_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate supply store. Objectives: Do not collide hit with the customer service desk. Conditions: States of the agent, customer service desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_service_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_service_desk = calculate_distance_min(s_agent, s_service_desk) \n    penalty_collision = -25 if (d_agent_service_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a supply store, the drone must steer clear of shopper. All states (agent, goal, shopper) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_shopper, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shopper = calculate_distance_min(s_agent, s_shopper) \n    penalty_collision = -25 if (d_agent_shopper < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: supply store. Avoid: Detect supply box and do not hitting with paket. Known: Agent, goal, paket states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_paket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paket = calculate_distance_min(s_agent, s_paket) \n    penalty_collision = -25 if (d_agent_paket < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating supply store. Objectives: It must avoid colliding with checkout counter. Conditions: The states of the drone, goal and checkout counter are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_checkout_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_checkout_counter = calculate_distance_min(s_agent, s_checkout_counter) \n    penalty_collision = -25 if (d_agent_checkout_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through supply store. Objectives: Avoid collision with checkout revolving store entrance, checkout counter and storage shelf. Conditions: The states of the agent and of the multiple obstacles: checkout revolving store entrance, checkout counter and storage shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating supply store. Objectives: It must avoid colliding with any supply box, supply store store entrance. Conditions: Agent's and of the multiple obstacle: supply box, supply store store entrance states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through supply store. Objectives: Do not collide with promo display. Conditions: The states of the drone, goal and the promo display are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display = calculate_distance_min(s_agent, s_display) \n    penalty = -25 if (d_agent_display < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along supply store and must avoid contact with the payment maschine. The states of the drone, goal and the payment maschine are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_payment_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_payment_maschine = calculate_distance_min(s_agent, s_payment_maschine) \n    penalty = -25 if (d_agent_payment_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in supply store. It must avoid colliding with the supply box, payment terminal and worker. The states of the agent and of the multiple obstacle: supply box, payment terminal and worker are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in supply store. It must avoid colliding with the payment terminal and supply box. The states of the drone, goal and of the multiple obstacle: the payment terminal and supply box are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in supply store. It must avoid colliding with the tool. Agent's state, goal's state and tool's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool = calculate_distance_min(s_agent, s_tool) \n    penalty_collision = -25 if (d_agent_tool < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: It must avoid colliding with forklift. Assumptions: The states of the drone, goal and the forklift's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -25 if (d_agent_forklift < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: It must avoid colliding with customer service desk, forklift and worker. Assumptions: The Agent's state, goal's state and multiple obstacle's state: customer service desk, forklift and worker are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: Detect store entrance, promo display and light and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: store entrance, promo display and light state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along art supply store. \n Objectives: It must avoid colliding with paint mixing station or drying rack. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the paint mixing station and the drying rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy art supply store. \n Objectives: Detect brush rack and aviod it. \n Conditions: The states of the agent, goal, the brush rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_brush_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_brush_rack = calculate_distance_min(s_agent, s_brush_rack) \n    penalty_collision = -25 if (d_agent_brush_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a art supply store. Objectives: It must avoid colliding with store artist. Conditions: States of the drone and the store artist are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_store_artist, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_store_artist = calculate_distance_min(s_agent, s_store_artist) \n    penalty_collision = -25 if (d_agent_store_artist < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a art supply store, the drone must maneuver around framing station. All entity states (agent, goal, framing station) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_framing_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_framing_station = calculate_distance_min(s_agent, s_framing_station) \n    penalty_collision = -25 if (d_agent_framing_station < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a art supply store. Requirement: Detect the three paper cutter and do not collide with it. Given: The states for the drone and multiple paper cutter are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a art supply store. \n Objectives: So not collide with clay bag. \n Conditions: The states of the agent, goal, the clay bag are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_clay_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clay_bag = calculate_distance_min(s_agent, s_clay_bag) \n    penalty_collision = -25 if (d_agent_clay_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate art supply store. Objectives: Do not collide hit with the color palette counter. Conditions: States of the agent, color palette counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_palette_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_palette_counter = calculate_distance_min(s_agent, s_palette_counter) \n    penalty_collision = -25 if (d_agent_palette_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a art supply store, the drone must steer clear of store artist. All states (agent, goal, store artist) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_store_artist, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_store_artist = calculate_distance_min(s_agent, s_store_artist) \n    penalty_collision = -25 if (d_agent_store_artist < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: art supply store. Avoid: Detect clay bag and do not hitting with clay bag. Known: Agent, goal, clay bag states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cash_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cash_bag = calculate_distance_min(s_agent, s_cash_bag) \n    penalty_collision = -25 if (d_agent_cash_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating art supply store. Objectives: It must avoid colliding with paint station. Conditions: The states of the drone, goal and paint station are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_paint_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paint_station = calculate_distance_min(s_agent, s_paint_station) \n    penalty_collision = -25 if (d_agent_paint_station < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through art supply store. Objectives: Avoid collision with paint bucket, paint station and drying rack. Conditions: The states of the agent and of the multiple obstacles: paint bucket, paint station and drying rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating art supply store. Objectives: It must avoid colliding with any clay bag, art supply store loading bay. Conditions: Agent's and of the multiple obstacle: clay bag, staff states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through art supply store. Objectives: Do not collide with kiln. Conditions: The states of the drone, goal and the kiln are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kiln, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kiln = calculate_distance_min(s_agent, s_kiln) \n    penalty = -25 if (d_agent_kiln < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along art supply store and must avoid contact with the 3D printer. The states of the drone, goal and the 3D printer are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_3D_printer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_3D_printer = calculate_distance_min(s_agent, s_3D_printer) \n    penalty = -25 if (d_agent_3D_printer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in art supply store. It must avoid colliding with the clay bag, 3D printer and kiln. The states of the agent and of the multiple obstacle: clay bag, 3D printer and kiln are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in art supply store. It must avoid colliding with the 3D printer and clay bag. The states of the drone, goal and of the multiple obstacle: the 3D printer and clay bag are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in art supply store. It must avoid colliding with the AC. Agent's state, goal's state and AC's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_AC, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_AC = calculate_distance_min(s_agent, s_AC) \n    penalty_collision = -25 if (d_agent_AC < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: It must avoid colliding with ventilation unit. Assumptions: The states of the drone, goal and the ventilation unit's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_ventilation, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ventilation = calculate_distance_min(s_agent, s_ventilation) \n    penalty_collision = -25 if (d_agent_ventilation < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: It must avoid colliding with color palette counter, supply return bin and store artist. Assumptions: The Agent's state, goal's state and multiple obstacle's state: color palette, supply tools and store artist are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: Detect loading bay, brush rack and hanging spotlight and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: brushes, brush rack and hanging spotlight state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along meeting room. \n Objectives: It must avoid colliding with conference table or whiteboard. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the conference table and the whiteboard are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy meeting room. \n Objectives: Detect projector stand and aviod it. \n Conditions: The states of the agent, goal, the projector stand are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_projector_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector_stand = calculate_distance_min(s_agent, s_projector_stand) \n    penalty_collision = -25 if (d_agent_projector_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a meeting room. Objectives: It must avoid colliding with attendee. Conditions: States of the drone and the attendee are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_attendee, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_attendee = calculate_distance_min(s_agent, s_attendee) \n    penalty_collision = -25 if (d_agent_attendee < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a meeting room, the drone must maneuver around podium. All entity states (agent, goal, podium) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_podium, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_podium = calculate_distance_min(s_agent, s_podium) \n    penalty_collision = -25 if (d_agent_podium < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a meeting room. Requirement: Detect the three coffee machine and do not collide with it. Given: The states for the drone and multiple coffee machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a meeting room. \n Objectives: So not collide with laptop bag. \n Conditions: The states of the agent, goal, the laptop bag are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_laptop_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop_bag = calculate_distance_min(s_agent, s_laptop_bag) \n    penalty_collision = -25 if (d_agent_laptop_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate meeting room. Objectives: Do not collide hit with the reception desk. Conditions: States of the agent, reception desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_reception_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception_desk = calculate_distance_min(s_agent, s_reception_desk) \n    penalty_collision = -25 if (d_agent_reception_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a meeting room, the drone must steer clear of attendee. All states (agent, goal, attendee) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_attendee, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_attendee = calculate_distance_min(s_agent, s_attendee) \n    penalty_collision = -25 if (d_agent_attendee < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: meeting room. Avoid: Detect laptop and do not hitting with laptop bag. Known: Agent, goal, laptop states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -25 if (d_agent_laptop < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating meeting room. Objectives: It must avoid colliding with conference table. Conditions: The states of the drone, goal and conference table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_conference_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_conference_table = calculate_distance_min(s_agent, s_conference_table) \n    penalty_collision = -25 if (d_agent_conference_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through meeting room. Objectives: Avoid collision with checkout revolving meeting room door, conference table and whiteboard. Conditions: The states of the agent and of the multiple obstacles: meeting room door, conference table and whiteboard are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating meeting room. Objectives: It must avoid colliding with any laptop bag, room door. Conditions: Agent's and of the multiple obstacle: laptop bag, room door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through meeting room. Objectives: Do not collide with coffee maschine. Conditions: The states of the drone, goal and the coffee maschine are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_maschine = calculate_distance_min(s_agent, s_coffee_maschine) \n    penalty = -25 if (d_agent_coffee_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along meeting room and must avoid contact with the video conferencing unit. The states of the drone, goal and the video camera. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_video_camera, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_video_camera = calculate_distance_min(s_agent, s_video_camera) \n    penalty = -25 if (d_agent_video_camera < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in meeting room. It must avoid colliding with the laptop bag, video conferencing unit and attendee. The states of the agent and of the multiple obstacle: laptop bag, video conferencing unit and attendee are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in meeting room. It must avoid colliding with the video conferencing unit and laptop bag. The states of the drone, goal and of the multiple obstacle: the video conferencing unit and laptop bag are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in meeting room. It must avoid colliding with the meeting room door. Agent's state, goal's state and meeting room door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s__door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent__door = calculate_distance_min(s_agent, s__door) \n    penalty_collision = -25 if (d_agent__door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: It must avoid colliding with air conditioner. Assumptions: The states of the drone, goal and the air conditioner's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_air_conditioner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_air_conditioner = calculate_distance_min(s_agent, s_air_conditioner) \n    penalty_collision = -25 if (d_agent_air_conditioner < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: It must avoid colliding with reception desk, document tray and attendee. Assumptions: The Agent's state, goal's state and multiple obstacle's state: reception desk, document tray and attendee are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: Detect meeting room door, projector stand and ceiling projector and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: meeting room door, projector stand and ceiling projector state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a Science Museum.\n Objectives: It must avoid colliding with a glass display case.\n Conditions: The states of the agent and the glass display case are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_glass_display_case, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_display_case = calculate_distance_min(s_agent, s_glass_display_case) \n    penalty_collision = -25 if (d_agent_glass_display_case < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating the atrium of a Science Museum.\n Objectives: Avoid the Foucault pendulum.\n Conditions: States of the drone and pendulum bob are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_pendulum, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pendulum = calculate_distance_min(s_agent, s_pendulum) \n    penalty_collision = -30 if (d_agent_pendulum < 1.0) else 15 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through the technology wing of a Science Museum.\nRequirement: Detect the interactive kiosk and do not collide with it.\n Given: The states for the drone and the kiosk are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_kiosk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kiosk = calculate_distance_min(s_agent, s_kiosk) \n    penalty_collision = -25 if (d_agent_kiosk < 0.7) else 15 \n    reward_reaching_goal = 26 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Science Museum gallery, the drone must steer clear of rope stanchions used for crowd control.\n All states (agent, goal, rope) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -22 if (d_agent_rope < 0.6) else 12 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Science Museum.\n Objectives: It must avoid colliding with the suspended aircraft exhibit wing.\n Conditions: The states of the drone, goal and the aircraft wing are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_aircraft_wing, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_aircraft_wingg = calculate_distance_min(s_agent, s_aircraft_wing) \n    penalty_collision = -35 if (d_agent_aircraft_wingg < 0.9) else 15 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating near the planetarium entrance of a Science Museum.\n Objectives: Do not enter the projector beam path.\n Conditions: The states of the agent and the projector beam volume are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_projector_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_projector_beam) \n    penalty_collision = -28 if (d_agent_beam < 0.8) else 10\n    reward_reaching_goal = 27 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is inspecting a Science Museum lab demo area.\n Goal: Avoid the Tesla coil safety cage.\n Assumptions: The states of the drone, goal and the Tesla coil cage are known. Implement a Python reward function.",
        "chosen": "def reward(s_agent, s_cage, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cage = calculate_distance_min(s_agent, s_cage) \n    penalty_collision = -30 if (d_agent_cage < 0.8) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: Science Museum. Avoid: Detect the rotating solar system model and do not collide with it.\n Known: Agent and rotating model states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_rotating_model, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rotating_model = calculate_distance_min(s_agent, s_rotating_model) \n    penalty_collision = -27 if (d_agent_rotating_model < 0.8) else 14\n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Science Museum hallway.\n Objectives: It must avoid colliding with the autonomous floor scrubber robot.\n Conditions: The states of the drone, goal and the scrubber are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_floor_scrubber_robot, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_robot = calculate_distance_min(s_agent, s_floor_scrubber_robot) \n    penalty_collision = -25 if (d_agent_robot < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Science Museum space.\n Objectives: Avoid collision with multiple 3D printer enclosures.\n Conditions: The states of the agent and of the multiple obstacles (3D printer enclosures) are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 24 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Science Museum, the drone must maneuver around the hologram display pedestal.\n All entity states (agent, goal, hologram pedestal) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_hologram_pedestal, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pedestal = calculate_distance_min(s_agent, s_hologram_pedestal) \n    penalty_collision = -23 if (d_agent_pedestal < 0.6) else 12 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Science Museum stairwell.\n Goal: Do not collide with the escalator handrail region.\n Assumptions: The Agent's state, goal's state and the escalator handrail volume state are known. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_escalator_handrail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_handrail = calculate_distance_min(s_agent, s_escalator_handrail) \n    penalty_collision = -26 if (d_agent_handrail < 0.7) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates inside a Science Museum ocean hall.\n Objectives: Do not collide with the suspended whale skeleton.\n Conditions: The states of the agent and the whale skeleton are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_whale_skeleton, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_skeleton = calculate_distance_min(s_agent, s_whale_skeleton) \n    penalty_collision = -34 if (d_agent_skeleton < 0.9) else 15 \n    reward_reaching_goal = 31 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying near the VR demo zone in a Science Museum.\nRequirement: Detect the tethered headset cable and avoid it.\n Given: The states for the drone and the cable are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -21 if (d_agent_cable < 0.5) else 10\n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating the Science Museum innovation gallery.\n Goal: It must avoid colliding with the magnetic levitation track.\n Assumptions: The states of the drone, goal and the maglev track are available. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_maglev_track, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_track = calculate_distance_min(s_agent, s_maglev_track) \n    penalty_collision = -24 if (d_agent_track < 0.7) else 14\n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is exploring the Science Museum fossil hall.\n Objective: Avoid collision with the large dinosaur skeleton tail.\n Conditions: The states of the drone, goal and the skeleton are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_skeleton, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_skeleton = calculate_distance_min(s_agent, s_skeleton) \n    penalty_collision = -33 if (d_agent_skeleton < 0.8) else 15\n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -d_agent_goal*4\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating the Science Museum optics exhibit.\n Objective: Avoid the rotating mirror array.\n Conditions: Agent and mirror states are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_mirror, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mirror = calculate_distance_min(s_agent, s_mirror) \n    penalty_collision = -28 if (d_agent_mirror < 0.7) else 12\n    reward_reaching_goal = 27 if (d_agent_goal < 0.2) else -d_agent_goal*4\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying inside the Science Museum energy gallery.\n Requirement: Avoid colliding with the spinning wind turbine model.\n Given: States for the drone and the turbine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_turbine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_turbine = calculate_distance_min(s_agent, s_turbine) \n    penalty_collision = -32 if (d_agent_turbine < 1.0) else 14\n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: A drone is operating in the Science Museum chemistry wing.\n Goal: It must avoid flying into the mist zone of the liquid nitrogen demo.\n Assumptions: The states of the drone, goal and mist cloud are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_mist_zone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mist = calculate_distance_min(s_agent, s_mist_zone) \n    penalty_collision = -20 if (d_agent_mist < 0.6) else 10\n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal*4\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Science Museum.\n Goal: Drone goal is to reach the charging dock goal.\n Assumptions: The states of the drone, goal and the charging dock are known. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along cellar. \n Objectives: It must avoid colliding with wine rack or barrel. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the wine rack and the barrel are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy cellar. \n Objectives: Detect support beam and aviod it. \n Conditions: The states of the agent, goal, the beam are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -25 if (d_agent_beam < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a cellar. Objectives: It must avoid colliding with cellar worker. Conditions: States of the drone and the cellar worker are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cellar_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cellar_worker = calculate_distance_min(s_agent, s_cellar_worker) \n    penalty_collision = -25 if (d_agent_cellar_worker < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a cellar, the drone must maneuver around tool bench. All entity states (agent, goal, tool bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_tool_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool_bench = calculate_distance_min(s_agent, s_tool_bench) \n    penalty_collision = -25 if (d_agent_tool_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a cellar. Requirement: Detect the three old machinery and do not collide with it. Given: The states for the drone and multiple old machinery are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a cellar. \n Objectives: So not collide with wooden crate. \n Conditions: The states of the agent, goal, the wooden crate are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_wooden_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wooden_crate = calculate_distance_min(s_agent, s_wooden_crate) \n    penalty_collision = -25 if (d_agent_wooden_crate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate cellar. Objectives: Do not collide hit with the storage table. Conditions: States of the agent, storage table are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_storage_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_table = calculate_distance_min(s_agent, s_storage_table) \n    penalty_collision = -25 if (d_agent_storage_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a cellar, the drone must steer clear of cellar worker. All states (agent, goal, cellar worker) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_cellar_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cellar_worker = calculate_distance_min(s_agent, s_cellar_worker) \n    penalty_collision = -25 if (d_agent_cellar_worker < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: cellar. Avoid: Detect wooden crate and do not hitting with wooden crate. Known: Agent, goal, wooden crate states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_wooden_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wooden_crate = calculate_distance_min(s_agent, s_wooden_crate) \n    penalty_collision = -25 if (d_agent_wooden_crate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating cellar. Objectives: It must avoid colliding with wine rack. Conditions: The states of the drone, goal and wine rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wine_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wine_rack = calculate_distance_min(s_agent, s_wine_rack) \n    penalty_collision = -25 if (d_agent_wine_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through cellar. Objectives: Avoid collision with checkout revolving cellar door, wine rack and barrel. Conditions: The states of the agent and of the multiple obstacles: cellar door, wine rack and barrel are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating cellar. Objectives: It must avoid colliding with any wooden crate, cellar cellar door. Conditions: Agent's and of the multiple obstacle: wooden crate, cellar cellar door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through cellar. Objectives: Do not collide with support beam. Conditions: The states of the drone, goal and the support beam are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_beam) \n    penalty = -25 if (d_agent_beam < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along cellar and must avoid contact with the wine press. The states of the drone, goal and the wine press are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_wine_press, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wine_press = calculate_distance_min(s_agent, s_wine_press) \n    penalty = -25 if (d_agent_wine_press < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in cellar. It must avoid colliding with the wooden crate, wine press and cellar worker. The states of the agent and of the multiple obstacle: wooden crate, wine press and cellar worker are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in cellar. It must avoid colliding with the wine press and wooden crate. The states of the drone, goal and of the multiple obstacle: the wine press and wooden crate are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in cellar. It must avoid colliding with the cellar door. Agent's state, goal's state and cellar door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cellar_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cellar_door = calculate_distance_min(s_agent, s_cellar_door) \n    penalty_collision = -25 if (d_agent_cellar_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: It must avoid colliding with moisture sensor. Assumptions: The states of the drone, goal and the moisture sensor's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_sensor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sensor = calculate_distance_min(s_agent, s_sensor) \n    penalty_collision = -25 if (d_agent_sensor < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: It must avoid colliding with storage table, storage box and cellar worker. Assumptions: The Agent's state, goal's state and multiple obstacle's state: storage table, storage box and cellar worker are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: Detect cellar door, support beam and hanging lamp and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: cellar door, support beam and hanging lamp state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along university. \n Objectives: It must avoid colliding with reception desk or supply shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the reception desk and the supply shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy university. \n Objectives: Detect notice board and aviod it. \n Conditions: The states of the agent, goal, the notice board are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_notice_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_notice_board = calculate_distance_min(s_agent, s_notice_board) \n    penalty_collision = -25 if (d_agent_notice_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a university. Objectives: It must avoid colliding with student. Conditions: States of the drone and the student are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -25 if (d_agent_student < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a university, the drone must maneuver around projector. All entity states (agent, goal, projector) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -25 if (d_agent_projector < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a university. Requirement: Detect the three kiosk and do not collide with it. Given: The states for the drone and multiple kiosks are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a university. \n Objectives: So not collide with backpack. \n Conditions: The states of the agent, goal, the backpack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -25 if (d_agent_backpack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate university. Objectives: Do not collide hit with the help desk. Conditions: States of the agent, help desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_help_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_help_desk = calculate_distance_min(s_agent, s_help_desk) \n    penalty_collision = -25 if (d_agent_help_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a university, the drone must steer clear of professor. All states (agent, goal, professor) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_professor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_professor = calculate_distance_min(s_agent, s_professor) \n    penalty_collision = -25 if (d_agent_professor < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: university. Avoid: Detect pipe and do not hitting with pipe. Known: Agent, goal, pipe states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -25 if (d_agent_pipe < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating university. Objectives: It must avoid colliding with reception desk. Conditions: The states of the drone, goal and reception desk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_reception_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception_desk = calculate_distance_min(s_agent, s_reception_desk) \n    penalty_collision = -25 if (d_agent_reception_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through university. Objectives: Avoid collision with entrance door, reception desk and shelf. Conditions: The states of the agent and of the multiple obstacles: entrance door, reception desk and shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating university. Objectives: It must avoid colliding with any backpack, university entrance. Conditions: Agent's and of the multiple obstacle: backpack, university entrance states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through university. Objectives: Do not collide with notice board. Conditions: The states of the drone, goal and the notice board are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_notice_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_notice_board = calculate_distance_min(s_agent, s_notice_board) \n    penalty = -25 if (d_agent_notice_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along university and must avoid contact with the vending machine. The states of the drone, goal and the vending machine are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_vending machine_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vending machine_maschine = calculate_distance_min(s_agent, s_vending machine_maschine) \n    penalty = -25 if (d_agent_vending machine_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in university. It must avoid colliding with the backpack, vending machine and faculty member. The states of the agent and of the multiple obstacle: backpack, vending machine and faculty member are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in university. It must avoid colliding with the vending machine and backpack. The states of the drone, goal and of the multiple obstacle: the vending machine and backpack are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in university. It must avoid colliding with the vault building entrance. Agent's state, goal's state and vault building entrancen's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_entrance, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_entrance = calculate_distance_min(s_agent, s_entrance) \n    penalty_collision = -25 if (d_agent_entrance < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: It must avoid colliding with fire alarm panel. Assumptions: The states of the drone, goal and the fire alarm panel's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_alarm_system, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_alarm_system = calculate_distance_min(s_agent, s_alarm_system) \n    penalty_collision = -25 if (d_agent_alarm_system < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: It must avoid colliding with help desk, assignment drop box and faculty member. Assumptions: The Agent's state, goal's state and multiple obstacle's state: help desk, assignment drop box and faculty member are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: Detect building entrance, notice board and overhead light and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: building entrance, notice board and overhead light state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along supply store. \n Objectives: It must avoid colliding with checkout counter or storage shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the checkout counter and the storage shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy supply store. \n Objectives: Detect promo display and aviod it. \n Conditions: The states of the agent, goal, the promo display are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display = calculate_distance_min(s_agent, s_display) \n    penalty_collision = -25 if (d_agent_display < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a supply store. Objectives: It must avoid colliding with shopper. Conditions: States of the drone and the shopper are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shopper, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shopper = calculate_distance_min(s_agent, s_shopper) \n    penalty_collision = -25 if (d_agent_shopper < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a supply store, the drone must maneuver around cash register. All entity states (agent, goal, cash register) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_cash_register, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cash_register = calculate_distance_min(s_agent, s_cash_register) \n    penalty_collision = -25 if (d_agent_cash_register < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a supply store. Requirement: Detect the three price scanner and do not collide with it. Given: The states for the drone and multiple price scanner are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a supply store. \n Objectives: So not collide with supply box. \n Conditions: The states of the agent, goal, the supply box are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_supply_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_supply_box = calculate_distance_min(s_agent, s_supply_box) \n    penalty_collision = -25 if (d_agent_supply_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate supply store. Objectives: Do not collide hit with the customer service desk. Conditions: States of the agent, customer service desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_service_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_service_desk = calculate_distance_min(s_agent, s_service_desk) \n    penalty_collision = -25 if (d_agent_service_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a supply store, the drone must steer clear of shopper. All states (agent, goal, shopper) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_shopper, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shopper = calculate_distance_min(s_agent, s_shopper) \n    penalty_collision = -25 if (d_agent_shopper < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: supply store. Avoid: Detect supply box and do not hitting with paket. Known: Agent, goal, paket states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_paket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paket = calculate_distance_min(s_agent, s_paket) \n    penalty_collision = -25 if (d_agent_paket < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating supply store. Objectives: It must avoid colliding with checkout counter. Conditions: The states of the drone, goal and checkout counter are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_checkout_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_checkout_counter = calculate_distance_min(s_agent, s_checkout_counter) \n    penalty_collision = -25 if (d_agent_checkout_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through supply store. Objectives: Avoid collision with checkout revolving store entrance, checkout counter and storage shelf. Conditions: The states of the agent and of the multiple obstacles: checkout revolving store entrance, checkout counter and storage shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating supply store. Objectives: It must avoid colliding with any supply box, supply store store entrance. Conditions: Agent's and of the multiple obstacle: supply box, supply store store entrance states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through supply store. Objectives: Do not collide with promo display. Conditions: The states of the drone, goal and the promo display are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display = calculate_distance_min(s_agent, s_display) \n    penalty = -25 if (d_agent_display < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along supply store and must avoid contact with the payment maschine. The states of the drone, goal and the payment maschine are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_payment_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_payment_maschine = calculate_distance_min(s_agent, s_payment_maschine) \n    penalty = -25 if (d_agent_payment_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in supply store. It must avoid colliding with the supply box, payment terminal and worker. The states of the agent and of the multiple obstacle: supply box, payment terminal and worker are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in supply store. It must avoid colliding with the payment terminal and supply box. The states of the drone, goal and of the multiple obstacle: the payment terminal and supply box are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in supply store. It must avoid colliding with the tool. Agent's state, goal's state and tool's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool = calculate_distance_min(s_agent, s_tool) \n    penalty_collision = -25 if (d_agent_tool < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: It must avoid colliding with forklift. Assumptions: The states of the drone, goal and the forklift's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -25 if (d_agent_forklift < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: It must avoid colliding with customer service desk, forklift and worker. Assumptions: The Agent's state, goal's state and multiple obstacle's state: customer service desk, forklift and worker are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: Detect store entrance, promo display and light and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: store entrance, promo display and light state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along art supply store. \n Objectives: It must avoid colliding with paint mixing station or drying rack. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the paint mixing station and the drying rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy art supply store. \n Objectives: Detect brush rack and aviod it. \n Conditions: The states of the agent, goal, the brush rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_brush_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_brush_rack = calculate_distance_min(s_agent, s_brush_rack) \n    penalty_collision = -25 if (d_agent_brush_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a art supply store. Objectives: It must avoid colliding with store artist. Conditions: States of the drone and the store artist are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_store_artist, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_store_artist = calculate_distance_min(s_agent, s_store_artist) \n    penalty_collision = -25 if (d_agent_store_artist < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a art supply store, the drone must maneuver around framing station. All entity states (agent, goal, framing station) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_framing_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_framing_station = calculate_distance_min(s_agent, s_framing_station) \n    penalty_collision = -25 if (d_agent_framing_station < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a art supply store. Requirement: Detect the three paper cutter and do not collide with it. Given: The states for the drone and multiple paper cutter are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a art supply store. \n Objectives: So not collide with clay bag. \n Conditions: The states of the agent, goal, the clay bag are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_clay_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clay_bag = calculate_distance_min(s_agent, s_clay_bag) \n    penalty_collision = -25 if (d_agent_clay_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate art supply store. Objectives: Do not collide hit with the color palette counter. Conditions: States of the agent, color palette counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_palette_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_palette_counter = calculate_distance_min(s_agent, s_palette_counter) \n    penalty_collision = -25 if (d_agent_palette_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a art supply store, the drone must steer clear of store artist. All states (agent, goal, store artist) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_store_artist, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_store_artist = calculate_distance_min(s_agent, s_store_artist) \n    penalty_collision = -25 if (d_agent_store_artist < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: art supply store. Avoid: Detect clay bag and do not hitting with clay bag. Known: Agent, goal, clay bag states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cash_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cash_bag = calculate_distance_min(s_agent, s_cash_bag) \n    penalty_collision = -25 if (d_agent_cash_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating art supply store. Objectives: It must avoid colliding with paint station. Conditions: The states of the drone, goal and paint station are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_paint_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paint_station = calculate_distance_min(s_agent, s_paint_station) \n    penalty_collision = -25 if (d_agent_paint_station < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through art supply store. Objectives: Avoid collision with paint bucket, paint station and drying rack. Conditions: The states of the agent and of the multiple obstacles: paint bucket, paint station and drying rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating art supply store. Objectives: It must avoid colliding with any clay bag, art supply store loading bay. Conditions: Agent's and of the multiple obstacle: clay bag, staff states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through art supply store. Objectives: Do not collide with kiln. Conditions: The states of the drone, goal and the kiln are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kiln, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kiln = calculate_distance_min(s_agent, s_kiln) \n    penalty = -25 if (d_agent_kiln < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along art supply store and must avoid contact with the 3D printer. The states of the drone, goal and the 3D printer are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_3D_printer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_3D_printer = calculate_distance_min(s_agent, s_3D_printer) \n    penalty = -25 if (d_agent_3D_printer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in art supply store. It must avoid colliding with the clay bag, 3D printer and kiln. The states of the agent and of the multiple obstacle: clay bag, 3D printer and kiln are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in art supply store. It must avoid colliding with the 3D printer and clay bag. The states of the drone, goal and of the multiple obstacle: the 3D printer and clay bag are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in art supply store. It must avoid colliding with the AC. Agent's state, goal's state and AC's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_AC, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_AC = calculate_distance_min(s_agent, s_AC) \n    penalty_collision = -25 if (d_agent_AC < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: It must avoid colliding with ventilation unit. Assumptions: The states of the drone, goal and the ventilation unit's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_ventilation, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ventilation = calculate_distance_min(s_agent, s_ventilation) \n    penalty_collision = -25 if (d_agent_ventilation < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: It must avoid colliding with color palette counter, supply return bin and store artist. Assumptions: The Agent's state, goal's state and multiple obstacle's state: color palette, supply tools and store artist are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: Detect loading bay, brush rack and hanging spotlight and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: brushes, brush rack and hanging spotlight state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along meeting room. \n Objectives: It must avoid colliding with conference table or whiteboard. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the conference table and the whiteboard are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy meeting room. \n Objectives: Detect projector stand and aviod it. \n Conditions: The states of the agent, goal, the projector stand are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_projector_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector_stand = calculate_distance_min(s_agent, s_projector_stand) \n    penalty_collision = -25 if (d_agent_projector_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a meeting room. Objectives: It must avoid colliding with attendee. Conditions: States of the drone and the attendee are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_attendee, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_attendee = calculate_distance_min(s_agent, s_attendee) \n    penalty_collision = -25 if (d_agent_attendee < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a meeting room, the drone must maneuver around podium. All entity states (agent, goal, podium) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_podium, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_podium = calculate_distance_min(s_agent, s_podium) \n    penalty_collision = -25 if (d_agent_podium < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a meeting room. Requirement: Detect the three coffee machine and do not collide with it. Given: The states for the drone and multiple coffee machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a meeting room. \n Objectives: So not collide with laptop bag. \n Conditions: The states of the agent, goal, the laptop bag are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_laptop_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop_bag = calculate_distance_min(s_agent, s_laptop_bag) \n    penalty_collision = -25 if (d_agent_laptop_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate meeting room. Objectives: Do not collide hit with the reception desk. Conditions: States of the agent, reception desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_reception_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception_desk = calculate_distance_min(s_agent, s_reception_desk) \n    penalty_collision = -25 if (d_agent_reception_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a meeting room, the drone must steer clear of attendee. All states (agent, goal, attendee) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_attendee, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_attendee = calculate_distance_min(s_agent, s_attendee) \n    penalty_collision = -25 if (d_agent_attendee < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: meeting room. Avoid: Detect laptop and do not hitting with laptop bag. Known: Agent, goal, laptop states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -25 if (d_agent_laptop < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating meeting room. Objectives: It must avoid colliding with conference table. Conditions: The states of the drone, goal and conference table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_conference_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_conference_table = calculate_distance_min(s_agent, s_conference_table) \n    penalty_collision = -25 if (d_agent_conference_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through meeting room. Objectives: Avoid collision with checkout revolving meeting room door, conference table and whiteboard. Conditions: The states of the agent and of the multiple obstacles: meeting room door, conference table and whiteboard are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating meeting room. Objectives: It must avoid colliding with any laptop bag, room door. Conditions: Agent's and of the multiple obstacle: laptop bag, room door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through meeting room. Objectives: Do not collide with coffee maschine. Conditions: The states of the drone, goal and the coffee maschine are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_maschine = calculate_distance_min(s_agent, s_coffee_maschine) \n    penalty = -25 if (d_agent_coffee_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along meeting room and must avoid contact with the video conferencing unit. The states of the drone, goal and the video camera. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_video_camera, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_video_camera = calculate_distance_min(s_agent, s_video_camera) \n    penalty = -25 if (d_agent_video_camera < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in meeting room. It must avoid colliding with the laptop bag, video conferencing unit and attendee. The states of the agent and of the multiple obstacle: laptop bag, video conferencing unit and attendee are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in meeting room. It must avoid colliding with the video conferencing unit and laptop bag. The states of the drone, goal and of the multiple obstacle: the video conferencing unit and laptop bag are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in meeting room. It must avoid colliding with the meeting room door. Agent's state, goal's state and meeting room door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s__door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent__door = calculate_distance_min(s_agent, s__door) \n    penalty_collision = -25 if (d_agent__door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: It must avoid colliding with air conditioner. Assumptions: The states of the drone, goal and the air conditioner's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_air_conditioner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_air_conditioner = calculate_distance_min(s_agent, s_air_conditioner) \n    penalty_collision = -25 if (d_agent_air_conditioner < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: It must avoid colliding with reception desk, document tray and attendee. Assumptions: The Agent's state, goal's state and multiple obstacle's state: reception desk, document tray and attendee are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: Detect meeting room door, projector stand and ceiling projector and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: meeting room door, projector stand and ceiling projector state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*4 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a Science Museum.\n Objectives: It must avoid colliding with a glass display case.\n Conditions: The states of the agent and the glass display case are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_glass_display_case, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_display_case = calculate_distance_min(s_agent, s_glass_display_case) \n    penalty_collision = -25 if (d_agent_glass_display_case < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating the atrium of a Science Museum.\n Objectives: Avoid the Foucault pendulum.\n Conditions: States of the drone and pendulum bob are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_pendulum, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pendulum = calculate_distance_min(s_agent, s_pendulum) \n    penalty_collision = -30 if (d_agent_pendulum < 1.0) else 15 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through the technology wing of a Science Museum.\nRequirement: Detect the interactive kiosk and do not collide with it.\n Given: The states for the drone and the kiosk are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_kiosk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kiosk = calculate_distance_min(s_agent, s_kiosk) \n    penalty_collision = -25 if (d_agent_kiosk < 0.7) else 15 \n    reward_reaching_goal = 26 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Science Museum gallery, the drone must steer clear of rope stanchions used for crowd control.\n All states (agent, goal, rope) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -22 if (d_agent_rope < 0.6) else 12 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Science Museum.\n Objectives: It must avoid colliding with the suspended aircraft exhibit wing.\n Conditions: The states of the drone, goal and the aircraft wing are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_aircraft_wing, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_aircraft_wingg = calculate_distance_min(s_agent, s_aircraft_wing) \n    penalty_collision = -35 if (d_agent_aircraft_wingg < 0.9) else 15 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating near the planetarium entrance of a Science Museum.\n Objectives: Do not enter the projector beam path.\n Conditions: The states of the agent and the projector beam volume are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_projector_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_projector_beam) \n    penalty_collision = -28 if (d_agent_beam < 0.8) else 10\n    reward_reaching_goal = 27 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is inspecting a Science Museum lab demo area.\n Goal: Avoid the Tesla coil safety cage.\n Assumptions: The states of the drone, goal and the Tesla coil cage are known. Implement a Python reward function.",
        "chosen": "def reward(s_agent, s_cage, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cage = calculate_distance_min(s_agent, s_cage) \n    penalty_collision = -30 if (d_agent_cage < 0.8) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: Science Museum. Avoid: Detect the rotating solar system model and do not collide with it.\n Known: Agent and rotating model states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_rotating_model, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rotating_model = calculate_distance_min(s_agent, s_rotating_model) \n    penalty_collision = -27 if (d_agent_rotating_model < 0.8) else 14\n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Science Museum hallway.\n Objectives: It must avoid colliding with the autonomous floor scrubber robot.\n Conditions: The states of the drone, goal and the scrubber are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_floor_scrubber_robot, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_robot = calculate_distance_min(s_agent, s_floor_scrubber_robot) \n    penalty_collision = -25 if (d_agent_robot < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Science Museum space.\n Objectives: Avoid collision with multiple 3D printer enclosures.\n Conditions: The states of the agent and of the multiple obstacles (3D printer enclosures) are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 24 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Science Museum, the drone must maneuver around the hologram display pedestal.\n All entity states (agent, goal, hologram pedestal) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_hologram_pedestal, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pedestal = calculate_distance_min(s_agent, s_hologram_pedestal) \n    penalty_collision = -23 if (d_agent_pedestal < 0.6) else 12 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Science Museum stairwell.\n Goal: Do not collide with the escalator handrail region.\n Assumptions: The Agent's state, goal's state and the escalator handrail volume state are known. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_escalator_handrail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_handrail = calculate_distance_min(s_agent, s_escalator_handrail) \n    penalty_collision = -26 if (d_agent_handrail < 0.7) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates inside a Science Museum ocean hall.\n Objectives: Do not collide with the suspended whale skeleton.\n Conditions: The states of the agent and the whale skeleton are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_whale_skeleton, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_skeleton = calculate_distance_min(s_agent, s_whale_skeleton) \n    penalty_collision = -34 if (d_agent_skeleton < 0.9) else 15 \n    reward_reaching_goal = 31 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying near the VR demo zone in a Science Museum.\nRequirement: Detect the tethered headset cable and avoid it.\n Given: The states for the drone and the cable are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -21 if (d_agent_cable < 0.5) else 10\n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating the Science Museum innovation gallery.\n Goal: It must avoid colliding with the magnetic levitation track.\n Assumptions: The states of the drone, goal and the maglev track are available. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_maglev_track, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_track = calculate_distance_min(s_agent, s_maglev_track) \n    penalty_collision = -24 if (d_agent_track < 0.7) else 14\n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is exploring the Science Museum fossil hall.\n Objective: Avoid collision with the large dinosaur skeleton tail.\n Conditions: The states of the drone, goal and the skeleton are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_skeleton, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_skeleton = calculate_distance_min(s_agent, s_skeleton) \n    penalty_collision = -33 if (d_agent_skeleton < 0.8) else 15\n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -d_agent_goal*c_1\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating the Science Museum optics exhibit.\n Objective: Avoid the rotating mirror array.\n Conditions: Agent and mirror states are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_mirror, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mirror = calculate_distance_min(s_agent, s_mirror) \n    penalty_collision = -28 if (d_agent_mirror < 0.7) else 12\n    reward_reaching_goal = 27 if (d_agent_goal < 0.2) else -d_agent_goal*c_1\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying inside the Science Museum energy gallery.\n Requirement: Avoid colliding with the spinning wind turbine model.\n Given: States for the drone and the turbine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_turbine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_turbine = calculate_distance_min(s_agent, s_turbine) \n    penalty_collision = -32 if (d_agent_turbine < 1.0) else 14\n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: A drone is operating in the Science Museum chemistry wing.\n Goal: It must avoid flying into the mist zone of the liquid nitrogen demo.\n Assumptions: The states of the drone, goal and mist cloud are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_mist_zone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mist = calculate_distance_min(s_agent, s_mist_zone) \n    penalty_collision = -20 if (d_agent_mist < 0.6) else 10\n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -d_agent_goal*c_1\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Science Museum.\n Goal: Drone goal is to reach the charging dock goal.\n Assumptions: The states of the drone, goal and the charging dock are known. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along cellar. \n Objectives: It must avoid colliding with wine rack or barrel. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the wine rack and the barrel are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy cellar. \n Objectives: Detect support beam and aviod it. \n Conditions: The states of the agent, goal, the beam are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -25 if (d_agent_beam < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a cellar. Objectives: It must avoid colliding with cellar worker. Conditions: States of the drone and the cellar worker are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cellar_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cellar_worker = calculate_distance_min(s_agent, s_cellar_worker) \n    penalty_collision = -25 if (d_agent_cellar_worker < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a cellar, the drone must maneuver around tool bench. All entity states (agent, goal, tool bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_tool_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool_bench = calculate_distance_min(s_agent, s_tool_bench) \n    penalty_collision = -25 if (d_agent_tool_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a cellar. Requirement: Detect the three old machinery and do not collide with it. Given: The states for the drone and multiple old machinery are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a cellar. \n Objectives: So not collide with wooden crate. \n Conditions: The states of the agent, goal, the wooden crate are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_wooden_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wooden_crate = calculate_distance_min(s_agent, s_wooden_crate) \n    penalty_collision = -25 if (d_agent_wooden_crate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate cellar. Objectives: Do not collide hit with the storage table. Conditions: States of the agent, storage table are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_storage_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_table = calculate_distance_min(s_agent, s_storage_table) \n    penalty_collision = -25 if (d_agent_storage_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a cellar, the drone must steer clear of cellar worker. All states (agent, goal, cellar worker) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_cellar_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cellar_worker = calculate_distance_min(s_agent, s_cellar_worker) \n    penalty_collision = -25 if (d_agent_cellar_worker < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: cellar. Avoid: Detect wooden crate and do not hitting with wooden crate. Known: Agent, goal, wooden crate states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_wooden_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wooden_crate = calculate_distance_min(s_agent, s_wooden_crate) \n    penalty_collision = -25 if (d_agent_wooden_crate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating cellar. Objectives: It must avoid colliding with wine rack. Conditions: The states of the drone, goal and wine rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wine_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wine_rack = calculate_distance_min(s_agent, s_wine_rack) \n    penalty_collision = -25 if (d_agent_wine_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through cellar. Objectives: Avoid collision with checkout revolving cellar door, wine rack and barrel. Conditions: The states of the agent and of the multiple obstacles: cellar door, wine rack and barrel are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating cellar. Objectives: It must avoid colliding with any wooden crate, cellar cellar door. Conditions: Agent's and of the multiple obstacle: wooden crate, cellar cellar door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through cellar. Objectives: Do not collide with support beam. Conditions: The states of the drone, goal and the support beam are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_beam) \n    penalty = -25 if (d_agent_beam < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along cellar and must avoid contact with the wine press. The states of the drone, goal and the wine press are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_wine_press, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wine_press = calculate_distance_min(s_agent, s_wine_press) \n    penalty = -25 if (d_agent_wine_press < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in cellar. It must avoid colliding with the wooden crate, wine press and cellar worker. The states of the agent and of the multiple obstacle: wooden crate, wine press and cellar worker are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in cellar. It must avoid colliding with the wine press and wooden crate. The states of the drone, goal and of the multiple obstacle: the wine press and wooden crate are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in cellar. It must avoid colliding with the cellar door. Agent's state, goal's state and cellar door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cellar_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cellar_door = calculate_distance_min(s_agent, s_cellar_door) \n    penalty_collision = -25 if (d_agent_cellar_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: It must avoid colliding with moisture sensor. Assumptions: The states of the drone, goal and the moisture sensor's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_sensor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sensor = calculate_distance_min(s_agent, s_sensor) \n    penalty_collision = -25 if (d_agent_sensor < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: It must avoid colliding with storage table, storage box and cellar worker. Assumptions: The Agent's state, goal's state and multiple obstacle's state: storage table, storage box and cellar worker are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: Detect cellar door, support beam and hanging lamp and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: cellar door, support beam and hanging lamp state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along university. \n Objectives: It must avoid colliding with reception desk or supply shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the reception desk and the supply shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy university. \n Objectives: Detect notice board and aviod it. \n Conditions: The states of the agent, goal, the notice board are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_notice_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_notice_board = calculate_distance_min(s_agent, s_notice_board) \n    penalty_collision = -25 if (d_agent_notice_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a university. Objectives: It must avoid colliding with student. Conditions: States of the drone and the student are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -25 if (d_agent_student < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a university, the drone must maneuver around projector. All entity states (agent, goal, projector) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -25 if (d_agent_projector < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a university. Requirement: Detect the three kiosk and do not collide with it. Given: The states for the drone and multiple kiosks are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a university. \n Objectives: So not collide with backpack. \n Conditions: The states of the agent, goal, the backpack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -25 if (d_agent_backpack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate university. Objectives: Do not collide hit with the help desk. Conditions: States of the agent, help desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_help_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_help_desk = calculate_distance_min(s_agent, s_help_desk) \n    penalty_collision = -25 if (d_agent_help_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a university, the drone must steer clear of professor. All states (agent, goal, professor) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_professor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_professor = calculate_distance_min(s_agent, s_professor) \n    penalty_collision = -25 if (d_agent_professor < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: university. Avoid: Detect pipe and do not hitting with pipe. Known: Agent, goal, pipe states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -25 if (d_agent_pipe < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating university. Objectives: It must avoid colliding with reception desk. Conditions: The states of the drone, goal and reception desk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_reception_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception_desk = calculate_distance_min(s_agent, s_reception_desk) \n    penalty_collision = -25 if (d_agent_reception_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through university. Objectives: Avoid collision with entrance door, reception desk and shelf. Conditions: The states of the agent and of the multiple obstacles: entrance door, reception desk and shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating university. Objectives: It must avoid colliding with any backpack, university entrance. Conditions: Agent's and of the multiple obstacle: backpack, university entrance states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through university. Objectives: Do not collide with notice board. Conditions: The states of the drone, goal and the notice board are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_notice_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_notice_board = calculate_distance_min(s_agent, s_notice_board) \n    penalty = -25 if (d_agent_notice_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along university and must avoid contact with the vending machine. The states of the drone, goal and the vending machine are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_vending machine_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vending machine_maschine = calculate_distance_min(s_agent, s_vending machine_maschine) \n    penalty = -25 if (d_agent_vending machine_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in university. It must avoid colliding with the backpack, vending machine and faculty member. The states of the agent and of the multiple obstacle: backpack, vending machine and faculty member are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in university. It must avoid colliding with the vending machine and backpack. The states of the drone, goal and of the multiple obstacle: the vending machine and backpack are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in university. It must avoid colliding with the vault building entrance. Agent's state, goal's state and vault building entrancen's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_entrance, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_entrance = calculate_distance_min(s_agent, s_entrance) \n    penalty_collision = -25 if (d_agent_entrance < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: It must avoid colliding with fire alarm panel. Assumptions: The states of the drone, goal and the fire alarm panel's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_alarm_system, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_alarm_system = calculate_distance_min(s_agent, s_alarm_system) \n    penalty_collision = -25 if (d_agent_alarm_system < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: It must avoid colliding with help desk, assignment drop box and faculty member. Assumptions: The Agent's state, goal's state and multiple obstacle's state: help desk, assignment drop box and faculty member are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: Detect building entrance, notice board and overhead light and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: building entrance, notice board and overhead light state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along supply store. \n Objectives: It must avoid colliding with checkout counter or storage shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the checkout counter and the storage shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy supply store. \n Objectives: Detect promo display and aviod it. \n Conditions: The states of the agent, goal, the promo display are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display = calculate_distance_min(s_agent, s_display) \n    penalty_collision = -25 if (d_agent_display < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a supply store. Objectives: It must avoid colliding with shopper. Conditions: States of the drone and the shopper are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shopper, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shopper = calculate_distance_min(s_agent, s_shopper) \n    penalty_collision = -25 if (d_agent_shopper < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a supply store, the drone must maneuver around cash register. All entity states (agent, goal, cash register) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_cash_register, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cash_register = calculate_distance_min(s_agent, s_cash_register) \n    penalty_collision = -25 if (d_agent_cash_register < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a supply store. Requirement: Detect the three price scanner and do not collide with it. Given: The states for the drone and multiple price scanner are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a supply store. \n Objectives: So not collide with supply box. \n Conditions: The states of the agent, goal, the supply box are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_supply_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_supply_box = calculate_distance_min(s_agent, s_supply_box) \n    penalty_collision = -25 if (d_agent_supply_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate supply store. Objectives: Do not collide hit with the customer service desk. Conditions: States of the agent, customer service desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_service_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_service_desk = calculate_distance_min(s_agent, s_service_desk) \n    penalty_collision = -25 if (d_agent_service_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a supply store, the drone must steer clear of shopper. All states (agent, goal, shopper) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_shopper, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shopper = calculate_distance_min(s_agent, s_shopper) \n    penalty_collision = -25 if (d_agent_shopper < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: supply store. Avoid: Detect supply box and do not hitting with paket. Known: Agent, goal, paket states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_paket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paket = calculate_distance_min(s_agent, s_paket) \n    penalty_collision = -25 if (d_agent_paket < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating supply store. Objectives: It must avoid colliding with checkout counter. Conditions: The states of the drone, goal and checkout counter are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_checkout_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_checkout_counter = calculate_distance_min(s_agent, s_checkout_counter) \n    penalty_collision = -25 if (d_agent_checkout_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through supply store. Objectives: Avoid collision with checkout revolving store entrance, checkout counter and storage shelf. Conditions: The states of the agent and of the multiple obstacles: checkout revolving store entrance, checkout counter and storage shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating supply store. Objectives: It must avoid colliding with any supply box, supply store store entrance. Conditions: Agent's and of the multiple obstacle: supply box, supply store store entrance states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through supply store. Objectives: Do not collide with promo display. Conditions: The states of the drone, goal and the promo display are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display = calculate_distance_min(s_agent, s_display) \n    penalty = -25 if (d_agent_display < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along supply store and must avoid contact with the payment maschine. The states of the drone, goal and the payment maschine are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_payment_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_payment_maschine = calculate_distance_min(s_agent, s_payment_maschine) \n    penalty = -25 if (d_agent_payment_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in supply store. It must avoid colliding with the supply box, payment terminal and worker. The states of the agent and of the multiple obstacle: supply box, payment terminal and worker are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in supply store. It must avoid colliding with the payment terminal and supply box. The states of the drone, goal and of the multiple obstacle: the payment terminal and supply box are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in supply store. It must avoid colliding with the tool. Agent's state, goal's state and tool's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool = calculate_distance_min(s_agent, s_tool) \n    penalty_collision = -25 if (d_agent_tool < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: It must avoid colliding with forklift. Assumptions: The states of the drone, goal and the forklift's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -25 if (d_agent_forklift < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: It must avoid colliding with customer service desk, forklift and worker. Assumptions: The Agent's state, goal's state and multiple obstacle's state: customer service desk, forklift and worker are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: Detect store entrance, promo display and light and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: store entrance, promo display and light state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along art supply store. \n Objectives: It must avoid colliding with paint mixing station or drying rack. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the paint mixing station and the drying rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy art supply store. \n Objectives: Detect brush rack and aviod it. \n Conditions: The states of the agent, goal, the brush rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_brush_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_brush_rack = calculate_distance_min(s_agent, s_brush_rack) \n    penalty_collision = -25 if (d_agent_brush_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a art supply store. Objectives: It must avoid colliding with store artist. Conditions: States of the drone and the store artist are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_store_artist, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_store_artist = calculate_distance_min(s_agent, s_store_artist) \n    penalty_collision = -25 if (d_agent_store_artist < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a art supply store, the drone must maneuver around framing station. All entity states (agent, goal, framing station) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_framing_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_framing_station = calculate_distance_min(s_agent, s_framing_station) \n    penalty_collision = -25 if (d_agent_framing_station < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a art supply store. Requirement: Detect the three paper cutter and do not collide with it. Given: The states for the drone and multiple paper cutter are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a art supply store. \n Objectives: So not collide with clay bag. \n Conditions: The states of the agent, goal, the clay bag are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_clay_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clay_bag = calculate_distance_min(s_agent, s_clay_bag) \n    penalty_collision = -25 if (d_agent_clay_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate art supply store. Objectives: Do not collide hit with the color palette counter. Conditions: States of the agent, color palette counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_palette_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_palette_counter = calculate_distance_min(s_agent, s_palette_counter) \n    penalty_collision = -25 if (d_agent_palette_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a art supply store, the drone must steer clear of store artist. All states (agent, goal, store artist) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_store_artist, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_store_artist = calculate_distance_min(s_agent, s_store_artist) \n    penalty_collision = -25 if (d_agent_store_artist < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: art supply store. Avoid: Detect clay bag and do not hitting with clay bag. Known: Agent, goal, clay bag states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cash_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cash_bag = calculate_distance_min(s_agent, s_cash_bag) \n    penalty_collision = -25 if (d_agent_cash_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating art supply store. Objectives: It must avoid colliding with paint station. Conditions: The states of the drone, goal and paint station are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_paint_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paint_station = calculate_distance_min(s_agent, s_paint_station) \n    penalty_collision = -25 if (d_agent_paint_station < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through art supply store. Objectives: Avoid collision with paint bucket, paint station and drying rack. Conditions: The states of the agent and of the multiple obstacles: paint bucket, paint station and drying rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating art supply store. Objectives: It must avoid colliding with any clay bag, art supply store loading bay. Conditions: Agent's and of the multiple obstacle: clay bag, staff states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through art supply store. Objectives: Do not collide with kiln. Conditions: The states of the drone, goal and the kiln are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kiln, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kiln = calculate_distance_min(s_agent, s_kiln) \n    penalty = -25 if (d_agent_kiln < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along art supply store and must avoid contact with the 3D printer. The states of the drone, goal and the 3D printer are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_3D_printer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_3D_printer = calculate_distance_min(s_agent, s_3D_printer) \n    penalty = -25 if (d_agent_3D_printer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in art supply store. It must avoid colliding with the clay bag, 3D printer and kiln. The states of the agent and of the multiple obstacle: clay bag, 3D printer and kiln are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in art supply store. It must avoid colliding with the 3D printer and clay bag. The states of the drone, goal and of the multiple obstacle: the 3D printer and clay bag are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in art supply store. It must avoid colliding with the AC. Agent's state, goal's state and AC's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_AC, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_AC = calculate_distance_min(s_agent, s_AC) \n    penalty_collision = -25 if (d_agent_AC < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: It must avoid colliding with ventilation unit. Assumptions: The states of the drone, goal and the ventilation unit's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_ventilation, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ventilation = calculate_distance_min(s_agent, s_ventilation) \n    penalty_collision = -25 if (d_agent_ventilation < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: It must avoid colliding with color palette counter, supply return bin and store artist. Assumptions: The Agent's state, goal's state and multiple obstacle's state: color palette, supply tools and store artist are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: Detect loading bay, brush rack and hanging spotlight and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: brushes, brush rack and hanging spotlight state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along meeting room. \n Objectives: It must avoid colliding with conference table or whiteboard. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the conference table and the whiteboard are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy meeting room. \n Objectives: Detect projector stand and aviod it. \n Conditions: The states of the agent, goal, the projector stand are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_projector_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector_stand = calculate_distance_min(s_agent, s_projector_stand) \n    penalty_collision = -25 if (d_agent_projector_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a meeting room. Objectives: It must avoid colliding with attendee. Conditions: States of the drone and the attendee are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_attendee, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_attendee = calculate_distance_min(s_agent, s_attendee) \n    penalty_collision = -25 if (d_agent_attendee < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a meeting room, the drone must maneuver around podium. All entity states (agent, goal, podium) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_podium, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_podium = calculate_distance_min(s_agent, s_podium) \n    penalty_collision = -25 if (d_agent_podium < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a meeting room. Requirement: Detect the three coffee machine and do not collide with it. Given: The states for the drone and multiple coffee machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a meeting room. \n Objectives: So not collide with laptop bag. \n Conditions: The states of the agent, goal, the laptop bag are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_laptop_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop_bag = calculate_distance_min(s_agent, s_laptop_bag) \n    penalty_collision = -25 if (d_agent_laptop_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate meeting room. Objectives: Do not collide hit with the reception desk. Conditions: States of the agent, reception desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_reception_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception_desk = calculate_distance_min(s_agent, s_reception_desk) \n    penalty_collision = -25 if (d_agent_reception_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a meeting room, the drone must steer clear of attendee. All states (agent, goal, attendee) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_attendee, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_attendee = calculate_distance_min(s_agent, s_attendee) \n    penalty_collision = -25 if (d_agent_attendee < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: meeting room. Avoid: Detect laptop and do not hitting with laptop bag. Known: Agent, goal, laptop states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -25 if (d_agent_laptop < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating meeting room. Objectives: It must avoid colliding with conference table. Conditions: The states of the drone, goal and conference table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_conference_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_conference_table = calculate_distance_min(s_agent, s_conference_table) \n    penalty_collision = -25 if (d_agent_conference_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through meeting room. Objectives: Avoid collision with checkout revolving meeting room door, conference table and whiteboard. Conditions: The states of the agent and of the multiple obstacles: meeting room door, conference table and whiteboard are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating meeting room. Objectives: It must avoid colliding with any laptop bag, room door. Conditions: Agent's and of the multiple obstacle: laptop bag, room door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through meeting room. Objectives: Do not collide with coffee maschine. Conditions: The states of the drone, goal and the coffee maschine are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_maschine = calculate_distance_min(s_agent, s_coffee_maschine) \n    penalty = -25 if (d_agent_coffee_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along meeting room and must avoid contact with the video conferencing unit. The states of the drone, goal and the video camera. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_video_camera, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_video_camera = calculate_distance_min(s_agent, s_video_camera) \n    penalty = -25 if (d_agent_video_camera < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in meeting room. It must avoid colliding with the laptop bag, video conferencing unit and attendee. The states of the agent and of the multiple obstacle: laptop bag, video conferencing unit and attendee are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in meeting room. It must avoid colliding with the video conferencing unit and laptop bag. The states of the drone, goal and of the multiple obstacle: the video conferencing unit and laptop bag are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in meeting room. It must avoid colliding with the meeting room door. Agent's state, goal's state and meeting room door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s__door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent__door = calculate_distance_min(s_agent, s__door) \n    penalty_collision = -25 if (d_agent__door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: It must avoid colliding with air conditioner. Assumptions: The states of the drone, goal and the air conditioner's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_air_conditioner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_air_conditioner = calculate_distance_min(s_agent, s_air_conditioner) \n    penalty_collision = -25 if (d_agent_air_conditioner < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: It must avoid colliding with reception desk, document tray and attendee. Assumptions: The Agent's state, goal's state and multiple obstacle's state: reception desk, document tray and attendee are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: Detect meeting room door, projector stand and ceiling projector and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: meeting room door, projector stand and ceiling projector state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal*c_1 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a Science Museum.\n Objectives: It must avoid colliding with a glass display case.\n Conditions: The states of the agent and the glass display case are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_glass_display_case, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_display_case = calculate_distance_min(s_agent, s_glass_display_case) \n    penalty_collision = -25 if (d_agent_glass_display_case < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating the atrium of a Science Museum.\n Objectives: Avoid the Foucault pendulum.\n Conditions: States of the drone and pendulum bob are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_pendulum, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pendulum = calculate_distance_min(s_agent, s_pendulum) \n    penalty_collision = -30 if (d_agent_pendulum < 1.0) else 15 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through the technology wing of a Science Museum.\nRequirement: Detect the interactive kiosk and do not collide with it.\n Given: The states for the drone and the kiosk are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_kiosk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kiosk = calculate_distance_min(s_agent, s_kiosk) \n    penalty_collision = -25 if (d_agent_kiosk < 0.7) else 15 \n    reward_reaching_goal = 26 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a Science Museum gallery, the drone must steer clear of rope stanchions used for crowd control.\n All states (agent, goal, rope) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -22 if (d_agent_rope < 0.6) else 12 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Science Museum.\n Objectives: It must avoid colliding with the suspended aircraft exhibit wing.\n Conditions: The states of the drone, goal and the aircraft wing are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_aircraft_wing, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_aircraft_wingg = calculate_distance_min(s_agent, s_aircraft_wing) \n    penalty_collision = -35 if (d_agent_aircraft_wingg < 0.9) else 15 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating near the planetarium entrance of a Science Museum.\n Objectives: Do not enter the projector beam path.\n Conditions: The states of the agent and the projector beam volume are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_projector_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_projector_beam) \n    penalty_collision = -28 if (d_agent_beam < 0.8) else 10\n    reward_reaching_goal = 27 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is inspecting a Science Museum lab demo area.\n Goal: Avoid the Tesla coil safety cage.\n Assumptions: The states of the drone, goal and the Tesla coil cage are known. Implement a Python reward function.",
        "chosen": "def reward(s_agent, s_cage, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cage = calculate_distance_min(s_agent, s_cage) \n    penalty_collision = -30 if (d_agent_cage < 0.8) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: Science Museum. Avoid: Detect the rotating solar system model and do not collide with it.\n Known: Agent and rotating model states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_rotating_model, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rotating_model = calculate_distance_min(s_agent, s_rotating_model) \n    penalty_collision = -27 if (d_agent_rotating_model < 0.8) else 14\n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating a Science Museum hallway.\n Objectives: It must avoid colliding with the autonomous floor scrubber robot.\n Conditions: The states of the drone, goal and the scrubber are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_floor_scrubber_robot, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_robot = calculate_distance_min(s_agent, s_floor_scrubber_robot) \n    penalty_collision = -25 if (d_agent_robot < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through a Science Museum space.\n Objectives: Avoid collision with multiple 3D printer enclosures.\n Conditions: The states of the agent and of the multiple obstacles (3D printer enclosures) are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 24 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a Science Museum, the drone must maneuver around the hologram display pedestal.\n All entity states (agent, goal, hologram pedestal) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_hologram_pedestal, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pedestal = calculate_distance_min(s_agent, s_hologram_pedestal) \n    penalty_collision = -23 if (d_agent_pedestal < 0.6) else 12 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Science Museum stairwell.\n Goal: Do not collide with the escalator handrail region.\n Assumptions: The Agent's state, goal's state and the escalator handrail volume state are known. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_escalator_handrail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_handrail = calculate_distance_min(s_agent, s_escalator_handrail) \n    penalty_collision = -26 if (d_agent_handrail < 0.7) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates inside a Science Museum ocean hall.\n Objectives: Do not collide with the suspended whale skeleton.\n Conditions: The states of the agent and the whale skeleton are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_whale_skeleton, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_skeleton = calculate_distance_min(s_agent, s_whale_skeleton) \n    penalty_collision = -34 if (d_agent_skeleton < 0.9) else 15 \n    reward_reaching_goal = 31 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying near the VR demo zone in a Science Museum.\nRequirement: Detect the tethered headset cable and avoid it.\n Given: The states for the drone and the cable are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -21 if (d_agent_cable < 0.5) else 10\n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating the Science Museum innovation gallery.\n Goal: It must avoid colliding with the magnetic levitation track.\n Assumptions: The states of the drone, goal and the maglev track are available. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_maglev_track, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_track = calculate_distance_min(s_agent, s_maglev_track) \n    penalty_collision = -24 if (d_agent_track < 0.7) else 14\n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is exploring the Science Museum fossil hall.\n Objective: Avoid collision with the large dinosaur skeleton tail.\n Conditions: The states of the drone, goal and the skeleton are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_skeleton, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_skeleton = calculate_distance_min(s_agent, s_skeleton) \n    penalty_collision = -33 if (d_agent_skeleton < 0.8) else 15\n    reward_reaching_goal = 29 if (d_agent_goal < 0.2) else -30\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating the Science Museum optics exhibit.\n Objective: Avoid the rotating mirror array.\n Conditions: Agent and mirror states are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_mirror, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mirror = calculate_distance_min(s_agent, s_mirror) \n    penalty_collision = -28 if (d_agent_mirror < 0.7) else 12\n    reward_reaching_goal = 27 if (d_agent_goal < 0.2) else -30\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying inside the Science Museum energy gallery.\n Requirement: Avoid colliding with the spinning wind turbine model.\n Given: States for the drone and the turbine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_turbine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_turbine = calculate_distance_min(s_agent, s_turbine) \n    penalty_collision = -32 if (d_agent_turbine < 1.0) else 14\n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: A drone is operating in the Science Museum chemistry wing.\n Goal: It must avoid flying into the mist zone of the liquid nitrogen demo.\n Assumptions: The states of the drone, goal and mist cloud are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_mist_zone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mist = calculate_distance_min(s_agent, s_mist_zone) \n    penalty_collision = -20 if (d_agent_mist < 0.6) else 10\n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -30\n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating a Science Museum.\n Goal: Drone goal is to reach the charging dock goal.\n Assumptions: The states of the drone, goal and the charging dock are known. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along cellar. \n Objectives: It must avoid colliding with wine rack or barrel. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the wine rack and the barrel are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy cellar. \n Objectives: Detect support beam and aviod it. \n Conditions: The states of the agent, goal, the beam are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -25 if (d_agent_beam < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a cellar. Objectives: It must avoid colliding with cellar worker. Conditions: States of the drone and the cellar worker are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cellar_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cellar_worker = calculate_distance_min(s_agent, s_cellar_worker) \n    penalty_collision = -25 if (d_agent_cellar_worker < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a cellar, the drone must maneuver around tool bench. All entity states (agent, goal, tool bench) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_tool_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool_bench = calculate_distance_min(s_agent, s_tool_bench) \n    penalty_collision = -25 if (d_agent_tool_bench < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a cellar. Requirement: Detect the three old machinery and do not collide with it. Given: The states for the drone and multiple old machinery are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a cellar. \n Objectives: So not collide with wooden crate. \n Conditions: The states of the agent, goal, the wooden crate are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_wooden_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wooden_crate = calculate_distance_min(s_agent, s_wooden_crate) \n    penalty_collision = -25 if (d_agent_wooden_crate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate cellar. Objectives: Do not collide hit with the storage table. Conditions: States of the agent, storage table are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_storage_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_storage_table = calculate_distance_min(s_agent, s_storage_table) \n    penalty_collision = -25 if (d_agent_storage_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a cellar, the drone must steer clear of cellar worker. All states (agent, goal, cellar worker) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_cellar_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cellar_worker = calculate_distance_min(s_agent, s_cellar_worker) \n    penalty_collision = -25 if (d_agent_cellar_worker < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: cellar. Avoid: Detect wooden crate and do not hitting with wooden crate. Known: Agent, goal, wooden crate states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_wooden_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wooden_crate = calculate_distance_min(s_agent, s_wooden_crate) \n    penalty_collision = -25 if (d_agent_wooden_crate < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating cellar. Objectives: It must avoid colliding with wine rack. Conditions: The states of the drone, goal and wine rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wine_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wine_rack = calculate_distance_min(s_agent, s_wine_rack) \n    penalty_collision = -25 if (d_agent_wine_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through cellar. Objectives: Avoid collision with checkout revolving cellar door, wine rack and barrel. Conditions: The states of the agent and of the multiple obstacles: cellar door, wine rack and barrel are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating cellar. Objectives: It must avoid colliding with any wooden crate, cellar cellar door. Conditions: Agent's and of the multiple obstacle: wooden crate, cellar cellar door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through cellar. Objectives: Do not collide with support beam. Conditions: The states of the drone, goal and the support beam are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_beam) \n    penalty = -25 if (d_agent_beam < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along cellar and must avoid contact with the wine press. The states of the drone, goal and the wine press are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_wine_press, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wine_press = calculate_distance_min(s_agent, s_wine_press) \n    penalty = -25 if (d_agent_wine_press < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in cellar. It must avoid colliding with the wooden crate, wine press and cellar worker. The states of the agent and of the multiple obstacle: wooden crate, wine press and cellar worker are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in cellar. It must avoid colliding with the wine press and wooden crate. The states of the drone, goal and of the multiple obstacle: the wine press and wooden crate are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in cellar. It must avoid colliding with the cellar door. Agent's state, goal's state and cellar door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cellar_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cellar_door = calculate_distance_min(s_agent, s_cellar_door) \n    penalty_collision = -25 if (d_agent_cellar_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: It must avoid colliding with moisture sensor. Assumptions: The states of the drone, goal and the moisture sensor's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_sensor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sensor = calculate_distance_min(s_agent, s_sensor) \n    penalty_collision = -25 if (d_agent_sensor < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: It must avoid colliding with storage table, storage box and cellar worker. Assumptions: The Agent's state, goal's state and multiple obstacle's state: storage table, storage box and cellar worker are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: Detect cellar door, support beam and hanging lamp and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: cellar door, support beam and hanging lamp state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating cellar. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along university. \n Objectives: It must avoid colliding with reception desk or supply shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the reception desk and the supply shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy university. \n Objectives: Detect notice board and aviod it. \n Conditions: The states of the agent, goal, the notice board are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_notice_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_notice_board = calculate_distance_min(s_agent, s_notice_board) \n    penalty_collision = -25 if (d_agent_notice_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a university. Objectives: It must avoid colliding with student. Conditions: States of the drone and the student are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -25 if (d_agent_student < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a university, the drone must maneuver around projector. All entity states (agent, goal, projector) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -25 if (d_agent_projector < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a university. Requirement: Detect the three kiosk and do not collide with it. Given: The states for the drone and multiple kiosks are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a university. \n Objectives: So not collide with backpack. \n Conditions: The states of the agent, goal, the backpack are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -25 if (d_agent_backpack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate university. Objectives: Do not collide hit with the help desk. Conditions: States of the agent, help desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_help_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_help_desk = calculate_distance_min(s_agent, s_help_desk) \n    penalty_collision = -25 if (d_agent_help_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a university, the drone must steer clear of professor. All states (agent, goal, professor) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_professor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_professor = calculate_distance_min(s_agent, s_professor) \n    penalty_collision = -25 if (d_agent_professor < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: university. Avoid: Detect pipe and do not hitting with pipe. Known: Agent, goal, pipe states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -25 if (d_agent_pipe < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating university. Objectives: It must avoid colliding with reception desk. Conditions: The states of the drone, goal and reception desk are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_reception_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception_desk = calculate_distance_min(s_agent, s_reception_desk) \n    penalty_collision = -25 if (d_agent_reception_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through university. Objectives: Avoid collision with entrance door, reception desk and shelf. Conditions: The states of the agent and of the multiple obstacles: entrance door, reception desk and shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating university. Objectives: It must avoid colliding with any backpack, university entrance. Conditions: Agent's and of the multiple obstacle: backpack, university entrance states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through university. Objectives: Do not collide with notice board. Conditions: The states of the drone, goal and the notice board are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_notice_board, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_notice_board = calculate_distance_min(s_agent, s_notice_board) \n    penalty = -25 if (d_agent_notice_board < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along university and must avoid contact with the vending machine. The states of the drone, goal and the vending machine are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_vending machine_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vending machine_maschine = calculate_distance_min(s_agent, s_vending machine_maschine) \n    penalty = -25 if (d_agent_vending machine_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in university. It must avoid colliding with the backpack, vending machine and faculty member. The states of the agent and of the multiple obstacle: backpack, vending machine and faculty member are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in university. It must avoid colliding with the vending machine and backpack. The states of the drone, goal and of the multiple obstacle: the vending machine and backpack are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in university. It must avoid colliding with the vault building entrance. Agent's state, goal's state and vault building entrancen's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_entrance, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_entrance = calculate_distance_min(s_agent, s_entrance) \n    penalty_collision = -25 if (d_agent_entrance < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: It must avoid colliding with fire alarm panel. Assumptions: The states of the drone, goal and the fire alarm panel's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_alarm_system, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_alarm_system = calculate_distance_min(s_agent, s_alarm_system) \n    penalty_collision = -25 if (d_agent_alarm_system < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: It must avoid colliding with help desk, assignment drop box and faculty member. Assumptions: The Agent's state, goal's state and multiple obstacle's state: help desk, assignment drop box and faculty member are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: Detect building entrance, notice board and overhead light and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: building entrance, notice board and overhead light state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating university. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along supply store. \n Objectives: It must avoid colliding with checkout counter or storage shelf. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the checkout counter and the storage shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy supply store. \n Objectives: Detect promo display and aviod it. \n Conditions: The states of the agent, goal, the promo display are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display = calculate_distance_min(s_agent, s_display) \n    penalty_collision = -25 if (d_agent_display < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a supply store. Objectives: It must avoid colliding with shopper. Conditions: States of the drone and the shopper are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shopper, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shopper = calculate_distance_min(s_agent, s_shopper) \n    penalty_collision = -25 if (d_agent_shopper < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a supply store, the drone must maneuver around cash register. All entity states (agent, goal, cash register) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_cash_register, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cash_register = calculate_distance_min(s_agent, s_cash_register) \n    penalty_collision = -25 if (d_agent_cash_register < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a supply store. Requirement: Detect the three price scanner and do not collide with it. Given: The states for the drone and multiple price scanner are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a supply store. \n Objectives: So not collide with supply box. \n Conditions: The states of the agent, goal, the supply box are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_supply_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_supply_box = calculate_distance_min(s_agent, s_supply_box) \n    penalty_collision = -25 if (d_agent_supply_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate supply store. Objectives: Do not collide hit with the customer service desk. Conditions: States of the agent, customer service desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_service_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_service_desk = calculate_distance_min(s_agent, s_service_desk) \n    penalty_collision = -25 if (d_agent_service_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a supply store, the drone must steer clear of shopper. All states (agent, goal, shopper) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_shopper, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shopper = calculate_distance_min(s_agent, s_shopper) \n    penalty_collision = -25 if (d_agent_shopper < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: supply store. Avoid: Detect supply box and do not hitting with paket. Known: Agent, goal, paket states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_paket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paket = calculate_distance_min(s_agent, s_paket) \n    penalty_collision = -25 if (d_agent_paket < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating supply store. Objectives: It must avoid colliding with checkout counter. Conditions: The states of the drone, goal and checkout counter are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_checkout_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_checkout_counter = calculate_distance_min(s_agent, s_checkout_counter) \n    penalty_collision = -25 if (d_agent_checkout_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through supply store. Objectives: Avoid collision with checkout revolving store entrance, checkout counter and storage shelf. Conditions: The states of the agent and of the multiple obstacles: checkout revolving store entrance, checkout counter and storage shelf are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating supply store. Objectives: It must avoid colliding with any supply box, supply store store entrance. Conditions: Agent's and of the multiple obstacle: supply box, supply store store entrance states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through supply store. Objectives: Do not collide with promo display. Conditions: The states of the drone, goal and the promo display are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_display, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display = calculate_distance_min(s_agent, s_display) \n    penalty = -25 if (d_agent_display < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along supply store and must avoid contact with the payment maschine. The states of the drone, goal and the payment maschine are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_payment_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_payment_maschine = calculate_distance_min(s_agent, s_payment_maschine) \n    penalty = -25 if (d_agent_payment_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in supply store. It must avoid colliding with the supply box, payment terminal and worker. The states of the agent and of the multiple obstacle: supply box, payment terminal and worker are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in supply store. It must avoid colliding with the payment terminal and supply box. The states of the drone, goal and of the multiple obstacle: the payment terminal and supply box are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in supply store. It must avoid colliding with the tool. Agent's state, goal's state and tool's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool = calculate_distance_min(s_agent, s_tool) \n    penalty_collision = -25 if (d_agent_tool < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: It must avoid colliding with forklift. Assumptions: The states of the drone, goal and the forklift's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -25 if (d_agent_forklift < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: It must avoid colliding with customer service desk, forklift and worker. Assumptions: The Agent's state, goal's state and multiple obstacle's state: customer service desk, forklift and worker are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: Detect store entrance, promo display and light and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: store entrance, promo display and light state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating supply store. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along art supply store. \n Objectives: It must avoid colliding with paint mixing station or drying rack. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the paint mixing station and the drying rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy art supply store. \n Objectives: Detect brush rack and aviod it. \n Conditions: The states of the agent, goal, the brush rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_brush_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_brush_rack = calculate_distance_min(s_agent, s_brush_rack) \n    penalty_collision = -25 if (d_agent_brush_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a art supply store. Objectives: It must avoid colliding with store artist. Conditions: States of the drone and the store artist are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_store_artist, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_store_artist = calculate_distance_min(s_agent, s_store_artist) \n    penalty_collision = -25 if (d_agent_store_artist < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a art supply store, the drone must maneuver around framing station. All entity states (agent, goal, framing station) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_framing_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_framing_station = calculate_distance_min(s_agent, s_framing_station) \n    penalty_collision = -25 if (d_agent_framing_station < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a art supply store. Requirement: Detect the three paper cutter and do not collide with it. Given: The states for the drone and multiple paper cutter are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a art supply store. \n Objectives: So not collide with clay bag. \n Conditions: The states of the agent, goal, the clay bag are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_clay_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_clay_bag = calculate_distance_min(s_agent, s_clay_bag) \n    penalty_collision = -25 if (d_agent_clay_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate art supply store. Objectives: Do not collide hit with the color palette counter. Conditions: States of the agent, color palette counter are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_palette_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_palette_counter = calculate_distance_min(s_agent, s_palette_counter) \n    penalty_collision = -25 if (d_agent_palette_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a art supply store, the drone must steer clear of store artist. All states (agent, goal, store artist) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_store_artist, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_store_artist = calculate_distance_min(s_agent, s_store_artist) \n    penalty_collision = -25 if (d_agent_store_artist < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: art supply store. Avoid: Detect clay bag and do not hitting with clay bag. Known: Agent, goal, clay bag states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_cash_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cash_bag = calculate_distance_min(s_agent, s_cash_bag) \n    penalty_collision = -25 if (d_agent_cash_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating art supply store. Objectives: It must avoid colliding with paint station. Conditions: The states of the drone, goal and paint station are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_paint_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_paint_station = calculate_distance_min(s_agent, s_paint_station) \n    penalty_collision = -25 if (d_agent_paint_station < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through art supply store. Objectives: Avoid collision with paint bucket, paint station and drying rack. Conditions: The states of the agent and of the multiple obstacles: paint bucket, paint station and drying rack are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating art supply store. Objectives: It must avoid colliding with any clay bag, art supply store loading bay. Conditions: Agent's and of the multiple obstacle: clay bag, staff states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through art supply store. Objectives: Do not collide with kiln. Conditions: The states of the drone, goal and the kiln are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kiln, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kiln = calculate_distance_min(s_agent, s_kiln) \n    penalty = -25 if (d_agent_kiln < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along art supply store and must avoid contact with the 3D printer. The states of the drone, goal and the 3D printer are known. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_3D_printer, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_3D_printer = calculate_distance_min(s_agent, s_3D_printer) \n    penalty = -25 if (d_agent_3D_printer < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in art supply store. It must avoid colliding with the clay bag, 3D printer and kiln. The states of the agent and of the multiple obstacle: clay bag, 3D printer and kiln are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in art supply store. It must avoid colliding with the 3D printer and clay bag. The states of the drone, goal and of the multiple obstacle: the 3D printer and clay bag are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in art supply store. It must avoid colliding with the AC. Agent's state, goal's state and AC's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_AC, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_AC = calculate_distance_min(s_agent, s_AC) \n    penalty_collision = -25 if (d_agent_AC < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: It must avoid colliding with ventilation unit. Assumptions: The states of the drone, goal and the ventilation unit's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_ventilation, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ventilation = calculate_distance_min(s_agent, s_ventilation) \n    penalty_collision = -25 if (d_agent_ventilation < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: It must avoid colliding with color palette counter, supply return bin and store artist. Assumptions: The Agent's state, goal's state and multiple obstacle's state: color palette, supply tools and store artist are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: Detect loading bay, brush rack and hanging spotlight and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: brushes, brush rack and hanging spotlight state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating art supply store. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating along meeting room. \n Objectives: It must avoid colliding with conference table or whiteboard. \n Conditions: The states of the agent, goal, and of the other multiple obstaces e.g. the conference table and the whiteboard are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a busy meeting room. \n Objectives: Detect projector stand and aviod it. \n Conditions: The states of the agent, goal, the projector stand are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_projector_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector_stand = calculate_distance_min(s_agent, s_projector_stand) \n    penalty_collision = -25 if (d_agent_projector_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a meeting room. Objectives: It must avoid colliding with attendee. Conditions: States of the drone and the attendee are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_attendee, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_attendee = calculate_distance_min(s_agent, s_attendee) \n    penalty_collision = -25 if (d_agent_attendee < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: Inside a meeting room, the drone must maneuver around podium. All entity states (agent, goal, podium) are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_podium, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_podium = calculate_distance_min(s_agent, s_podium) \n    penalty_collision = -25 if (d_agent_podium < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying through a meeting room. Requirement: Detect the three coffee machine and do not collide with it. Given: The states for the drone and multiple coffee machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone operates near a meeting room. \n Objectives: So not collide with laptop bag. \n Conditions: The states of the agent, goal, the laptop bag are known. Write the Python reward function.",
        "chosen": "def reward(s_agent, s_laptop_bag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop_bag = calculate_distance_min(s_agent, s_laptop_bag) \n    penalty_collision = -25 if (d_agent_laptop_bag < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: Navigate meeting room. Objectives: Do not collide hit with the reception desk. Conditions: States of the agent, reception desk are obtainable. Deliver: Python reward function.",
        "chosen": "def reward(s_agent, s_reception_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_reception_desk = calculate_distance_min(s_agent, s_reception_desk) \n    penalty_collision = -25 if (d_agent_reception_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Context: Within a meeting room, the drone must steer clear of attendee. All states (agent, goal, attendee) are known. Provide a Python reward function for training.",
        "chosen": "def reward(s_agent, s_attendee, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_attendee = calculate_distance_min(s_agent, s_attendee) \n    penalty_collision = -25 if (d_agent_attendee < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task Briefing: Environment: meeting room. Avoid: Detect laptop and do not hitting with laptop bag. Known: Agent, goal, laptop states. Create the Python reward function.",
        "chosen": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -25 if (d_agent_laptop < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating meeting room. Objectives: It must avoid colliding with conference table. Conditions: The states of the drone, goal and conference table are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_conference_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_conference_table = calculate_distance_min(s_agent, s_conference_table) \n    penalty_collision = -25 if (d_agent_conference_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through meeting room. Objectives: Avoid collision with checkout revolving meeting room door, conference table and whiteboard. Conditions: The states of the agent and of the multiple obstacles: meeting room door, conference table and whiteboard are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating meeting room. Objectives: It must avoid colliding with any laptop bag, room door. Conditions: Agent's and of the multiple obstacle: laptop bag, room door states are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying through meeting room. Objectives: Do not collide with coffee maschine. Conditions: The states of the drone, goal and the coffee maschine are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_maschine = calculate_distance_min(s_agent, s_coffee_maschine) \n    penalty = -25 if (d_agent_coffee_maschine < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating along meeting room and must avoid contact with the video conferencing unit. The states of the drone, goal and the video camera. Write a Python reward function for this case.",
        "chosen": "def reward(s_agent, s_video_camera, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_video_camera = calculate_distance_min(s_agent, s_video_camera) \n    penalty = -25 if (d_agent_video_camera < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in meeting room. It must avoid colliding with the laptop bag, video conferencing unit and attendee. The states of the agent and of the multiple obstacle: laptop bag, video conferencing unit and attendee are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is operating in meeting room. It must avoid colliding with the video conferencing unit and laptop bag. The states of the drone, goal and of the multiple obstacle: the video conferencing unit and laptop bag are known. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in meeting room. It must avoid colliding with the meeting room door. Agent's state, goal's state and meeting room door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s__door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent__door = calculate_distance_min(s_agent, s__door) \n    penalty_collision = -25 if (d_agent__door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: It must avoid colliding with air conditioner. Assumptions: The states of the drone, goal and the air conditioner's state are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_air_conditioner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_air_conditioner = calculate_distance_min(s_agent, s_air_conditioner) \n    penalty_collision = -25 if (d_agent_air_conditioner < 0.7) else 15 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: It must avoid colliding with reception desk, document tray and attendee. Assumptions: The Agent's state, goal's state and multiple obstacle's state: reception desk, document tray and attendee are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: Detect meeting room door, projector stand and ceiling projector and do not collide. Assumptions: The states of the drone, goal and multiple obstcale: meeting room door, projector stand and ceiling projector state are availalbe. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating meeting room. Goal: Drone goal is to reach the goal. Assumptions: The states of the drone, goal and the goal are known. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -30 \n    return reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a mine. \n Objectives: It must avoid colliding with stalactites hanging from the ceiling. \n Conditions: The states of the agent, goal, and of the stalactites are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stalactites, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stalactites = calculate_distance_min(s_agent, s_stalactites) \n    penalty_collision = -40 if (d_agent_stalactites < 0.5) else 12 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying inside a mine tunnel. \n Objectives: Detect moving minecart and avoid collision. \n Conditions: The states of the agent and minecart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_minecart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_minecart = calculate_distance_min(s_agent, s_minecart) \n    penalty_collision = -50 if (d_agent_minecart < 0.7) else 15 \n    reward_reaching_goal = 40 if (d_agent_goal < 0.25) else -22 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is exploring an underground mine shaft. \n Goal: It must avoid gas pockets that are hazardous. \n Assumptions: The states of the agent and the gas bottle are known. Provide a reward function in Python.",
        "chosen": "def reward(s_agent, s_gas_bottle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gas_bottle = calculate_distance_min(s_agent, s_gas_bottle) \n    penalty_collision = -60 if (d_agent_gas_bottle < 1.0) else 8 \n    reward_reaching_goal = 45 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine corridor. \n Objectives: Do not collide with the conveyor belt system used to transport rocks. \n Conditions: States of the drone and conveyor belt are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_conveyor_belt, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_conveyor_belt = calculate_distance_min(s_agent, s_conveyor_belt) \n    penalty_collision = -35 if (d_agent_conveyor_belt < 0.5) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -25 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying deep in a mine. \n Requirement: Detect drilling machine and avoid them. \n Given: The states for the drone and drilling machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_drilling_machine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drilling_machine = calculate_distance_min(s_agent, s_drilling_machine) \n    penalty_collision = -55 if (d_agent_drilling_machine < 0.6) else 14 \n    reward_reaching_goal = 38 if (d_agent_goal < 0.25) else -28 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is mapping an abandoned mine. \n Objectives: Avoid colliding with fallen rock debris. \n Conditions: The states of the drone, goal and rock debris are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rock_debris, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock_debris = calculate_distance_min(s_agent, s_rock_debris) \n    penalty_collision = -30 if (d_agent_rock_debris < 0.5) else 11 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.35) else -18 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is patrolling inside a mine shaft. \n Goal: Avoid narrow shaft wall. \n Assumptions: The states of the drone, goal and wall are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -45 if (d_agent_wall < 0.4) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.3) else -21 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying inside a mine with water leaks. \n Objectives: Avoid underground water bucket. \n Conditions: The states of the agent and water bucket are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_water_bucket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_water_bucket = calculate_distance_min(s_agent, s_water_bucket) \n    penalty_collision = -25 if (d_agent_water_bucket < 0.5) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.35) else -17 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is inspecting a mine. \n Goal: Avoid hitting rock. \n Assumptions: The states of the drone, goal and rock are available. Provide a Python water reward function.",
        "chosen": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -33 if (d_agent_rock < 0.5) else 9 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.25) else -19 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating in an underground mine. \n Requirement: Detect wooden support beam and avoid hitting them. \n Conditions: The states of the drone, goal and support beam are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_support_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_support_beam = calculate_distance_min(s_agent, s_support_beam) \n    penalty_collision = -42 if (d_agent_support_beam < 0.5) else 10 \n    reward_reaching_goal = 34 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with elevator. \n Conditions: States of agent and elevator are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -40 if (d_agent_elevator < 0.5) else 10 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.3) else -25 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with loose cables. \n Conditions: States of agent and cable are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -28 if (d_agent_cable < 0.5) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -25 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with metal pipes. \n Conditions: States of agent and metal pipe are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_metal_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_metal_pipe = calculate_distance_min(s_agent, s_metal_pipe) \n    penalty_collision = -36 if (d_agent_metal_pipe < 0.5) else 10 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.3) else -25 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with toxic barrels. \n Conditions: States of agent and toxic barrel are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_toxic_barrel, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toxic_barrel = calculate_distance_min(s_agent, s_toxic_barrel) \n    penalty_collision = -55 if (d_agent_toxic_barrel < 0.5) else 10 \n    reward_reaching_goal = 37 if (d_agent_goal < 0.3) else -25 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with slippery mud. \n Conditions: States of agent and maschine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_maschine = calculate_distance_min(s_agent, s_maschine) \n    penalty_collision = -20 if (d_agent_maschine < 0.5) else 10 \n    reward_reaching_goal = 18 if (d_agent_goal < 0.3) else -25 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with collapsed beam. \n Conditions: States of agent and beam are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -48 if (d_agent_beam < 0.5) else 10 \n    reward_reaching_goal = 34 if (d_agent_goal < 0.3) else -25 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with explosive crates. \n Conditions: States of agent and crate are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crate = calculate_distance_min(s_agent, s_crate) \n    penalty_collision = -60 if (d_agent_crate < 0.5) else 10 \n    reward_reaching_goal = 40 if (d_agent_goal < 0.3) else -25 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with chains. \n Conditions: States of agent and chains are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_chains, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chains = calculate_distance_min(s_agent, s_chains) \n    penalty_collision = -32 if (d_agent_chains < 0.5) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.3) else -25 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with rusted railings. \n Conditions: States of agent and railing are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_railing, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_railing = calculate_distance_min(s_agent, s_railing) \n    penalty_collision = -30 if (d_agent_railing < 0.5) else 10 \n    reward_reaching_goal = 24 if (d_agent_goal < 0.3) else -25 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with machinery parts. \n Conditions: States of agent and machinery are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_machinery, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_machinery = calculate_distance_min(s_agent, s_machinery) \n    penalty_collision = -45 if (d_agent_machinery < 0.5) else 10 \n    reward_reaching_goal = 33 if (d_agent_goal < 0.3) else -25 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with loose hanging cables or dripping water pipes. \n Conditions: The states of the drone, goal and loose hanging cables or dripping water pipes are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with car on the walls. \n Conditions: The states of the drone, goal and car on the walls are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_car = calculate_distance_min(s_agent, s_car) \n    penalty_collision = -25 if (d_agent_car < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with emergency exit signs protruding from the wall. \n Conditions: The states of the drone, goal and emergency exit signs protruding from the wall are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_exit_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_exit_signs = calculate_distance_min(s_agent, s_exit_sign) \n    penalty_collision = -25 if (d_agent_exit_signs < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with temporary scaffolding. \n Conditions: The states of the drone, goal and scaffolding are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_scaffolding, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scaffolding = calculate_distance_min(s_agent, s_scaffolding) \n    penalty_collision = -25 if (d_agent_scaffolding < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with uneven ceiling protrusions. \n Conditions: The states of the drone, goal and uneven ceiling protrusions are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_protrusion, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_protrusion = calculate_distance_min(s_agent, s_protrusion) \n    penalty_collision = -25 if (d_agent_protrusion < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with small inspection platforms attached to the wall. \n Conditions: The states of the drone, goal and platform attached to the wall are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -25 if (d_agent_platform < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with ventilation ducts. \n Conditions: The states of the drone, goal and ventilation duct are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ventilation_duct, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ventilation_duct = calculate_distance_min(s_agent, s_ventilation_duct) \n    penalty_collision = -25 if (d_agent_ventilation_duct < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with abandoned maintenance cart left on the track. \n Conditions: The states of the drone, goal and maintenance cart are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cart = calculate_distance_min(s_agent, s_cart) \n    penalty_collision = -25 if (d_agent_cart < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with narrow choke points created by tunnel reinforcements. \n Conditions: The states of the drone, goal and narrow choke point are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_choke_point, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_choke_point = calculate_distance_min(s_agent, s_choke_point) \n    penalty_collision = -25 if (d_agent_choke_point < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with loose rock debris piles. \n Conditions: The states of the drone, goal and loose rock debris piles are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_debris, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_debris) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with partially collapsed sections. \n Conditions: The states of the drone, goal and partially collapsed sections are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_collapse_section, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_collapse_section = calculate_distance_min(s_agent, s_collapse_section) \n    penalty_collision = -25 if (d_agent_collapse_section < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with rail tracks with equipment left behind. \n Conditions: The states of the drone, goal and equipment are avaiable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -25 if (d_agent_equipment < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with low-hanging lighting fixtures. \n Conditions: The states of the drone, goal and low-hanging lighting fixtures are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_light = calculate_distance_min(s_agent, s_light) \n    penalty_collision = -25 if (d_agent_light < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with water bottle. \n Conditions: The states of the drone, goal and water bottle are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_watter_bottle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_watter_bottle = calculate_distance_min(s_agent, s_watter_bottle) \n    penalty_collision = -25 if (d_agent_watter_bottle < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with cable stored in passageway. \n Conditions: The states of the drone, goal and cable are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -25 if (d_agent_cable < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with wall and car in the tunnel. \n Conditions: The states of the drone, goal and of the multiple obstacle:car and wall along the wall are avaiable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_generators, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_generators) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with cable and exit sign . \n Conditions: The states of the drone, goal and multiple obstacle: cable and sign are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_crates, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_crates) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with equipment and staff. \n Conditions: The states of the drone, goal and many itmes: equipment and staff are avaiable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fans, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_fans) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with sensor and camera. \n Conditions: The states of the drone, goal and multiple obstacle: sensor and camera are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tripods, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_tripods) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with pipe, car and cart. \n Conditions: The states of the drone, goal and multiple obstacle: pipe, car and cart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_grates, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_grates) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the showroom car. \n Given: Agent's state, goal's state and showroom car's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_showroom_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_showroom_car = calculate_distance_min(s_agent, s_showroom_car) \n    penalty_collision = -25 if (d_agent_showroom_car < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the sales desk. \n Given: Agent's state, goal's state and sales desk's state are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sales_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sales_desk = calculate_distance_min(s_agent, s_sales_desk) \n    penalty_collision = -25 if (d_agent_sales_desk < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the brochure stand. \n Given: Agent's state, goal's state and brochure stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_brochure_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_brochure_stand = calculate_distance_min(s_agent, s_brochure_stand) \n    penalty_collision = -25 if (d_agent_brochure_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the car. \n Given: Agent's state, goal's state and car's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_car = calculate_distance_min(s_agent, s_car) \n    penalty_collision = -25 if (d_agent_car < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the customer lounge table. \n Given: Agent's state, goal's state and customer lounge table's state are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lounge_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lounge_table = calculate_distance_min(s_agent, s_lounge_table) \n    penalty_collision = -25 if (d_agent_lounge_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the truck. \n Given: Agent's state, goal's state and truck's state are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_truck, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_truck = calculate_distance_min(s_agent, s_truck) \n    penalty_collision = -25 if (d_agent_truck < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the stanchion rope. \n Given: Agent's state, goal's state and stanchion rope's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stanchion_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stanchion_rope = calculate_distance_min(s_agent, s_stanchion_rope) \n    penalty_collision = -25 if (d_agent_stanchion_rope < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the banner stand. \n Given: Agent's state, goal's state and banner stand's state are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_banner_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banner_stand = calculate_distance_min(s_agent, s_banner_stand) \n    penalty_collision = -25 if (d_agent_banner_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the charging station. \n Given: Agent's state, goal's state and charging station's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_charging_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_charging_station = calculate_distance_min(s_agent, s_charging_station) \n    penalty_collision = -25 if (d_agent_charging_station < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the tire rack. \n Given: Agent's state, goal's state and tire rack's state are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tire_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tire_rack = calculate_distance_min(s_agent, s_tire_rack) \n    penalty_collision = -25 if (d_agent_tire_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the parts counter. \n Given: Agent's state, goal's state and parts counter's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_parts_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_parts_counter = calculate_distance_min(s_agent, s_parts_counter) \n    penalty_collision = -25 if (d_agent_parts_counter < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the toolbox cart. \n Given: Agent's state, goal's state and toolbox cart's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_toolbox_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toolbox_cart = calculate_distance_min(s_agent, s_toolbox_cart) \n    penalty_collision = -25 if (d_agent_toolbox_cart < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's showroom car, glass partition and banner stand. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: showroom car, glass partition, and banner stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's sales desk and rolling chair. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: sales desk, and rolling chair are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's reception counter, stanchion rope and brochure stand. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: reception counter, stanchion rope, and brochure stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's service bay door and tire rack. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: service bay door, and tire rack are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's car lift, toolbox cart and wheel alignment machine. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: car lift, toolbox cart, and wheel alignment machine are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's charging station and display podium. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: charging station, and display podium are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's customer lounge table, indoor plant and signboard. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: customer lounge table, indoor plant, and signboard are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's parts counter and cashier desk. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: parts counter, and cashier desk are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's key cabinet and brochure stand. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: key cabinet, and brochure stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's demo vehicle, sales kiosk and queue barrier. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: demo vehicle, sales kiosk, and queue barrier are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the tent. Agent's state, goal's state and tent's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tent = calculate_distance_min(s_agent, s_tent) \n    penalty_collision = -25 if (d_agent_tent < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the campfire pit. Agent's state, goal's state and campfire pit's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_campfire_pit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_campfire_pit = calculate_distance_min(s_agent, s_campfire_pit) \n    penalty_collision = -25 if (d_agent_campfire_pit < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the picnic table. Agent's state, goal's state and picnic table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_picnic_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_picnic_table = calculate_distance_min(s_agent, s_picnic_table) \n    penalty_collision = -25 if (d_agent_picnic_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the cooler box. Agent's state, goal's state and cooler box's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cooler_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cooler_box = calculate_distance_min(s_agent, s_cooler_box) \n    penalty_collision = -25 if (d_agent_cooler_box < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the hammock stand. Agent's state, goal's state and hammock stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_hammock_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_hammock_stand = calculate_distance_min(s_agent, s_hammock_stand) \n    penalty_collision = -25 if (d_agent_hammock_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the lantern pole. Agent's state, goal's state and lantern pole's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lantern_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lantern_pole = calculate_distance_min(s_agent, s_lantern_pole) \n    penalty_collision = -25 if (d_agent_lantern_pole < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the water tap. Agent's state, goal's state and water tap's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_water_tap, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_water_tap = calculate_distance_min(s_agent, s_water_tap) \n    penalty_collision = -25 if (d_agent_water_tap < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the trash bin. Agent's state, goal's state and trash bin's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -25 if (d_agent_trash_bin < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the bear-proof food locker. Agent's state, goal's state and bear-proof food locker's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bear_proof_locker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bear_proof_locker = calculate_distance_min(s_agent, s_bear_proof_locker) \n    penalty_collision = -25 if (d_agent_bear_proof_locker < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the firewood stack. Agent's state, goal's state and firewood stack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_firewood_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_firewood_stack = calculate_distance_min(s_agent, s_firewood_stack) \n    penalty_collision = -25 if (d_agent_firewood_stack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the barbecue grill. Agent's state, goal's state and barbecue grill's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bbq_grill, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bbq_grill = calculate_distance_min(s_agent, s_bbq_grill) \n    penalty_collision = -25 if (d_agent_bbq_grill < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the car at campsite. Agent's state, goal's state and car at campsite's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_campsite_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_campsite_car = calculate_distance_min(s_agent, s_campsite_car) \n    penalty_collision = -25 if (d_agent_campsite_car < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the RV. Agent's state, goal's state and RV's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rv, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rv = calculate_distance_min(s_agent, s_rv) \n    penalty_collision = -25 if (d_agent_rv < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the guyline stake. Agent's state, goal's state and guyline stake's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_guyline_stake, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_guyline_stake = calculate_distance_min(s_agent, s_guyline_stake) \n    penalty_collision = -25 if (d_agent_guyline_stake < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the tent pole. Agent's state, goal's state and tent pole's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tent_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tent_pole = calculate_distance_min(s_agent, s_tent_pole) \n    penalty_collision = -25 if (d_agent_tent_pole < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the picnic shelter post. Agent's state, goal's state and picnic shelter post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shelter_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shelter_post = calculate_distance_min(s_agent, s_shelter_post) \n    penalty_collision = -25 if (d_agent_shelter_post < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the portable toilet. Agent's state, goal's state and portable toilet's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_porta_toilet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_porta_toilet = calculate_distance_min(s_agent, s_porta_toilet) \n    penalty_collision = -25 if (d_agent_porta_toilet < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the trail signpost. Agent's state, goal's state and trail signpost's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trail_signpost, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trail_signpost = calculate_distance_min(s_agent, s_trail_signpost) \n    penalty_collision = -25 if (d_agent_trail_signpost < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the kayak rack. Agent's state, goal's state and kayak rack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kayak_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kayak_rack = calculate_distance_min(s_agent, s_kayak_rack) \n    penalty_collision = -25 if (d_agent_kayak_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the solar panel stand. Agent's state, goal's state and solar panel stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_solar_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_solar_stand = calculate_distance_min(s_agent, s_solar_stand) \n    penalty_collision = -25 if (d_agent_solar_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the generator. Agent's state, goal's state and generator's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_generator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_generator = calculate_distance_min(s_agent, s_generator) \n    penalty_collision = -25 if (d_agent_generator < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's tent, campfire pit and picnic table. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: tent, campfire pit, and picnic table are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's RV and generator. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: RV, and generator are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's trail signpost, kayak rack and trash bin. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: trail signpost, kayak rack, and trash bin are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's lantern pole and guyline stake. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: lantern pole, and guyline stake are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the coffee table. Agent's state, goal's state and coffee table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_table = calculate_distance_min(s_agent, s_coffee_table) \n    penalty_collision = -25 if (d_agent_coffee_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the sofa. Agent's state, goal's state and sofa's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sofa, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sofa = calculate_distance_min(s_agent, s_sofa) \n    penalty_collision = -25 if (d_agent_sofa < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the TV stand. Agent's state, goal's state and TV stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tv_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tv_stand = calculate_distance_min(s_agent, s_tv_stand) \n    penalty_collision = -25 if (d_agent_tv_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the floor lamp. Agent's state, goal's state and floor lamp's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_floor_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_floor_lamp = calculate_distance_min(s_agent, s_floor_lamp) \n    penalty_collision = -25 if (d_agent_floor_lamp < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the bookshelf. Agent's state, goal's state and bookshelf's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bookshelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelf = calculate_distance_min(s_agent, s_bookshelf) \n    penalty_collision = -25 if (d_agent_bookshelf < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the indoor plant. Agent's state, goal's state and indoor plant's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_indoor_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_indoor_plant = calculate_distance_min(s_agent, s_indoor_plant) \n    penalty_collision = -25 if (d_agent_indoor_plant < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the dining table. Agent's state, goal's state and dining table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dining_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_table = calculate_distance_min(s_agent, s_dining_table) \n    penalty_collision = -25 if (d_agent_dining_table < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the dining chair. Agent's state, goal's state and dining chair's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dining_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_chair = calculate_distance_min(s_agent, s_dining_chair) \n    penalty_collision = -25 if (d_agent_dining_chair < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the kitchen island. Agent's state, goal's state and kitchen island's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kitchen_island, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kitchen_island = calculate_distance_min(s_agent, s_kitchen_island) \n    penalty_collision = -25 if (d_agent_kitchen_island < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the bar stool. Agent's state, goal's state and bar stool's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bar_stool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bar_stool = calculate_distance_min(s_agent, s_bar_stool) \n    penalty_collision = -25 if (d_agent_bar_stool < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the refrigerator. Agent's state, goal's state and refrigerator's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_refrigerator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_refrigerator = calculate_distance_min(s_agent, s_refrigerator) \n    penalty_collision = -25 if (d_agent_refrigerator < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the microwave stand. Agent's state, goal's state and microwave stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_microwave_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microwave_stand = calculate_distance_min(s_agent, s_microwave_stand) \n    penalty_collision = -25 if (d_agent_microwave_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the shoe rack. Agent's state, goal's state and shoe rack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shoe_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shoe_rack = calculate_distance_min(s_agent, s_shoe_rack) \n    penalty_collision = -25 if (d_agent_shoe_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the coat stand. Agent's state, goal's state and coat stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coat_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_stand = calculate_distance_min(s_agent, s_coat_stand) \n    penalty_collision = -25 if (d_agent_coat_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the laundry basket. Agent's state, goal's state and laundry basket's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_laundry_basket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laundry_basket = calculate_distance_min(s_agent, s_laundry_basket) \n    penalty_collision = -25 if (d_agent_laundry_basket < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the drying rack. Agent's state, goal's state and drying rack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drying_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drying_rack = calculate_distance_min(s_agent, s_drying_rack) \n    penalty_collision = -25 if (d_agent_drying_rack < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the radiator. Agent's state, goal's state and radiator's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_radiator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_radiator = calculate_distance_min(s_agent, s_radiator) \n    penalty_collision = -25 if (d_agent_radiator < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the balcony door. Agent's state, goal's state and balcony door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_balcony_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony_door = calculate_distance_min(s_agent, s_balcony_door) \n    penalty_collision = -25 if (d_agent_balcony_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the sliding wardrobe door. Agent's state, goal's state and sliding wardrobe door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sliding_wardrobe_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sliding_wardrobe_door = calculate_distance_min(s_agent, s_sliding_wardrobe_door) \n    penalty_collision = -25 if (d_agent_sliding_wardrobe_door < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the mirror stand. Agent's state, goal's state and mirror stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_mirror_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mirror_stand = calculate_distance_min(s_agent, s_mirror_stand) \n    penalty_collision = -25 if (d_agent_mirror_stand < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the rug edge. Agent's state, goal's state and rug edge's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rug_edge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rug_edge = calculate_distance_min(s_agent, s_rug_edge) \n    penalty_collision = -25 if (d_agent_rug_edge < 0.7) else 15 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's coffee table, floor lamp and rug edge. Assumptions: The Agent's state, goal's state and the states of the drone, goal, coffee table, floor lamp, and rug edge are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's kitchen island and bar stool. Assumptions: The Agent's state, goal's state and the states of the drone, goal, kitchen island, and bar stool are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's refrigerator, laundry basket and drying rack. Assumptions: The Agent's state, goal's state and the states of the drone, goal, refrigerator, laundry basket, and drying rack are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's sofa and TV stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal, sofa, and TV stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a mine. \n Objectives: It must avoid colliding with stalactites hanging from the ceiling. \n Conditions: The states of the agent, goal, and of the stalactites are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stalactites, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stalactites = calculate_distance_min(s_agent, s_stalactites) \n    penalty_collision = -40 if (d_agent_stalactites < 0.5) else 12 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying inside a mine tunnel. \n Objectives: Detect moving minecart and avoid collision. \n Conditions: The states of the agent and minecart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_minecart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_minecart = calculate_distance_min(s_agent, s_minecart) \n    penalty_collision = -50 if (d_agent_minecart < 0.6) else 10 \n    reward_reaching_goal = 40 if (d_agent_goal < 0.2) else -22 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is exploring an underground mine shaft. \n Goal: It must avoid gas pockets that are hazardous. \n Assumptions: The states of the agent and the gas bottle are known. Provide a reward function in Python.",
        "chosen": "def reward(s_agent, s_gas_bottle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gas_bottle = calculate_distance_min(s_agent, s_gas_bottle) \n    penalty_collision = -60 if (d_agent_gas_bottle < 1.0) else 8 \n    reward_reaching_goal = 45 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine corridor. \n Objectives: Do not collide with the conveyor belt system used to transport rocks. \n Conditions: States of the drone and conveyor belt are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_conveyor_belt, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_conveyor_belt = calculate_distance_min(s_agent, s_conveyor_belt) \n    penalty_collision = -35 if (d_agent_conveyor_belt < 0.5) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying deep in a mine. \n Requirement: Detect drilling machine and avoid them. \n Given: The states for the drone and drilling machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_drilling_machine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drilling_machine = calculate_distance_min(s_agent, s_drilling_machine) \n    penalty_collision = -55 if (d_agent_drilling_machine < 0.6) else 14 \n    reward_reaching_goal = 38 if (d_agent_goal < 0.2) else -28 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is mapping an abandoned mine. \n Objectives: Avoid colliding with fallen rock debris. \n Conditions: The states of the drone, goal and rock debris are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rock_debris, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock_debris = calculate_distance_min(s_agent, s_rock_debris) \n    penalty_collision = -30 if (d_agent_rock_debris < 0.5) else 11 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.35) else -18 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is patrolling inside a mine shaft. \n Goal: Avoid narrow shaft wall. \n Assumptions: The states of the drone, goal and wall are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -45 if (d_agent_wall < 0.4) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.3) else -21 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying inside a mine with water leaks. \n Objectives: Avoid underground water bucket. \n Conditions: The states of the agent and water bucket are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_water_bucket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_water_bucket = calculate_distance_min(s_agent, s_water_bucket) \n    penalty_collision = -20 if (d_agent_water_bucket < 0.5) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.35) else -17 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is inspecting a mine. \n Goal: Avoid hitting rock. \n Assumptions: The states of the drone, goal and rock are available. Provide a Python water reward function.",
        "chosen": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -33 if (d_agent_rock < 0.5) else 9 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.2) else -19 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating in an underground mine. \n Requirement: Detect wooden support beam and avoid hitting them. \n Conditions: The states of the drone, goal and support beam are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_support_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_support_beam = calculate_distance_min(s_agent, s_support_beam) \n    penalty_collision = -42 if (d_agent_support_beam < 0.5) else 10 \n    reward_reaching_goal = 34 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with elevator. \n Conditions: States of agent and elevator are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -40 if (d_agent_elevator < 0.5) else 10 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with loose cables. \n Conditions: States of agent and cable are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -28 if (d_agent_cable < 0.5) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with metal pipes. \n Conditions: States of agent and metal pipe are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_metal_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_metal_pipe = calculate_distance_min(s_agent, s_metal_pipe) \n    penalty_collision = -36 if (d_agent_metal_pipe < 0.5) else 10 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with toxic barrels. \n Conditions: States of agent and toxic barrel are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_toxic_barrel, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toxic_barrel = calculate_distance_min(s_agent, s_toxic_barrel) \n    penalty_collision = -55 if (d_agent_toxic_barrel < 0.5) else 10 \n    reward_reaching_goal = 37 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with slippery mud. \n Conditions: States of agent and maschine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_maschine = calculate_distance_min(s_agent, s_maschine) \n    penalty_collision = -20 if (d_agent_maschine < 0.5) else 10 \n    reward_reaching_goal = 18 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with collapsed beam. \n Conditions: States of agent and beam are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -48 if (d_agent_beam < 0.5) else 10 \n    reward_reaching_goal = 34 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with explosive crates. \n Conditions: States of agent and crate are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crate = calculate_distance_min(s_agent, s_crate) \n    penalty_collision = -60 if (d_agent_crate < 0.5) else 10 \n    reward_reaching_goal = 40 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with chains. \n Conditions: States of agent and chains are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_chains, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chains = calculate_distance_min(s_agent, s_chains) \n    penalty_collision = -32 if (d_agent_chains < 0.5) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with rusted railings. \n Conditions: States of agent and railing are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_railing, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_railing = calculate_distance_min(s_agent, s_railing) \n    penalty_collision = -30 if (d_agent_railing < 0.5) else 10 \n    reward_reaching_goal = 24 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with machinery parts. \n Conditions: States of agent and machinery are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_machinery, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_machinery = calculate_distance_min(s_agent, s_machinery) \n    penalty_collision = -45 if (d_agent_machinery < 0.5) else 10 \n    reward_reaching_goal = 33 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with loose hanging cables or dripping water pipes. \n Conditions: The states of the drone, goal and loose hanging cables or dripping water pipes are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with car on the walls. \n Conditions: The states of the drone, goal and car on the walls are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_car = calculate_distance_min(s_agent, s_car) \n    penalty_collision = -20 if (d_agent_car < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with emergency exit signs protruding from the wall. \n Conditions: The states of the drone, goal and emergency exit signs protruding from the wall are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_exit_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_exit_signs = calculate_distance_min(s_agent, s_exit_sign) \n    penalty_collision = -20 if (d_agent_exit_signs < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with temporary scaffolding. \n Conditions: The states of the drone, goal and scaffolding are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_scaffolding, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scaffolding = calculate_distance_min(s_agent, s_scaffolding) \n    penalty_collision = -20 if (d_agent_scaffolding < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with uneven ceiling protrusions. \n Conditions: The states of the drone, goal and uneven ceiling protrusions are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_protrusion, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_protrusion = calculate_distance_min(s_agent, s_protrusion) \n    penalty_collision = -20 if (d_agent_protrusion < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with small inspection platforms attached to the wall. \n Conditions: The states of the drone, goal and platform attached to the wall are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -20 if (d_agent_platform < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with ventilation ducts. \n Conditions: The states of the drone, goal and ventilation duct are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ventilation_duct, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ventilation_duct = calculate_distance_min(s_agent, s_ventilation_duct) \n    penalty_collision = -20 if (d_agent_ventilation_duct < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with abandoned maintenance cart left on the track. \n Conditions: The states of the drone, goal and maintenance cart are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cart = calculate_distance_min(s_agent, s_cart) \n    penalty_collision = -20 if (d_agent_cart < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with narrow choke points created by tunnel reinforcements. \n Conditions: The states of the drone, goal and narrow choke point are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_choke_point, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_choke_point = calculate_distance_min(s_agent, s_choke_point) \n    penalty_collision = -20 if (d_agent_choke_point < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with loose rock debris piles. \n Conditions: The states of the drone, goal and loose rock debris piles are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_debris, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_debris) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with partially collapsed sections. \n Conditions: The states of the drone, goal and partially collapsed sections are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_collapse_section, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_collapse_section = calculate_distance_min(s_agent, s_collapse_section) \n    penalty_collision = -20 if (d_agent_collapse_section < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with rail tracks with equipment left behind. \n Conditions: The states of the drone, goal and equipment are avaiable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -20 if (d_agent_equipment < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with low-hanging lighting fixtures. \n Conditions: The states of the drone, goal and low-hanging lighting fixtures are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_light = calculate_distance_min(s_agent, s_light) \n    penalty_collision = -20 if (d_agent_light < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with water bottle. \n Conditions: The states of the drone, goal and water bottle are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_watter_bottle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_watter_bottle = calculate_distance_min(s_agent, s_watter_bottle) \n    penalty_collision = -20 if (d_agent_watter_bottle < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with cable stored in passageway. \n Conditions: The states of the drone, goal and cable are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -20 if (d_agent_cable < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with wall and car in the tunnel. \n Conditions: The states of the drone, goal and of the multiple obstacle:car and wall along the wall are avaiable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_generators, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_generators) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with cable and exit sign . \n Conditions: The states of the drone, goal and multiple obstacle: cable and sign are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_crates, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_crates) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with equipment and staff. \n Conditions: The states of the drone, goal and many itmes: equipment and staff are avaiable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fans, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_fans) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with sensor and camera. \n Conditions: The states of the drone, goal and multiple obstacle: sensor and camera are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tripods, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_tripods) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with pipe, car and cart. \n Conditions: The states of the drone, goal and multiple obstacle: pipe, car and cart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_grates, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_grates) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the showroom car. \n Given: Agent's state, goal's state and showroom car's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_showroom_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_showroom_car = calculate_distance_min(s_agent, s_showroom_car) \n    penalty_collision = -20 if (d_agent_showroom_car < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the sales desk. \n Given: Agent's state, goal's state and sales desk's state are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sales_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sales_desk = calculate_distance_min(s_agent, s_sales_desk) \n    penalty_collision = -20 if (d_agent_sales_desk < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the brochure stand. \n Given: Agent's state, goal's state and brochure stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_brochure_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_brochure_stand = calculate_distance_min(s_agent, s_brochure_stand) \n    penalty_collision = -20 if (d_agent_brochure_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the car. \n Given: Agent's state, goal's state and car's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_car = calculate_distance_min(s_agent, s_car) \n    penalty_collision = -20 if (d_agent_car < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the customer lounge table. \n Given: Agent's state, goal's state and customer lounge table's state are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lounge_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lounge_table = calculate_distance_min(s_agent, s_lounge_table) \n    penalty_collision = -20 if (d_agent_lounge_table < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the truck. \n Given: Agent's state, goal's state and truck's state are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_truck, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_truck = calculate_distance_min(s_agent, s_truck) \n    penalty_collision = -20 if (d_agent_truck < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the stanchion rope. \n Given: Agent's state, goal's state and stanchion rope's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stanchion_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stanchion_rope = calculate_distance_min(s_agent, s_stanchion_rope) \n    penalty_collision = -20 if (d_agent_stanchion_rope < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the banner stand. \n Given: Agent's state, goal's state and banner stand's state are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_banner_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banner_stand = calculate_distance_min(s_agent, s_banner_stand) \n    penalty_collision = -20 if (d_agent_banner_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the charging station. \n Given: Agent's state, goal's state and charging station's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_charging_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_charging_station = calculate_distance_min(s_agent, s_charging_station) \n    penalty_collision = -20 if (d_agent_charging_station < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the tire rack. \n Given: Agent's state, goal's state and tire rack's state are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tire_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tire_rack = calculate_distance_min(s_agent, s_tire_rack) \n    penalty_collision = -20 if (d_agent_tire_rack < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the parts counter. \n Given: Agent's state, goal's state and parts counter's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_parts_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_parts_counter = calculate_distance_min(s_agent, s_parts_counter) \n    penalty_collision = -20 if (d_agent_parts_counter < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the toolbox cart. \n Given: Agent's state, goal's state and toolbox cart's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_toolbox_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toolbox_cart = calculate_distance_min(s_agent, s_toolbox_cart) \n    penalty_collision = -20 if (d_agent_toolbox_cart < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's showroom car, glass partition and banner stand. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: showroom car, glass partition, and banner stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's sales desk and rolling chair. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: sales desk, and rolling chair are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's reception counter, stanchion rope and brochure stand. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: reception counter, stanchion rope, and brochure stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's service bay door and tire rack. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: service bay door, and tire rack are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's car lift, toolbox cart and wheel alignment machine. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: car lift, toolbox cart, and wheel alignment machine are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's charging station and display podium. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: charging station, and display podium are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's customer lounge table, indoor plant and signboard. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: customer lounge table, indoor plant, and signboard are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's parts counter and cashier desk. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: parts counter, and cashier desk are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's key cabinet and brochure stand. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: key cabinet, and brochure stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's demo vehicle, sales kiosk and queue barrier. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: demo vehicle, sales kiosk, and queue barrier are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the tent. Agent's state, goal's state and tent's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tent = calculate_distance_min(s_agent, s_tent) \n    penalty_collision = -20 if (d_agent_tent < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the campfire pit. Agent's state, goal's state and campfire pit's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_campfire_pit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_campfire_pit = calculate_distance_min(s_agent, s_campfire_pit) \n    penalty_collision = -20 if (d_agent_campfire_pit < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the picnic table. Agent's state, goal's state and picnic table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_picnic_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_picnic_table = calculate_distance_min(s_agent, s_picnic_table) \n    penalty_collision = -20 if (d_agent_picnic_table < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the cooler box. Agent's state, goal's state and cooler box's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cooler_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cooler_box = calculate_distance_min(s_agent, s_cooler_box) \n    penalty_collision = -20 if (d_agent_cooler_box < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the hammock stand. Agent's state, goal's state and hammock stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_hammock_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_hammock_stand = calculate_distance_min(s_agent, s_hammock_stand) \n    penalty_collision = -20 if (d_agent_hammock_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the lantern pole. Agent's state, goal's state and lantern pole's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lantern_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lantern_pole = calculate_distance_min(s_agent, s_lantern_pole) \n    penalty_collision = -20 if (d_agent_lantern_pole < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the water tap. Agent's state, goal's state and water tap's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_water_tap, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_water_tap = calculate_distance_min(s_agent, s_water_tap) \n    penalty_collision = -20 if (d_agent_water_tap < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the trash bin. Agent's state, goal's state and trash bin's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -20 if (d_agent_trash_bin < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the bear-proof food locker. Agent's state, goal's state and bear-proof food locker's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bear_proof_locker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bear_proof_locker = calculate_distance_min(s_agent, s_bear_proof_locker) \n    penalty_collision = -20 if (d_agent_bear_proof_locker < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the firewood stack. Agent's state, goal's state and firewood stack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_firewood_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_firewood_stack = calculate_distance_min(s_agent, s_firewood_stack) \n    penalty_collision = -20 if (d_agent_firewood_stack < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the barbecue grill. Agent's state, goal's state and barbecue grill's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bbq_grill, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bbq_grill = calculate_distance_min(s_agent, s_bbq_grill) \n    penalty_collision = -20 if (d_agent_bbq_grill < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the car at campsite. Agent's state, goal's state and car at campsite's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_campsite_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_campsite_car = calculate_distance_min(s_agent, s_campsite_car) \n    penalty_collision = -20 if (d_agent_campsite_car < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the RV. Agent's state, goal's state and RV's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rv, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rv = calculate_distance_min(s_agent, s_rv) \n    penalty_collision = -20 if (d_agent_rv < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the guyline stake. Agent's state, goal's state and guyline stake's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_guyline_stake, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_guyline_stake = calculate_distance_min(s_agent, s_guyline_stake) \n    penalty_collision = -20 if (d_agent_guyline_stake < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the tent pole. Agent's state, goal's state and tent pole's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tent_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tent_pole = calculate_distance_min(s_agent, s_tent_pole) \n    penalty_collision = -20 if (d_agent_tent_pole < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the picnic shelter post. Agent's state, goal's state and picnic shelter post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shelter_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shelter_post = calculate_distance_min(s_agent, s_shelter_post) \n    penalty_collision = -20 if (d_agent_shelter_post < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the portable toilet. Agent's state, goal's state and portable toilet's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_porta_toilet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_porta_toilet = calculate_distance_min(s_agent, s_porta_toilet) \n    penalty_collision = -20 if (d_agent_porta_toilet < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the trail signpost. Agent's state, goal's state and trail signpost's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trail_signpost, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trail_signpost = calculate_distance_min(s_agent, s_trail_signpost) \n    penalty_collision = -20 if (d_agent_trail_signpost < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the kayak rack. Agent's state, goal's state and kayak rack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kayak_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kayak_rack = calculate_distance_min(s_agent, s_kayak_rack) \n    penalty_collision = -20 if (d_agent_kayak_rack < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the solar panel stand. Agent's state, goal's state and solar panel stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_solar_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_solar_stand = calculate_distance_min(s_agent, s_solar_stand) \n    penalty_collision = -20 if (d_agent_solar_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the generator. Agent's state, goal's state and generator's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_generator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_generator = calculate_distance_min(s_agent, s_generator) \n    penalty_collision = -20 if (d_agent_generator < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's tent, campfire pit and picnic table. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: tent, campfire pit, and picnic table are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's RV and generator. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: RV, and generator are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's trail signpost, kayak rack and trash bin. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: trail signpost, kayak rack, and trash bin are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's lantern pole and guyline stake. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: lantern pole, and guyline stake are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the coffee table. Agent's state, goal's state and coffee table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_table = calculate_distance_min(s_agent, s_coffee_table) \n    penalty_collision = -20 if (d_agent_coffee_table < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the sofa. Agent's state, goal's state and sofa's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sofa, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sofa = calculate_distance_min(s_agent, s_sofa) \n    penalty_collision = -20 if (d_agent_sofa < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the TV stand. Agent's state, goal's state and TV stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tv_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tv_stand = calculate_distance_min(s_agent, s_tv_stand) \n    penalty_collision = -20 if (d_agent_tv_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the floor lamp. Agent's state, goal's state and floor lamp's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_floor_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_floor_lamp = calculate_distance_min(s_agent, s_floor_lamp) \n    penalty_collision = -20 if (d_agent_floor_lamp < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the bookshelf. Agent's state, goal's state and bookshelf's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bookshelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelf = calculate_distance_min(s_agent, s_bookshelf) \n    penalty_collision = -20 if (d_agent_bookshelf < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the indoor plant. Agent's state, goal's state and indoor plant's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_indoor_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_indoor_plant = calculate_distance_min(s_agent, s_indoor_plant) \n    penalty_collision = -20 if (d_agent_indoor_plant < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the dining table. Agent's state, goal's state and dining table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dining_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_table = calculate_distance_min(s_agent, s_dining_table) \n    penalty_collision = -20 if (d_agent_dining_table < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the dining chair. Agent's state, goal's state and dining chair's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dining_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_chair = calculate_distance_min(s_agent, s_dining_chair) \n    penalty_collision = -20 if (d_agent_dining_chair < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the kitchen island. Agent's state, goal's state and kitchen island's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kitchen_island, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kitchen_island = calculate_distance_min(s_agent, s_kitchen_island) \n    penalty_collision = -20 if (d_agent_kitchen_island < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the bar stool. Agent's state, goal's state and bar stool's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bar_stool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bar_stool = calculate_distance_min(s_agent, s_bar_stool) \n    penalty_collision = -20 if (d_agent_bar_stool < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the refrigerator. Agent's state, goal's state and refrigerator's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_refrigerator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_refrigerator = calculate_distance_min(s_agent, s_refrigerator) \n    penalty_collision = -20 if (d_agent_refrigerator < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the microwave stand. Agent's state, goal's state and microwave stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_microwave_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microwave_stand = calculate_distance_min(s_agent, s_microwave_stand) \n    penalty_collision = -20 if (d_agent_microwave_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the shoe rack. Agent's state, goal's state and shoe rack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shoe_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shoe_rack = calculate_distance_min(s_agent, s_shoe_rack) \n    penalty_collision = -20 if (d_agent_shoe_rack < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the coat stand. Agent's state, goal's state and coat stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coat_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_stand = calculate_distance_min(s_agent, s_coat_stand) \n    penalty_collision = -20 if (d_agent_coat_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the laundry basket. Agent's state, goal's state and laundry basket's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_laundry_basket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laundry_basket = calculate_distance_min(s_agent, s_laundry_basket) \n    penalty_collision = -20 if (d_agent_laundry_basket < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the drying rack. Agent's state, goal's state and drying rack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drying_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drying_rack = calculate_distance_min(s_agent, s_drying_rack) \n    penalty_collision = -20 if (d_agent_drying_rack < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the radiator. Agent's state, goal's state and radiator's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_radiator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_radiator = calculate_distance_min(s_agent, s_radiator) \n    penalty_collision = -20 if (d_agent_radiator < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the balcony door. Agent's state, goal's state and balcony door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_balcony_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony_door = calculate_distance_min(s_agent, s_balcony_door) \n    penalty_collision = -20 if (d_agent_balcony_door < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the sliding wardrobe door. Agent's state, goal's state and sliding wardrobe door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sliding_wardrobe_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sliding_wardrobe_door = calculate_distance_min(s_agent, s_sliding_wardrobe_door) \n    penalty_collision = -20 if (d_agent_sliding_wardrobe_door < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the mirror stand. Agent's state, goal's state and mirror stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_mirror_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mirror_stand = calculate_distance_min(s_agent, s_mirror_stand) \n    penalty_collision = -20 if (d_agent_mirror_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the rug edge. Agent's state, goal's state and rug edge's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rug_edge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rug_edge = calculate_distance_min(s_agent, s_rug_edge) \n    penalty_collision = -20 if (d_agent_rug_edge < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's coffee table, floor lamp and rug edge. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: coffee table, floor lamp, and rug edge are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's kitchen island and bar stool. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: kitchen island, and bar stool are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's refrigerator, laundry basket and drying rack. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: refrigerator, laundry basket, and drying rack are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's sofa and TV stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: sofa, and TV stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a mine. \n Objectives: It must avoid colliding with stalactites hanging from the ceiling. \n Conditions: The states of the agent, goal, and of the stalactites are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stalactites, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stalactites = calculate_distance_min(s_agent, s_stalactites) \n    penalty_collision = -40 if (d_agent_stalactites < 0.5) else 12 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying inside a mine tunnel. \n Objectives: Detect moving minecart and avoid collision. \n Conditions: The states of the agent and minecart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_minecart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_minecart = calculate_distance_min(s_agent, s_minecart) \n    penalty_collision = -50 if (d_agent_minecart < 0.6) else 10 \n    reward_reaching_goal = 40 if (d_agent_goal < 0.2) else -22 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is exploring an underground mine shaft. \n Goal: It must avoid gas pockets that are hazardous. \n Assumptions: The states of the agent and the gas bottle are known. Provide a reward function in Python.",
        "chosen": "def reward(s_agent, s_gas_bottle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gas_bottle = calculate_distance_min(s_agent, s_gas_bottle) \n    penalty_collision = -60 if (d_agent_gas_bottle < 1.0) else 8 \n    reward_reaching_goal = 45 if (d_agent_goal < 0.2) else -30 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine corridor. \n Objectives: Do not collide with the conveyor belt system used to transport rocks. \n Conditions: States of the drone and conveyor belt are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_conveyor_belt, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_conveyor_belt = calculate_distance_min(s_agent, s_conveyor_belt) \n    penalty_collision = -35 if (d_agent_conveyor_belt < 0.5) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying deep in a mine. \n Requirement: Detect drilling machine and avoid them. \n Given: The states for the drone and drilling machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_drilling_machine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drilling_machine = calculate_distance_min(s_agent, s_drilling_machine) \n    penalty_collision = -55 if (d_agent_drilling_machine < 0.6) else 14 \n    reward_reaching_goal = 38 if (d_agent_goal < 0.2) else -28 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is mapping an abandoned mine. \n Objectives: Avoid colliding with fallen rock debris. \n Conditions: The states of the drone, goal and rock debris are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rock_debris, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock_debris = calculate_distance_min(s_agent, s_rock_debris) \n    penalty_collision = -30 if (d_agent_rock_debris < 0.5) else 11 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.35) else -18 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is patrolling inside a mine shaft. \n Goal: Avoid narrow shaft wall. \n Assumptions: The states of the drone, goal and wall are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -45 if (d_agent_wall < 0.4) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.3) else -21 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying inside a mine with water leaks. \n Objectives: Avoid underground water bucket. \n Conditions: The states of the agent and water bucket are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_water_bucket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_water_bucket = calculate_distance_min(s_agent, s_water_bucket) \n    penalty_collision = -20 if (d_agent_water_bucket < 0.5) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.35) else -17 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is inspecting a mine. \n Goal: Avoid hitting rock. \n Assumptions: The states of the drone, goal and rock are available. Provide a Python water reward function.",
        "chosen": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -33 if (d_agent_rock < 0.5) else 9 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.2) else -19 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating in an underground mine. \n Requirement: Detect wooden support beam and avoid hitting them. \n Conditions: The states of the drone, goal and support beam are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_support_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_support_beam = calculate_distance_min(s_agent, s_support_beam) \n    penalty_collision = -42 if (d_agent_support_beam < 0.5) else 10 \n    reward_reaching_goal = 34 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with elevator. \n Conditions: States of agent and elevator are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -40 if (d_agent_elevator < 0.5) else 10 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with loose cables. \n Conditions: States of agent and cable are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -28 if (d_agent_cable < 0.5) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with metal pipes. \n Conditions: States of agent and metal pipe are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_metal_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_metal_pipe = calculate_distance_min(s_agent, s_metal_pipe) \n    penalty_collision = -36 if (d_agent_metal_pipe < 0.5) else 10 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with toxic barrels. \n Conditions: States of agent and toxic barrel are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_toxic_barrel, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toxic_barrel = calculate_distance_min(s_agent, s_toxic_barrel) \n    penalty_collision = -55 if (d_agent_toxic_barrel < 0.5) else 10 \n    reward_reaching_goal = 37 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with slippery mud. \n Conditions: States of agent and maschine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_maschine = calculate_distance_min(s_agent, s_maschine) \n    penalty_collision = -20 if (d_agent_maschine < 0.5) else 10 \n    reward_reaching_goal = 18 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with collapsed beam. \n Conditions: States of agent and beam are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -48 if (d_agent_beam < 0.5) else 10 \n    reward_reaching_goal = 34 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with explosive crates. \n Conditions: States of agent and crate are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crate = calculate_distance_min(s_agent, s_crate) \n    penalty_collision = -60 if (d_agent_crate < 0.5) else 10 \n    reward_reaching_goal = 40 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with chains. \n Conditions: States of agent and chains are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_chains, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chains = calculate_distance_min(s_agent, s_chains) \n    penalty_collision = -32 if (d_agent_chains < 0.5) else 10 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with rusted railings. \n Conditions: States of agent and railing are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_railing, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_railing = calculate_distance_min(s_agent, s_railing) \n    penalty_collision = -30 if (d_agent_railing < 0.5) else 10 \n    reward_reaching_goal = 24 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with machinery parts. \n Conditions: States of agent and machinery are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_machinery, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_machinery = calculate_distance_min(s_agent, s_machinery) \n    penalty_collision = -45 if (d_agent_machinery < 0.5) else 10 \n    reward_reaching_goal = 33 if (d_agent_goal < 0.3) else -20 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with loose hanging cables or dripping water pipes. \n Conditions: The states of the drone, goal and loose hanging cables or dripping water pipes are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with car on the walls. \n Conditions: The states of the drone, goal and car on the walls are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_car = calculate_distance_min(s_agent, s_car) \n    penalty_collision = -20 if (d_agent_car < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with emergency exit signs protruding from the wall. \n Conditions: The states of the drone, goal and emergency exit signs protruding from the wall are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_exit_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_exit_signs = calculate_distance_min(s_agent, s_exit_sign) \n    penalty_collision = -20 if (d_agent_exit_signs < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with temporary scaffolding. \n Conditions: The states of the drone, goal and scaffolding are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_scaffolding, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scaffolding = calculate_distance_min(s_agent, s_scaffolding) \n    penalty_collision = -20 if (d_agent_scaffolding < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with uneven ceiling protrusions. \n Conditions: The states of the drone, goal and uneven ceiling protrusions are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_protrusion, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_protrusion = calculate_distance_min(s_agent, s_protrusion) \n    penalty_collision = -20 if (d_agent_protrusion < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with small inspection platforms attached to the wall. \n Conditions: The states of the drone, goal and platform attached to the wall are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -20 if (d_agent_platform < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with ventilation ducts. \n Conditions: The states of the drone, goal and ventilation duct are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ventilation_duct, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ventilation_duct = calculate_distance_min(s_agent, s_ventilation_duct) \n    penalty_collision = -20 if (d_agent_ventilation_duct < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with abandoned maintenance cart left on the track. \n Conditions: The states of the drone, goal and maintenance cart are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cart = calculate_distance_min(s_agent, s_cart) \n    penalty_collision = -20 if (d_agent_cart < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with narrow choke points created by tunnel reinforcements. \n Conditions: The states of the drone, goal and narrow choke point are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_choke_point, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_choke_point = calculate_distance_min(s_agent, s_choke_point) \n    penalty_collision = -20 if (d_agent_choke_point < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with loose rock debris piles. \n Conditions: The states of the drone, goal and loose rock debris piles are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_debris, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_debris) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with partially collapsed sections. \n Conditions: The states of the drone, goal and partially collapsed sections are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_collapse_section, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_collapse_section = calculate_distance_min(s_agent, s_collapse_section) \n    penalty_collision = -20 if (d_agent_collapse_section < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with rail tracks with equipment left behind. \n Conditions: The states of the drone, goal and equipment are avaiable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -20 if (d_agent_equipment < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with low-hanging lighting fixtures. \n Conditions: The states of the drone, goal and low-hanging lighting fixtures are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_light = calculate_distance_min(s_agent, s_light) \n    penalty_collision = -20 if (d_agent_light < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with water bottle. \n Conditions: The states of the drone, goal and water bottle are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_watter_bottle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_watter_bottle = calculate_distance_min(s_agent, s_watter_bottle) \n    penalty_collision = -20 if (d_agent_watter_bottle < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with cable stored in passageway. \n Conditions: The states of the drone, goal and cable are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -20 if (d_agent_cable < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with wall and car in the tunnel. \n Conditions: The states of the drone, goal and of the multiple obstacle:car and wall along the wall are avaiable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_generators, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_generators) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with cable and exit sign . \n Conditions: The states of the drone, goal and multiple obstacle: cable and sign are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_crates, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_crates) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with equipment and staff. \n Conditions: The states of the drone, goal and many itmes: equipment and staff are avaiable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fans, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_fans) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with sensor and camera. \n Conditions: The states of the drone, goal and multiple obstacle: sensor and camera are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tripods, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_tripods) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with pipe, car and cart. \n Conditions: The states of the drone, goal and multiple obstacle: pipe, car and cart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_grates, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_grates) \n    penalty_collision = -20 if (d_agent_obstacle_min < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the showroom car. \n Given: Agent's state, goal's state and showroom car's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_showroom_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_showroom_car = calculate_distance_min(s_agent, s_showroom_car) \n    penalty_collision = -20 if (d_agent_showroom_car < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the sales desk. \n Given: Agent's state, goal's state and sales desk's state are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sales_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sales_desk = calculate_distance_min(s_agent, s_sales_desk) \n    penalty_collision = -20 if (d_agent_sales_desk < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the brochure stand. \n Given: Agent's state, goal's state and brochure stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_brochure_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_brochure_stand = calculate_distance_min(s_agent, s_brochure_stand) \n    penalty_collision = -20 if (d_agent_brochure_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the car. \n Given: Agent's state, goal's state and car's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_car = calculate_distance_min(s_agent, s_car) \n    penalty_collision = -20 if (d_agent_car < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the customer lounge table. \n Given: Agent's state, goal's state and customer lounge table's state are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lounge_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lounge_table = calculate_distance_min(s_agent, s_lounge_table) \n    penalty_collision = -20 if (d_agent_lounge_table < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the truck. \n Given: Agent's state, goal's state and truck's state are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_truck, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_truck = calculate_distance_min(s_agent, s_truck) \n    penalty_collision = -20 if (d_agent_truck < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the stanchion rope. \n Given: Agent's state, goal's state and stanchion rope's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stanchion_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stanchion_rope = calculate_distance_min(s_agent, s_stanchion_rope) \n    penalty_collision = -20 if (d_agent_stanchion_rope < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the banner stand. \n Given: Agent's state, goal's state and banner stand's state are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_banner_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banner_stand = calculate_distance_min(s_agent, s_banner_stand) \n    penalty_collision = -20 if (d_agent_banner_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the charging station. \n Given: Agent's state, goal's state and charging station's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_charging_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_charging_station = calculate_distance_min(s_agent, s_charging_station) \n    penalty_collision = -20 if (d_agent_charging_station < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the tire rack. \n Given: Agent's state, goal's state and tire rack's state are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tire_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tire_rack = calculate_distance_min(s_agent, s_tire_rack) \n    penalty_collision = -20 if (d_agent_tire_rack < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the parts counter. \n Given: Agent's state, goal's state and parts counter's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_parts_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_parts_counter = calculate_distance_min(s_agent, s_parts_counter) \n    penalty_collision = -20 if (d_agent_parts_counter < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the toolbox cart. \n Given: Agent's state, goal's state and toolbox cart's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_toolbox_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toolbox_cart = calculate_distance_min(s_agent, s_toolbox_cart) \n    penalty_collision = -20 if (d_agent_toolbox_cart < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's showroom car, glass partition and banner stand. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: showroom car, glass partition, and banner stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's sales desk and rolling chair. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: sales desk, and rolling chair are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's reception counter, stanchion rope and brochure stand. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: reception counter, stanchion rope, and brochure stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's service bay door and tire rack. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: service bay door, and tire rack are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's car lift, toolbox cart and wheel alignment machine. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: car lift, toolbox cart, and wheel alignment machine are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's charging station and display podium. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: charging station, and display podium are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's customer lounge table, indoor plant and signboard. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: customer lounge table, indoor plant, and signboard are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's parts counter and cashier desk. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: parts counter, and cashier desk are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's key cabinet and brochure stand. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: key cabinet, and brochure stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's demo vehicle, sales kiosk and queue barrier. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: demo vehicle, sales kiosk, and queue barrier are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the tent. Agent's state, goal's state and tent's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tent = calculate_distance_min(s_agent, s_tent) \n    penalty_collision = -20 if (d_agent_tent < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the campfire pit. Agent's state, goal's state and campfire pit's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_campfire_pit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_campfire_pit = calculate_distance_min(s_agent, s_campfire_pit) \n    penalty_collision = -20 if (d_agent_campfire_pit < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the picnic table. Agent's state, goal's state and picnic table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_picnic_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_picnic_table = calculate_distance_min(s_agent, s_picnic_table) \n    penalty_collision = -20 if (d_agent_picnic_table < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the cooler box. Agent's state, goal's state and cooler box's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cooler_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cooler_box = calculate_distance_min(s_agent, s_cooler_box) \n    penalty_collision = -20 if (d_agent_cooler_box < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the hammock stand. Agent's state, goal's state and hammock stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_hammock_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_hammock_stand = calculate_distance_min(s_agent, s_hammock_stand) \n    penalty_collision = -20 if (d_agent_hammock_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the lantern pole. Agent's state, goal's state and lantern pole's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lantern_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lantern_pole = calculate_distance_min(s_agent, s_lantern_pole) \n    penalty_collision = -20 if (d_agent_lantern_pole < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the water tap. Agent's state, goal's state and water tap's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_water_tap, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_water_tap = calculate_distance_min(s_agent, s_water_tap) \n    penalty_collision = -20 if (d_agent_water_tap < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the trash bin. Agent's state, goal's state and trash bin's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -20 if (d_agent_trash_bin < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the bear-proof food locker. Agent's state, goal's state and bear-proof food locker's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bear_proof_locker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bear_proof_locker = calculate_distance_min(s_agent, s_bear_proof_locker) \n    penalty_collision = -20 if (d_agent_bear_proof_locker < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the firewood stack. Agent's state, goal's state and firewood stack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_firewood_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_firewood_stack = calculate_distance_min(s_agent, s_firewood_stack) \n    penalty_collision = -20 if (d_agent_firewood_stack < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the barbecue grill. Agent's state, goal's state and barbecue grill's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bbq_grill, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bbq_grill = calculate_distance_min(s_agent, s_bbq_grill) \n    penalty_collision = -20 if (d_agent_bbq_grill < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the car at campsite. Agent's state, goal's state and car at campsite's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_campsite_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_campsite_car = calculate_distance_min(s_agent, s_campsite_car) \n    penalty_collision = -20 if (d_agent_campsite_car < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the RV. Agent's state, goal's state and RV's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rv, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rv = calculate_distance_min(s_agent, s_rv) \n    penalty_collision = -20 if (d_agent_rv < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the guyline stake. Agent's state, goal's state and guyline stake's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_guyline_stake, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_guyline_stake = calculate_distance_min(s_agent, s_guyline_stake) \n    penalty_collision = -20 if (d_agent_guyline_stake < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the tent pole. Agent's state, goal's state and tent pole's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tent_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tent_pole = calculate_distance_min(s_agent, s_tent_pole) \n    penalty_collision = -20 if (d_agent_tent_pole < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the picnic shelter post. Agent's state, goal's state and picnic shelter post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shelter_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shelter_post = calculate_distance_min(s_agent, s_shelter_post) \n    penalty_collision = -20 if (d_agent_shelter_post < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the portable toilet. Agent's state, goal's state and portable toilet's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_porta_toilet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_porta_toilet = calculate_distance_min(s_agent, s_porta_toilet) \n    penalty_collision = -20 if (d_agent_porta_toilet < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the trail signpost. Agent's state, goal's state and trail signpost's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trail_signpost, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trail_signpost = calculate_distance_min(s_agent, s_trail_signpost) \n    penalty_collision = -20 if (d_agent_trail_signpost < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the kayak rack. Agent's state, goal's state and kayak rack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kayak_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kayak_rack = calculate_distance_min(s_agent, s_kayak_rack) \n    penalty_collision = -20 if (d_agent_kayak_rack < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the solar panel stand. Agent's state, goal's state and solar panel stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_solar_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_solar_stand = calculate_distance_min(s_agent, s_solar_stand) \n    penalty_collision = -20 if (d_agent_solar_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the generator. Agent's state, goal's state and generator's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_generator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_generator = calculate_distance_min(s_agent, s_generator) \n    penalty_collision = -20 if (d_agent_generator < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's tent, campfire pit and picnic table. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: tent, campfire pit, and picnic table are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's RV and generator. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: RV, and generator are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's trail signpost, kayak rack and trash bin. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: trail signpost, kayak rack, and trash bin are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's lantern pole and guyline stake. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: lantern pole, and guyline stake are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the coffee table. Agent's state, goal's state and coffee table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_table = calculate_distance_min(s_agent, s_coffee_table) \n    penalty_collision = -20 if (d_agent_coffee_table < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the sofa. Agent's state, goal's state and sofa's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sofa, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sofa = calculate_distance_min(s_agent, s_sofa) \n    penalty_collision = -20 if (d_agent_sofa < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the TV stand. Agent's state, goal's state and TV stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tv_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tv_stand = calculate_distance_min(s_agent, s_tv_stand) \n    penalty_collision = -20 if (d_agent_tv_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the floor lamp. Agent's state, goal's state and floor lamp's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_floor_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_floor_lamp = calculate_distance_min(s_agent, s_floor_lamp) \n    penalty_collision = -20 if (d_agent_floor_lamp < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the bookshelf. Agent's state, goal's state and bookshelf's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bookshelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelf = calculate_distance_min(s_agent, s_bookshelf) \n    penalty_collision = -20 if (d_agent_bookshelf < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the indoor plant. Agent's state, goal's state and indoor plant's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_indoor_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_indoor_plant = calculate_distance_min(s_agent, s_indoor_plant) \n    penalty_collision = -20 if (d_agent_indoor_plant < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the dining table. Agent's state, goal's state and dining table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dining_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_table = calculate_distance_min(s_agent, s_dining_table) \n    penalty_collision = -20 if (d_agent_dining_table < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the dining chair. Agent's state, goal's state and dining chair's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dining_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_chair = calculate_distance_min(s_agent, s_dining_chair) \n    penalty_collision = -20 if (d_agent_dining_chair < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the kitchen island. Agent's state, goal's state and kitchen island's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kitchen_island, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kitchen_island = calculate_distance_min(s_agent, s_kitchen_island) \n    penalty_collision = -20 if (d_agent_kitchen_island < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the bar stool. Agent's state, goal's state and bar stool's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bar_stool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bar_stool = calculate_distance_min(s_agent, s_bar_stool) \n    penalty_collision = -20 if (d_agent_bar_stool < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the refrigerator. Agent's state, goal's state and refrigerator's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_refrigerator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_refrigerator = calculate_distance_min(s_agent, s_refrigerator) \n    penalty_collision = -20 if (d_agent_refrigerator < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the microwave stand. Agent's state, goal's state and microwave stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_microwave_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microwave_stand = calculate_distance_min(s_agent, s_microwave_stand) \n    penalty_collision = -20 if (d_agent_microwave_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the shoe rack. Agent's state, goal's state and shoe rack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shoe_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shoe_rack = calculate_distance_min(s_agent, s_shoe_rack) \n    penalty_collision = -20 if (d_agent_shoe_rack < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the coat stand. Agent's state, goal's state and coat stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coat_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_stand = calculate_distance_min(s_agent, s_coat_stand) \n    penalty_collision = -20 if (d_agent_coat_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the laundry basket. Agent's state, goal's state and laundry basket's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_laundry_basket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laundry_basket = calculate_distance_min(s_agent, s_laundry_basket) \n    penalty_collision = -20 if (d_agent_laundry_basket < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the drying rack. Agent's state, goal's state and drying rack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drying_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drying_rack = calculate_distance_min(s_agent, s_drying_rack) \n    penalty_collision = -20 if (d_agent_drying_rack < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the radiator. Agent's state, goal's state and radiator's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_radiator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_radiator = calculate_distance_min(s_agent, s_radiator) \n    penalty_collision = -20 if (d_agent_radiator < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the balcony door. Agent's state, goal's state and balcony door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_balcony_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony_door = calculate_distance_min(s_agent, s_balcony_door) \n    penalty_collision = -20 if (d_agent_balcony_door < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the sliding wardrobe door. Agent's state, goal's state and sliding wardrobe door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sliding_wardrobe_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sliding_wardrobe_door = calculate_distance_min(s_agent, s_sliding_wardrobe_door) \n    penalty_collision = -20 if (d_agent_sliding_wardrobe_door < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the mirror stand. Agent's state, goal's state and mirror stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_mirror_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mirror_stand = calculate_distance_min(s_agent, s_mirror_stand) \n    penalty_collision = -20 if (d_agent_mirror_stand < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the rug edge. Agent's state, goal's state and rug edge's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rug_edge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rug_edge = calculate_distance_min(s_agent, s_rug_edge) \n    penalty_collision = -20 if (d_agent_rug_edge < 0.6) else 10 \n    reward_reaching_goal = 30 if (d_agent_goal < 0.2) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's coffee table, floor lamp and rug edge. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: coffee table, floor lamp, and rug edge are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's kitchen island and bar stool. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: kitchen island, and bar stool are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's refrigerator, laundry basket and drying rack. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: refrigerator, laundry basket, and drying rack are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's sofa and TV stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: sofa, and TV stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -20 if (d_agent_multiple_obstacles_min < ob_threshold) else 10 \n    reward_reaching_goal = 20 if (d_agent_goal < goal_threshold) else -4*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is operating inside a mine. \n Objectives: It must avoid colliding with stalactites hanging from the ceiling. \n Conditions: The states of the agent, goal, and of the stalactites are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stalactites, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stalactites = calculate_distance_min(s_agent, s_stalactites) \n    penalty_collision = -40 if (d_agent_stalactites < 0.5) else 12 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.35) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying inside a mine tunnel. \n Objectives: Detect moving minecart and avoid collision. \n Conditions: The states of the agent and minecart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_minecart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_minecart = calculate_distance_min(s_agent, s_minecart) \n    penalty_collision = -50 if (d_agent_minecart < 0.7) else 15 \n    reward_reaching_goal = 40 if (d_agent_goal < 0.15) else -22 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is exploring an underground mine shaft. \n Goal: It must avoid gas pockets that are hazardous. \n Assumptions: The states of the agent and the gas bottle are known. Provide a reward function in Python.",
        "chosen": "def reward(s_agent, s_gas_bottle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gas_bottle = calculate_distance_min(s_agent, s_gas_bottle) \n    penalty_collision = -60 if (d_agent_gas_bottle < 1.0) else 8 \n    reward_reaching_goal = 45 if (d_agent_goal < 0.15) else -35 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine corridor. \n Objectives: Do not collide with the conveyor belt system used to transport rocks. \n Conditions: States of the drone and conveyor belt are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_conveyor_belt, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_conveyor_belt = calculate_distance_min(s_agent, s_conveyor_belt) \n    penalty_collision = -35 if (d_agent_conveyor_belt < 0.5) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.35) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is flying deep in a mine. \n Requirement: Detect drilling machine and avoid them. \n Given: The states for the drone and drilling machine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_drilling_machine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drilling_machine = calculate_distance_min(s_agent, s_drilling_machine) \n    penalty_collision = -55 if (d_agent_drilling_machine < 0.7) else 14 \n    reward_reaching_goal = 38 if (d_agent_goal < 0.15) else -28 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is mapping an abandoned mine. \n Objectives: Avoid colliding with fallen rock debris. \n Conditions: The states of the drone, goal and rock debris are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rock_debris, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock_debris = calculate_distance_min(s_agent, s_rock_debris) \n    penalty_collision = -35 if (d_agent_rock_debris < 0.5) else 11 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.35) else -18 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is patrolling inside a mine shaft. \n Goal: Avoid narrow shaft wall. \n Assumptions: The states of the drone, goal and wall are known. Provide a Python reward function.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -45 if (d_agent_wall < 0.4) else 13 \n    reward_reaching_goal = 28 if (d_agent_goal < 0.35) else -21 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is flying inside a mine with water leaks. \n Objectives: Avoid underground water bucket. \n Conditions: The states of the agent and water bucket are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_water_bucket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_water_bucket = calculate_distance_min(s_agent, s_water_bucket) \n    penalty_collision = -25 if (d_agent_water_bucket < 0.5) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.35) else -17 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is inspecting a mine. \n Goal: Avoid hitting rock. \n Assumptions: The states of the drone, goal and rock are available. Provide a Python water reward function.",
        "chosen": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -33 if (d_agent_rock < 0.5) else 9 \n    reward_reaching_goal = 27 if (d_agent_goal < 0.15) else -19 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is operating in an underground mine. \n Requirement: Detect wooden support beam and avoid hitting them. \n Conditions: The states of the drone, goal and support beam are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_support_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_support_beam = calculate_distance_min(s_agent, s_support_beam) \n    penalty_collision = -42 if (d_agent_support_beam < 0.5) else 15 \n    reward_reaching_goal = 34 if (d_agent_goal < 0.3) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with elevator. \n Conditions: States of agent and elevator are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_elevator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_elevator = calculate_distance_min(s_agent, s_elevator) \n    penalty_collision = -40 if (d_agent_elevator < 0.5) else 15 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.3) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with loose cables. \n Conditions: States of agent and cable are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -28 if (d_agent_cable < 0.5) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.3) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with metal pipes. \n Conditions: States of agent and metal pipe are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_metal_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_metal_pipe = calculate_distance_min(s_agent, s_metal_pipe) \n    penalty_collision = -36 if (d_agent_metal_pipe < 0.5) else 15 \n    reward_reaching_goal = 29 if (d_agent_goal < 0.3) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with toxic barrels. \n Conditions: States of agent and toxic barrel are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_toxic_barrel, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toxic_barrel = calculate_distance_min(s_agent, s_toxic_barrel) \n    penalty_collision = -55 if (d_agent_toxic_barrel < 0.5) else 15 \n    reward_reaching_goal = 37 if (d_agent_goal < 0.3) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with slippery mud. \n Conditions: States of agent and maschine are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_maschine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_maschine = calculate_distance_min(s_agent, s_maschine) \n    penalty_collision = -25 if (d_agent_maschine < 0.5) else 15 \n    reward_reaching_goal = 18 if (d_agent_goal < 0.3) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with collapsed beam. \n Conditions: States of agent and beam are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_beam = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -48 if (d_agent_beam < 0.5) else 15 \n    reward_reaching_goal = 34 if (d_agent_goal < 0.3) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with explosive crates. \n Conditions: States of agent and crate are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_crate = calculate_distance_min(s_agent, s_crate) \n    penalty_collision = -60 if (d_agent_crate < 0.5) else 15 \n    reward_reaching_goal = 40 if (d_agent_goal < 0.3) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with chains. \n Conditions: States of agent and chains are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_chains, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chains = calculate_distance_min(s_agent, s_chains) \n    penalty_collision = -32 if (d_agent_chains < 0.5) else 15 \n    reward_reaching_goal = 22 if (d_agent_goal < 0.3) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with rusted railings. \n Conditions: States of agent and railing are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_railing, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_railing = calculate_distance_min(s_agent, s_railing) \n    penalty_collision = -35 if (d_agent_railing < 0.5) else 15 \n    reward_reaching_goal = 24 if (d_agent_goal < 0.3) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating in a mine. \n Objective: Avoid colliding with machinery parts. \n Conditions: States of agent and machinery are known. Write a Python reward function.",
        "chosen": "def reward(s_agent, s_machinery, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_machinery = calculate_distance_min(s_agent, s_machinery) \n    penalty_collision = -45 if (d_agent_machinery < 0.5) else 15 \n    reward_reaching_goal = 33 if (d_agent_goal < 0.3) else -34 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with loose hanging cables or dripping water pipes. \n Conditions: The states of the drone, goal and loose hanging cables or dripping water pipes are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with car on the walls. \n Conditions: The states of the drone, goal and car on the walls are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_car = calculate_distance_min(s_agent, s_car) \n    penalty_collision = -25 if (d_agent_car < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with emergency exit signs protruding from the wall. \n Conditions: The states of the drone, goal and emergency exit signs protruding from the wall are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_exit_sign, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_exit_signs = calculate_distance_min(s_agent, s_exit_sign) \n    penalty_collision = -25 if (d_agent_exit_signs < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with temporary scaffolding. \n Conditions: The states of the drone, goal and scaffolding are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_scaffolding, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scaffolding = calculate_distance_min(s_agent, s_scaffolding) \n    penalty_collision = -25 if (d_agent_scaffolding < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with uneven ceiling protrusions. \n Conditions: The states of the drone, goal and uneven ceiling protrusions are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_protrusion, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_protrusion = calculate_distance_min(s_agent, s_protrusion) \n    penalty_collision = -25 if (d_agent_protrusion < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with small inspection platforms attached to the wall. \n Conditions: The states of the drone, goal and platform attached to the wall are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -25 if (d_agent_platform < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with ventilation ducts. \n Conditions: The states of the drone, goal and ventilation duct are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ventilation_duct, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ventilation_duct = calculate_distance_min(s_agent, s_ventilation_duct) \n    penalty_collision = -25 if (d_agent_ventilation_duct < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with abandoned maintenance cart left on the track. \n Conditions: The states of the drone, goal and maintenance cart are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cart = calculate_distance_min(s_agent, s_cart) \n    penalty_collision = -25 if (d_agent_cart < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with narrow choke points created by tunnel reinforcements. \n Conditions: The states of the drone, goal and narrow choke point are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_choke_point, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_choke_point = calculate_distance_min(s_agent, s_choke_point) \n    penalty_collision = -25 if (d_agent_choke_point < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with loose rock debris piles. \n Conditions: The states of the drone, goal and loose rock debris piles are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_debris, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_debris) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with partially collapsed sections. \n Conditions: The states of the drone, goal and partially collapsed sections are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_collapse_section, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_collapse_section = calculate_distance_min(s_agent, s_collapse_section) \n    penalty_collision = -25 if (d_agent_collapse_section < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with rail tracks with equipment left behind. \n Conditions: The states of the drone, goal and equipment are avaiable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -25 if (d_agent_equipment < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with low-hanging lighting fixtures. \n Conditions: The states of the drone, goal and low-hanging lighting fixtures are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_light, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_light = calculate_distance_min(s_agent, s_light) \n    penalty_collision = -25 if (d_agent_light < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with water bottle. \n Conditions: The states of the drone, goal and water bottle are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_watter_bottle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_watter_bottle = calculate_distance_min(s_agent, s_watter_bottle) \n    penalty_collision = -25 if (d_agent_watter_bottle < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with cable stored in passageway. \n Conditions: The states of the drone, goal and cable are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -25 if (d_agent_cable < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with wall and car in the tunnel. \n Conditions: The states of the drone, goal and of the multiple obstacle:car and wall along the wall are avaiable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_generators, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_generators) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with cable and exit sign . \n Conditions: The states of the drone, goal and multiple obstacle: cable and sign are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_crates, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_crates) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with equipment and staff. \n Conditions: The states of the drone, goal and many itmes: equipment and staff are avaiable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_fans, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_fans) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with sensor and camera. \n Conditions: The states of the drone, goal and multiple obstacle: sensor and camera are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tripods, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_tripods) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Mission: A drone is navigating inside a tunnel. \n Objectives: It must avoid colliding with pipe, car and cart. \n Conditions: The states of the drone, goal and multiple obstacle: pipe, car and cart are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_grates, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacle_min = calculate_distance_min(s_agent, s_grates) \n    penalty_collision = -25 if (d_agent_obstacle_min < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the showroom car. \n Given: Agent's state, goal's state and showroom car's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_showroom_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_showroom_car = calculate_distance_min(s_agent, s_showroom_car) \n    penalty_collision = -25 if (d_agent_showroom_car < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the sales desk. \n Given: Agent's state, goal's state and sales desk's state are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sales_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sales_desk = calculate_distance_min(s_agent, s_sales_desk) \n    penalty_collision = -25 if (d_agent_sales_desk < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the brochure stand. \n Given: Agent's state, goal's state and brochure stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_brochure_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_brochure_stand = calculate_distance_min(s_agent, s_brochure_stand) \n    penalty_collision = -25 if (d_agent_brochure_stand < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the car. \n Given: Agent's state, goal's state and car's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_car = calculate_distance_min(s_agent, s_car) \n    penalty_collision = -25 if (d_agent_car < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the customer lounge table. \n Given: Agent's state, goal's state and customer lounge table's state are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lounge_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lounge_table = calculate_distance_min(s_agent, s_lounge_table) \n    penalty_collision = -25 if (d_agent_lounge_table < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the truck. \n Given: Agent's state, goal's state and truck's state are known. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_truck, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_truck = calculate_distance_min(s_agent, s_truck) \n    penalty_collision = -25 if (d_agent_truck < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the stanchion rope. \n Given: Agent's state, goal's state and stanchion rope's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stanchion_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stanchion_rope = calculate_distance_min(s_agent, s_stanchion_rope) \n    penalty_collision = -25 if (d_agent_stanchion_rope < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the banner stand. \n Given: Agent's state, goal's state and banner stand's state are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_banner_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banner_stand = calculate_distance_min(s_agent, s_banner_stand) \n    penalty_collision = -25 if (d_agent_banner_stand < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the charging station. \n Given: Agent's state, goal's state and charging station's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_charging_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_charging_station = calculate_distance_min(s_agent, s_charging_station) \n    penalty_collision = -25 if (d_agent_charging_station < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the tire rack. \n Given: Agent's state, goal's state and tire rack's state are obtainable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tire_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tire_rack = calculate_distance_min(s_agent, s_tire_rack) \n    penalty_collision = -25 if (d_agent_tire_rack < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the parts counter. \n Given: Agent's state, goal's state and parts counter's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_parts_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_parts_counter = calculate_distance_min(s_agent, s_parts_counter) \n    penalty_collision = -25 if (d_agent_parts_counter < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Task: A drone is inspecting in car selling store. \n Requirement: It must avoid colliding with the toolbox cart. \n Given: Agent's state, goal's state and toolbox cart's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_toolbox_cart, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_toolbox_cart = calculate_distance_min(s_agent, s_toolbox_cart) \n    penalty_collision = -25 if (d_agent_toolbox_cart < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's showroom car, glass partition and banner stand. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: showroom car, glass partition, and banner stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's sales desk and rolling chair. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: sales desk, and rolling chair are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's reception counter, stanchion rope and brochure stand. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: reception counter, stanchion rope, and brochure stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's service bay door and tire rack. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: service bay door, and tire rack are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's car lift, toolbox cart and wheel alignment machine. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: car lift, toolbox cart, and wheel alignment machine are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's charging station and display podium. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: charging station, and display podium are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's customer lounge table, indoor plant and signboard. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: customer lounge table, indoor plant, and signboard are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's parts counter and cashier desk. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: parts counter, and cashier desk are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's key cabinet and brochure stand. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: key cabinet, and brochure stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Car Selling Store. Goal: It must avoid colliding with Car Selling Store's demo vehicle, sales kiosk and queue barrier. Assumptions: The Agent's state, goal's state and the states of the  drone and multiple obstacles: demo vehicle, sales kiosk, and queue barrier are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the tent. Agent's state, goal's state and tent's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tent = calculate_distance_min(s_agent, s_tent) \n    penalty_collision = -25 if (d_agent_tent < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the campfire pit. Agent's state, goal's state and campfire pit's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_campfire_pit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_campfire_pit = calculate_distance_min(s_agent, s_campfire_pit) \n    penalty_collision = -25 if (d_agent_campfire_pit < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the picnic table. Agent's state, goal's state and picnic table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_picnic_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_picnic_table = calculate_distance_min(s_agent, s_picnic_table) \n    penalty_collision = -25 if (d_agent_picnic_table < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the cooler box. Agent's state, goal's state and cooler box's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cooler_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cooler_box = calculate_distance_min(s_agent, s_cooler_box) \n    penalty_collision = -25 if (d_agent_cooler_box < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the hammock stand. Agent's state, goal's state and hammock stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_hammock_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_hammock_stand = calculate_distance_min(s_agent, s_hammock_stand) \n    penalty_collision = -25 if (d_agent_hammock_stand < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the lantern pole. Agent's state, goal's state and lantern pole's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lantern_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lantern_pole = calculate_distance_min(s_agent, s_lantern_pole) \n    penalty_collision = -25 if (d_agent_lantern_pole < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the water tap. Agent's state, goal's state and water tap's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_water_tap, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_water_tap = calculate_distance_min(s_agent, s_water_tap) \n    penalty_collision = -25 if (d_agent_water_tap < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the trash bin. Agent's state, goal's state and trash bin's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -25 if (d_agent_trash_bin < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the bear-proof food locker. Agent's state, goal's state and bear-proof food locker's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bear_proof_locker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bear_proof_locker = calculate_distance_min(s_agent, s_bear_proof_locker) \n    penalty_collision = -25 if (d_agent_bear_proof_locker < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the firewood stack. Agent's state, goal's state and firewood stack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_firewood_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_firewood_stack = calculate_distance_min(s_agent, s_firewood_stack) \n    penalty_collision = -25 if (d_agent_firewood_stack < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the barbecue grill. Agent's state, goal's state and barbecue grill's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bbq_grill, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bbq_grill = calculate_distance_min(s_agent, s_bbq_grill) \n    penalty_collision = -25 if (d_agent_bbq_grill < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the car at campsite. Agent's state, goal's state and car at campsite's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_campsite_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_campsite_car = calculate_distance_min(s_agent, s_campsite_car) \n    penalty_collision = -25 if (d_agent_campsite_car < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the RV. Agent's state, goal's state and RV's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rv, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rv = calculate_distance_min(s_agent, s_rv) \n    penalty_collision = -25 if (d_agent_rv < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the guyline stake. Agent's state, goal's state and guyline stake's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_guyline_stake, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_guyline_stake = calculate_distance_min(s_agent, s_guyline_stake) \n    penalty_collision = -25 if (d_agent_guyline_stake < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the tent pole. Agent's state, goal's state and tent pole's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tent_pole, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tent_pole = calculate_distance_min(s_agent, s_tent_pole) \n    penalty_collision = -25 if (d_agent_tent_pole < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the picnic shelter post. Agent's state, goal's state and picnic shelter post's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shelter_post, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shelter_post = calculate_distance_min(s_agent, s_shelter_post) \n    penalty_collision = -25 if (d_agent_shelter_post < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the portable toilet. Agent's state, goal's state and portable toilet's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_porta_toilet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_porta_toilet = calculate_distance_min(s_agent, s_porta_toilet) \n    penalty_collision = -25 if (d_agent_porta_toilet < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the trail signpost. Agent's state, goal's state and trail signpost's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trail_signpost, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trail_signpost = calculate_distance_min(s_agent, s_trail_signpost) \n    penalty_collision = -25 if (d_agent_trail_signpost < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the kayak rack. Agent's state, goal's state and kayak rack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kayak_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kayak_rack = calculate_distance_min(s_agent, s_kayak_rack) \n    penalty_collision = -25 if (d_agent_kayak_rack < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the solar panel stand. Agent's state, goal's state and solar panel stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_solar_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_solar_stand = calculate_distance_min(s_agent, s_solar_stand) \n    penalty_collision = -25 if (d_agent_solar_stand < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in camping site. It must avoid colliding with the generator. Agent's state, goal's state and generator's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_generator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_generator = calculate_distance_min(s_agent, s_generator) \n    penalty_collision = -25 if (d_agent_generator < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's tent, campfire pit and picnic table. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: tent, campfire pit, and picnic table are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's RV and generator. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: RV, and generator are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's trail signpost, kayak rack and trash bin. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: trail signpost, kayak rack, and trash bin are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Camping Site. Goal: It must avoid colliding with Camping Site's lantern pole and guyline stake. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: lantern pole, and guyline stake are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the coffee table. Agent's state, goal's state and coffee table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coffee_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coffee_table = calculate_distance_min(s_agent, s_coffee_table) \n    penalty_collision = -25 if (d_agent_coffee_table < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the sofa. Agent's state, goal's state and sofa's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sofa, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sofa = calculate_distance_min(s_agent, s_sofa) \n    penalty_collision = -25 if (d_agent_sofa < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the TV stand. Agent's state, goal's state and TV stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tv_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tv_stand = calculate_distance_min(s_agent, s_tv_stand) \n    penalty_collision = -25 if (d_agent_tv_stand < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the floor lamp. Agent's state, goal's state and floor lamp's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_floor_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_floor_lamp = calculate_distance_min(s_agent, s_floor_lamp) \n    penalty_collision = -25 if (d_agent_floor_lamp < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the bookshelf. Agent's state, goal's state and bookshelf's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bookshelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelf = calculate_distance_min(s_agent, s_bookshelf) \n    penalty_collision = -25 if (d_agent_bookshelf < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the indoor plant. Agent's state, goal's state and indoor plant's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_indoor_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_indoor_plant = calculate_distance_min(s_agent, s_indoor_plant) \n    penalty_collision = -25 if (d_agent_indoor_plant < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the dining table. Agent's state, goal's state and dining table's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dining_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_table = calculate_distance_min(s_agent, s_dining_table) \n    penalty_collision = -25 if (d_agent_dining_table < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the dining chair. Agent's state, goal's state and dining chair's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_dining_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dining_chair = calculate_distance_min(s_agent, s_dining_chair) \n    penalty_collision = -25 if (d_agent_dining_chair < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the kitchen island. Agent's state, goal's state and kitchen island's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_kitchen_island, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_kitchen_island = calculate_distance_min(s_agent, s_kitchen_island) \n    penalty_collision = -25 if (d_agent_kitchen_island < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the bar stool. Agent's state, goal's state and bar stool's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bar_stool, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bar_stool = calculate_distance_min(s_agent, s_bar_stool) \n    penalty_collision = -25 if (d_agent_bar_stool < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the refrigerator. Agent's state, goal's state and refrigerator's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_refrigerator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_refrigerator = calculate_distance_min(s_agent, s_refrigerator) \n    penalty_collision = -25 if (d_agent_refrigerator < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the microwave stand. Agent's state, goal's state and microwave stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_microwave_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microwave_stand = calculate_distance_min(s_agent, s_microwave_stand) \n    penalty_collision = -25 if (d_agent_microwave_stand < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the shoe rack. Agent's state, goal's state and shoe rack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_shoe_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shoe_rack = calculate_distance_min(s_agent, s_shoe_rack) \n    penalty_collision = -25 if (d_agent_shoe_rack < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the coat stand. Agent's state, goal's state and coat stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_coat_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coat_stand = calculate_distance_min(s_agent, s_coat_stand) \n    penalty_collision = -25 if (d_agent_coat_stand < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the laundry basket. Agent's state, goal's state and laundry basket's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_laundry_basket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laundry_basket = calculate_distance_min(s_agent, s_laundry_basket) \n    penalty_collision = -25 if (d_agent_laundry_basket < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the drying rack. Agent's state, goal's state and drying rack's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drying_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drying_rack = calculate_distance_min(s_agent, s_drying_rack) \n    penalty_collision = -25 if (d_agent_drying_rack < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the radiator. Agent's state, goal's state and radiator's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_radiator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_radiator = calculate_distance_min(s_agent, s_radiator) \n    penalty_collision = -25 if (d_agent_radiator < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the balcony door. Agent's state, goal's state and balcony door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_balcony_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony_door = calculate_distance_min(s_agent, s_balcony_door) \n    penalty_collision = -25 if (d_agent_balcony_door < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the sliding wardrobe door. Agent's state, goal's state and sliding wardrobe door's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sliding_wardrobe_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sliding_wardrobe_door = calculate_distance_min(s_agent, s_sliding_wardrobe_door) \n    penalty_collision = -25 if (d_agent_sliding_wardrobe_door < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the mirror stand. Agent's state, goal's state and mirror stand's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_mirror_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_mirror_stand = calculate_distance_min(s_agent, s_mirror_stand) \n    penalty_collision = -25 if (d_agent_mirror_stand < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "A drone is inspecting in flat. It must avoid colliding with the rug edge. Agent's state, goal's state and rug edge's state are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rug_edge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rug_edge = calculate_distance_min(s_agent, s_rug_edge) \n    penalty_collision = -25 if (d_agent_rug_edge < 0.7) else 15 \n    reward_reaching_goal = 35 if (d_agent_goal < 0.1) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's coffee table, floor lamp and rug edge. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: coffee table, floor lamp, and rug edge are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's kitchen island and bar stool. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: kitchen island, and bar stool are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's refrigerator, laundry basket and drying rack. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: refrigerator, laundry basket, and drying rack are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    },
    {
        "prompt": "Scenario: A drone is navigating Flat. Goal: It must avoid colliding with Flat's sofa and TV stand. Assumptions: The Agent's state, goal's state and the states of the drone, goal and multiple obstacle: sofa, and TV stand are available. Instruction: Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < ob_threshold) else 15 \n    reward_reaching_goal = 25 if (d_agent_goal < goal_threshold) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def calculate(): \n    return 1"
    }
]