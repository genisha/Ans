[
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the dasher board corner. \n Given: Agent's state, goal's state and dasher board corner's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_dasher_corner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_dasher_corner = calculate_distance_min(s_agent, s_dasher_corner) \n    penalty_collision = -28 if (d_agent_dasher_corner < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_dasher_corner): \n    d_agent_dasher_corner = calculate_distance_min(s_agent, s_dasher_corner) \n    penalty_collision = -28 if (d_agent_dasher_corner < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the scoreboard truss. \n Given: Agent's state, goal's state and scoreboard truss's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_scoreboard_truss, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard_truss = calculate_distance_min(s_agent, s_scoreboard_truss) \n    penalty_collision = -28 if (d_agent_scoreboard_truss < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_scoreboard_truss): \n    d_agent_scoreboard_truss = calculate_distance_min(s_agent, s_scoreboard_truss) \n    penalty_collision = -28 if (d_agent_scoreboard_truss < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the safety net anchor. \n Given: Agent's state, goal's state and safety net anchor's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_net_anchor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net_anchor = calculate_distance_min(s_agent, s_net_anchor) \n    penalty_collision = -28 if (d_agent_net_anchor < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_net_anchor): \n    d_agent_net_anchor = calculate_distance_min(s_agent, s_net_anchor) \n    penalty_collision = -28 if (d_agent_net_anchor < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the ice resurfacer bay. \n Given: Agent's state, goal's state and ice resurfacer bay's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_resurfacer_bay, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_resurfacer_bay = calculate_distance_min(s_agent, s_resurfacer_bay) \n    penalty_collision = -28 if (d_agent_resurfacer_bay < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_resurfacer_bay): \n    d_agent_resurfacer_bay = calculate_distance_min(s_agent, s_resurfacer_bay) \n    penalty_collision = -28 if (d_agent_resurfacer_bay < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the flood hose coil. \n Given: Agent's state, goal's state and flood hose coil's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_flood_hose_coil, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flood_hose_coil = calculate_distance_min(s_agent, s_flood_hose_coil) \n    penalty_collision = -28 if (d_agent_flood_hose_coil < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_flood_hose_coil): \n    d_agent_flood_hose_coil = calculate_distance_min(s_agent, s_flood_hose_coil) \n    penalty_collision = -28 if (d_agent_flood_hose_coil < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the penalty box gate. \n Given: Agent's state, goal's state and penalty box gate's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_penalty_box_gate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_penalty_box_gate = calculate_distance_min(s_agent, s_penalty_box_gate) \n    penalty_collision = -28 if (d_agent_penalty_box_gate < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_penalty_box_gate): \n    d_agent_penalty_box_gate = calculate_distance_min(s_agent, s_penalty_box_gate) \n    penalty_collision = -28 if (d_agent_penalty_box_gate < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the foam bumper stack. \n Given: Agent's state, goal's state and foam bumper stack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_foam_bumper_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_foam_bumper_stack = calculate_distance_min(s_agent, s_foam_bumper_stack) \n    penalty_collision = -28 if (d_agent_foam_bumper_stack < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_foam_bumper_stack): \n    d_agent_foam_bumper_stack = calculate_distance_min(s_agent, s_foam_bumper_stack) \n    penalty_collision = -28 if (d_agent_foam_bumper_stack < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the coach's whiteboard. \n Given: Agent's state, goal's state and coach's whiteboard's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_coach_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_coach_whiteboard = calculate_distance_min(s_agent, s_coach_whiteboard) \n    penalty_collision = -28 if (d_agent_coach_whiteboard < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_coach_whiteboard): \n    d_agent_coach_whiteboard = calculate_distance_min(s_agent, s_coach_whiteboard) \n    penalty_collision = -28 if (d_agent_coach_whiteboard < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the advert banner frame. \n Given: Agent's state, goal's state and advert banner frame's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_banner_frame, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_banner_frame = calculate_distance_min(s_agent, s_banner_frame) \n    penalty_collision = -28 if (d_agent_banner_frame < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_banner_frame): \n    d_agent_banner_frame = calculate_distance_min(s_agent, s_banner_frame) \n    penalty_collision = -28 if (d_agent_banner_frame < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the netting loops. \n Given: Agent's state, goal's state and netting loops's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_netting_loops, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_netting_loops = calculate_distance_min(s_agent, s_netting_loops) \n    penalty_collision = -28 if (d_agent_netting_loops < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_netting_loops): \n    d_agent_netting_loops = calculate_distance_min(s_agent, s_netting_loops) \n    penalty_collision = -28 if (d_agent_netting_loops < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the goal frame. \n Given: Agent's state, goal's state and goal frame's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_goal_frame, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_goal_frame = calculate_distance_min(s_agent, s_goal_frame) \n    penalty_collision = -28 if (d_agent_goal_frame < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_goal_frame): \n    d_agent_goal_frame = calculate_distance_min(s_agent, s_goal_frame) \n    penalty_collision = -28 if (d_agent_goal_frame < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the puck bucket. \n Given: Agent's state, goal's state and puck bucket's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_puck_bucket, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_puck_bucket = calculate_distance_min(s_agent, s_puck_bucket) \n    penalty_collision = -28 if (d_agent_puck_bucket < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_puck_bucket): \n    d_agent_puck_bucket = calculate_distance_min(s_agent, s_puck_bucket) \n    penalty_collision = -28 if (d_agent_puck_bucket < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the ice edging station. \n Given: Agent's state, goal's state and ice edging station's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_ice_edging_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ice_edging_station = calculate_distance_min(s_agent, s_ice_edging_station) \n    penalty_collision = -28 if (d_agent_ice_edging_station < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_ice_edging_station): \n    d_agent_ice_edging_station = calculate_distance_min(s_agent, s_ice_edging_station) \n    penalty_collision = -28 if (d_agent_ice_edging_station < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the tool crate. \n Given: Agent's state, goal's state and tool crate's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_tool_crate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tool_crate = calculate_distance_min(s_agent, s_tool_crate) \n    penalty_collision = -28 if (d_agent_tool_crate < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_tool_crate): \n    d_agent_tool_crate = calculate_distance_min(s_agent, s_tool_crate) \n    penalty_collision = -28 if (d_agent_tool_crate < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the maintenance step ladder. \n Given: Agent's state, goal's state and maintenance step ladder's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_maintenance_step_ladder, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_maintenance_step_ladder = calculate_distance_min(s_agent, s_maintenance_step_ladder) \n    penalty_collision = -28 if (d_agent_maintenance_step_ladder < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_maintenance_step_ladder): \n    d_agent_maintenance_step_ladder = calculate_distance_min(s_agent, s_maintenance_step_ladder) \n    penalty_collision = -28 if (d_agent_maintenance_step_ladder < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the first-aid cabinet. \n Given: Agent's state, goal's state and first-aid cabinet's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_first_aid_cabinet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_first_aid_cabinet = calculate_distance_min(s_agent, s_first_aid_cabinet) \n    penalty_collision = -28 if (d_agent_first_aid_cabinet < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_first_aid_cabinet): \n    d_agent_first_aid_cabinet = calculate_distance_min(s_agent, s_first_aid_cabinet) \n    penalty_collision = -28 if (d_agent_first_aid_cabinet < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the bottle refill station. \n Given: Agent's state, goal's state and bottle refill station's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_bottle_refill_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bottle_refill_station = calculate_distance_min(s_agent, s_bottle_refill_station) \n    penalty_collision = -28 if (d_agent_bottle_refill_station < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_bottle_refill_station): \n    d_agent_bottle_refill_station = calculate_distance_min(s_agent, s_bottle_refill_station) \n    penalty_collision = -28 if (d_agent_bottle_refill_station < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the skate rack. \n Given: Agent's state, goal's state and skate rack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_skate_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_skate_rack = calculate_distance_min(s_agent, s_skate_rack) \n    penalty_collision = -28 if (d_agent_skate_rack < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_skate_rack): \n    d_agent_skate_rack = calculate_distance_min(s_agent, s_skate_rack) \n    penalty_collision = -28 if (d_agent_skate_rack < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the helmet rack. \n Given: Agent's state, goal's state and helmet rack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_helmet_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_helmet_rack = calculate_distance_min(s_agent, s_helmet_rack) \n    penalty_collision = -28 if (d_agent_helmet_rack < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_helmet_rack): \n    d_agent_helmet_rack = calculate_distance_min(s_agent, s_helmet_rack) \n    penalty_collision = -28 if (d_agent_helmet_rack < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the goal judge box. \n Given: Agent's state, goal's state and goal judge box's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_goal_judge_box, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_goal_judge_box = calculate_distance_min(s_agent, s_goal_judge_box) \n    penalty_collision = -28 if (d_agent_goal_judge_box < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_goal_judge_box): \n    d_agent_goal_judge_box = calculate_distance_min(s_agent, s_goal_judge_box) \n    penalty_collision = -28 if (d_agent_goal_judge_box < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice rink. \n Conditions:  It must avoid colliding with the broadcast tripod mount. \n Given: Agent's state, goal's state and broadcast tripod mount's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_broadcast_tripod, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_broadcast_tripod = calculate_distance_min(s_agent, s_broadcast_tripod) \n    penalty_collision = -28 if (d_agent_broadcast_tripod < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_broadcast_tripod): \n    d_agent_broadcast_tripod = calculate_distance_min(s_agent, s_broadcast_tripod) \n    penalty_collision = -28 if (d_agent_broadcast_tripod < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an ice rink. Goal: It must avoid colliding with Ice Rink's safety net anchor, ice resurfacer bay and penalty box gate. Assumptions: The Agent's state, goal's state and the states of multiple obstacles: safety net anchor, ice resurfacer bay, and penalty box gate are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an ice rink. Goal: It must avoid colliding with Ice Rink's dasher board corner and scoreboard truss. Assumptions: The Agent's state, goal's state and the states of multiple obstacles: dasher board corner, and scoreboard truss are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an ice rink. Goal: It must avoid colliding with Ice Rink's foam bumper stack, maintenance step ladder and tool crate. Assumptions: The Agent's state, goal's state and the states of multiple obstacles: foam bumper stack, maintenance step ladder, and tool crate are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an ice rink. Goal: It must avoid colliding with Ice Rink's flood hose coil and skate rack. Assumptions: The Agent's state, goal's state and the states of multiple obstacles: flood hose coil, and skate rack are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    reward_reaching_goal = 32 if (d_agent_goal < 0.17) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    return penalty_collision"
  },


  
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the freezer. \n Given: Agent's state, target's state and freezer's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_freezer, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_freezer = calculate_distance_min(s_agent, s_freezer) \n    penalty_collision = -28 if (d_agent_freezer < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_freezer): \n    d_agent_freezer = calculate_distance_min(s_agent, s_freezer) \n    penalty_collision = -28 if (d_agent_freezer < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the menu board. \n Given: Agent's state, target's state and menu board's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_menu_board, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_menu_board = calculate_distance_min(s_agent, s_menu_board) \n    penalty_collision = -28 if (d_agent_menu_board < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_menu_board): \n    d_agent_menu_board = calculate_distance_min(s_agent, s_menu_board) \n    penalty_collision = -28 if (d_agent_menu_board < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the chair leg. \n Given: Agent's state, target's state and chair leg's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_net_anchor, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_net_anchor = calculate_distance_min(s_agent, s_net_anchor) \n    penalty_collision = -28 if (d_agent_net_anchor < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_net_anchor): \n    d_agent_net_anchor = calculate_distance_min(s_agent, s_net_anchor) \n    penalty_collision = -28 if (d_agent_net_anchor < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the back storage door. \n Given: Agent's state, target's state and back storage door's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_door, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_door = calculate_distance_min(s_agent, s_door) \n    penalty_collision = -28 if (d_agent_door < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_door): \n    d_agent_door = calculate_distance_min(s_agent, s_door) \n    penalty_collision = -28 if (d_agent_door < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the topping station. \n Given: Agent's state, target's state and topping station's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_topping_statio, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_topping_statio = calculate_distance_min(s_agent, s_topping_statio) \n    penalty_collision = -28 if (d_agent_topping_statio < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_topping_statio): \n    d_agent_topping_statio = calculate_distance_min(s_agent, s_topping_statio) \n    penalty_collision = -28 if (d_agent_topping_statio < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the counter gate. \n Given: Agent's state, target's state and counter gate's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_counter_gate, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_counter_gate = calculate_distance_min(s_agent, s_counter_gate) \n    penalty_collision = -28 if (d_agent_counter_gate < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_counter_gate): \n    d_agent_counter_gate = calculate_distance_min(s_agent, s_counter_gate) \n    penalty_collision = -28 if (d_agent_counter_gate < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the napkin dispenser stack. \n Given: Agent's state, target's state and napkin dispenser stack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_dispenser_stack, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_dispenser_stack = calculate_distance_min(s_agent, s_dispenser_stack) \n    penalty_collision = -28 if (d_agent_dispenser_stack < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_dispenser_stack): \n    d_agent_dispenser_stack = calculate_distance_min(s_agent, s_dispenser_stack) \n    penalty_collision = -28 if (d_agent_dispenser_stack < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the wall menu board. \n Given: Agent's state, target's state and wall menu board's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_coach_whiteboard, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_coach_whiteboard = calculate_distance_min(s_agent, s_coach_whiteboard) \n    penalty_collision = -28 if (d_agent_coach_whiteboard < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_coach_whiteboard): \n    d_agent_coach_whiteboard = calculate_distance_min(s_agent, s_coach_whiteboard) \n    penalty_collision = -28 if (d_agent_coach_whiteboard < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the poster frame. \n Given: Agent's state, target's state and poster frame's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_poster_frame, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_poster_frame = calculate_distance_min(s_agent, s_poster_frame) \n    penalty_collision = -28 if (d_agent_poster_frame < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_poster_frame): \n    d_agent_poster_frame = calculate_distance_min(s_agent, s_poster_frame) \n    penalty_collision = -28 if (d_agent_poster_frame < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the table. \n Given: Agent's state, target's state and table's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_table, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -28 if (d_agent_table < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_table): \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -28 if (d_agent_table < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the target frame. \n Given: Agent's state, target's state and target frame's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_target_frame, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_target_frame = calculate_distance_min(s_agent, s_target_frame) \n    penalty_collision = -28 if (d_agent_target_frame < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_target_frame): \n    d_agent_target_frame = calculate_distance_min(s_agent, s_target_frame) \n    penalty_collision = -28 if (d_agent_target_frame < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the topping bucket. \n Given: Agent's state, target's state and topping bucket's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_topping_bucket, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_topping_bucket = calculate_distance_min(s_agent, s_topping_bucket) \n    penalty_collision = -28 if (d_agent_topping_bucket < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_topping_bucket): \n    d_agent_topping_bucket = calculate_distance_min(s_agent, s_topping_bucket) \n    penalty_collision = -28 if (d_agent_topping_bucket < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the cash register stand. \n Given: Agent's state, target's state and cash register stand's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cash_counter, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cash_counter = calculate_distance_min(s_agent, s_cash_counter) \n    penalty_collision = -28 if (d_agent_cash_counter < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cash_counter): \n    d_agent_cash_counter = calculate_distance_min(s_agent, s_cash_counter) \n    penalty_collision = -28 if (d_agent_cash_counter < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the utensil crate. \n Given: Agent's state, target's state and utensil crate's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_tool_crate, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_tool_crate = calculate_distance_min(s_agent, s_tool_crate) \n    penalty_collision = -28 if (d_agent_tool_crate < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_tool_crate): \n    d_agent_tool_crate = calculate_distance_min(s_agent, s_tool_crate) \n    penalty_collision = -28 if (d_agent_tool_crate < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the step stool. \n Given: Agent's state, target's state and step stool's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_step_stool, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_step_stool = calculate_distance_min(s_agent, s_step_stool) \n    penalty_collision = -28 if (d_agent_step_stool < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_step_stool): \n    d_agent_step_stool = calculate_distance_min(s_agent, s_step_stool) \n    penalty_collision = -28 if (d_agent_step_stool < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the supply cabinet. \n Given: Agent's state, target's state and supply cabinet's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_supply_cabinet, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_supply_cabinet = calculate_distance_min(s_agent, s_supply_cabinet) \n    penalty_collision = -28 if (d_agent_supply_cabinet < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_supply_cabinet): \n    d_agent_supply_cabinet = calculate_distance_min(s_agent, s_supply_cabinet) \n    penalty_collision = -28 if (d_agent_supply_cabinet < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the soda machine. \n Given: Agent's state, target's state and soda machine's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_soda_machine, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_soda_machine = calculate_distance_min(s_agent, s_soda_machine) \n    penalty_collision = -28 if (d_agent_soda_machine < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_soda_machine): \n    d_agent_soda_machine = calculate_distance_min(s_agent, s_soda_machine) \n    penalty_collision = -28 if (d_agent_soda_machine < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the cone holder rack. \n Given: Agent's state, target's state and cone holder rack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cone_rack, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cone_rack = calculate_distance_min(s_agent, s_cone_rack) \n    penalty_collision = -28 if (d_agent_cone_rack < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cone_rack): \n    d_agent_cone_rack = calculate_distance_min(s_agent, s_cone_rack) \n    penalty_collision = -28 if (d_agent_cone_rack < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the cup holder rack. \n Given: Agent's state, target's state and cup holder rack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cup_rack, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cup_rack = calculate_distance_min(s_agent, s_cup_rack) \n    penalty_collision = -28 if (d_agent_cup_rack < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cup_rack): \n    d_agent_cup_rack = calculate_distance_min(s_agent, s_cup_rack) \n    penalty_collision = -28 if (d_agent_cup_rack < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the customer. \n Given: Agent's state, target's state and customer's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_customer, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -28 if (d_agent_customer < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_customer): \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -28 if (d_agent_customer < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in an ice cream shop. \n Conditions:  The drone must avoid colliding with the ceiling fan pole. \n Given: Agent's state, target's state and ceiling fan pole's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_fan_pole, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_fan_pole = calculate_distance_min(s_agent, s_fan_pole) \n    penalty_collision = -28 if (d_agent_fan_pole < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_fan_pole): \n    d_agent_fan_pole = calculate_distance_min(s_agent, s_fan_pole) \n    penalty_collision = -28 if (d_agent_fan_pole < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an ice cream shop. Target: The drone must avoid colliding with chair, back storage door and counter gate. Assumptions: The Agent's state, target's state and the states of multiple obstacles: chair, back storage door, and counter gate are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an ice cream shop. Target: The drone must avoid colliding with freezer corner and menu board frame. Assumptions: The Agent's state, target's state and the states of multiple obstacles: freezer corner, and menu board frame are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an ice cream shop. Target: The drone must avoid colliding with napkin dispenser stack, step stool and utensil crate. Assumptions: The Agent's state, target's state and the states of multiple obstacles: napkin dispenser stack, step stool, and utensil crate are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an ice cream shop. Target: The drone must avoid colliding with topping station pipe and cone holder rack. Assumptions: The Agent's state, target's state and the states of multiple obstacles: topping station pipe, and cone holder rack are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    return penalty_collision"
  },



  
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the cereal box. \n Given: Agent's state, target's state and cereal box's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cereal box, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cereal box = calculate_distance_min(s_agent, s_cereal box) \n    penalty_collision = -28 if (d_agent_cereal box < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cereal box): \n    d_agent_cereal box = calculate_distance_min(s_agent, s_cereal box) \n    penalty_collision = -28 if (d_agent_cereal box < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the jar of rice. \n Given: Agent's state, target's state and jar of rice's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_rice_jar, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_rice_jar = calculate_distance_min(s_agent, s_rice_jar) \n    penalty_collision = -28 if (d_agent_rice_jar < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_rice_jar): \n    d_agent_rice_jar = calculate_distance_min(s_agent, s_rice_jar) \n    penalty_collision = -28 if (d_agent_rice_jar < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the olive oil bottle. \n Given: Agent's state, target's state and olive oil bottle's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_oil_bottle, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_oil_bottle = calculate_distance_min(s_agent, s_oil_bottle) \n    penalty_collision = -28 if (d_agent_oil_bottle < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_oil_bottle): \n    d_agent_oil_bottle = calculate_distance_min(s_agent, s_oil_bottle) \n    penalty_collision = -28 if (d_agent_oil_bottle < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the bag of flour. \n Given: Agent's state, target's state and bag of flour's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_flour_bag, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_flour_bag = calculate_distance_min(s_agent, s_flour_bag) \n    penalty_collision = -28 if (d_agent_flour_bag < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_flour_bag): \n    d_agent_flour_bag = calculate_distance_min(s_agent, s_flour_bag) \n    penalty_collision = -28 if (d_agent_flour_bag < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the spice jar. \n Given: Agent's state, target's state and spice jar's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_spice_jar, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_spice_jar = calculate_distance_min(s_agent, s_spice_jar) \n    penalty_collision = -28 if (d_agent_spice_jar < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_spice_jar): \n    d_agent_spice_jar = calculate_distance_min(s_agent, s_spice_jar) \n    penalty_collision = -28 if (d_agent_spice_jar < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the storage bin. \n Given: Agent's state, target's state and storage bin's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_storage_bin, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_storage_bin = calculate_distance_min(s_agent, s_storage_bin) \n    penalty_collision = -28 if (d_agent_storage_bin < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_storage_bin): \n    d_agent_storage_bin = calculate_distance_min(s_agent, s_storage_bin) \n    penalty_collision = -28 if (d_agent_storage_bin < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the can stack. \n Given: Agent's state, target's state and can stack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_can_stack, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_can_stack = calculate_distance_min(s_agent, s_can_stack) \n    penalty_collision = -28 if (d_agent_can_stack < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_can_stack): \n    d_agent_can_stack = calculate_distance_min(s_agent, s_can_stack) \n    penalty_collision = -28 if (d_agent_can_stack < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the measurement cup. \n Given: Agent's state, target's state and measurement cup's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_measurement_cup, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_measurement_cup = calculate_distance_min(s_agent, s_measurement_cup) \n    penalty_collision = -28 if (d_agent_measurement_cup < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_measurement_cup): \n    d_agent_measurement_cup = calculate_distance_min(s_agent, s_measurement_cup) \n    penalty_collision = -28 if (d_agent_measurement_cup < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the label sticker. \n Given: Agent's state, target's state and label sticker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_label_stciker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_label_stciker = calculate_distance_min(s_agent, s_label_stciker) \n    penalty_collision = -28 if (d_agent_label_stciker < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_label_stciker): \n    d_agent_label_stciker = calculate_distance_min(s_agent, s_label_stciker) \n    penalty_collision = -28 if (d_agent_label_stciker < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the plastic container. \n Given: Agent's state, target's state and plastic container's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_plastic_container, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_plastic_container = calculate_distance_min(s_agent, s_plastic_container) \n    penalty_collision = -28 if (d_agent_plastic_container < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_plastic_container): \n    d_agent_plastic_container = calculate_distance_min(s_agent, s_plastic_container) \n    penalty_collision = -28 if (d_agent_plastic_container < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the food container. \n Given: Agent's state, target's state and food container's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_food_container, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_food_container = calculate_distance_min(s_agent, s_food_container) \n    penalty_collision = -28 if (d_agent_food_container < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_food_container): \n    d_agent_food_container = calculate_distance_min(s_agent, s_food_container) \n    penalty_collision = -28 if (d_agent_food_container < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the grain sack. \n Given: Agent's state, target's state and grain sack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_grain_sack, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_grain_sack = calculate_distance_min(s_agent, s_grain_sack) \n    penalty_collision = -28 if (d_agent_grain_sack < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_grain_sack): \n    d_agent_grain_sack = calculate_distance_min(s_agent, s_grain_sack) \n    penalty_collision = -28 if (d_agent_grain_sack < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the weighing scale. \n Given: Agent's state, target's state and weighing scale's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_weighing_scale, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_weighing_scale = calculate_distance_min(s_agent, s_weighing_scale) \n    penalty_collision = -28 if (d_agent_weighing_scale < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_weighing_scale): \n    d_agent_weighing_scale = calculate_distance_min(s_agent, s_weighing_scale) \n    penalty_collision = -28 if (d_agent_weighing_scale < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the utensil set. \n Given: Agent's state, target's state and utensil set's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_utensil_set, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_utensil_set = calculate_distance_min(s_agent, s_utensil_set) \n    penalty_collision = -28 if (d_agent_utensil_set < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_utensil_set): \n    d_agent_utensil_set = calculate_distance_min(s_agent, s_utensil_set) \n    penalty_collision = -28 if (d_agent_utensil_set < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the ladder rung. \n Given: Agent's state, target's state and ladder rung's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_ladder_rung, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_ladder_rung = calculate_distance_min(s_agent, s_ladder_rung) \n    penalty_collision = -28 if (d_agent_ladder_rung < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_ladder_rung): \n    d_agent_ladder_rung = calculate_distance_min(s_agent, s_ladder_rung) \n    penalty_collision = -28 if (d_agent_ladder_rung < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the pantry shelf unit. \n Given: Agent's state, target's state and pantry shelf unit's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_shelf, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -28 if (d_agent_shelf < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_shelf): \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -28 if (d_agent_shelf < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the water jug. \n Given: Agent's state, target's state and water jug's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_water_jug, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_water_jug = calculate_distance_min(s_agent, s_water_jug) \n    penalty_collision = -28 if (d_agent_water_jug < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_water_jug): \n    d_agent_water_jug = calculate_distance_min(s_agent, s_water_jug) \n    penalty_collision = -28 if (d_agent_water_jug < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the bag of sugar. \n Given: Agent's state, target's state and bag of sugar's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_sugar_bag, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_sugar_bag = calculate_distance_min(s_agent, s_sugar_bag) \n    penalty_collision = -28 if (d_agent_sugar_bag < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_sugar_bag): \n    d_agent_sugar_bag = calculate_distance_min(s_agent, s_sugar_bag) \n    penalty_collision = -28 if (d_agent_sugar_bag < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the bag of pasta. \n Given: Agent's state, target's state and bag of pasta's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_pasta_bag, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_pasta_bag = calculate_distance_min(s_agent, s_pasta_bag) \n    penalty_collision = -28 if (d_agent_pasta_bag < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_pasta_bag): \n    d_agent_pasta_bag = calculate_distance_min(s_agent, s_pasta_bag) \n    penalty_collision = -28 if (d_agent_pasta_bag < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the pantry worker. \n Given: Agent's state, target's state and pantry worker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_pantry_worker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_pantry_worker = calculate_distance_min(s_agent, s_pantry_worker) \n    penalty_collision = -28 if (d_agent_pantry_worker < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_pantry_worker): \n    d_agent_pantry_worker = calculate_distance_min(s_agent, s_pantry_worker) \n    penalty_collision = -28 if (d_agent_pantry_worker < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is moveing in an pantry. \n Conditions:  The drone must avoid colliding with the hanging lamp. \n Given: Agent's state, target's state and hanging lamp's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_lamp, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -28 if (d_agent_lamp < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_lamp): \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -28 if (d_agent_lamp < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an pantry. Target: The drone must avoid colliding with chair, bag of flour and storage bin. Assumptions: The Agent's state, target's state and the states of multiple obstacles: chair, bag of flour, and storage bin are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an pantry. Target: The drone must avoid colliding with cereal box corner and jar of rice frame. Assumptions: The Agent's state, target's state and the states of multiple obstacles: cereal box corner, and jar of rice, frame are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an pantry. Target: The drone must avoid colliding with can stack, ladder rung and utensil set. Assumptions: The Agent's state, target's state and the states of multiple obstacles: can stack, ladder rung, and utensil set are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.6) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an pantry. Target: The drone must avoid colliding with spice jar pipe and bag of sugar. Assumptions: The Agent's state, target's state and the states of multiple obstacles: spice jar pipe, and bag of sugar are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.6) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.6) else 20 \n    return penalty_collision"
  },



  
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the paint set. \n Given: Agent's state, target's state and paint set's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_paint_set, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_paint_set = calculate_distance_min(s_agent, s_paint_set) \n    penalty_collision = -28 if (d_agent_paint_set < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_paint_set): \n    d_agent_paint_set = calculate_distance_min(s_agent, s_paint_set) \n    penalty_collision = -28 if (d_agent_paint_set < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the model kit. \n Given: Agent's state, target's state and model kit's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_model_kit, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_model_kit = calculate_distance_min(s_agent, s_model_kit) \n    penalty_collision = -28 if (d_agent_model_kit < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_model_kit): \n    d_agent_model_kit = calculate_distance_min(s_agent, s_model_kit) \n    penalty_collision = -28 if (d_agent_model_kit < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the glue bottle. \n Given: Agent's state, target's state and glue bottle's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_glue_bottle, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_glue_bottle = calculate_distance_min(s_agent, s_glue_bottle) \n    penalty_collision = -28 if (d_agent_glue_bottle < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_glue_bottle): \n    d_agent_glue_bottle = calculate_distance_min(s_agent, s_glue_bottle) \n    penalty_collision = -28 if (d_agent_glue_bottle < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the craft fabric roll. \n Given: Agent's state, target's state and craft fabric roll's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_craft_roll, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_craft_roll = calculate_distance_min(s_agent, s_craft_roll) \n    penalty_collision = -28 if (d_agent_craft_roll < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_craft_roll): \n    d_agent_craft_roll = calculate_distance_min(s_agent, s_craft_roll) \n    penalty_collision = -28 if (d_agent_craft_roll < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the bead jar. \n Given: Agent's state, target's state and bead jar's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_bead_jar, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_bead_jar = calculate_distance_min(s_agent, s_bead_jar) \n    penalty_collision = -28 if (d_agent_bead_jar < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_bead_jar): \n    d_agent_bead_jar = calculate_distance_min(s_agent, s_bead_jar) \n    penalty_collision = -28 if (d_agent_bead_jar < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the tool box. \n Given: Agent's state, target's state and tool box's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_tool_box, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_tool_box = calculate_distance_min(s_agent, s_tool_box) \n    penalty_collision = -28 if (d_agent_tool_box < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_tool_box): \n    d_agent_tool_box = calculate_distance_min(s_agent, s_tool_box) \n    penalty_collision = -28 if (d_agent_tool_box < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the yarn bundle. \n Given: Agent's state, target's state and yarn bundle's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_yarn_bundle, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_yarn_bundle = calculate_distance_min(s_agent, s_yarn_bundle) \n    penalty_collision = -28 if (d_agent_yarn_bundle < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_yarn_bundle): \n    d_agent_yarn_bundle = calculate_distance_min(s_agent, s_yarn_bundle) \n    penalty_collision = -28 if (d_agent_yarn_bundle < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the wall model kit. \n Given: Agent's state, target's state and wall model kit's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_model_kit, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_model_kit = calculate_distance_min(s_agent, s_model_kit) \n    penalty_collision = -28 if (d_agent_model_kit < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_model_kit): \n    d_agent_model_kit = calculate_distance_min(s_agent, s_model_kit) \n    penalty_collision = -28 if (d_agent_model_kit < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the sketch pad. \n Given: Agent's state, target's state and sketch pad's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_sketch_pad, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_sketch_pad = calculate_distance_min(s_agent, s_sketch_pad) \n    penalty_collision = -28 if (d_agent_sketch_pad < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_sketch_pad): \n    d_agent_sketch_pad = calculate_distance_min(s_agent, s_sketch_pad) \n    penalty_collision = -28 if (d_agent_sketch_pad < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the craft supply box. \n Given: Agent's state, target's state and craft supply box's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_craft_supply_box, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_craft_supply_box = calculate_distance_min(s_agent, s_craft_supply_box) \n    penalty_collision = -28 if (d_agent_craft_supply_box < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_craft_supply_box): \n    d_agent_craft_supply_box = calculate_distance_min(s_agent, s_craft_supply_box) \n    penalty_collision = -28 if (d_agent_craft_supply_box < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the storage case. \n Given: Agent's state, target's state and storage case's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_storage_case, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_storage_case = calculate_distance_min(s_agent, s_storage_case) \n    penalty_collision = -28 if (d_agent_storage_case < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_storage_case): \n    d_agent_storage_case = calculate_distance_min(s_agent, s_storage_case) \n    penalty_collision = -28 if (d_agent_storage_case < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the clay block. \n Given: Agent's state, target's state and clay block's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_clay_block, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_clay_block = calculate_distance_min(s_agent, s_clay_block) \n    penalty_collision = -28 if (d_agent_clay_block < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_clay_block): \n    d_agent_clay_block = calculate_distance_min(s_agent, s_clay_block) \n    penalty_collision = -28 if (d_agent_clay_block < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the cutting mat. \n Given: Agent's state, target's state and cutting mat's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cutting_mat, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cutting_mat = calculate_distance_min(s_agent, s_cutting_mat) \n    penalty_collision = -28 if (d_agent_cutting_mat < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cutting_mat): \n    d_agent_cutting_mat = calculate_distance_min(s_agent, s_cutting_mat) \n    penalty_collision = -28 if (d_agent_cutting_mat < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the paintbrush set. \n Given: Agent's state, target's state and paintbrush set's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_paintbrush, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_paintbrush = calculate_distance_min(s_agent, s_paintbrush) \n    penalty_collision = -28 if (d_agent_paintbrush < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_paintbrush): \n    d_agent_paintbrush = calculate_distance_min(s_agent, s_paintbrush) \n    penalty_collision = -28 if (d_agent_paintbrush < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the easel leg. \n Given: Agent's state, target's state and easel leg's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_easel_leg, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_easel_leg = calculate_distance_min(s_agent, s_easel_leg) \n    penalty_collision = -28 if (d_agent_easel_leg < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_easel_leg): \n    d_agent_easel_leg = calculate_distance_min(s_agent, s_easel_leg) \n    penalty_collision = -28 if (d_agent_easel_leg < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the hobby room shelf unit. \n Given: Agent's state, target's state and hobby room shelf unit's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_shelf, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -28 if (d_agent_shelf < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_shelf): \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -28 if (d_agent_shelf < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the water cup. \n Given: Agent's state, target's state and water cup's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_water_cup, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_water_cup = calculate_distance_min(s_agent, s_water_cup) \n    penalty_collision = -28 if (d_agent_water_cup < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_water_cup): \n    d_agent_water_cup = calculate_distance_min(s_agent, s_water_cup) \n    penalty_collision = -28 if (d_agent_water_cup < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the sandpaper sheet. \n Given: Agent's state, target's state and sandpaper sheet's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_sandpaper_sheet, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_sandpaper_sheet = calculate_distance_min(s_agent, s_sandpaper_sheet) \n    penalty_collision = -28 if (d_agent_sandpaper_sheet < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_sandpaper_sheet): \n    d_agent_sandpaper_sheet = calculate_distance_min(s_agent, s_sandpaper_sheet) \n    penalty_collision = -28 if (d_agent_sandpaper_sheet < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the wire spool. \n Given: Agent's state, target's state and wire spool's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_wire_spool, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_wire_spool = calculate_distance_min(s_agent, s_wire_spool) \n    penalty_collision = -28 if (d_agent_wire_spool < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_wire_spool): \n    d_agent_wire_spool = calculate_distance_min(s_agent, s_wire_spool) \n    penalty_collision = -28 if (d_agent_wire_spool < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the hobby room worker. \n Given: Agent's state, target's state and hobby room worker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_worker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -28 if (d_agent_worker < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -28 if (d_agent_worker < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying in an hobby room. \n Conditions:  The drone must avoid colliding with the desk lamp. \n Given: Agent's state, target's state and desk lamp's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_desk_lamp, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_desk_lamp = calculate_distance_min(s_agent, s_desk_lamp) \n    penalty_collision = -28 if (d_agent_desk_lamp < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_desk_lamp): \n    d_agent_desk_lamp = calculate_distance_min(s_agent, s_desk_lamp) \n    penalty_collision = -28 if (d_agent_desk_lamp < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an hobby room. Target: The drone must avoid colliding with chair, craft fabric roll and tool box. Assumptions: The Agent's state, target's state and the states of multiple obstacles: chair, craft fabric roll, and tool box are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an hobby room. Target: The drone must avoid colliding with paint set corner and model kit frame. Assumptions: The Agent's state, target's state and the states of multiple obstacles: paint set corner, and model kit frame are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an hobby room. Target: The drone must avoid colliding with yarn bundle, easel leg and paintbrush set. Assumptions: The Agent's state, target's state and the states of multiple obstacles: yarn bundle, easel leg, and paintbrush set are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an hobby room. Target: The drone must avoid colliding with bead jar pipe and sandpaper sheet. Assumptions: The Agent's state, target's state and the states of multiple obstacles: bead jar pipe, and sandpaper sheet are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    reward_reaching_target = 32 if (d_agent_target < 0.17) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.57) else 12 \n    return penalty_collision"
  },




  
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the toolbox. \n Assumption: Agent's state, target's state and toolbox's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_toolbox, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_toolbox = calculate_distance_min(s_agent, s_toolbox) \n    penalty_collision = -28 if (d_agent_toolbox < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_toolbox): \n    d_agent_toolbox = calculate_distance_min(s_agent, s_toolbox) \n    penalty_collision = -28 if (d_agent_toolbox < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the storage box. \n Assumption: Agent's state, target's state and storage box's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_storage_box, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_storage_box = calculate_distance_min(s_agent, s_storage_box) \n    penalty_collision = -28 if (d_agent_storage_box < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_storage_box): \n    d_agent_storage_box = calculate_distance_min(s_agent, s_storage_box) \n    penalty_collision = -28 if (d_agent_storage_box < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the detergent bottle. \n Assumption: Agent's state, target's state and detergent bottle's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_detergent_bottle, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_detergent_bottle = calculate_distance_min(s_agent, s_detergent_bottle) \n    penalty_collision = -28 if (d_agent_detergent_bottle < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_detergent_bottle): \n    d_agent_detergent_bottle = calculate_distance_min(s_agent, s_detergent_bottle) \n    penalty_collision = -28 if (d_agent_detergent_bottle < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the old rug. \n Assumption: Agent's state, target's state and old rug's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_rug, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_rug = calculate_distance_min(s_agent, s_rug) \n    penalty_collision = -28 if (d_agent_rug < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_rug): \n    d_agent_rug = calculate_distance_min(s_agent, s_rug) \n    penalty_collision = -28 if (d_agent_rug < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the jar of nails. \n Assumption: Agent's state, target's state and jar of nails's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_jar_nail, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_jar_nail = calculate_distance_min(s_agent, s_jar_nail) \n    penalty_collision = -28 if (d_agent_jar_nail < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_jar_nail): \n    d_agent_jar_nail = calculate_distance_min(s_agent, s_jar_nail) \n    penalty_collision = -28 if (d_agent_jar_nail < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the workbench. \n Assumption: Agent's state, target's state and workbench's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_workbench, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_workbench = calculate_distance_min(s_agent, s_workbench) \n    penalty_collision = -28 if (d_agent_workbench < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_workbench): \n    d_agent_workbench = calculate_distance_min(s_agent, s_workbench) \n    penalty_collision = -28 if (d_agent_workbench < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the rope coil. \n Assumption: Agent's state, target's state and rope coil's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_rope_coil, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_rope_coil = calculate_distance_min(s_agent, s_rope_coil) \n    penalty_collision = -28 if (d_agent_rope_coil < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_rope_coil): \n    d_agent_rope_coil = calculate_distance_min(s_agent, s_rope_coil) \n    penalty_collision = -28 if (d_agent_rope_coil < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the wall storage box. \n Assumption: Agent's state, target's state and wall storage box's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_box, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -28 if (d_agent_box < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_box): \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -28 if (d_agent_box < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the cardboard stack. \n Assumption: Agent's state, target's state and cardboard stack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cardboard_stack, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cardboard_stack = calculate_distance_min(s_agent, s_cardboard_stack) \n    penalty_collision = -28 if (d_agent_cardboard_stack < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cardboard_stack): \n    d_agent_cardboard_stack = calculate_distance_min(s_agent, s_cardboard_stack) \n    penalty_collision = -28 if (d_agent_cardboard_stack < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the plastic tub. \n Assumption: Agent's state, target's state and plastic tub's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_plastic_tub, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_plastic_tub = calculate_distance_min(s_agent, s_plastic_tub) \n    penalty_collision = -28 if (d_agent_plastic_tub < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_plastic_tub): \n    d_agent_plastic_tub = calculate_distance_min(s_agent, s_plastic_tub) \n    penalty_collision = -28 if (d_agent_plastic_tub < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the metal cabinet. \n Assumption: Agent's state, target's state and metal cabinet's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cabinet, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cabinet = calculate_distance_min(s_agent, s_cabinet) \n    penalty_collision = -28 if (d_agent_cabinet < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cabinet): \n    d_agent_cabinet = calculate_distance_min(s_agent, s_cabinet) \n    penalty_collision = -28 if (d_agent_cabinet < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the cement bag. \n Assumption: Agent's state, target's state and cement bag's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cement_bag, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cement_bag = calculate_distance_min(s_agent, s_cement_bag) \n    penalty_collision = -28 if (d_agent_cement_bag < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cement_bag): \n    d_agent_cement_bag = calculate_distance_min(s_agent, s_cement_bag) \n    penalty_collision = -28 if (d_agent_cement_bag < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the plywood board. \n Assumption: Agent's state, target's state and plywood board's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_plywood_board, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_plywood_board = calculate_distance_min(s_agent, s_plywood_board) \n    penalty_collision = -28 if (d_agent_plywood_board < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_plywood_board): \n    d_agent_plywood_board = calculate_distance_min(s_agent, s_plywood_board) \n    penalty_collision = -28 if (d_agent_plywood_board < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the wrench set. \n Assumption: Agent's state, target's state and wrench set's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_wrench_set, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_wrench_set = calculate_distance_min(s_agent, s_wrench_set) \n    penalty_collision = -28 if (d_agent_wrench_set < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_wrench_set): \n    d_agent_wrench_set = calculate_distance_min(s_agent, s_wrench_set) \n    penalty_collision = -28 if (d_agent_wrench_set < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the pipe. \n Assumption: Agent's state, target's state and pipe's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_pipe, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -28 if (d_agent_pipe < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_pipe): \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -28 if (d_agent_pipe < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the basement shelf unit. \n Assumption: Agent's state, target's state and basement shelf unit's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_shelf, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -28 if (d_agent_shelf < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_shelf): \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -28 if (d_agent_shelf < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the bucket of water. \n Assumption: Agent's state, target's state and bucket of water's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_bucket, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_bucket = calculate_distance_min(s_agent, s_bucket) \n    penalty_collision = -28 if (d_agent_bucket < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_bucket): \n    d_agent_bucket = calculate_distance_min(s_agent, s_bucket) \n    penalty_collision = -28 if (d_agent_bucket < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the loose brick. \n Assumption: Agent's state, target's state and loose brick's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_brick, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_brick = calculate_distance_min(s_agent, s_brick) \n    penalty_collision = -28 if (d_agent_brick < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_brick): \n    d_agent_brick = calculate_distance_min(s_agent, s_brick) \n    penalty_collision = -28 if (d_agent_brick < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the extension cord. \n Assumption: Agent's state, target's state and extension cord's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cord, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cord = calculate_distance_min(s_agent, s_cord) \n    penalty_collision = -28 if (d_agent_cord < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cord): \n    d_agent_cord = calculate_distance_min(s_agent, s_cord) \n    penalty_collision = -28 if (d_agent_cord < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the basement worker. \n Assumption: Agent's state, target's state and basement worker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_basement_worker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_basement_worker = calculate_distance_min(s_agent, s_basement_worker) \n    penalty_collision = -28 if (d_agent_basement_worker < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_basement_worker): \n    d_agent_basement_worker = calculate_distance_min(s_agent, s_basement_worker) \n    penalty_collision = -28 if (d_agent_basement_worker < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an basement. \n Goal:  The drone must avoid colliding with the bare light bulb. \n Assumption: Agent's state, target's state and bare light bulb's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_light_bulb, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_light_bulb = calculate_distance_min(s_agent, s_light_bulb) \n    penalty_collision = -28 if (d_agent_light_bulb < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_light_bulb): \n    d_agent_light_bulb = calculate_distance_min(s_agent, s_light_bulb) \n    penalty_collision = -28 if (d_agent_light_bulb < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an basement. Target: The drone must avoid colliding with chair, old rug and workbench. Assumptions: The Agent's state, target's state and the states of multiple obstacles: chair, old rug, and workbench are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an basement. Target: The drone must avoid colliding with toolbox corner and storage box frame. Assumptions: The Agent's state, target's state and the states of multiple obstacles: toolbox corner, and storage box frame are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an basement. Target: The drone must avoid colliding with rope coil, pipe section and wrench set. Assumptions: The Agent's state, target's state and the states of multiple obstacles: rope coil, pipe section, and wrench set are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an basement. Target: The drone must avoid colliding with jar of nails pipe and loose brick. Assumptions: The Agent's state, target's state and the states of multiple obstacles: jar of nails pipe, and loose brick are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },


  
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the shoe rack. \n Assumption: Agent's state, target's state and shoe rack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_shoe_rack, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_shoe_rack = calculate_distance_min(s_agent, s_shoe_rack) \n    penalty_collision = -30 if (d_agent_shoe_rack < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_shoe_rack): \n    d_agent_shoe_rack = calculate_distance_min(s_agent, s_shoe_rack) \n    penalty_collision = -30 if (d_agent_shoe_rack < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the laundry basket. \n Assumption: Agent's state, target's state and laundry basket's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_laundry_basket, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_laundry_basket = calculate_distance_min(s_agent, s_laundry_basket) \n    penalty_collision = -30 if (d_agent_laundry_basket < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_laundry_basket): \n    d_agent_laundry_basket = calculate_distance_min(s_agent, s_laundry_basket) \n    penalty_collision = -30 if (d_agent_laundry_basket < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the perfume bottle. \n Assumption: Agent's state, target's state and perfume bottle's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_perfume_bottle, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_perfume_bottle = calculate_distance_min(s_agent, s_perfume_bottle) \n    penalty_collision = -30 if (d_agent_perfume_bottle < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_perfume_bottle): \n    d_agent_perfume_bottle = calculate_distance_min(s_agent, s_perfume_bottle) \n    penalty_collision = -30 if (d_agent_perfume_bottle < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the carpet. \n Assumption: Agent's state, target's state and carpet's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_carpet, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_carpet = calculate_distance_min(s_agent, s_carpet) \n    penalty_collision = -30 if (d_agent_carpet < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_carpet): \n    d_agent_carpet = calculate_distance_min(s_agent, s_carpet) \n    penalty_collision = -30 if (d_agent_carpet < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the jewelry box. \n Assumption: Agent's state, target's state and jewelry box's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_jewelry_box, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_jewelry_box = calculate_distance_min(s_agent, s_jewelry_box) \n    penalty_collision = -30 if (d_agent_jewelry_box < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_jewelry_box): \n    d_agent_jewelry_box = calculate_distance_min(s_agent, s_jewelry_box) \n    penalty_collision = -30 if (d_agent_jewelry_box < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the vanity table. \n Assumption: Agent's state, target's state and vanity table's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_vanity_table, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_vanity_table = calculate_distance_min(s_agent, s_vanity_table) \n    penalty_collision = -30 if (d_agent_vanity_table < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_vanity_table): \n    d_agent_vanity_table = calculate_distance_min(s_agent, s_vanity_table) \n    penalty_collision = -30 if (d_agent_vanity_table < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the scarf bundle. \n Assumption: Agent's state, target's state and scarf bundle's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_bundle, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_bundle = calculate_distance_min(s_agent, s_bundle) \n    penalty_collision = -30 if (d_agent_bundle < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_bundle): \n    d_agent_bundle = calculate_distance_min(s_agent, s_bundle) \n    penalty_collision = -30 if (d_agent_bundle < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the wall mirror. \n Assumption: Agent's state, target's state and wall mirror's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_wall_mirror, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_wall_mirror = calculate_distance_min(s_agent, s_wall_mirror) \n    penalty_collision = -30 if (d_agent_wall_mirror < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_wall_mirror): \n    d_ = calculate_distance_min(s_agent, s_wall_mirror) \n    penalty_collision = -30 if (d_agent_wall_mirror < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the clothing pile. \n Assumption: Agent's state, target's state and clothing pile's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_clothing_pile, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_clothing_pile = calculate_distance_min(s_agent, s_clothing_pile) \n    penalty_collision = -30 if (d_agent_clothing_pile < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_clothing_pile): \n    d_agent_clothing_pile = calculate_distance_min(s_agent, s_clothing_pile) \n    penalty_collision = -30 if (d_agent_clothing_pile < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the makeup kit. \n Assumption: Agent's state, target's state and makeup kit's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_makeup_kit, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_makeup_kit = calculate_distance_min(s_agent, s_makeup_kit) \n    penalty_collision = -30 if (d_agent_makeup_kit < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_makeup_kit): \n    d_agent_makeup_kit = calculate_distance_min(s_agent, s_makeup_kit) \n    penalty_collision = -30 if (d_agent_makeup_kit < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the wardrobe. \n Assumption: Agent's state, target's state and wardrobe's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_wardrobe, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = -30 if (d_agent_wardrobe < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_wardrobe): \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = -30 if (d_agent_wardrobe < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the clothes. \n Assumption: Agent's state, target's state and clothes's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_clothe, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_clothe = calculate_distance_min(s_agent, s_clothe) \n    penalty_collision = -30 if (d_agent_clothe < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_clothe): \n    d_agent_clothe = calculate_distance_min(s_agent, s_clothe) \n    penalty_collision = -30 if (d_agent_clothe < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the full-length mirror. \n Assumption: Agent's state, target's state and full-length mirror's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_mirror, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_mirror = calculate_distance_min(s_agent, s_mirror) \n    penalty_collision = -30 if (d_agent_mirror < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_mirror): \n    d_agent_mirror = calculate_distance_min(s_agent, s_mirror) \n    penalty_collision = -30 if (d_agent_mirror < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the makeup brush set. \n Assumption: Agent's state, target's state and makeup brush set's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_makeup_brush, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_makeup_brush = calculate_distance_min(s_agent, s_makeup_brush) \n    penalty_collision = -30 if (d_agent_makeup_brush < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_makeup_brush): \n    d_agent_makeup_brush = calculate_distance_min(s_agent, s_makeup_brush) \n    penalty_collision = -30 if (d_agent_makeup_brush < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the hanger rod. \n Assumption: Agent's state, target's state and hanger rod's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_hanger_rod, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_hanger_rod = calculate_distance_min(s_agent, s_hanger_rod) \n    penalty_collision = -30 if (d_agent_hanger_rod < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_hanger_rod): \n    d_agent_hanger_rod = calculate_distance_min(s_agent, s_hanger_rod) \n    penalty_collision = -30 if (d_agent_hanger_rod < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the dressing room shelf unit. \n Assumption: Agent's state, target's state and dressing room shelf unit's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_shelf, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -30 if (d_agent_shelf < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_shelf): \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -30 if (d_agent_shelf < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the laundry hamper. \n Assumption: Agent's state, target's state and laundry hamper's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_laundry_hamper, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_laundry_hamper = calculate_distance_min(s_agent, s_laundry_hamper) \n    penalty_collision = -30 if (d_agent_laundry_hamper < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_laundry_hamper): \n    d_agent_laundry_hamper = calculate_distance_min(s_agent, s_laundry_hamper) \n    penalty_collision = -30 if (d_agent_laundry_hamper < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the shoe box. \n Assumption: Agent's state, target's state and shoe box's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_shoe_box, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_shoe_box = calculate_distance_min(s_agent, s_shoe_box) \n    penalty_collision = -30 if (d_agent_shoe_box < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_shoe_box): \n    d_agent_shoe_box = calculate_distance_min(s_agent, s_shoe_box) \n    penalty_collision = -30 if (d_agent_shoe_box < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the belt. \n Assumption: Agent's state, target's state and belt's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_belt, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_belt = calculate_distance_min(s_agent, s_belt) \n    penalty_collision = -30 if (d_agent_belt < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_belt): \n    d_agent_belt = calculate_distance_min(s_agent, s_belt) \n    penalty_collision = -30 if (d_agent_belt < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the lamp. \n Assumption: Agent's state, target's state and lamp's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_lamp, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -30 if (d_agent_lamp < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_lamp): \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -30 if (d_agent_lamp < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an dressing room. \n Goal:  The drone must avoid colliding with the dressing light. \n Assumption: Agent's state, target's state and dressing light's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_light, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_light = calculate_distance_min(s_agent, s_light) \n    penalty_collision = -30 if (d_agent_light < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_light): \n    d_agent_light = calculate_distance_min(s_agent, s_light) \n    penalty_collision = -30 if (d_agent_light < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an dressing room. Target: The drone must avoid colliding with chair, carpet and vanity table. Assumptions: The Agent's state, target's state and the states of multiple obstacles: chair, carpet, and vanity table are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -30 if (d_agent_multiple_obstacles_min < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -30 if (d_agent_multiple_obstacles_min < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an dressing room. Target: The drone must avoid colliding with shoe rack corner and laundry basket frame. Assumptions: The Agent's state, target's state and the states of multiple obstacles: shoe rack corner, and laundry basket frame are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -30 if (d_agent_multiple_obstacles_min < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -30 if (d_agent_multiple_obstacles_min < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an dressing room. Target: The drone must avoid colliding with scarf bundle, hanger rod section and makeup brush set. Assumptions: The Agent's state, target's state and the states of multiple obstacles: scarf bundle, hanger rod section, and makeup brush set are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -30 if (d_agent_multiple_obstacles_min < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -30 if (d_agent_multiple_obstacles_min < 0.8) else 20 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an dressing room. Target: The drone must avoid colliding with jewelry box hanger rod and shoe box. Assumptions: The Agent's state, target's state and the states of multiple obstacles: jewelry box hanger rod, and shoe box are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -30 if (d_agent_multiple_obstacles_min < 0.8) else 20 \n    reward_reaching_target = 32 if (d_agent_target < 0.1) else -math.exp(d_agent_target) \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -30 if (d_agent_multiple_obstacles_min < 0.8) else 20 \n    return penalty_collision"
  },



  
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the trunk. \n Assumption: Agent's state, target's state and trunk's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_trunk, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_trunk = calculate_distance_min(s_agent, s_trunk) \n    penalty_collision = -10 if (d_agent_trunk < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_trunk): \n    d_agent_trunk = calculate_distance_min(s_agent, s_trunk) \n    penalty_collision = -10 if (d_agent_trunk < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the old suitcase. \n Assumption: Agent's state, target's state and old suitcase's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_suitcase, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_suitcase = calculate_distance_min(s_agent, s_suitcase) \n    penalty_collision = -10 if (d_agent_suitcase < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_suitcase): \n    d_agent_suitcase = calculate_distance_min(s_agent, s_suitcase) \n    penalty_collision = -10 if (d_agent_suitcase < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the oil lamp. \n Assumption: Agent's state, target's state and oil lamp's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_oil_lamp, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_oil_lamp = calculate_distance_min(s_agent, s_oil_lamp) \n    penalty_collision = -10 if (d_agent_oil_lamp < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_oil_lamp): \n    d_agent_oil_lamp = calculate_distance_min(s_agent, s_oil_lamp) \n    penalty_collision = -10 if (d_agent_oil_lamp < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the stair. \n Assumption: Agent's state, target's state and stair's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_stair, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_stair = calculate_distance_min(s_agent, s_stair) \n    penalty_collision = -10 if (d_agent_stair < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_stair): \n    d_agent_stair = calculate_distance_min(s_agent, s_stair) \n    penalty_collision = -10 if (d_agent_stair < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the wooden chest. \n Assumption: Agent's state, target's state and wooden chest's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_wooden_chest, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_wooden_chest = calculate_distance_min(s_agent, s_wooden_chest) \n    penalty_collision = -10 if (d_agent_wooden_chest < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_wooden_chest): \n    d_agent_wooden_chest = calculate_distance_min(s_agent, s_wooden_chest) \n    penalty_collision = -10 if (d_agent_wooden_chest < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the broken chair. \n Assumption: Agent's state, target's state and broken chair's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_chair, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -10 if (d_agent_chair < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_chair): \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -10 if (d_agent_chair < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the rope bundle. \n Assumption: Agent's state, target's state and rope bundle's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_rope_bundle, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_rope_bundle = calculate_distance_min(s_agent, s_rope_bundle) \n    penalty_collision = -10 if (d_agent_rope_bundle < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_rope_bundle): \n    d_agent_rope_bundle = calculate_distance_min(s_agent, s_rope_bundle) \n    penalty_collision = -10 if (d_agent_rope_bundle < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the food jar. \n Assumption: Agent's state, target's state and food jar's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_food_jar, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_food_jar = calculate_distance_min(s_agent, s_food_jar) \n    penalty_collision = -10 if (d_agent_food_jar < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_food_jar): \n    d_agent_food_jar = calculate_distance_min(s_agent, s_food_jar) \n    penalty_collision = -10 if (d_agent_food_jar < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the newspaper stack. \n Assumption: Agent's state, target's state and newspaper stack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_newspaper_stack, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_newspaper_stack = calculate_distance_min(s_agent, s_newspaper_stack) \n    penalty_collision = -10 if (d_agent_newspaper_stack < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_newspaper_stack): \n    d_agent_newspaper_stack = calculate_distance_min(s_agent, s_newspaper_stack) \n    penalty_collision = -10 if (d_agent_newspaper_stack < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the paint can. \n Assumption: Agent's state, target's state and paint can's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_paint_can, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_paint_can = calculate_distance_min(s_agent, s_paint_can) \n    penalty_collision = -10 if (d_agent_paint_can < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_paint_can): \n    d_agent_paint_can = calculate_distance_min(s_agent, s_paint_can) \n    penalty_collision = -10 if (d_agent_paint_can < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the old attic worker. \n Assumption: Agent's state, target's state and old attic worker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_worker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -10 if (d_agent_worker < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -10 if (d_agent_worker < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the box of books. \n Assumption: Agent's state, target's state and box of books's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_book, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -10 if (d_agent_book < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_book): \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -10 if (d_agent_book < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the full-length attic window. \n Assumption: Agent's state, target's state and full-length attic window's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_window, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_window = calculate_distance_min(s_agent, s_window) \n    penalty_collision = -10 if (d_agent_window < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_window): \n    d_agent_window = calculate_distance_min(s_agent, s_window) \n    penalty_collision = -10 if (d_agent_window < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the cobweb cluster. \n Assumption: Agent's state, target's state and cobweb cluster's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cobweb_cluster, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cobweb_cluster = calculate_distance_min(s_agent, s_cobweb_cluster) \n    penalty_collision = -10 if (d_agent_cobweb_cluster < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cobweb_cluster): \n    d_agent_cobweb_cluster = calculate_distance_min(s_agent, s_cobweb_cluster) \n    penalty_collision = -10 if (d_agent_cobweb_cluster < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the wooden beam. \n Assumption: Agent's state, target's state and wooden beam's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_wooden_beam, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_wooden_beam = calculate_distance_min(s_agent, s_wooden_beam) \n    penalty_collision = -10 if (d_agent_wooden_beam < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_wooden_beam): \n    d_agent_wooden_beam = calculate_distance_min(s_agent, s_wooden_beam) \n    penalty_collision = -10 if (d_agent_wooden_beam < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the attic shelf unit. \n Assumption: Agent's state, target's state and attic shelf unit's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_shelf_unit, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_shelf_unit = calculate_distance_min(s_agent, s_shelf_unit) \n    penalty_collision = -10 if (d_agent_shelf_unit < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_shelf_unit): \n    d_agent_shelf_unit = calculate_distance_min(s_agent, s_shelf_unit) \n    penalty_collision = -10 if (d_agent_shelf_unit < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the basket of apples. \n Assumption: Agent's state, target's state and basket of apples's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_apple_basket, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_apple_basket = calculate_distance_min(s_agent, s_apple_basket) \n    penalty_collision = -10 if (d_agent_apple_basket < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_apple_basket): \n    d_agent_apple_basket = calculate_distance_min(s_agent, s_apple_basket) \n    penalty_collision = -10 if (d_agent_apple_basket < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the hat box. \n Assumption: Agent's state, target's state and hat box's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_box, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -10 if (d_agent_box < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_box): \n    d_agent_box = calculate_distance_min(s_agent, s_box) \n    penalty_collision = -10 if (d_agent_box < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the coat hook. \n Assumption: Agent's state, target's state and coat hook's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_coat_hook, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_coat_hook = calculate_distance_min(s_agent, s_coat_hook) \n    penalty_collision = -10 if (d_agent_coat_hook < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_coat_hook): \n    d_agent_coat_hook = calculate_distance_min(s_agent, s_coat_hook) \n    penalty_collision = -10 if (d_agent_coat_hook < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the attic worker. \n Assumption: Agent's state, target's state and attic worker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_attic_worker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_attic_worker = calculate_distance_min(s_agent, s_attic_worker) \n    penalty_collision = -10 if (d_agent_attic_worker < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_attic_worker): \n    d_agent_attic_worker = calculate_distance_min(s_agent, s_attic_worker) \n    penalty_collision = -10 if (d_agent_attic_worker < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an attic. \n Goal:  The drone must avoid hitting with the hanging lantern. \n Assumption: Agent's state, target's state and hanging lantern's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_lantern, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_lantern = calculate_distance_min(s_agent, s_lantern) \n    penalty_collision = -10 if (d_agent_lantern < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_lantern): \n    d_agent_lantern = calculate_distance_min(s_agent, s_lantern) \n    penalty_collision = -10 if (d_agent_lantern < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an attic. Target: The drone must avoid hitting with chair, dusty stair and broken chair. Assumptions: The Agent's state, target's state and the states of multiple obstacles: chair, dusty stair, and broken chair are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an attic. Target: The drone must avoid hitting with trunk corner and old suitcase frame. Assumptions: The Agent's state, target's state and the states of multiple obstacles: trunk corner, and old suitcase frame are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an attic. Target: The drone must avoid hitting with rope bundle, wooden beam section and cobweb cluster. Assumptions: The Agent's state, target's state and the states of multiple obstacles: rope bundle, wooden beam section, and cobweb cluster are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 0 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an attic. Target: The drone must avoid hitting with wooden chest wooden beam and hat box. Assumptions: The Agent's state, target's state and the states of multiple obstacles: wooden chest wooden beam, and hat box are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 0 \n    reward_reaching_target = 20 if (d_agent_target < 0.3) else -3*d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 0 \n    return penalty_collision"
  },

  
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the bench. \n Assumption: Agent's state, target's state and bench's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_bench, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -28 if (d_agent_bench < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_bench): \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -28 if (d_agent_bench < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the file clerk_desk. \n Assumption: Agent's state, target's state and file clerk_desk's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_file_clerk_desk, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_file_clerk_desk = calculate_distance_min(s_agent, s_file_clerk_desk) \n    penalty_collision = -28 if (d_agent_file_clerk_desk < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_file_clerk_desk): \n    d_agent_file_clerk_desk = calculate_distance_min(s_agent, s_file_clerk_desk) \n    penalty_collision = -28 if (d_agent_file_clerk_desk < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the court seal plaque. \n Assumption: Agent's state, target's state and court seal plaque's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_seal_plaque, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_seal_plaque = calculate_distance_min(s_agent, s_seal_plaque) \n    penalty_collision = -28 if (d_agent_seal_plaque < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_seal_plaque): \n    d_agent_seal_plaque = calculate_distance_min(s_agent, s_seal_plaque) \n    penalty_collision = -28 if (d_agent_seal_plaque < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the lawyer. \n Assumption: Agent's state, target's state and lawyer's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_lawyer, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_lawyer = calculate_distance_min(s_agent, s_lawyer) \n    penalty_collision = -28 if (d_agent_lawyer < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_lawyer): \n    d_agent_lawyer = calculate_distance_min(s_agent, s_lawyer) \n    penalty_collision = -28 if (d_agent_lawyer < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the evidence locker. \n Assumption: Agent's state, target's state and evidence locker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_evidence_locker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_evidence_locker = calculate_distance_min(s_agent, s_evidence_locker) \n    penalty_collision = -28 if (d_agent_evidence_locker < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_evidence_locker): \n    d_agent_evidence_locker = calculate_distance_min(s_agent, s_evidence_locker) \n    penalty_collision = -28 if (d_agent_evidence_locker < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the witness stand. \n Assumption: Agent's state, target's state and witness stand's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_witness_stand, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_witness_stand = calculate_distance_min(s_agent, s_witness_stand) \n    penalty_collision = -28 if (d_agent_witness_stand < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_witness_stand): \n    d_agent_witness_stand = calculate_distance_min(s_agent, s_witness_stand) \n    penalty_collision = -28 if (d_agent_witness_stand < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the judge. \n Assumption: Agent's state, target's state and judge's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_judge, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_judge = calculate_distance_min(s_agent, s_judge) \n    penalty_collision = -28 if (d_agent_judge < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_judge): \n    d_agent_judge = calculate_distance_min(s_agent, s_judge) \n    penalty_collision = -28 if (d_agent_judge < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the jury box. \n Assumption: Agent's state, target's state and jury box's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_jury_box, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_jury_box = calculate_distance_min(s_agent, s_jury_box) \n    penalty_collision = -28 if (d_agent_jury_box < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_jury_box): \n    d_agent_jury_box = calculate_distance_min(s_agent, s_jury_box) \n    penalty_collision = -28 if (d_agent_jury_box < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the witness stand. \n Assumption: Agent's state, target's state and witness stand's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_witness_stand, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_witness_stand = calculate_distance_min(s_agent, s_witness_stand) \n    penalty_collision = -28 if (d_agent_witness_stand < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_witness_stand): \n    d_agent_witness_stand = calculate_distance_min(s_agent, s_witness_stand) \n    penalty_collision = -28 if (d_agent_witness_stand < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the water pitcher. \n Assumption: Agent's state, target's state and water pitcher's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_water_pitcher, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_water_pitcher = calculate_distance_min(s_agent, s_water_pitcher) \n    penalty_collision = -28 if (d_agent_water_pitcher < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_water_pitcher): \n    d_agent_water_pitcher = calculate_distance_min(s_agent, s_water_pitcher) \n    penalty_collision = -28 if (d_agent_water_pitcher < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the clerk desk. \n Assumption: Agent's state, target's state and clerk desk's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_clerk_desk, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_clerk_desk = calculate_distance_min(s_agent, s_clerk_desk) \n    penalty_collision = -28 if (d_agent_clerk_desk < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_clerk_desk): \n    d_agent_clerk_desk = calculate_distance_min(s_agent, s_clerk_desk) \n    penalty_collision = -28 if (d_agent_clerk_desk < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the podium. \n Assumption: Agent's state, target's state and podiums's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_podium, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_podium = calculate_distance_min(s_agent, s_podium) \n    penalty_collision = -28 if (d_agent_podium < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_podium): \n    d_agent_podium = calculate_distance_min(s_agent, s_podium) \n    penalty_collision = -28 if (d_agent_podium < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the camera. \n Assumption: Agent's state, target's state and camera's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_camera, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_camera = calculate_distance_min(s_agent, s_camera) \n    penalty_collision = -28 if (d_agent_camera < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_camera): \n    d_agent_camera = calculate_distance_min(s_agent, s_camera) \n    penalty_collision = -28 if (d_agent_camera < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the victim. \n Assumption: Agent's state, target's state and witness's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_witness, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_witness = calculate_distance_min(s_agent, s_witness) \n    penalty_collision = -28 if (d_agent_witness < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_witness): \n    d_agent_witness = calculate_distance_min(s_agent, s_witness) \n    penalty_collision = -28 if (d_agent_witness < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the clock. \n Assumption: Agent's state, target's state and clock's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_clock, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_clock = calculate_distance_min(s_agent, s_clock) \n    penalty_collision = -28 if (d_agent_clock < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_clock): \n    d_agent_clock = calculate_distance_min(s_agent, s_clock) \n    penalty_collision = -28 if (d_agent_clock < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the courthouse platform. \n Assumption: Agent's state, target's state and courthouse platform's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_platform, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -28 if (d_agent_platform < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_platform): \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -28 if (d_agent_platform < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the evidence box. \n Assumption: Agent's state, target's state and evidence box's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_evidence_box, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_evidence_box = calculate_distance_min(s_agent, s_evidence_box) \n    penalty_collision = -28 if (d_agent_evidence_box < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_evidence_box): \n    d_agent_evidence_box = calculate_distance_min(s_agent, s_evidence_box) \n    penalty_collision = -28 if (d_agent_evidence_box < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the briefcase. \n Assumption: Agent's state, target's state and briefcase's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_brief, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_briefcase = calculate_distance_min(s_agent, s_briefcase) \n    penalty_collision = -28 if (d_agent_briefcase < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_briefcase): \n    d_agent_briefcase = calculate_distance_min(s_agent, s_briefcase) \n    penalty_collision = -28 if (d_agent_briefcase < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the gavel block. \n Assumption: Agent's state, target's state and gavel block's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_gavel_block, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_gavel_block = calculate_distance_min(s_agent, s_gavel_block) \n    penalty_collision = -28 if (d_agent_gavel_block < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_gavel_block): \n    d_agent_gavel_block = calculate_distance_min(s_agent, s_gavel_block) \n    penalty_collision = -28 if (d_agent_gavel_block < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the courthouse worker. \n Assumption: Agent's state, target's state and courthouse worker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_courthouse_worker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_courthouse_worker = calculate_distance_min(s_agent, s_courthouse_worker) \n    penalty_collision = -28 if (d_agent_courthouse_worker < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_courthouse_worker): \n    d_agent_courthouse_worker = calculate_distance_min(s_agent, s_courthouse_worker) \n    penalty_collision = -28 if (d_agent_courthouse_worker < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an courthouse. \n Goal:  The drone must avoid colliding with the microphone stand. \n Assumption: Agent's state, target's state and microphone stand's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_microphone_stand, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_microphone_stand = calculate_distance_min(s_agent, s_microphone_stand) \n    penalty_collision = -28 if (d_agent_microphone_stand < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_microphone_stand): \n    d_agent_microphone_stand = calculate_distance_min(s_agent, s_microphone_stand) \n    penalty_collision = -28 if (d_agent_microphone_stand < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an courthouse. Target: The drone must avoid colliding with chair, carpet runner and witness stand. Assumptions: The Agent's state, target's state and the states of multiple obstacles: chair, judge, and witness stand are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an courthouse. Target: The drone must avoid colliding with wooden bench corner and file clerk_desk frame. Assumptions: The Agent's state, target's state and the states of multiple obstacles: wooden bench corner, and file, clerk desk frame are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an courthouse. Target: The drone must avoid colliding with restricted rope, clock section and pile of papers. Assumptions: The Agent's state, target's state and the states of multiple obstacles: restricted rope, clock, and pile of papers are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an courthouse. Target: The drone must avoid colliding with evidence locker clock and briefcase. Assumptions: The Agent's state, target's state and the states of multiple obstacles: evidence locker clock, and briefcase are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },



  
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the lab bench. \n Assumption: Agent's state, target's state and lab bench's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_lab bench, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_lab bench = calculate_distance_min(s_agent, s_lab bench) \n    penalty_collision = -25 if (d_agent_lab bench < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_lab bench): \n    d_agent_lab bench = calculate_distance_min(s_agent, s_lab bench) \n    penalty_collision = -25 if (d_agent_lab bench < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the chemical locker. \n Assumption: Agent's state, target's state and chemical locker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_chemical_locker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_chemical_locker = calculate_distance_min(s_agent, s_chemical_locker) \n    penalty_collision = -25 if (d_agent_chemical_locker < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_chemical_locker): \n    d_agent_chemical_locker = calculate_distance_min(s_agent, s_chemical_locker) \n    penalty_collision = -25 if (d_agent_chemical_locker < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the bunsen burner. \n Assumption: Agent's state, target's state and bunsen burner's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_bunsen_burner, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_bunsen_burner = calculate_distance_min(s_agent, s_bunsen_burner) \n    penalty_collision = -25 if (d_agent_bunsen_burner < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_bunsen_burner): \n    d_agent_bunsen_burner = calculate_distance_min(s_agent, s_bunsen_burner) \n    penalty_collision = -25 if (d_agent_bunsen_burner < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the floor mat. \n Assumption: Agent's state, target's state and floor mat's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_floor_mat, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_floor_mat = calculate_distance_min(s_agent, s_floor_mat) \n    penalty_collision = -25 if (d_agent_floor_mat < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_floor_mat): \n    d_agent_floor_mat = calculate_distance_min(s_agent, s_floor_mat) \n    penalty_collision = -25 if (d_agent_floor_mat < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the sample. \n Assumption: Agent's state, target's state and sample's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_sample, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_sample = calculate_distance_min(s_agent, s_sample) \n    penalty_collision = -25 if (d_agent_sample < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_sample): \n    d_agent_sample = calculate_distance_min(s_agent, s_sample) \n    penalty_collision = -25 if (d_agent_sample < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the lab stool. \n Assumption: Agent's state, target's state and lab stool's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_lab stool, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_lab stool = calculate_distance_min(s_agent, s_lab stool) \n    penalty_collision = -25 if (d_agent_lab stool < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_lab stool): \n    d_agent_lab stool = calculate_distance_min(s_agent, s_lab stool) \n    penalty_collision = -25 if (d_agent_lab stool < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the tube. \n Assumption: Agent's state, target's state and tube's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_tube, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_tube = calculate_distance_min(s_agent, s_tube) \n    penalty_collision = -25 if (d_agent_tube < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_tube): \n    d_agent_tube = calculate_distance_min(s_agent, s_tube) \n    penalty_collision = -25 if (d_agent_tube < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the wall chemical locker. \n Assumption: Agent's state, target's state and wall chemical locker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_chemical_locker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_chemical_locker = calculate_distance_min(s_agent, s_chemical_locker) \n    penalty_collision = -25 if (d_agent_chemical_locker < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_chemical_locker): \n    d_agent_chemical_locker = calculate_distance_min(s_agent, s_chemical_locker) \n    penalty_collision = -25 if (d_agent_chemical_locker < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the acid bottle. \n Assumption: Agent's state, target's state and acid bottle's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_acid_bottle, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_acid_bottle = calculate_distance_min(s_agent, s_acid_bottle) \n    penalty_collision = -25 if (d_agent_acid_bottle < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_acid_bottle): \n    d_agent_acid_bottle = calculate_distance_min(s_agent, s_acid_bottle) \n    penalty_collision = -25 if (d_agent_acid_bottle < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the reagent bottle. \n Assumption: Agent's state, target's state and reagent bottle's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_reagent_bottle, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_reagent_bottle = calculate_distance_min(s_agent, s_reagent_bottle) \n    penalty_collision = -25 if (d_agent_reagent_bottle < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_reagent_bottle): \n    d_agent_reagent_bottle = calculate_distance_min(s_agent, s_reagent_bottle) \n    penalty_collision = -25 if (d_agent_reagent_bottle < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the pipette stand. \n Assumption: Agent's state, target's state and pipette stand's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_pipette_stand, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_pipette_stand = calculate_distance_min(s_agent, s_pipette_stand) \n    penalty_collision = -25 if (d_agent_pipette_stand < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_pipette_stand): \n    d_agent_pipette_stand = calculate_distance_min(s_agent, s_pipette_stand) \n    penalty_collision = -25 if (d_agent_pipette_stand < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the incubator. \n Assumption: Agent's state, target's state and incubator's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_incubator, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_incubator = calculate_distance_min(s_agent, s_incubator) \n    penalty_collision = -25 if (d_agent_incubator < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_incubator): \n    d_agent_incubator = calculate_distance_min(s_agent, s_incubator) \n    penalty_collision = -25 if (d_agent_incubator < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the centrifuge. \n Assumption: Agent's state, target's state and centrifuge's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_centrifuge, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_centrifuge = calculate_distance_min(s_agent, s_centrifuge) \n    penalty_collision = -25 if (d_agent_centrifuge < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_centrifuge): \n    d_agent_centrifuge = calculate_distance_min(s_agent, s_centrifuge) \n    penalty_collision = -25 if (d_agent_centrifuge < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the gas cylinder. \n Assumption: Agent's state, target's state and gas cylinder's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_gas_cylinder, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_gas_cylinder = calculate_distance_min(s_agent, s_gas_cylinder) \n    penalty_collision = -25 if (d_agent_gas_cylinder < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_gas_cylinder): \n    d_agent_gas_cylinder = calculate_distance_min(s_agent, s_gas_cylinder) \n    penalty_collision = -25 if (d_agent_gas_cylinder < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the glassware rack. \n Assumption: Agent's state, target's state and glassware rack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_glassware_rack, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_glassware_rack = calculate_distance_min(s_agent, s_glassware_rack) \n    penalty_collision = -25 if (d_agent_glassware_rack < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_glassware_rack): \n    d_agent_glassware_rack = calculate_distance_min(s_agent, s_glassware_rack) \n    penalty_collision = -25 if (d_agent_glassware_rack < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the laboratory shelf unit. \n Assumption: Agent's state, target's state and laboratory shelf unit's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_shelf, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -25 if (d_agent_shelf < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_shelf): \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -25 if (d_agent_shelf < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the sink. \n Assumption: Agent's state, target's state and sink's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_sink, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_sink = calculate_distance_min(s_agent, s_sink) \n    penalty_collision = -25 if (d_agent_sink < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_sink): \n    d_agent_sink = calculate_distance_min(s_agent, s_sink) \n    penalty_collision = -25 if (d_agent_sink < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the sample container. \n Assumption: Agent's state, target's state and sample container's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_sample_container, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_sample_container = calculate_distance_min(s_agent, s_sample_container) \n    penalty_collision = -25 if (d_agent_sample_container < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_sample_container): \n    d_agent_sample_container = calculate_distance_min(s_agent, s_sample_container) \n    penalty_collision = -25 if (d_agent_sample_container < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the test tube rack. \n Assumption: Agent's state, target's state and test tube rack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cord, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cord = calculate_distance_min(s_agent, s_cord) \n    penalty_collision = -25 if (d_agent_cord < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cord): \n    d_agent_cord = calculate_distance_min(s_agent, s_cord) \n    penalty_collision = -25 if (d_agent_cord < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the refrigerator. \n Assumption: Agent's state, target's state and refrigerator's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_refrigerator, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_refrigerator = calculate_distance_min(s_agent, s_refrigerator) \n    penalty_collision = -25 if (d_agent_refrigerator < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_refrigerator): \n    d_agent_refrigerator = calculate_distance_min(s_agent, s_refrigerator) \n    penalty_collision = -25 if (d_agent_refrigerator < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in an laboratory. \n Goal:  The drone must avoid colliding with the waste bin. \n Assumption: Agent's state, target's state and waste bin's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_waste_bin, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_waste_bin = calculate_distance_min(s_agent, s_waste_bin) \n    penalty_collision = -25 if (d_agent_waste_bin < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_waste_bin): \n    d_agent_waste_bin = calculate_distance_min(s_agent, s_waste_bin) \n    penalty_collision = -25 if (d_agent_waste_bin < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an laboratory. Target: The drone must avoid colliding with chair, floor mat and lab stool. Assumptions: The Agent's state, target's state and the states of multiple obstacles: chair, floor mat, and lab stool are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an laboratory. Target: The drone must avoid colliding with lab bench corner and chemical locker frame. Assumptions: The Agent's state, target's state and the states of multiple obstacles: lab bench corner, and chemical locker frame are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an laboratory. Target: The drone must avoid colliding with tubing coil, support pole section and wires cluster. Assumptions: The Agent's state, target's state and the states of multiple obstacles: tubing coil, support pole section, and wires cluster are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating an laboratory. Target: The drone must avoid colliding with sample freezer support pole and sample container. Assumptions: The Agent's state, target's state and the states of multiple obstacles: sample freezer support pole, and sample container are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 30 if (d_agent_target < 0.1) else -40 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -25 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },


  
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the prison bench. \n Assumption: Agent's state, target's state and prison bench's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_prison_bench, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_prison_bench = calculate_distance_min(s_agent, s_prison_bench) \n    penalty_collision = -28 if (d_agent_prison_bench < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_prison_bench): \n    d_agent_prison_bench = calculate_distance_min(s_agent, s_prison_bench) \n    penalty_collision = -28 if (d_agent_prison_bench < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the cell locker. \n Assumption: Agent's state, target's state and cell locker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cell_locker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cell_locker = calculate_distance_min(s_agent, s_cell_locker) \n    penalty_collision = -28 if (d_agent_cell_locker < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cell_locker): \n    d_agent_cell_locker = calculate_distance_min(s_agent, s_cell_locker) \n    penalty_collision = -28 if (d_agent_cell_locker < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the metal tray. \n Assumption: Agent's state, target's state and metal tray's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_metal_tray, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_metal_tray = calculate_distance_min(s_agent, s_metal_tray) \n    penalty_collision = -28 if (d_agent_metal_tray < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_metal_tray): \n    d_agent_metal_tray = calculate_distance_min(s_agent, s_metal_tray) \n    penalty_collision = -28 if (d_agent_metal_tray < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the concrete floor. \n Assumption: Agent's state, target's state and concrete floor's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_concrete_floor, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_concrete_floor = calculate_distance_min(s_agent, s_concrete_floor) \n    penalty_collision = -28 if (d_agent_concrete_floor < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_concrete_floor): \n    d_agent_concrete_floor = calculate_distance_min(s_agent, s_concrete_floor) \n    penalty_collision = -28 if (d_agent_concrete_floor < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the storage trunk. \n Assumption: Agent's state, target's state and storage trunk's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_storage_trunk, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_storage_trunk = calculate_distance_min(s_agent, s_storage_trunk) \n    penalty_collision = -28 if (d_agent_storage_trunk < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_storage_trunk): \n    d_agent_storage_trunk = calculate_distance_min(s_agent, s_storage_trunk) \n    penalty_collision = -28 if (d_agent_storage_trunk < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the prison stool. \n Assumption: Agent's state, target's state and prison stool's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_prison_stool, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_prison_stool = calculate_distance_min(s_agent, s_prison_stool) \n    penalty_collision = -28 if (d_agent_prison_stool < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_prison_stool): \n    d_agent_prison_stool = calculate_distance_min(s_agent, s_prison_stool) \n    penalty_collision = -28 if (d_agent_prison_stool < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the handcuffs. \n Assumption: Agent's state, target's state and handcuffs's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_handcuff, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_handcuff = calculate_distance_min(s_agent, s_handcuff) \n    penalty_collision = -28 if (d_agent_handcuff < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_handcuff): \n    d_agent_handcuff = calculate_distance_min(s_agent, s_handcuff) \n    penalty_collision = -28 if (d_agent_handcuff < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the wall cell locker. \n Assumption: Agent's state, target's state and wall cell locker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cell_locker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cell_locker = calculate_distance_min(s_agent, s_cell_locker) \n    penalty_collision = -28 if (d_agent_cell_locker < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cell_locker): \n    d_agent_cell_locker = calculate_distance_min(s_agent, s_cell_locker) \n    penalty_collision = -28 if (d_agent_cell_locker < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the prison log. \n Assumption: Agent's state, target's state and prison log's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_prison_log, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_prison_log = calculate_distance_min(s_agent, s_prison_log) \n    penalty_collision = -28 if (d_agent_prison_log < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_prison_log): \n    d_agent_prison_log = calculate_distance_min(s_agent, s_prison_log) \n    penalty_collision = -28 if (d_agent_prison_log < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the water bottle. \n Assumption: Agent's state, target's state and water bottle's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_water_bottle, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_water_bottle = calculate_distance_min(s_agent, s_water_bottle) \n    penalty_collision = -28 if (d_agent_water_bottle < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_water_bottle): \n    d_agent_water_bottle = calculate_distance_min(s_agent, s_water_bottle) \n    penalty_collision = -28 if (d_agent_water_bottle < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the old jail worker. \n Assumption: Agent's state, target's state and old jail worker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_worker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -28 if (d_agent_worker < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -28 if (d_agent_worker < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the bed frame. \n Assumption: Agent's state, target's state and bed frame's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_bed_frame, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_bed_frame = calculate_distance_min(s_agent, s_bed_frame) \n    penalty_collision = -28 if (d_agent_bed_frame < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_bed_frame): \n    d_agent_bed_frame = calculate_distance_min(s_agent, s_bed_frame) \n    penalty_collision = -28 if (d_agent_bed_frame < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the TV. \n Assumption: Agent's state, target's state and TV's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_TV, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_TV = calculate_distance_min(s_agent, s_TV) \n    penalty_collision = -28 if (d_agent_TV < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_TV): \n    d_agent_TV = calculate_distance_min(s_agent, s_TV) \n    penalty_collision = -28 if (d_agent_TV < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the loose wires. \n Assumption: Agent's state, target's state and loose wires's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_wire, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = -28 if (d_agent_wire < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_wire): \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = -28 if (d_agent_wire < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the cell bars. \n Assumption: Agent's state, target's state and cell bars's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cell_bars, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cell_bars = calculate_distance_min(s_agent, s_cell_bars) \n    penalty_collision = -28 if (d_agent_cell_bars < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cell_bars): \n    d_agent_cell_bars = calculate_distance_min(s_agent, s_cell_bars) \n    penalty_collision = -28 if (d_agent_cell_bars < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the jail shelf unit. \n Assumption: Agent's state, target's state and jail shelf unit's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_shelf, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -28 if (d_agent_shelf < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_shelf): \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -28 if (d_agent_shelf < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the tin plate set. \n Assumption: Agent's state, target's state and tin plate set's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_tin_plate_set, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_tin_plate_set = calculate_distance_min(s_agent, s_tin_plate_set) \n    penalty_collision = -28 if (d_agent_tin_plate_set < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_tin_plate_set): \n    d_agent_tin_plate_set = calculate_distance_min(s_agent, s_tin_plate_set) \n    penalty_collision = -28 if (d_agent_tin_plate_set < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the evidence bag. \n Assumption: Agent's state, target's state and evidence bag's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_evidence_bag, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_evidence_bag = calculate_distance_min(s_agent, s_evidence_bag) \n    penalty_collision = -28 if (d_agent_evidence_bag < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_evidence_bag): \n    d_agent_evidence_bag = calculate_distance_min(s_agent, s_evidence_bag) \n    penalty_collision = -28 if (d_agent_evidence_bag < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the cup holder. \n Assumption: Agent's state, target's state and cup holder's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cup_holder, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cup_holder = calculate_distance_min(s_agent, s_cup_holder) \n    penalty_collision = -28 if (d_agent_cup_holder < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cup_holder): \n    d_agent_cup_holder = calculate_distance_min(s_agent, s_cup_holder) \n    penalty_collision = -28 if (d_agent_cup_holder < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the jail worker. \n Assumption: Agent's state, target's state and jail worker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_jail_worker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_jail_worker = calculate_distance_min(s_agent, s_jail_worker) \n    penalty_collision = -28 if (d_agent_jail_worker < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_jail_worker): \n    d_agent_jail_worker = calculate_distance_min(s_agent, s_jail_worker) \n    penalty_collision = -28 if (d_agent_jail_worker < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a jail. \n Goal:  The drone must avoid colliding with the guard. \n Assumption: Agent's state, target's state and guard's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_guard, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_guard = calculate_distance_min(s_agent, s_guard) \n    penalty_collision = -28 if (d_agent_guard < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_guard): \n    d_agent_guard = calculate_distance_min(s_agent, s_guard) \n    penalty_collision = -28 if (d_agent_guard < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating a jail. Target: The drone must avoid colliding with chair, concrete floor and prison stool. Assumptions: The Agent's state, target's state and the states of multiple obstacles: chair, concrete floor, and prison stool are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating a jail. Target: The drone must avoid colliding with prison bench corner and cell locker frame. Assumptions: The Agent's state, target's state and the states of multiple obstacles: prison bench corner, and cell locker frame are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating a jail. Target: The drone must avoid colliding with handcuffs, cell bars section and loose wires. Assumptions: The Agent's state, target's state and the states of multiple obstacles: handcuffs, cell bars section, and loose wires are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating a jail. Target: The drone must avoid colliding with storage trunk cell bars and evidence bag. Assumptions: The Agent's state, target's state and the states of multiple obstacles: storage trunk cell bars, and evidence bag are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target*2 \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },



  
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the candy counter. \n Assumption: Agent's state, target's state and candy counter's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_candy_counter, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_candy_counter = calculate_distance_min(s_agent, s_candy_counter) \n    penalty_collision = -28 if (d_agent_candy_counter < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_candy_counter): \n    d_agent_candy_counter = calculate_distance_min(s_agent, s_candy_counter) \n    penalty_collision = -28 if (d_agent_candy_counter < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the candy display case. \n Assumption: Agent's state, target's state and candy display case's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_display_case, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_display_case = calculate_distance_min(s_agent, s_display_case) \n    penalty_collision = -28 if (d_agent_display_case < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_display_case): \n    d_agent_display_case = calculate_distance_min(s_agent, s_display_case) \n    penalty_collision = -28 if (d_agent_display_case < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the chocolate tray. \n Assumption: Agent's state, target's state and chocolate tray's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_chocolate_tray, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_chocolate_tray = calculate_distance_min(s_agent, s_chocolate_tray) \n    penalty_collision = -28 if (d_agent_chocolate_tray < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_chocolate_tray): \n    d_agent_chocolate_tray = calculate_distance_min(s_agent, s_chocolate_tray) \n    penalty_collision = -28 if (d_agent_chocolate_tray < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the sticky floor. \n Assumption: Agent's state, target's state and sticky floor's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_floor, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_floor = calculate_distance_min(s_agent, s_floor) \n    penalty_collision = -28 if (d_agent_floor < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_floor): \n    d_agent_floor = calculate_distance_min(s_agent, s_floor) \n    penalty_collision = -28 if (d_agent_floor < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the candy barrel. \n Assumption: Agent's state, target's state and candy barrel's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_candy_barrel, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_candy_barrel = calculate_distance_min(s_agent, s_candy_barrel) \n    penalty_collision = -28 if (d_agent_candy_barrel < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_candy_barrel): \n    d_agent_candy_barrel = calculate_distance_min(s_agent, s_candy_barrel) \n    penalty_collision = -28 if (d_agent_candy_barrel < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the lollipop stand. \n Assumption: Agent's state, target's state and lollipop stand's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_lollipop_stand, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_lollipop_stand = calculate_distance_min(s_agent, s_lollipop_stand) \n    penalty_collision = -28 if (d_agent_lollipop_stand < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_lollipop_stand): \n    d_agent_lollipop_stand = calculate_distance_min(s_agent, s_lollipop_stand) \n    penalty_collision = -28 if (d_agent_lollipop_stand < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the candy cane. \n Assumption: Agent's state, target's state and candy cane's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_candy_cane, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_candy_cane = calculate_distance_min(s_agent, s_candy_cane) \n    penalty_collision = -28 if (d_agent_candy_cane < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_candy_cane): \n    d_agent_candy_cane = calculate_distance_min(s_agent, s_candy_cane) \n    penalty_collision = -28 if (d_agent_candy_cane < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the wall candy display case. \n Assumption: Agent's state, target's state and wall candy display case's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_display_case, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_display_case = calculate_distance_min(s_agent, s_display_case) \n    penalty_collision = -28 if (d_agent_display_case < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_display_case): \n    d_agent_display_case = calculate_distance_min(s_agent, s_display_case) \n    penalty_collision = -28 if (d_agent_display_case < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the order receipt stack. \n Assumption: Agent's state, target's state and order receipt stack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_receipt_stack, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_receipt_stack = calculate_distance_min(s_agent, s_receipt_stack) \n    penalty_collision = -28 if (d_agent_receipt_stack < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_receipt_stack): \n    d_agent_receipt_stack = calculate_distance_min(s_agent, s_receipt_stack) \n    penalty_collision = -28 if (d_agent_receipt_stack < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the soda bottle. \n Assumption: Agent's state, target's state and soda bottle's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_soda_bottle, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_soda_bottle = calculate_distance_min(s_agent, s_soda_bottle) \n    penalty_collision = -28 if (d_agent_soda_bottle < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_soda_bottle): \n    d_agent_soda_bottle = calculate_distance_min(s_agent, s_soda_bottle) \n    penalty_collision = -28 if (d_agent_soda_bottle < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the old candy shop worker. \n Assumption: Agent's state, target's state and old candy shop worker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_worker, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -28 if (d_agent_worker < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -28 if (d_agent_worker < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the candy wrapper. \n Assumption: Agent's state, target's state and candy wrapper's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_candy_wrapper, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_candy_wrapper = calculate_distance_min(s_agent, s_candy_wrapper) \n    penalty_collision = -28 if (d_agent_candy_wrapper < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_candy_wrapper): \n    d_agent_candy_wrapper = calculate_distance_min(s_agent, s_candy_wrapper) \n    penalty_collision = -28 if (d_agent_candy_wrapper < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the candy. \n Assumption: Agent's state, target's state and candy's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_candy, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_candy = calculate_distance_min(s_agent, s_candy) \n    penalty_collision = -28 if (d_agent_candy < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_candy): \n    d_agent_candy = calculate_distance_min(s_agent, s_candy) \n    penalty_collision = -28 if (d_agent_candy < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the licorice strings. \n Assumption: Agent's state, target's state and licorice strings's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_licorice_stringt, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_licorice_stringt = calculate_distance_min(s_agent, s_licorice_stringt) \n    penalty_collision = -28 if (d_agent_licorice_stringt < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_licorice_stringt): \n    d_agent_licorice_stringt = calculate_distance_min(s_agent, s_licorice_stringt) \n    penalty_collision = -28 if (d_agent_licorice_stringt < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the chocolate. \n Assumption: Agent's state, target's state and chocolate's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_chocolate, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_chocolate = calculate_distance_min(s_agent, s_chocolate) \n    penalty_collision = -28 if (d_agent_chocolate < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_chocolate): \n    d_agent_chocolate = calculate_distance_min(s_agent, s_chocolate) \n    penalty_collision = -28 if (d_agent_chocolate < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the jelly bean bag. \n Assumption: Agent's state, target's state and jelly bean bag's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_jelly_bean_bag, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_jelly_bean_bag = calculate_distance_min(s_agent, s_jelly_bean_bag) \n    penalty_collision = -28 if (d_agent_jelly_bean_bag < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_jelly_bean_bag): \n    d_agent_jelly_bean_bag = calculate_distance_min(s_agent, s_jelly_bean_bag) \n    penalty_collision = -28 if (d_agent_jelly_bean_bag < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the cupcake tray. \n Assumption: Agent's state, target's state and cupcake tray's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cupcake_tray, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cupcake_tray = calculate_distance_min(s_agent, s_cupcake_tray) \n    penalty_collision = -28 if (d_agent_cupcake_tray < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cupcake_tray): \n    d_agent_cupcake_tray = calculate_distance_min(s_agent, s_cupcake_tray) \n    penalty_collision = -28 if (d_agent_cupcake_tray < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the gummy bag. \n Assumption: Agent's state, target's state and gummy bag's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_gummy_bag, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_gummy_bag = calculate_distance_min(s_agent, s_gummy_bag) \n    penalty_collision = -28 if (d_agent_gummy_bag < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_gummy_bag): \n    d_agent_gummy_bag = calculate_distance_min(s_agent, s_gummy_bag) \n    penalty_collision = -28 if (d_agent_gummy_bag < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the ice cream cone. \n Assumption: Agent's state, target's state and ice cream cone's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_ice_cream_cone, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_ice_cream_cone = calculate_distance_min(s_agent, s_ice_cream_cone) \n    penalty_collision = -28 if (d_agent_ice_cream_cone < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_ice_cream_cone): \n    d_agent_ice_cream_cone = calculate_distance_min(s_agent, s_ice_cream_cone) \n    penalty_collision = -28 if (d_agent_ice_cream_cone < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the customer. \n Assumption: Agent's state, target's state and customer's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_customer, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -28 if (d_agent_customer < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_customer): \n    d_agent_customer = calculate_distance_min(s_agent, s_customer) \n    penalty_collision = -28 if (d_agent_customer < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is inspecting in a candy shop. \n Goal:  The drone must avoid colliding with the cash register. \n Assumption: Agent's state, target's state and cash register's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cash_register, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_cash_register = calculate_distance_min(s_agent, s_cash_register) \n    penalty_collision = -28 if (d_agent_cash_register < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_cash_register): \n    d_agent_cash_register = calculate_distance_min(s_agent, s_cash_register) \n    penalty_collision = -28 if (d_agent_cash_register < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating a candy shop. Target: The drone must avoid colliding with chair, sticky floor and lollipop stand. Assumptions: The Agent's state, target's state and the states of multiple obstacles: chair, sticky floor, and lollipop stand are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating a candy shop. Target: The drone must avoid colliding with candy counter corner and candy display case frame. Assumptions: The Agent's state, target's state and the states of multiple obstacles: candy counter corner, and candy display case frame are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating a candy shop. Target: The drone must avoid colliding with candy cane bundle, candy cane poles section and licorice strings. Assumptions: The Agent's state, target's state and the states of multiple obstacles: candy cane bundle, candy cane poles section, and licorice strings are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating a candy shop. Target: The drone must avoid colliding with candy barrel candy cane poles and gummy bag. Assumptions: The Agent's state, target's state and the states of multiple obstacles: candy barrel candy cane poles, and gummy bag are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    reward_reaching_target = 32 if (d_agent_target < 0.3) else -d_agent_target \n    return penalty_collision + reward_reaching_target",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -28 if (d_agent_multiple_obstacles_min < 0.8) else 30 \n    return penalty_collision"
  },


  
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the display counter. \n Assumption: Agent's state, goal's state and display counter's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_display_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display_counter = calculate_distance_min(s_agent, s_display_counter) \n    penalty_collision = -10 if (d_agent_display_counter < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_display_counter): \n    d_agent_display_counter = calculate_distance_min(s_agent, s_display_counter) \n    penalty_collision = -10 if (d_agent_display_counter < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the glass showcase. \n Assumption: Agent's state, goal's state and glass showcase's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_glass_showcase, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_showcase = calculate_distance_min(s_agent, s_glass_showcase) \n    penalty_collision = -10 if (d_agent_glass_showcase < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_glass_showcase): \n    d_agent_glass_showcase = calculate_distance_min(s_agent, s_glass_showcase) \n    penalty_collision = -10 if (d_agent_glass_showcase < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the ring tray. \n Assumption: Agent's state, goal's state and ring tray's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_ring_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ring_tray = calculate_distance_min(s_agent, s_ring_tray) \n    penalty_collision = -10 if (d_agent_ring_tray < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_ring_tray): \n    d_agent_ring_tray = calculate_distance_min(s_agent, s_ring_tray) \n    penalty_collision = -10 if (d_agent_ring_tray < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the polished floor. \n Assumption: Agent's state, goal's state and polished floor's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_floor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_floor = calculate_distance_min(s_agent, s_floor) \n    penalty_collision = -10 if (d_agent_floor < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_floor): \n    d_agent_floor = calculate_distance_min(s_agent, s_floor) \n    penalty_collision = -10 if (d_agent_floor < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the jewelry safe. \n Assumption: Agent's state, goal's state and jewelry safe's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_jewelry_safe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_jewelry_safe = calculate_distance_min(s_agent, s_jewelry_safe) \n    penalty_collision = -10 if (d_agent_jewelry_safe < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_jewelry_safe): \n    d_agent_jewelry_safe = calculate_distance_min(s_agent, s_jewelry_safe) \n    penalty_collision = -10 if (d_agent_jewelry_safe < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the necklace stand. \n Assumption: Agent's state, goal's state and necklace stand's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_necklace_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_necklace_stand = calculate_distance_min(s_agent, s_necklace_stand) \n    penalty_collision = -10 if (d_agent_necklace_stand < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_necklace_stand): \n    d_agent_necklace_stand = calculate_distance_min(s_agent, s_necklace_stand) \n    penalty_collision = -10 if (d_agent_necklace_stand < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the chain. \n Assumption: Agent's state, goal's state and chain's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_chain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chain = calculate_distance_min(s_agent, s_chain) \n    penalty_collision = -10 if (d_agent_chain < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_chain): \n    d_agent_chain = calculate_distance_min(s_agent, s_chain) \n    penalty_collision = -10 if (d_agent_chain < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the wall glass showcase. \n Assumption: Agent's state, goal's state and wall glass showcase's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_glass_showcase, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_glass_showcase = calculate_distance_min(s_agent, s_glass_showcase) \n    penalty_collision = -10 if (d_agent_glass_showcase < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_glass_showcase): \n    d_agent_glass_showcase = calculate_distance_min(s_agent, s_glass_showcase) \n    penalty_collision = -10 if (d_agent_glass_showcase < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the invoice stack. \n Assumption: Agent's state, goal's state and invoice stack's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_invoice_stack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_invoice_stack = calculate_distance_min(s_agent, s_invoice_stack) \n    penalty_collision = -10 if (d_agent_invoice_stack < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_invoice_stack): \n    d_agent_invoice_stack = calculate_distance_min(s_agent, s_invoice_stack) \n    penalty_collision = -10 if (d_agent_invoice_stack < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the cleaning solution bottle. \n Assumption: Agent's state, goal's state and cleaning solution bottle's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_cleaning_bottle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cleaning_bottle = calculate_distance_min(s_agent, s_cleaning_bottle) \n    penalty_collision = -10 if (d_agent_cleaning_bottle < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_cleaning_bottle): \n    d_agent_cleaning_bottle = calculate_distance_min(s_agent, s_cleaning_bottle) \n    penalty_collision = -10 if (d_agent_cleaning_bottle < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the old jewelry store worker. \n Assumption: Agent's state, goal's state and old jewelry store worker's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -10 if (d_agent_worker < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -10 if (d_agent_worker < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the frame. \n Assumption: Agent's state, goal's state and frame's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_frame, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_frame = calculate_distance_min(s_agent, s_frame) \n    penalty_collision = -10 if (d_agent_frame < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_frame): \n    d_agent_frame = calculate_distance_min(s_agent, s_frame) \n    penalty_collision = -10 if (d_agent_frame < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the counter. \n Assumption: Agent's state, goal's state and counter's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -10 if (d_agent_counter < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_counter): \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -10 if (d_agent_counter < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the gold chains. \n Assumption: Agent's state, goal's state and gold chains's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_gold_chain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gold_chain = calculate_distance_min(s_agent, s_gold_chain) \n    penalty_collision = -10 if (d_agent_gold_chain < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_gold_chain): \n    d_agent_gold_chain = calculate_distance_min(s_agent, s_gold_chain) \n    penalty_collision = -10 if (d_agent_gold_chain < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the security bars. \n Assumption: Agent's state, goal's state and security bars's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_security bars, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_security bars = calculate_distance_min(s_agent, s_security bars) \n    penalty_collision = -10 if (d_agent_security bars < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_security bars): \n    d_agent_security bars = calculate_distance_min(s_agent, s_security bars) \n    penalty_collision = -10 if (d_agent_security bars < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the jewelry store shelf unit. \n Assumption: Agent's state, goal's state and jewelry store shelf unit's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_shelf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -10 if (d_agent_shelf < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_shelf): \n    d_agent_shelf = calculate_distance_min(s_agent, s_shelf) \n    penalty_collision = -10 if (d_agent_shelf < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the earring tray. \n Assumption: Agent's state, goal's state and earring tray's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_earring_tray, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_earring_tray = calculate_distance_min(s_agent, s_earring_tray) \n    penalty_collision = -10 if (d_agent_earring_tray < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_earring_tray): \n    d_agent_earring_tray = calculate_distance_min(s_agent, s_earring_tray) \n    penalty_collision = -10 if (d_agent_earring_tray < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the velvet pouch. \n Assumption: Agent's state, goal's state and velvet pouch's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_velvet_pouch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_velvet_pouch = calculate_distance_min(s_agent, s_velvet_pouch) \n    penalty_collision = -10 if (d_agent_velvet_pouch < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_velvet_pouch): \n    d_agent_velvet_pouch = calculate_distance_min(s_agent, s_velvet_pouch) \n    penalty_collision = -10 if (d_agent_velvet_pouch < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the ring holder. \n Assumption: Agent's state, goal's state and ring holder's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_ring_holder, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ring_holder = calculate_distance_min(s_agent, s_ring_holder) \n    penalty_collision = -10 if (d_agent_ring_holder < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_ring_holder): \n    d_agent_ring_holder = calculate_distance_min(s_agent, s_ring_holder) \n    penalty_collision = -10 if (d_agent_ring_holder < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the human. \n Assumption: Agent's state, goal's state and human's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_human): \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is inspecting in a jewelry store. \n Goal:  The drone must avoid colliding with the payment terminal. \n Assumption: Agent's state, goal's state and payment terminal's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_payment_terminal, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_payment_terminal = calculate_distance_min(s_agent, s_payment_terminal) \n    penalty_collision = -10 if (d_agent_payment_terminal < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_payment_terminal): \n    d_agent_payment_terminal = calculate_distance_min(s_agent, s_payment_terminal) \n    penalty_collision = -10 if (d_agent_payment_terminal < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating a jewelry store. goal: The drone must avoid colliding with chair, polished floor and necklace stand. Assumptions: The Agent's state, goal's state and the states of multiple obstacles: chair, polished floor, and necklace stand are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating a jewelry store. goal: The drone must avoid colliding with display counter corner and glass showcase frame. Assumptions: The Agent's state, goal's state and the states of multiple obstacles: display counter corner, and glass showcase frame are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating a jewelry store. goal: The drone must avoid colliding with chain bundle, security bars section and gold chains. Assumptions: The Agent's state, goal's state and the states of multiple obstacles: chain bundle, security bars section, and gold chains are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 15 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating a jewelry store. goal: The drone must avoid colliding with jewelry safe security bars and velvet pouch. Assumptions: The Agent's state, goal's state and the states of multiple obstacles: jewelry safe security bars, and velvet pouch are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 15 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -10 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles): \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -10 if (d_agent_multiple_obstacles_min < 0.8) else 15 \n    return penalty_collision"
  }











]
