[

    {
        "prompt": "Scenario: Drone indoor exploration in a room. \n Aim: Avoid collision with ceiling fan blades. \n Assumption: Agent's state and static fan blades's status are available. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = -15 if (d_agent_blade < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = 15 if (d_agent_blade < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a room. \n Aim: Avoid collision with chair. \n Assumption: Agent's state and chair's status are available. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a room. \n Aim: Avoid collision with hanging lamps. \n Assumption: Agent's state and lamp's status are available. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a room. \n Aim: Avoid collision with curtain. \n Assumption: Agent's state and static curtain's status available. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -15 if (d_agent_curtain < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = 15 if (d_agent_curtain < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a room. \n Aim: Avoid collision with obstacles. \n Assumption: Agent's state and obstacles's status are available. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a room. \n Aim: Avoid collision with drapes. \n Assumption: Agent's state and drape's status are available. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -15 if (d_agent_drape < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 15 if (d_agent_drape < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a room. \n Aim: Avoid collision with static obstacle (wardrobe). \n Assumption: Agent's state, wardrobe's state are available. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = -15 if (d_agent_wardrobe < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = 15 if (d_agent_wardrobe < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone in-door navigation and reach other side of the small room. \n Aim: Do not collide with the walls of the room. \n Assumption: Agent's state, wall's information accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Guide the drone through an indoor space to the far side of a small room. \n Aim: Prevent contact with the people. \n Assumption: Agent's state, people's state accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Guide the drone through an indoor space such as a small room. \n Aim: Prevent contact with chairs and tables. \n Assumption: Agent's state, obstacles' state accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Guide the drone through an indoor space such as a small room. \n Aim: Prevent contact with fan blades and curtains. \n Assumption: Agent's state, obstacles' state accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Guide the drone through an indoor space such as a small room. \n Aim: Prevent contact with drapes and people. \n Assumption: Agent's state, obstacles' state accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Guide the drone through an indoor space such as a small room. \n Aim: Prevent contact with lamps and projectors. \n Assumption: Agent's state, obstacles' state accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Guide the drone through an indoor space such as a small room. \n Aim: Prevent contact with boxes and chairs. \n Assumption: Agent's state, obstacles' state accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Guide the drone through an indoor space such as a small room. \n Aim: Avoid collision with boxes and chairs. \n Assumption: Agent's state, obstacles' state accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Guide the drone through an indoor space such as a small room. \n Aim: Prevent contact with humans and chairs. \n Assumption: Agent's state, obstacles' state accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Guide the drone through an indoor space such as a small room. \n Aim: Prevent contact with humans, chairs and table. \n Assumption: Agent's state, obstacles' state accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Guide the drone through an indoor space such as a small room. \n Aim: Prevent contact with humans, projector and bench. \n Assumption: Agent's state, obstacles' state accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Guide the drone through an indoor space such as a small room. \n Aim: Prevent contact with people, boxes and bench. \n Assumption: Agent's state, obstacles' state accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Guide the drone through an indoor space such as a small room. \n Aim: Prevent contact with shelf, plants and curtains. \n Assumption: Agent's state, obstacles' state accessible. \n Implement a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },



    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid hitting the surrounding walls. \n Conditions: Agent's state, wall's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Navigate without crashing into walls. \n Conditions: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (chairs) and avoid collision. \n Conditions: Agent's state, chair's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (table) and avoid collision. \n Conditions: Agent's state, table's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 15 if (d_agent_table_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect bookshelves and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -15 if (d_agent_bookshelve < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 15 if (d_agent_bookshelve < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect smoke detectors and avoid collision. \n Conditions: Agent's state, smoke detector's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detectore = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = -15 if (d_agent_smoke_detector < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detector = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = 15 if (d_agent_smoke_detector < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (stacked books) and avoid collision. \n Conditions: Agent's state, book's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -15 if (d_agent_book < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = 15 if (d_agent_book < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect chairs and tabels and avoid collision. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect students and shelves and avoid collision. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with lamps and plants. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with decorations and tall shelves. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stack books and lamps. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with books and lights. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with books, lights and humans. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with chair, table and humans. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with desks, lamps and students. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stacked books, computers and staffs. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stacked books, laptops and book carts. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with  curtains, plants and staffs. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },



    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },   
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect static obstacle such as a tree and avoid collision. \n Conditions: Agent's state, tree's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = -15 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = 15 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle such as a leaf and avoid collision. \n Conditions: Agent's state, leaf's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = -15 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = 15 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect birds and avoid collision. \n Conditions: Agent's state, bird's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = -15 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = 15 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with stumps. \n Conditions: Agent's state and stump's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = -15 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = 15 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle such as a rock and avoid collision. \n Conditions: Agent's state, rock's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -15 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = 15 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect thin branches and avoid collision. \n Conditions: Agent's state, branche's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = -15 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = 15 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with thick tree branches. \n Conditions: Agent's state, tree branche's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = -15 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = 15 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect people and avoid collision. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect stones and avoid collision. \n Conditions: Agent's state and stone's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = -15 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = 15 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect stones and trees and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect branches and trees and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect humans and animals and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect leaves and trees avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with the many trees. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with trees, branches and humans. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with stumps, birds and humans. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with trees, animals and stones. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },


    

    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect humans as dynamic obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of nearby humans, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect lamp, and Avoid collisions.  \n Assumptions: The drones own state, the states of lamp, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect counter, and Avoid collisions.  \n Assumptions: The drones own state, the states of counter, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -15 if (d_agent_counter < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = 15 if (d_agent_counter < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect chair, and Avoid collisions.  \n Assumptions: The drones own state, the states of chair, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect table, and Avoid collisions.  \n Assumptions: The drones own state, the states of table, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 15 if (d_agent_table < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect trash bin and Avoid collisions.  \n Assumptions: The drones own state, the states of trash bin, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -15 if (d_agent_trash_bin < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = 15 if (d_agent_trash_bin < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect decoration and Avoid collisions.  \n Assumptions: The drones own state, the states of decoration, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = -15 if (d_agent_decoration < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = 15 if (d_agent_decoration < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect plant and Avoid collisions.  \n Assumptions: The drones own state, the states of plant, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = -15 if (d_agent_plant < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = 15 if (d_agent_plant < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect metal rail and Avoid collisions.  \n Assumptions: The drones own state, the states of rail, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = -15 if (d_agent_rail < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = 15 if (d_agent_rail < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect camera, and Avoid collisions.  \n Assumptions: The drones own state, the states of camera, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = -15 if (d_agent_cameras < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = 15 if (d_agent_cameras < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect people and table, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect students and chair, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect plants and chair, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect plant and desk, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect decoration and plants, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect students and table, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect chair, plant and table, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect staff, student and table, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect counter, rails and camera, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor mensa environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect food counter, trash bin and staff, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },




    
    {
        "prompt": "Mission: Drone in-door navigation in a classroom. \n Objectives: Do not collide with the a wall of the room. \n Conditions: Agent's state, wall's location are avialable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone in-door navigation in a classroom. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state and people's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a classroom. \n Objectives: Avoid hitting the ceiling projector. \n Conditions: Agent's state and projector's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 15 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a classroom. \n Objectives: Navigate without crashing into overhead lamps. \n Conditions: Agent's state, overhead lamp's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect static obstacle (blackboard) and avoid collision. \n Conditions: Agent's state, blackboard's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = -15 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = 15 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (tall bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -15 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 15 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (backpack) and avoid collision. \n Conditions: Agent's state and backpack's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -15 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = 15 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Do not collide with human. \n Conditions: Agent's state and human's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect dynamic obstacle (a teacher) and avoid collision. \n Conditions: Agent's state and teacher's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -15 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = 15 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect dynamic obstacle (a student) and avoid collision. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -15 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = 15 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with student and teacher. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with chair and desk. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with student and backpack. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves and backpack. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with blackboards and whiteboards. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with teacher, blackboards and whiteboards. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with teacher, pupils and desk. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves, chair and table. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves, chair and table. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with three boxes. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },





    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a conference room. The drone must detect and avoid moving obstacles (people) while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of people in the room.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_people + reward_reaching_goal"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a conference room. The drone must detect and avoid desk while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of desk in the room.",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -15 if (d_agent_desk < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_desk): \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = 15 if (d_agent_desk < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a conference room. The drone must detect and avoid sideboard while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of sideboard in the room.",
        "chosen": "def reward(s_agent, s_sideboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    penalty_collision = -15 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_sideboard s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_sideboard + reward_reaching_goal"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a conference room. The drone must detect and avoid bench while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of bench in the room.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -15 if (d_agent_bench < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bench): \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = 15 if (d_agent_bench < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a conference room. The drone must detect and avoid whiteboard while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of whiteboard in the room.",
        "chosen": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -15 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_whiteboard s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_whiteboard + reward_reaching_goal"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a conference room. The drone must detect and avoid projector while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of projector in the room.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_projector): \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 15 if (d_agent_projector < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a conference room. The drone must detect and avoid equipment while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of equipment in the room.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -15 if (d_agent_equipment < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_equipment): \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = 15 if (d_agent_equipment < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a conference room. The drone must detect and avoid speaker while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of speaker in the room.",
        "chosen": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -15 if (d_agent_speaker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_speaker s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_speaker + reward_reaching_goal"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a conference room. The drone must detect and avoid laptop while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of laptop in the room.",
        "chosen": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -15 if (d_agent_laptop < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_laptop): \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = 15 if (d_agent_laptop < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a conference room. The drone must detect and avoid screen while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of screen in the room.",
        "chosen": "def reward(s_agent, s_screen, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = -15 if (d_agent_screen < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_screen): \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = 15 if (d_agent_screen < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a conference room. The drone must detect and avoid screen and desk while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of multiple obstacles in the room.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked with navigating inside a conference room. The drone must detect and avoid table and chair while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of multiple obstacles in the room.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked which piloting inside a conference room. The drone must detect and avoid computer and person while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of multiple obstacles in the room.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked which piloting inside a conference room. The drone must detect and avoid plant and shelf while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of multiple obstacles in the room.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked which piloting inside a conference room. The drone must detect and avoid two boxes while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of multiple obstacles in the room.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked which piloting inside a conference room. The drone must detect and avoid table, chair and table while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of multiple obstacles in the room.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked which piloting inside a conference room. The drone must detect and avoid laptop, shelf and plant while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of multiple obstacles in the room.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked which piloting inside a conference room. The drone must detect and avoid shelf, box and person while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of multiple obstacles in the room",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked which piloting inside a conference room. The drone must detect and avoid whiteboard, screen and plant while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of multiple obstacles in the room.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Design a Python reward function for a drone tasked which piloting inside a conference room. The drone must detect and avoid multiple boxes while heading toward a target goal. You are provided with the agents state, the goals state, and the positions of multiple obstacles in the room.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },





    {
        "prompt": "ission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (one staff) and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -15 if (d_agent_staff < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_staff s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_staff + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a worker) and avoid collision. \n Conditions: Agent's state and worker's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -15 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 15 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_human + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a worker) and avoid collision. \n Conditions: Agent's state and worker's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -15 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 15 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with high storage racks. \n Conditions: Agent's state and storage rack's information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rack = calculate_distance_min(s_agent, s_rack) \n    penalty_collision = -15 if (d_agent_rack < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rack = calculate_distance_min(s_agent, s_rack) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_rack + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with a forklift . \n Conditions: Agent's state and forklift's information are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -15 if (d_agent_forklift < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_forklift): \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = 15 if (d_agent_forklift < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with a hanging cable. \n Conditions: Agent's state and cable's information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -15 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 30 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission:Operate the drone in a warehouse. \n Objectives: Avoid collison with a stack of pallets. \n Conditions: Agent's state and pallet's information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = -15 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = 30 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with a package. \n Conditions: Agent's state and package's information are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = -15 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = 30 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with overhead pipes. \n Conditions: Agent's state and pipe's information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -15 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = 30 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the overhead beam and do not collide with it. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -15 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = 30 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the shelves and human and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the pakets and staffs and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the stackes boxes and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
     {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the maschines and staffs and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the beams and hanging lamps and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the cable, rack and people and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the desk, chair and computer and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the beam, pipes and lamps and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the forklift, stairs and rails and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },



    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect people, avoid collisions with them, and use the available agent and people states.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_people + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect spotlamp, avoid collisions with them and reach goal, and use the available agent and spotlmap and agent states.",
        "chosen": "def reward(s_agent, s_spotlamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = -15 if (d_agent_spotlamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_spotlamp): \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = 15 if (d_agent_spotlamp < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect balcony, avoid collisions with them and reach goal, and use the available agent and balcony and agent states.",
        "chosen": "def reward(s_agent, s_balcony, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    penalty_collision = -15 if (d_agent_balcony < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_baloncy, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_balcony + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect seat, avoid collisions with them and reach goal, and use the available agent and seat and agent states.",
        "chosen": "def reward(s_agent, s_seat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = -15 if (d_agent_seat < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_seat): \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = 15 if (d_agent_seat < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect projector, avoid collisions with them and reach goal, and use the available agent and projector and agent states.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_projector + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect cable, avoid collisions with them and reach goal, and use the available agent and cable and agent states.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -15 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cable): \n    d_agent_seat = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 15 if (d_agent_cable < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect human, avoid collisions with them and reach goal, and use the available agent and human and agent states.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect platform, avoid collisions with them and reach goal, and use the available agent and platform and agent states.",
        "chosen": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -15 if (d_agent_platform < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = 15 if (d_agent_platform < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect drape, avoid collisions with them and reach goal, and use the available agent and drape and agent states.",
        "chosen": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -15 if (d_agent_drape < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 15 if (d_agent_drape < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect microphone, avoid collisions with them and reach goal, and use the available agent and microphone and agent states.",
        "chosen": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = -15 if (d_agent_microphone < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = 15 if (d_agent_microphone < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect spotlamp and projector, avoid collisions with them and reach goal, and use the available agent and multiple obstacles and agent states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect chair and actor, avoid collisions with them and reach goal, and use the available agent and multiple obstacles and agent states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect stage and drape, avoid collisions with them and reach goal, and use the available agent and multiple obstacles and agent states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect microphone and music box, avoid collisions with them and reach goal, and use the available agent and multiple obstacles and agent states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect staff and visitor, avoid collisions with them and reach goal, and use the available agent and multiple obstacles and agent states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect chandler, rope and stage, avoid collisions with them and reach goal, and use the available agent and multiple obstacles and agent states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect table, chair and human, avoid collisions with them and reach goal, and use the available agent and multiple obstacles and agent states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect three boxes and projector, avoid collisions with them and reach goal, and use the available agent and multiple obstacles and agent states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect beam, balcony railing and spotlight, avoid collisions with them and reach goal, and use the available agent and multiple obstacles and agent states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect platform, microphone and drape, avoid collisions with them and reach goal, and use the available agent and multiple obstacles and agent states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a theater. The drone must detect visitor seat and box, avoid collisions with them and reach goal, and use the available agent and multiple obstacles and agent states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },






    {
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect  dynamic obstacle (person) and avoid collision. \n Conditions: Agent's state, person's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = -15 if (d_agent_person < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = 15 if (d_agent_person < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect the static obstacle basket hoop and avoid collision. \n Conditions: Agent's state, basket hoop's state are usable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = -15 if (d_agent_basket_hoop < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = 15 if (d_agent_basket_hoop < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect the scoreboard and avoid collision. \n Conditions: Agent's state, scoreboard's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -15 if (d_agent_scoreboard < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = 15 if (d_agent_scoreboard < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect the climbing rope and avoid collision. \n Conditions: Agent's state and climbing rope's state are usable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -15 if (d_agent_rope < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = 15 if (d_agent_rope < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with volleyball nets. \n Conditions: Agent's state and net's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = -15 if (d_agent_net < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = 15 if (d_agent_net < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with hanging flags. \n Conditions: Agent's state and flag's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = -15 if (d_agent_flag < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = 15 if (d_agent_flag < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (moving players) and avoid collision. \n Conditions: Agent's state and player's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with a ball. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle flying ball and avoid collision. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_ball): \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 15 if (d_agent_ball < 0.6) else 0 \n    return penalty_collision"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (player) and avoid collision. \n Conditions: Agent's state and player's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_player s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with ball and player. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with rope and net. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with coach and flag. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and rope. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with coach, basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with player, ball and rope. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with flag, student and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
    },



    {
        "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Detect the patient and avoid collision. \n Conditions: Agent's state and patient's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -15 if (d_agent_patient < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 15 if (d_agent_patient < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect dynamic obstacle such as a doctor and avoid collision. \n Conditions: Agent's state and doctor's state are usable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = -15 if (d_agent_doctor < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = 15 if (d_agent_doctor < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Detect the wire and avoid collision. \n Conditions: Agent's state and wire's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = -15 if (d_agent_wire < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_wire + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone explores the hospital. \n Objectives: Avoid collision with a medical equipment. \n Conditions: Agent's state and equipment's state are usable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -15 if (d_agent_equipment < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent,s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    return d_agent_equipment + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Detect the wheelchair and avoid collisions. \n Conditions: Agent's state and wheelchair's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wheelchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = -15 if (d_agent_wheelchair < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wheelchair): \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = 15 if (d_agent_wheelchair < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staffr) \n    penalty_collision = -15 if (d_agent_staff < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_staff): \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = 15 if (d_agent_staff < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Avoid collision with the defibrillator. \n Conditions: Agent's state and defibrillator's state are usable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_defibrillator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrillator) \n    penalty_collision = -15 if (d_agent_defibrillator < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_defibrillator,  s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrillator) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_defibrillator + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone explores the hospital. \n Objectives: Avoid  any collision with wall-mounted emergency devices. \n Conditions: Agent's state and device's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_device) \n    penalty_collision = -15 if (d_agent_device < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_device) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_device + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a hospital. \n Objectives:  Avoid collision with the lamp. \n Conditions: Agent's state and lamp's state are usable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_lamp + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and patient avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the defibrillator and equipment avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the wire and wheelchair avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the patient and wheelchair avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and lamp avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the three packages and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the doctor, the patient and the wheelchair and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the defibrillator, the equipment and the wheelchair and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the lamp, the bed and the screen and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the counter, the nurse and the patient and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect  are three boxes and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },




















    {
        "prompt": "A drone explores a room, avoids ceiling fan blades, and aims to reach a goal using its state and avoid hitting blade with using blade's status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = -15 if (d_agent_blade < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = 15 if (d_agent_blade < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a room, avoids chair, and aims to reach a goal using its state and avoid hitting clair with using chair status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a room, avoids lamp, and aims to reach a goal using its state and avoid hitting lamp with using lamp status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a room, avoids curtain, and aims to reach a goal using its state and avoid hitting curtain with using curtain status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -15 if (d_agent_curtain < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = 15 if (d_agent_curtain < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a room, avoids obstacles, and aims to reach a goal using its state and avoid hitting obstacles with using obstacles status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a room, avoids drape, and aims to reach a goal using its state and avoid hitting drape with using drape status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -15 if (d_agent_drape < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 15 if (d_agent_drape < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a room, avoids wardrobe, and aims to reach a goal using its state and avoid hitting wardrobe with using wardrobe status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = -15 if (d_agent_wardrobe < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = 15 if (d_agent_wardrobe < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a room, avoids wall, and aims to reach a goal using its state and avoid hitting wall with using wall status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a room, avoids ceiling people, and aims to reach a goal using its state and avoid hitting people with using people status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigate inside a small room, avoids obstacles, and aims to reach a goal using its state and avoid hitting obstcales with using obstacles status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigate inside a big room, avoids obstacles, and aims to reach a goal using its state and avoid hitting obstcales with using obstacles status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with drapes and people. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a small room, aims to reach a goal, and avoids hitting obstacles such as lamps and projectors using its state and multiple obstacle status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a small room, aims to reach a goal, and avoids hitting obstacles such as boxes and chairs using its state and multiple obstacle status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a small room, aims to reach a goal, and avoids hitting obstacles such as boxes and table using its state and multiple obstacle status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a small room, aims to reach a goal, and avoids hitting obstacles such as human and chair using its state and multiple obstacle status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a small room, aims to reach a goal, and avoids hitting obstacles such as human and chair, table using its state and multiple obstacle status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a small room, aims to reach a goal, and avoids hitting obstacles such as human, bench and projectors using its state and multiple obstacle status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a small room, aims to reach a goal, and avoids hitting obstacles such as people, box and bench using its state and multiple obstacle status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a small room, aims to reach a goal, and avoids hitting obstacles such as shelf, plant and curtain using its state and multiple obstacle status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },



    {
        "prompt": "A drone explores a library, attempts to reach a goal, and must prevent collisions with surrounding walls using drone state, the wall status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, attempts to reach a goal, and must prevent collisions with surrounding opposite walls using drone state, the wall status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, attempts to reach a goal, and must prevent collisions with chair using drone state, the chair state, and goal state. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, attempts to reach a goal, and must prevent collisions with table using table state, the chair state, and goal state. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 15 if (d_agent_table_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, attempts to reach a goal, and must prevent collisions with bookshelve using table state, the bookshelf state, and goal state. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -15 if (d_agent_bookshelve < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 15 if (d_agent_bookshelve < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, attempts to reach a goal, and must prevent collisions with smoke detector using table state, the smoke detector state, and goal state. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detectore = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = -15 if (d_agent_smoke_detector < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detector = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = 15 if (d_agent_smoke_detector < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, attempts to reach a goal, and must prevent collisions with stacked book using table state, the book state, and goal state. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -15 if (d_agent_book < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = 15 if (d_agent_book < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, attempts to reach a goal, and must prevent collisions with human using table state, the human state, and goal state. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, tries to reach a goal, and must avoid crashing into multiple obstacles such as chair, tables using its own state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, tries to reach a goal, and must avoid crashing into multiple obstacles such as student and shelf using its own state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, tries to reach a goal, and must avoid crashing into multiple obstacles such as student and lamp using its own state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, tries to reach a goal, and must avoid crashing into multiple obstacles such as decoration and tall shelfves using its own state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, tries to reach a goal, and must avoid crashing into multiple obstacles such as stack book and lamp using its own state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, tries to reach a goal, and must avoid crashing into multiple obstacles such as book and light using its own state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, tries to reach a goal, and must avoid crashing into multiple obstacles such as student, book and light using its own state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, tries to reach a goal, and must avoid crashing into multiple obstacles such as chair, table and human using its own state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, tries to reach a goal, and must avoid crashing into multiple obstacles such as desks, students and book using its own state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, tries to reach a goal, and must avoid crashing into multiple obstacles such as book, computers and staff using its own state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, tries to reach a goal, and must avoid crashing into multiple obstacles such as book, laptop and lamp using its own state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a library, tries to reach a goal, and must avoid crashing into multiple obstacles such as curtain, book and decor using its own state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },



    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Detect dynamic obstacle (human) and avoid collision. \n Inputs: Agent's state, human's state obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },   
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Detect static obstacle such as a tree and avoid collision. \n Inputs: Agent's state, tree's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = -15 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = 15 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Detect obstacle such as a leaf and avoid collision. \n Inputs: Agent's state, leaf's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = -15 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = 15 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Detect birds and avoid collision. \n Inputs: Agent's state, bird's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = -15 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = 15 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Avoid collision with stumps. \n Inputs: Agent's state and stump's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = -15 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = 15 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Detect obstacle such as a rock and avoid collision. \n Inputs: Agent's state, rock's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -15 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = 15 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Detect thin branches and avoid collision. \n Inputs: Agent's state, branche's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = -15 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = 15 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Avoid collision with thick tree branches. \n Inputs: Agent's state, tree branche's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = -15 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = 15 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Detect people and avoid collision. \n Inputs: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Detect stones and avoid collision. \n Inputs: Agent's state and stone's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = -15 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = 15 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Detect stones and trees and avoid collision. \n Inputs: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Detect branches and trees and avoid collision. \n Inputs: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Detect humans and animals and avoid collision. \n Inputs: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Detect leaves and trees avoid collision. \n Inputs: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Avoid collisions with the many trees. \n Inputs: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Avoid collisions with trees, branches and humans. \n Inputs: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Avoid collisions with stumps, birds and humans. \n Inputs: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Avoid collisions with trees, animals and stones. \n Inputs: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Avoid collisions with maple trees, cliffs and signs. \n Inputs: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a forest. \n Duties: Avoid collisions with maple trees, cliffs and signs. \n Inputs: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },


    

    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting humans as dynamic obstacles and avoiding collisions, assuming the agents state, human states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting lamps as obstacles and avoiding collisions, assuming the agents state, lamp states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting counter as obstacles and avoiding collisions, assuming the agents state, counter states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -15 if (d_agent_counter < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = 15 if (d_agent_counter < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting chairs as obstacles and avoiding collisions, assuming the agents state, chair states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting tables as obstacles and avoiding collisions, assuming the agents state, table states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 15 if (d_agent_table < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting trash bin as obstacles and avoiding collisions, assuming the agents state, trash bin states, and the goal state are observable. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -15 if (d_agent_trash_bin < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = 15 if (d_agent_trash_bin < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting decoration as obstacles and avoiding collisions, assuming the agents state, decoration states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = -15 if (d_agent_decoration < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = 15 if (d_agent_decoration < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting plants as obstacles and avoiding collisions, assuming the agents state, plant states, and the goal state are observable. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = -15 if (d_agent_plant < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = 15 if (d_agent_plant < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting metal rail as obstacles and avoiding collisions, assuming the agents state, rail states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = -15 if (d_agent_rail < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = 15 if (d_agent_rail < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting cameras as obstacles and avoiding collisions, assuming the agents state, camera states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = -15 if (d_agent_cameras < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = 15 if (d_agent_cameras < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting obstacles as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting students and chairs as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting platns and chairs as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting platns and desks as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting decoration and plants as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting camera, students and chairs as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting chair, plant and table as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting students and staff, student and chair as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting food counter, rails and camera as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor mensa with a drone, where the drone must reach the goal while detecting food counter, trash bin and student as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },




    
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the walls and reach the goal. The drones state, goal's state and the information of the walls are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the peoples and reach the goal. The drones state, goal's state and the information of the people are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the projector and reach the goal. The drones state, goal's state and the information of the projector are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 15 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the lamp and reach the goal. The drones state, goal's state and the information of the lamp are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the blackboard and reach the goal. The drones state, goal's state and the information of the blackboard are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = -15 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = 15 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the bookshelve and reach the goal. The drones state, goal's state and the information of the bookshelve are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -15 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 15 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the backpack and reach the goal. The drones state, goal's state and the information of the backpack are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -15 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = 15 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the human and reach the goal. The drones state, goal's state and the information of the human are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the teacher and reach the goal. The drones state, goal's state and the information of the teacher are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -15 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = 15 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the student and reach the goal. The drones state, goal's state and the information of the student are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -15 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = 15 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the student and teacher and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the chair and desk and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the student and backpack and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the shelf and backpack and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the blackboard and whiteboard and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the blackboard, student and teacher and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the pupil, desk and teacher and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the shelf, chair and table and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the cupboard, frame and teacher and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a classroom, where it must avoid colliding with the multiple boxes and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },





    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid dynamic obstacles (humans) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and human states.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_people + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacles (desk) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and desk states.",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -15 if (d_agent_desk < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_desk): \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = 15 if (d_agent_desk < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacle (sideboard) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and sideboard states.",
        "chosen": "def reward(s_agent, s_sideboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    penalty_collision = -15 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_sideboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_sideboard + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacle (bench) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and bench states.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -15 if (d_agent_bench < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bench): \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = 15 if (d_agent_bench < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacles(whiteboard) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and whiteboard states.",
        "chosen": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -15 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_whiteboard + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacle (projector) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and projector states.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_projector): \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 15 if (d_agent_projector < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacle (equipment) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and equipment states.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -15 if (d_agent_equipment < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_equipment): \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = 15 if (d_agent_equipment < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacle (speaker) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and speaker states.",
        "chosen": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -15 if (d_agent_speaker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speakers) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_speaker + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacle (laptop) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and laptop states.",
        "chosen": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -15 if (d_agent_laptop < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_laptop): \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = 15 if (d_agent_laptop < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacle (screen) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and screen states.",
        "chosen": "def reward(s_agent, s_screen, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = -15 if (d_agent_screen < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_screen): \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = 15 if (d_agent_screen < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacles (screen, laptop) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and multiple obstacles states.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "MImplement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacles (table, chair) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacles (computer, screen) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacles (plant, shelf) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and multiple obstacles states.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacles (box, plant) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and multiple obstacles states.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacles (screen, laptop) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and multiple obstacles states",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacles (plant, shelf, laptop) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstcales + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacles (shelf, box, laptop) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstcales + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacles (screen, whiteboard, box) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstcales + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function suitable for reinforcement learning. \n Scenario: an indoor drone explores a conference room. \n Requirements: the drone should identify and avoid obstacles (multiple box) while progressing toward the goal. \n The environment provides access to the agent state, goal state, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstcales + reward_reaching_goal"
    },





    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a staff member as an obstacle, prevent collisions, and move toward the designated target. \n The agent, target, and staff states are provided.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -15 if (d_agent_staff < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a worker as an obstacle, prevent collisions, and move toward the designated target. \n The agent, target, and worker states are provided.",
        "chosen": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -15 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 15 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a human as an obstacle, prevent collisions, and move toward the designated target. \n The agent, target, and human states are provided.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a worker as an obstacle, prevent collisions, and move toward the designated target. \n The agent, target, and worker states are provided.",
        "chosen": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -15 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 15 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a rack as an obstacle, prevent collisions, and move toward the designated target. \n The agent, target, and rack states are provided.",
        "chosen": "def reward(s_agent, s_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rack = calculate_distance_min(s_agent, s_rack) \n    penalty_collision = -15 if (d_agent_rack < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a forklift as an obstacle, prevent collisions, and move toward the designated target. \n The agent, target, and forklift states are provided",
        "chosen": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -15 if (d_agent_forklift < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_forklift): \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = 15 if (d_agent_forklift < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a cable as an obstacle, prevent collisions, and move toward the designated target. \n The agent, target, and cable states are provided.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -15 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 30 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a stacked of pallet as an obstacle, prevent collisions, and move toward the designated target. \n The agent, target, and pallet states are provided.",
        "chosen": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = -15 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = 30 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a package as an obstacle, prevent collisions, and move toward the designated target. \n The agent, target, and package states are provided.",
        "chosen": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = -15 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = 30 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a overhead pipe as an obstacle, prevent collisions, and move toward the designated target. \n The agent, target, and pipe states are provided.",
        "chosen": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -15 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = 30 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a beam as an obstacle, prevent collisions, and move toward the designated target. \n The agent, target, and beam states are provided.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -15 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = 30 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a shelves and human as an obstacle, prevent collisions, and move toward the designated target. \n The agent, target, and multiple obstacles states are provided.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify a packet and staff, prevent collisions, and move toward the designated target. \n The agent, target, and multiple obstacles states are provided.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify the stacked boxes, prevent collisions, and move toward the designated target. \n The agent, target, and multiple obstacles states are provided.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
     {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify the maschine and staffs, prevent collisions, and move toward the designated target. \n The agent, target, and multiple obstacles states are provided.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify the beam and lamps, prevent collisions, and move toward the designated target. \n The agent, target, and multiple obstacles states are provided.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify the cable, rack and table, prevent collisions, and move toward the designated target. \n The agent, target, and multiple obstacles states are provided.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify the desk, chair and computer, prevent collisions, and move toward the designated target. \n The agent, target, and multiple obstacles states are provided",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify the beam, pipe and lamo, prevent collisions, and move toward the designated target. \n The agent, target, and multiple obstacles states are provided",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Implement in Python a reward function for reinforcement learning. \n Scenario: a drone operates in a warehouse environment. \n It must identify the forklift, stair and lift, prevent collisions, and move toward the designated target. \n The agent, target, and multiple obstacles states are provided.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },



    {
        "prompt": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with people. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_people + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a theater. \n Objectives: Detect spotlamp and avoid collison with the spotlamp. \n Conditions: Agent's state and spotlamp information are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_spotlamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = -15 if (d_agent_spotlamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_spotlamp): \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = 15 if (d_agent_spotlamp < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone moves in a theater. \n Objectives: Avoid collison with the balcony. \n Conditions: Agent's state and balcony's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_balcony, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    penalty_collision = -15 if (d_agent_balcony < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_balcony, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_balcony + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collison with the visitor's seat. \n Conditions: Agent's states and seat's information are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_seat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = -15 if (d_agent_seat < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_seat): \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = 15 if (d_agent_seat < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone moves in a theater. \n Objectives: Avoid collison with the projector. \n Conditions: Agent's state, projectors's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_projector,  s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_projector + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collision with a cable. \n Conditions: Agent's state, cable's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -15 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cable): \n    d_agent_seat = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 15 if (d_agent_cable < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state and human's state obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Detect static obstacle (overhead platform) and avoid collision. \n Conditions: Agent's state, platform's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -15 if (d_agent_platform < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = 15 if (d_agent_platform < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone explores the theater. \n Objectives: Detect static obstacle (drape) and avoid collision. \n Conditions: Agent's state, drape's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -15 if (d_agent_drape < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 15 if (d_agent_drape < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (hangings microphone) and avoid collision. \n Conditions: Agent's state, microphone's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = -15 if (d_agent_microphone < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = 15 if (d_agent_microphone < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a theater. \n Objectives: Detect the spotlamp and projectors and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a theater. \n Objectives: Detect the chair and people and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a theater. \n Objectives: Detect the stage and drape and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a v. \n Objectives: Detect the microphone and music box do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Operate the drone in a theater. \n Objectives: Detect the staff and visitor do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Operate the drone in a theater. \n Objectives: Detect the chandelier, catwalk and rigging ropes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a theater. \n Objectives: Detect the table, chair and human and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a theater. \n Objectives: Detect the three boxes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a theater. \n Objectives: Detect the ceiling beam, balcony railing and spotlight and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a theater. \n Objectives: Detect the platform, microphone and drapes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Operate the drone in a theater. \n Objectives: Detect the visitorn seat and box and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"    },






    {
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the human and reach the goal. The drones state, goal's state and the information of the human are available.  Create a Python code for reward function..",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the person and reach the goal. The drones state, goal's state and the information of the person are available.  Create a Python code for reward function..",
        "chosen": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = -15 if (d_agent_person < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = 15 if (d_agent_person < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the basket hoop and reach the goal. The drones state, goal's state and the information of the basket hoop are available.  Create a Python code for reward function..",
        "chosen": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = -15 if (d_agent_basket_hoop < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = 15 if (d_agent_basket_hoop < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the scoreboard and reach the goal. The drones state, goal's state and the information of the scoreboard are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -15 if (d_agent_scoreboard < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = 15 if (d_agent_scoreboard < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the rope and reach the goal. The drones state, goal's state and the information of the rope are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -15 if (d_agent_rope < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = 15 if (d_agent_rope < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the volleyball net and reach the goal. The drones state, goal's state and the information of the net are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = -15 if (d_agent_net < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = 15 if (d_agent_net < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the flag and reach the goal. The drones state, goal's state and the information of the flag are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = -15 if (d_agent_flag < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = 15 if (d_agent_flag < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the player and reach the goal. The drones state, goal's state and the information of the player are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the ball and reach the goal. The drones state, goal's state and the information of the ball are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the small ball and reach the goal. The drones state, goal's state and the information of the ball are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_ball): \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 15 if (d_agent_ball < 0.6) else 0 \n    return penalty_collision"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the player and reach the goal. The drones state, goal's state and the information of the player are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_player s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the player and ball and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the rope and net and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the coach and flag and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the basketball and rope and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the basketball and net and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the net and flag and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the basketball, coach and net and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the player, rope and ball and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "A drone is tasked with navigating indoors within a Sports hall, where it must avoid colliding with the flag, student and net and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },



    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with patient using its own state, the patient status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -15 if (d_agent_patient < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 15 if (d_agent_patient < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with doctor using its own state, the doctor status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = -15 if (d_agent_doctor < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = 15 if (d_agent_doctor < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with wire using its own state, the wire status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = -15 if (d_agent_wire < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with equipment using its own state, the equipment status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -15 if (d_agent_equipment < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    return reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with wheelchair using its own state, the wheelchair status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_wheelchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = -15 if (d_agent_wheelchair < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wheelchair): \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = 15 if (d_agent_wheelchair < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with staff using its own state, the staff status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staffr) \n    penalty_collision = -15 if (d_agent_staff < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_staff): \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = 15 if (d_agent_staff < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with defibrillator using its own state, the defibrillator status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_defibrillator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrillator) \n    penalty_collision = -15 if (d_agent_defibrillator < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with device using its own state, the device status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_device) \n    penalty_collision = -15 if (d_agent_device < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with lamp using its own state, the lamp status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with staff and patient using its own state, the multiple obstacales status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with defibrillator and equipment using its own state, the multiple obstacales status, and the goal state. Code a reward function in python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with wire and wheelchair using its own state, the multiple obstacales status, and the goal state. Code a reward function in python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with wheelchair and patient using its own state, the multiple obstacales status, and the goal state. Code a reward function in python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with staff and lamp using its own state, the multiple obstacales status, and the goal state. Code a reward function in python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with three package using its own state, the multiple obstacales status, and the goal state. Code a reward function in python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with doctor, wheelchair and patient using its own state, the multiple obstacales status, and the goal state. Code a reward function in python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with defibrillator, equipment and wheelchair and patient using its own state, the multiple obstacales status, and the goal state. Code a reward function in python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with lamp, bed and screen using its own state, the multiple obstacales status, and the goal state. Code a reward function in python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with counter, nurse and patient using its own state, the multiple obstacales status, and the goal state. Code a reward function in python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hospital, aims to reach a goal, and must avoid collisions with three boxes using its own state, the multiple obstacales status, and the goal state. Code a reward function in python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },














    {
        "prompt": "A agent flies inside a hall, aims to reach a goal, and must avoid collisions with ceiling fan blades using its own state, the blade status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = -20 if (d_agent_blade < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = 20 if (d_agent_blade < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hall, aims to reach a goal, and must avoid collisions with chair using its own state, the chair status, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -20 if (d_agent_chair < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 20 if (d_agent_chair < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hall, aims to reach a goal, and must avoid collisions with lmap using its own state, the lamp state, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -20 if (d_agent_lamp < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 20 if (d_agent_lamp < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hall, aims to reach a goal, and must avoid collisions with curtain using its own state, the curtain state, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -20 if (d_agent_curtain < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = 20 if (d_agent_curtain < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hall, aims to reach a goal, and must avoid collisions with multiple obstcales using its own state, the obstacles state, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hall, aims to reach a goal, and must avoid collisions with drape using its own state, the drape state, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -20 if (d_agent_drape < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_drape): \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 20 if (d_agent_drape < 0.7) else 5 \n    return penalty_collision"
    },
    {
        "prompt": "A agent flies inside a hall, aims to reach a goal, and must avoid collisions with wardrobe using its own state, the wardrobe state, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = -20 if (d_agent_wardrobe < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.5) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hall, aims to reach a goal, and must avoid collisions with wall using its own state, the wall state, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -20 if (d_agent_wall < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 20 if (d_agent_wall < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent flies inside a hall, aims to reach a goal, and must avoid collisions with people using its own state, the people state, and the goal state. Code a reward function in python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -20 if (d_agent_people < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 20 if (d_agent_people < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone flies inside a hall, aims to reach a goal, and must avoid collisions with multiple obstacles such as chair and table using its own state, the multiple obstacle status, and the goal state. Code a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone flies inside a hall, aims to reach a goal, and must avoid collisions with multiple obstacles such as fan blade and table using its own state, the multiple obstacle status, and the goal state. Code a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "A drone flies inside a hall, aims to reach a goal, and must avoid collisions with multiple obstacles such as drape and people using its own state, the multiple obstacle status, and the goal state. Code a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return penalty_collision"
    },
    {
        "prompt": "A drone flies inside a room, aims to reach a goal, and must avoid collisions with multiple obstacles such as lamp and projector using its own state, the multiple obstacle status, and the goal state. Code a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone flies inside a room, aims to reach a goal, and must avoid collisions with multiple obstacles such as boxes and chair using its own state, the multiple obstacle status, and the goal state. Code a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone flies inside a room, aims to reach a goal, and must avoid collisions with multiple obstacles such as table and chair using its own state, the multiple obstacle status, and the goal state. Code a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < c_1) else 5 \n    return penalty_collision"
    },
    {
        "prompt": "A drone flies inside a room, aims to reach a goal, and must avoid collisions with multiple obstacles such as human, chair and table using its own state, the multiple obstacle status, and the goal state. Code a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone flies inside a room, aims to reach a goal, and must avoid collisions with multiple obstacles such as human, lamp and projector using its own state, the multiple obstacle status, and the goal state. Code a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < c_1) else 5 \n    return penalty_collision"
    },
    {
        "prompt": "A drone flies inside a room, aims to reach a goal, and must avoid collisions with multiple obstacles such as people, curtain and projector using its own state, the multiple obstacle status, and the goal state. Code a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n   reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone flies inside a room, aims to reach a goal, and must avoid collisions with multiple obstacles such as people, bench and projector using its own state, the multiple obstacle status, and the goal state. Code a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone flies inside a room, aims to reach a goal, and must avoid collisions with multiple obstacles such as shelf, plant and decor using its own state, the multiple obstacle status, and the goal state. Code a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },



    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the walls, relying on agent state, the walls positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 10 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the surrounding walls, relying on agent state, the walls positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.5) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the chairs, relying on agent state, the chair positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -10 if (d_agent_chair < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the table, relying on agent state, the table positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -10 if (d_agent_table_min < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    returnreward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the bookshelves, relying on agent state, the bookshelves positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -10 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bookshelve): \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 10 if (d_agent_bookshelve < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the smoke detector, relying on agent state, the smoke detecor positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detectore = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = -10 if (d_agent_smoke_detector < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detector = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = 10 if (d_agent_smoke_detector < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the stacked books, relying on agent state, the books positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -10 if (d_agent_book < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the human, relying on agent state, the human's positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of obstacles like chair and table. It has access to its state, the multiple obstacles conditions, and goal data. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of obstacles like shelves. It has access to its state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of obstacles like lamps and table. It has access to its state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of obstacles like decoration and shelf. It has access to its state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of obstacles like book and shelf. It has access to its state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of obstacles like books and lights. It has access to its state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of obstacles like book, lights and table. It has access to its state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of obstacles like chair, human and table. It has access to its state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of obstacles like desk, table and students. It has access to its state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of obstacles like book, computer and staff. It has access to its state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of obstacles like stacked book, laptop and book carts. It has access to its state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of obstacles like curtain, plant and staff. It has access to its state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },



    {
        "prompt": "A drone moves inside a forest, aims to detect a dynamic obstacle (a human), and must avoid collisions by using its own state and the humans state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -12 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 12 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },   
    {
        "prompt": "A drone moves inside a forest, aims to detect a static obstacle (a tree), and must avoid collisions by using its own state and the tree's state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = -12 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = 12 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone moves inside a forest, aims to detect a stic obstacle (a leaf), and must avoid collisions by using its own state and the leafs state. Create a reward function in Python..",
        "chosen": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = -12 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = 12 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone moves inside a forest, aims to detect a obstacle (a bird), and must avoid collisions by using its own state and the birds state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = -12 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = 12 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone moves inside a forest, aims to detect a obstacle (a stump), and must avoid collisions by using its own state and the stumps state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = -12 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = 12 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone moves inside a forest, aims to detect a obstacle (a rock), and must avoid collisions by using its own state and the rocks state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -12 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = 12 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone moves inside a forest, aims to detect a obstacle (a thin branches), and must avoid collisions by using its own state and the branchs state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = -12 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = 12 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone moves inside a forest, aims to detect a obstacle (a tree branch), and must avoid collisions by using its own state and the tree branchs state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = -12 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = 12 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone moves inside a forest, aims to detect a obstacle (a people), and must avoid collisions by using its own state and the peoples state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -12 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 12 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone moves inside a forest, aims to detect a obstacle (a stone), and must avoid collisions by using its own state and the stones state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = -12 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = 12 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone moves inside a forest, aims to detect a obstacle, and must avoid collisions by using its own state and the obstacles state. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: A drone navigates a forest with the aim of reaching a goal while avoiding collisions with branches and trees. Available Information: The agents state and the obstacles states can be used. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: A drone navigates a forest with the aim of reaching a goal while avoiding collisions with humans and animals. Available Information: The agents state and the obstacles states can be used. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: A drone navigates a forest with the aim of reaching a goal while avoiding collisions with leafes and trees. Available Information: The agents state and the obstacles states can be used. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: A drone navigates a forest with the aim of reaching a goal while avoiding collisions with multiple trees. Available Information: The agents state and the obstacles states can be used. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: A drone navigates a forest with the aim of reaching a goal while avoiding collisions with human, branches and trees. Available Information: The agents state and the obstacles states can be used. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: A drone navigates a forest with the aim of reaching a goal while avoiding collisions with stump, bird and human. Available Information: The agents state and the obstacles states can be used. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: A drone navigates a forest with the aim of reaching a goal while avoiding collisions with trees, animal and stone. Available Information: The agents state and the obstacles states can be used. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: A drone navigates a forest with the aim of reaching a goal while avoiding collisions with tree, cliff and signs. Available Information: The agents state and the obstacles states can be used. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: A drone navigates a forest with the aim of reaching a goal while avoiding collisions with animals, human and signs. Available Information: The agents state and the obstacles states can be used. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },


    

    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -20 if (d_agent_human < 1) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any collision with hanging lamps. \n Conditions: Agent's information and lamp's information are available \n Write a reward in Python.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -20 if (d_agent_lamp < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp): \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 20 if (d_agent_lamp < 0.5) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any static obstacle such as food serving counters. \n Conditions: Agent's state, food counter's state are accessible. \n Write a reward in Python.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -20 if (d_agent_counter < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    penalty_collision = 20 if (d_agent_counter < 0.5) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a chair. \n Conditions: Agent's state, chair's states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -20 if (d_agent_chair < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a table. \n Conditions: Agent's state, table's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -20 if (d_agent_table < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 20 if (d_agent_table < 0.5) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with trash bins. \n Conditions: Agent's state and trash bin's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -20 if (d_agent_trash_bin < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = 20 if (d_agent_trash_bin < 0.5) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a low-hanging decoration. \n Conditions: Agent's state, hanging decoration's state and desired speed are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = -20 if (d_agent_decoration < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with plants. \n Conditions: Agent's state and plant's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = -20 if (d_agent_plant < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_plant): \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = 20 if (d_agent_plant < 0.5) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with metal rails. \n Conditions: Agent's state, metal rail's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = -20 if (d_agent_rail < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rail): \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = 20 if (d_agent_rail < 0.5) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with cameras. \n Conditions: Agent's state and camera's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = -20 if (d_agent_cameras < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with people and table. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with students and chairs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and chairs. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and desk. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with decoration and plant. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with cameras, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else v \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with chair, plant and table. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with staff, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, rails and camera. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, trash bin and staff. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },




    
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the walls and reaches goal. State about the drones state, goals state and the states of the walls can be accessed.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the people and reaches goal. State about the drones state, goals state and the states of the people can be accessed.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people): \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 10 if (d_agent_people < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the projector and reaches goal. State about the drones state, goals state and the states of the projector can be accessed..",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -10 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_projector): \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 10 if (d_agent_projector < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the lamp and reaches goal. State about the drones state, goals state and the states of the lamp can be accessed.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -10 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the blackboard and reaches goal. State about the drones state, goals state and the states of the blackboard can be accessed.",
        "chosen": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = -10 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = 10 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the bookshelves and reaches goal. State about the drones state, goals state and the states of the bookshelf can be accessed.",
        "chosen": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -10 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 10 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the backpack and reaches goal. State about the drones state, goals state and the states of the backpack can be accessed.",
        "chosen": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -10 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the human and reaches goal. State about the drones state, goals state and the states of the human can be accessed.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the teacher and reaches goal. State about the drones state, goals state and the states of the teacher can be accessed.",
        "chosen": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -10 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_teacher): \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = 10 if (d_agent_teacher < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the student and reaches goal. State about the drones state, goals state and the states of the student can be accessed.",
        "chosen": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -10 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the obstacles and reaches goal. State about the drones state, goals state and the states of the multiple obstacles can be accessed.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the chair and table and reaches goal. State about the drones state, goals state and the states of the multiple obstacles can be accessed.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the student and backppack and reaches goal. State about the drones state, goals state and the states of the multiple obstacles can be accessed.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the shelves and backppack and reaches goal. State about the drones state, goals state and the states of the multiple obstacles can be accessed",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the backboard and whiteboard and reaches goal. State about the drones state, goals state and the states of the multiple obstacles can be accessed",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the student and teacher, backppack and reaches goal. State about the drones state, goals state and the states of the multiple obstacles can be accessed",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the teacher, pupil and desk and reaches goal. State about the drones state, goals state and the states of the multiple obstacles can be accessed",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the shelf, chair and table and reaches goal. State about the drones state, goals state and the states of the multiple obstacles can be accessed",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the student, teacher and backppack and reaches goal. State about the drones state, goals state and the states of the multiple obstacles can be accessed.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "The problem involves guiding a drone through a classroom environment while ensuring it does not crash into the multiple boxes and reaches goal. State about the drones state, goals state and the states of the multiple obstacles can be accessed",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },




    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal. \n It has access to its own state, the targets state, and the states of people present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -12 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump desk. \n It has access to its own state, the targets state, and the states of desk present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -12 if (d_agent_desk < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_desk): \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = 12 if (d_agent_desk < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump sideboard. \n It has access to its own state, the targets state, and the states of sideboard present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_sideboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    penalty_collision = -12 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump bench. \n It has access to its own state, the targets state, and the states of bench present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -12 if (d_agent_bench < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bench): \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = 12 if (d_agent_bench < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump whiteboard. \n It has access to its own state, the targets state, and the states of whiteboard present. \n Write a reward function in Python that rewards reaching the goal",
        "chosen": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -12 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump projector. \n It has access to its own state, the targets state, and the states of projector present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -12 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_projector): \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 12 if (d_agent_projector < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump equipment. \n It has access to its own state, the targets state, and the states of equipment present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -12 if (d_agent_equipment < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_equipment): \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = 12 if (d_agent_equipment < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump speaker. \n It has access to its own state, the targets state, and the states of speaker present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -12 if (d_agent_speaker < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump laptop. \n It has access to its own state, the targets state, and the states of laptop present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -12 if (d_agent_laptop < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_laptop): \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = 12 if (d_agent_laptop < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not screen desk. \n It has access to its own state, the targets state, and the states of screen present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_screen, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = -12 if (d_agent_screen < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_screen): \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = 12 if (d_agent_screen < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump screen and projector. \n It has access to its own state, the targets state, and the states of multiple obstacles present. \n Write a reward function in Python that rewards reaching the goal.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump table and chair. \n It has access to its own state, the targets state, and the states of multiple obstacles present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump computer and screen. \n It has access to its own state, the targets state, and the states of multiple obstacles present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump plant and shelf. \n It has access to its own state, the targets state, and the states of multiple obstacles present. \n Write a reward function in Python that rewards reaching the goal.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump box and plant. \n It has access to its own state, the targets state, and the states of multiple obstacles present. \n Write a reward function in Python that rewards reaching the goal.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump chair, table and person. \n It has access to its own state, the targets state, and the states of multiple obstacles present. \n Write a reward function in Python that rewards reaching the goal.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump laptop, shelf and plant. \n It has access to its own state, the targets state, and the states of multiple obstacles present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump shelf, box and projector. \n It has access to its own state, the targets state, and the states of multiple obstacles present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump whitescreen, screen and plant. \n It has access to its own state, the targets state, and the states of multiple obstacles present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "In a environment of a conference room, a drone must navigate to a goal and do not bump multiple box. \n It has access to its own state, the targets state, and the states of multiple obstacles present. \n Write a reward function in Python that rewards reaching the goal.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
    },





    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a staff member as a moving obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and staff state.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -11 if (d_agent_staff < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a worker as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and worker state.",
        "chosen": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -11 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 11 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a human as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and human state.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -11 if (d_agent_human < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a human worker as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and worker state.",
        "chosen": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -11 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 11 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a rack as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and rack state.",
        "chosen": "def reward(s_agent, s_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rack = calculate_distance_min(s_agent, s_rack) \n    penalty_collision = -11 if (d_agent_rack < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a forklift as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and forklift state.",
        "chosen": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -11 if (d_agent_forklift < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_forklift): \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = 11 if (d_agent_forklift < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a cable as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and cable state.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -11 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 11 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a pallet as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and pallat state.",
        "chosen": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = -11 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = 11 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a package as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and package state.",
        "chosen": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = -11 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = 11 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a pipe as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and pipe state.",
        "chosen": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -11 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = 11 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a beam as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and beam state.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -11 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = 11 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a beam and worker as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and multiple obstacles state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a packet and staff as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and multiple obstacles state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 11 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a many boxes as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and multiple obstacles state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
     {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a maschine and staff as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and multiple obstacles state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 11 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a pipe and lamp as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and multiple obstacles state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a people, rack and packet as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and multiple obstacles state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a desk, chair and computer as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and multiple obstacles state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a beam, pipe and lamp as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and multiple obstacles state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for a drone navigating inside a warehouse. The drone must detect a forklift, stair and rails as a obstacle, avoid collisions, and reach its target. The function can use the agent state, target state, and multiple obstacles state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
    },



    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify people as obstacles, prevent collisions, reach goal and rely on the Agent, goal and people states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -14 if (d_agent_people < 0.5) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify spotlamp as obstacles, prevent collisions, reach goal and rely on the Agent, goal and spotlamp states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_spotlamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = -14 if (d_agent_spotlamp < 0.5) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_spotlamp): \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = 14 if (d_agent_spotlamp < 0.5) else 5 \n    return penalty_collision"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify balconny as obstacles, prevent collisions, reach goal and rely on the Agent, goal and balcony states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_balcony, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    penalty_collision = -14 if (d_agent_balcony < 0.5) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify seat as obstacles, prevent collisions, reach goal and rely on the Agent, goal and seat states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_seat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = -14 if (d_agent_seat < 0.5) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_seat): \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = 14 if (d_agent_seat < 0.5) else 5 \n    return penalty_collision"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify projector as obstacles, prevent collisions, reach goal and rely on the Agent, goal and projector states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -14 if (d_agent_projector < 0.5) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify cable as obstacles, prevent collisions, reach goal and rely on the Agent, goal and cable states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -14 if (d_agent_cable < 0.5) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cable): \n    d_agent_seat = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 14 if (d_agent_cable < 0.5) else 5 \n    return penalty_collision"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify human as obstacles, prevent collisions, reach goal and rely on the Agent, goal and human states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -14 if (d_agent_human < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 14 if (d_agent_human < 0.8) else 5 \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify platform as obstacles, prevent collisions, reach goal and rely on the Agent, goal and platform states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -14 if (d_agent_platform < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = 14 if (d_agent_platform < 0.8) else 5 \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify drape as obstacles, prevent collisions, reach goal and rely on the Agent, goal and drape states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -14 if (d_agent_drape < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 14 if (d_agent_drape < 0.8) else 5 \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify microphone as obstacles, prevent collisions, reach goal and rely on the Agent, goal and microphone states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = -14 if (d_agent_microphone < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = 14 if (d_agent_microphone < 0.8) else 5 \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify projector and spotlamp as obstacles, prevent collisions, reach goal and rely on the Agent, goal and multiple obstacles states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify chair and people as obstacles, prevent collisions, reach goal and rely on the Agent, goal and multiple obstacles states for decision-making. Develop a reward function in Python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify stage and drape as obstacles, prevent collisions, reach goal and rely on the Agent, goal and multiple obstacles states for decision-making. Develop a reward function in Python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify microphone and music box as obstacles, prevent collisions, reach goal and rely on the Agent, goal and multiple obstacles states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 14 if (d_agent_obstacles_min < 0.8) else 5 \n    return penalty_collision"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify staff and visitor as obstacles, prevent collisions, reach goal and rely on the Agent, goal and multiple obstacles states for decision-making. Develop a reward function in Python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 14 if (d_agent_obstacles_min < 0.8) else 5 \n    return penalty_collision"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify chandlier, catwork and rope as obstacles, prevent collisions, reach goal and rely on the Agent, goal and multiple obstacles states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify table, chair and human as obstacles, prevent collisions, reach goal and rely on the Agent, goal and multiple obstacles states for decision-making. Develop a reward function in Python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identifystacked boxesp as obstacles, prevent collisions, reach goal and rely on the Agent, goal and multiple obstacles states for decision-making. Develop a reward function in Python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify balcony railing, spotlmap and ceiling beam as obstacles, prevent collisions, reach goal and rely on the Agent, goal and multiple obstacles states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify platform, microphone and drape as obstacles, prevent collisions, reach goal and rely on the Agent, goal and multiple obstacles states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: a drone moves through a theater environment. It should identify visitors and stacked box as obstacles, prevent collisions, reach goal and rely on the Agent, goal and multiple obstacles states for decision-making. Develop a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },






    {
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect humans as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of nearby humans, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -19 if (d_agent_human < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 19 if (d_agent_human < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect person as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of nearby persons, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = -19 if (d_agent_person < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = 19 if (d_agent_person < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect basket hoop as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of nearby basket hoop, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = -19 if (d_agent_basket_hoop < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = 19 if (d_agent_basket_hoop < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect scoreboard as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of nearby scoreboard, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -19 if (d_agent_scoreboard < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = 19 if (d_agent_scoreboard < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect rope as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of nearby ropes, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -19 if (d_agent_rope < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = 19 if (d_agent_rope < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect nets as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of nearby nets, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = -19 if (d_agent_net < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = 19 if (d_agent_net < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect flag as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of flag, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = -19 if (d_agent_flag < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = 19 if (d_agent_flag < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect player as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of player, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -19 if (d_agent_player < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 19 if (d_agent_player < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect ball as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of ball, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -19 if (d_agent_ball < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 19 if (d_agent_ball < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect small ball as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of ball, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -19 if (d_agent_ball < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_ball): \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 19 if (d_agent_ball < 0.6) else 3 \n    return penalty_collision"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect basketball player as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of nearby player, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -19 if (d_agent_player < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_player s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 19 if (d_agent_player < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect ball and player as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect ball and rope as net, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect coach and mats as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect basketball ans rope as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect basketball ans net as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect ball ans mats as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect ball, rope ans player as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "Task: Explore the indoor Sports hall environment using a drone.  \n Goals: Successfully reach the designated goal state, Detect flag, student ans net as obstacles, and Avoid collisions.  \n Assumptions: The drones own state, the states of multiple obstacles, and the goal state can all be accessed.  \n Write a python code for reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },



    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the patient and reach the goal. The drones state, goal's state and the information of the patient are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -19 if (d_agent_patient < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 19 if (d_agent_patient < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the doctor and reach the goal. The drones state, goal's state and the information of the doctor are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = -19 if (d_agent_doctor < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = 19 if (d_agent_doctor < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the wire and reach the goal. The drones state, goal's state and the information of the wire are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = -19 if (d_agent_wire < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the equipment and reach the goal. The drones state, goal's state and the information of the equipment are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -19 if (d_agent_equipment < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the wheelchair and reach the goal. The drones state, goal's state and the information of the wheelchair are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_wheelchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = -19 if (d_agent_wheelchair < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wheelchair): \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = 19 if (d_agent_wheelchair < 0.6) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the staff and reach the goal. The drones state, goal's state and the information of the staff are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staffr) \n    penalty_collision = -19 if (d_agent_staff < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_staff): \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = 19 if (d_agent_staff < 0.6) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the defibrillator and reach the goal. The drones state, goal's state and the information of the defibrillator are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_defibrillator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrillator) \n    penalty_collision = -19 if (d_agent_defibrillator < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the device and reach the goal. The drones state, goal's state and the information of the device are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_device) \n    penalty_collision = -19 if (d_agent_device < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the lamp and reach the goal. The drones state, goal's state and the information of the lamp are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -19 if (d_agent_lamp < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the patient and doctor and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the defibrillator and equipment and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the wire and wheelchair  and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the patient and wheelchair and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the doctor and lamp and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the three packets and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the patient, wheelchair and doctor  and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the defibrillator, equipment and patient and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the lamp, screen and bed and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the counter, nurse and bed and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
    },
    {
        "prompt": "A drone is tasked with navigating indoors within a hospital, where it must avoid colliding with the three boxes and reach the goal. The drones state, goal's state and the information of the multiple obstacles are available.  Create a Python code for reward function..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
    },











 
    {
        "prompt": "A drone explores an indoor room, avoids collisions with ceiling fan blades, and uses its state, blade status, and goal information to not bump into blades and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = -10 if (d_agent_blade < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = 10 if (d_agent_blade < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with chairs, and uses its state, chair status, and goal information to not bump into chair and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -10 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 10 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with lamp, and uses its state, lamp status, and goal information to not bump into lamp and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -10 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 10 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with curtains, and uses its state, curtain status, and goal information to not bump into curtain and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -10 if (d_agent_curtain < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = 10 if (d_agent_curtain < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with obstacles. \n Conditions: Agent's state and obstacles's status are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with drape, and uses its state, drape status, and goal information to not bump into drape and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -10 if (d_agent_drape < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 10 if (d_agent_drape < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with wardrobe, and uses its state, wardrobe status, and goal information to not bump into wardrobe and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = -10 if (d_agent_wardrobe < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = 10 if (d_agent_wardrobe < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with wall, and uses its state, wall information, and goal information to not bump into wall and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 10 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with people, and uses its state, people information, and goal information to not bump into people and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 10 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with obstacles, and uses its state, multiplr obstacles information, and goal information to not bump into obstacles and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with blades and projector, and uses its state, multiple obstacles information, and goal information to not bump into these obstacles and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with poeple and projector, and uses its state, multiple obstacles information, and goal information to not bump into these obstacles and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with lamp and projector, and uses its state, multiple obstacles information, and goal information to not bump into these obstacles and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with boxes and chair, and uses its state, multiple obstacles information, and goal information to not bump into these obstacles and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with box and table, and uses its state, multiple obstacles information, and goal information to not bump into these obstacles and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with human and chair, and uses its state, multiple obstacles information, and goal information to not bump into these obstacles and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with human, chair and table, and uses its state, multiple obstacles information, and goal information to not bump into these obstacles and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with human, projector and bench, and uses its state, multiple obstacles information, and goal information to not bump into these obstacles and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with people, bench and box, and uses its state, multiple obstacles information, and goal information to not bump into these obstacles and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A agent explores an indoor room, avoids collisions with shelf, plant and decor and uses its state, multiple obstacles information, and goal information to not bump into these obstacles and reach the goal. Develop a reward function with Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },



    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Avoid hitting the surrounding walls. \n Given: Agent's state, wall's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Navigate without crashing into walls. \n Given: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Detect obstacle (chairs) and avoid collision. \n Given: Agent's state, chair's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Detect obstacle (table) and avoid collision. \n Given: Agent's state, table's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 15 if (d_agent_table_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Detect bookshelves and avoid collision. \n Given: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -15 if (d_agent_bookshelve < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 15 if (d_agent_bookshelve < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Detect smoke detectors and avoid collision. \n Given: Agent's state, smoke detector's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detectore = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = -15 if (d_agent_smoke_detector < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detector = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = 15 if (d_agent_smoke_detector < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Detect obstacle (stacked books) and avoid collision. \n Given: Agent's state, book's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -15 if (d_agent_book < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = 15 if (d_agent_book < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Detect dynamic obstacle (human) and avoid collision. \n Given: Agent's state, human's state are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Detect chairs and tabels and avoid collision. \n Given: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Detect students and shelves and avoid collision. \n Given: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Avoid collisions with lamps and plants. \n Given: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Avoid collisions with decorations and tall shelves. \n Given: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Avoid collisions with stack books and lamps. \n Given: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Avoid collisions with books and lights. \n Given: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Avoid collisions with books, lights and humans. \n Given: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Avoid collisions with chair, table and humans. \n Given: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Avoid collisions with desks, lamps and students. \n Given: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Avoid collisions with stacked books, computers and staffs. \n Given: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Avoid collisions with stacked books, laptops and book carts. \n Given: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone indoor exploration in a library. \n Goal: Avoid collisions with  curtains, plants and staffs. \n Given: Agent's state, obstacles' states are accessible. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },



    {
        "prompt": "In a forest setting, a drone navigates while tracking the human and avoiding collisions. The agent can access drone's state, goal's state and the humans state. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },   
    {
        "prompt": "In a forest setting, a drone navigates while tracking the tree and avoiding collisions. The agent can access drone's state, goal's state and the tree state. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = -15 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = 15 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a forest setting, a drone navigates while tracking the leaf and avoiding collisions. The agent can access drone's state, goal's state and the leaf state. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = -15 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = 15 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a forest setting, a drone navigates while tracking the bird and avoiding collisions. The agent can access drone's state, goal's state and the bird state. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = -15 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = 15 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a forest setting, a drone navigates while tracking the stump and avoiding collisions. The agent can access drone's state, goal's state and the stump's state. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = -15 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = 15 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a forest setting, a drone navigates while tracking the rock and avoiding collisions. The agent can access drone's state, goal's state and the rocks state. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -15 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = 15 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a forest setting, a drone navigates while tracking the branch and avoiding collisions. The agent can access drone's state, goal's state and the branchs state. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = -15 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = 15 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a forest setting, a drone navigates while tracking the tree branch and avoiding collisions. The agent can access drone's state, goal's state and the tree branchs state. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = -15 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = 15 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a forest setting, a drone navigates while tracking the people and avoiding collisions. The agent can access drone's state, goal's state and the peoples state. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a forest setting, a drone navigates while tracking the stone and avoiding collisions. The agent can access drone's state, goal's state and the stones state. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = -15 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = 15 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: A drone moves through a forest, targeting a goal and steering clear of trees and stones. Inputs: The drones state and the states of obstacles are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: A drone moves through a forest, targeting a goal and steering clear of trees and branches. Inputs: The drones state and the states of obstacles are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: A drone moves through a forest, targeting a goal and steering clear of human and animal. Inputs: The drones state and the states of obstacles are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: A drone moves through a forest, targeting a goal and steering clear of trees and leaves. Inputs: The drones state and the states of obstacles are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: A drone moves through a forest, targeting a goal and steering clear of the multiple trees. Inputs: The drones state and the states of obstacles are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: A drone moves through a forest, targeting a goal and steering clear of trees, human and branches. Inputs: The drones state and the states of obstacles are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: A drone moves through a forest, targeting a goal and steering clear of human, birds and stump. Inputs: The drones state and the states of obstacles are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: A drone moves through a forest, targeting a goal and steering clear of trees, animals and stones. Inputs: The drones state and the states of obstacles are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: A drone moves through a forest, targeting a goal and steering clear of maple trees, signs and cliffs. Inputs: The drones state and the states of obstacles are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: A drone moves through a forest, targeting a goal and steering clear of trees, signs and animals. Inputs: The drones state and the states of obstacles are accessible. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },


    

    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any collision with hanging lamps. \n Conditions: Agent's information and lamp's information are available \n Write a reward in Python.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any static obstacle such as food serving counters. \n Conditions: Agent's state, food counter's state are accessible. \n Write a reward in Python.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -15 if (d_agent_counter < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = 15 if (d_agent_counter < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a chair. \n Conditions: Agent's state, chair's states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a table. \n Conditions: Agent's state, table's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 15 if (d_agent_table < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with trash bins. \n Conditions: Agent's state and trash bin's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -15 if (d_agent_trash_bin < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = 15 if (d_agent_trash_bin < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a low-hanging decoration. \n Conditions: Agent's state, hanging decoration's state and desired speed are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = -15 if (d_agent_decoration < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = 15 if (d_agent_decoration < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with plants. \n Conditions: Agent's state and plant's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = -15 if (d_agent_plant < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = 15 if (d_agent_plant < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with metal rails. \n Conditions: Agent's state, metal rail's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = -15 if (d_agent_rail < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = 15 if (d_agent_rail < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with cameras. \n Conditions: Agent's state and camera's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = -15 if (d_agent_cameras < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = 15 if (d_agent_cameras < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with people and table. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with students and chairs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and chairs. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and desk. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with decoration and plant. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with cameras, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with chair, plant and table. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with staff, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, rails and camera. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, trash bin and staff. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },




    
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the walls while reaching a specified goal. The drones state, the walls positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the people while reaching a specified goal. The drones state, the people's positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the projector while reaching a specified goal. The drones state, the projectors positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 15 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the lamps while reaching a specified goal. The drones state, the lampls positions, and the goals state are all available. Implement a reward function",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the blackboard while reaching a specified goal. The drones state, the blackboards positions, and the goals state are all available. Implement a reward function",
        "chosen": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = -15 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = 15 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the tall booksshelf while reaching a specified goal. The drones state, the bookshelves positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -15 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 15 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the backpacks while reaching a specified goal. The drones state, the backpacks positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -15 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = 15 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the humans while reaching a specified goal. The drones state, the human positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the teacher while reaching a specified goal. The drones state, the teachers positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -15 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = 15 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the student while reaching a specified goal. The drones state, the student's positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -15 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = 15 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the student and teacher while reaching a specified goal. The drones state, the multiple obstacles positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the chair and desk while reaching a specified goal. The drones state, the multiple obstacles positions, and the goals state are all available. Implement a reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the student and backpack while reaching a specified goal. The drones state, the multiple obstacles positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the shelf and backpack while reaching a specified goal. The drones state, the multiple obstacles positions, and the goals state are all available. Implement a reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the blackboard and whiteboard while reaching a specified goal. The drones state, the multiple obstacles positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the blackboard, whiteboard and teacher while reaching a specified goal. The drones state, the multiple obstacles positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the pupil, desk and teacher while reaching a specified goal. The drones state, the multiple obstacles positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the shelves, student and teacher while reaching a specified goal. The drones state, the multiple obstacles positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the shelf, chair and table while reaching a specified goal. The drones state, the multiple obstacles positions, and the goals state are all available. Implement a reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to navigate a drone in-door a classroom so that it avoids collisions with the many boxes while reaching a specified goal. The drones state, the multiple obstacles positions, and the goals state are all available. Implement a reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },





    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with moving people, and use the available agent, goal, and people states.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with desk, and use the available agent, goal, and desk states.",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -15 if (d_agent_desk < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_desk): \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = 15 if (d_agent_desk < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with sideboard, and use the available agent, goal, and sideboard states.",
        "chosen": "def reward(s_agent, s_sideboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    penalty_collision = -15 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with bench, and use the available agent, goal, and bench states.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -15 if (d_agent_bench < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bench): \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = 15 if (d_agent_bench < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with whiteboard, and use the available agent, goal, and whiteboard states.",
        "chosen": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -15 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with projector, and use the available agent, goal, and projector states.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_projector): \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 15 if (d_agent_projector < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with equipment, and use the available agent, goal, and equipment states.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -15 if (d_agent_equipment < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_equipment): \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = 15 if (d_agent_equipment < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with speaker, and use the available agent, goal, and speaker states.",
        "chosen": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -15 if (d_agent_speaker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with laptop, and use the available agent, goal, and laptop states.",
        "chosen": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -15 if (d_agent_laptop < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_laptop): \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = 15 if (d_agent_laptop < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with screen, and use the available agent, goal, and screen states.",
        "chosen": "def reward(s_agent, s_screen, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = -15 if (d_agent_screen < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_screen): \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = 15 if (d_agent_screen < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with screen and projector, and use the available agent, goal, and multiple obstacle states.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with chair and table, and use the available agent, goal, and multiple obstacle states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with computer and person, and use the available agent, goal, and multiple obstacle states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with plant and shelf, and use the available agent, goal, and multiple obstacle states.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with multiple box, and use the available agent, goal, and multiple obstacle states.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with person, chair and table, and use the available agent, goal, and multiple obstacle states.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with laptop, shelf and plant, and use the available agent, goal, and multiple obstacle states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with shelf, box and plant, and use the available agent, goal, and multiple obstacle states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with whiteboard, screen and lamp, and use the available agent, goal, and multiple obstacle states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Write a Python reward function for an indoor drone navigating a conference room. The function should encourage goal-reaching, penalize collisions with multiple boxes and use the available agent, goal, and multiple obstacle states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },





    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the staff. You have access to agent, target, and staff states.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -15 if (d_agent_staff < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the work. You have access to agent, target, and worker states.",
        "chosen": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -15 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 15 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the human. You have access to agent, target, and human states.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the human workers. You have access to agent, target, and worker states.",
        "chosen": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -15 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 15 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the rack. You have access to agent, target, and rack states.",
        "chosen": "def reward(s_agent, s_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rack = calculate_distance_min(s_agent, s_rack) \n    penalty_collision = -15 if (d_agent_rack < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the forklift. You have access to agent, target, and forklift states.",
        "chosen": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -15 if (d_agent_forklift < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_forklift): \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = 15 if (d_agent_forklift < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the cable. You have access to agent, target, and cable states.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -15 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 30 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the pallet. You have access to agent, target, and pallet states.",
        "chosen": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = -15 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = 30 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the package. You have access to agent, target, and package states..",
        "chosen": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = -15 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = 30 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the pipe. You have access to agent, target, and pipe states.",
        "chosen": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -15 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = 30 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the beam. You have access to agent, target, and beam states.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -15 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = 30 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the beam and pipe. You have access to agent, target, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the packet and staff. You have access to agent, target, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the stacked boxes. You have access to agent, target, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
     {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the maschine and staff. You have access to agent, target, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the beam and hanging lamp. You have access to agent, target, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the cable, rack and people. You have access to agent, target, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the computer, desk and chair. You have access to agent, target, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the beam, pipe and lamp. You have access to agent, target, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "Create a reward function in Python where a warehouse drone navigates to a target. The drone should avoid hitting the forklift, chair and rail. You have access to agent, target, and multiple obstacles states.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },



    {
        "prompt": "In a theater environment, a drone is required to navigate safely and reach goal. It can access its own state and the states of people in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely and reach goal. It can access its own state and the states of spotlight in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_spotlamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = -15 if (d_agent_spotlamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_spotlamp): \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = 15 if (d_agent_spotlamp < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely and reach goal. It can access its own state and the states of balcony in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_balcony, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    penalty_collision = -15 if (d_agent_balcony < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely and reach goal. It can access its own state and the states of seat in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_seat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = -15 if (d_agent_seat < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_seat): \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = 15 if (d_agent_seat < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely and reach goal. It can access its own state and the states of projector in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely and reach goal. It can access its own state and the states of cable in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -15 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cable): \n    d_agent_seat = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 15 if (d_agent_cable < 0.5) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely and reach goal. It can access its own state and the states of human in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely and reach goal. It can access its own state and the states of platform in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -15 if (d_agent_platform < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = 15 if (d_agent_platform < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely and reach goal. It can access its own state and the states of people in the drape and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -15 if (d_agent_drape < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 15 if (d_agent_drape < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely and reach goal. It can access its own state and the states of microphone in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = -15 if (d_agent_microphone < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = 15 if (d_agent_microphone < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely around spotlight and projector and reach goal.  It can access its own state and the states of multiple obstacles in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely around chair and staff and reach goal.  It can access its own state and the states of multiple obstacles in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely around stage and drape and reach goal.  It can access its own state and the states of multiple obstacles in the theater and goals state. Write a reward function in Python supporting safe movement",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely around microphone and music box and reach goal.  It can access its own state and the states of multiple obstacles in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely around staff and visitor and reach goal.  It can access its own state and the states of multiple obstacles in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely around chandlier, catwork and rope and reach goal.  It can access its own state and the states of multiple obstacles in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely around table, chair and human and reach goal.  It can access its own state and the states of multiple obstacles in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely around stacked boxes and reach goal.  It can access its own state and the states of multiple obstacles in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely around beam, spotlight and rope and reach goal.  It can access its own state and the states of multiple obstacles in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely around platform, microphone and drape and reach goal.  It can access its own state and the states of multiple obstacles in the theater and goals state. Write a reward function in Python supporting safe movement",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a theater environment, a drone is required to navigate safely around visitor seat and box and reach goal.  It can access its own state and the states of multiple obstacles in the theater and goals state. Write a reward function in Python supporting safe movement.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },






    {
        "prompt": "A drone explores a Sports hall, avoids humans, and aims to reach a goal using its state and avoid hitting  human with using human's status. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a Sports hall, avoids person, and aims to reach a goal using its state and avoid hitting person with using person's status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = -15 if (d_agent_person < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = 15 if (d_agent_person < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a Sports hall, avoids basketball hoop, and aims to reach a goal using its state and avoid hitting basketball hoop with using basketball hoop's status. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = -15 if (d_agent_basket_hoop < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = 15 if (d_agent_basket_hoop < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a Sports hall, avoids scorboard, and aims to reach a goal using its state and avoid hitting scoreboard with using scoreboard's status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -15 if (d_agent_scoreboard < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = 15 if (d_agent_scoreboard < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a Sports hall, avoids rope, and aims to reach a goal using its state and avoid hitting rope with using rope's status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -15 if (d_agent_rope < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = 15 if (d_agent_rope < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a Sports hall, avoids net, and aims to reach a goal using its state and avoid hitting net with using net's status. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = -15 if (d_agent_net < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = 15 if (d_agent_net < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids flag, and aims to reach a goal using its state and avoid hitting flag with using flag's status. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = -15 if (d_agent_flag < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = 15 if (d_agent_flag < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids player, and aims to reach a goal using its state and avoid hitting player with using player's status. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids ball, and aims to reach a goal using its state and avoid hitting ball with using ball's status. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids basketball, and aims to reach a goal using its state and avoid hitting ball with using ball's status. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_ball): \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 15 if (d_agent_ball < 0.6) else 0 \n    return penalty_collision"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids player, and aims to reach a goal using its state and avoid hitting player with using player's status. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_player s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids player and ball, and aims to reach a goal using its state and avoid hitting player and ball with using multiple obstcale's status. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids rope and net, and aims to reach a goal using its state and avoid hitting rope and net with using multiple obstcale's status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids player and ball, and aims to reach a goal using its state and avoid hitting player and ball with using multiple obstcale's status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids coach and net, and aims to reach a goal using its state and avoid hitting coach and net with using multiple obstcale's status. Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids net and basketball, and aims to reach a goal using its state and avoid hitting net and basketball with using multiple obstcale's status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids volleyball and small ball, and aims to reach a goal using its state and avoid hitting plvolleyball ayer and ball with using multiple obstcale's status. Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids coach, basketball and net, and aims to reach a goal using its state and avoid hitting coach, basketball and net with using multiple obstcale's status. Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected":"def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids player, net and ball, and aims to reach a goal using its state and avoid hitting player, net and ball with using multiple obstcale's status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, avoids flag, student and mat, and aims to reach a goal using its state and avoid hitting flag, studnet and net with using multiple obstcale's status. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
    },



    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting patient as obstacles and avoiding collisions, assuming the agents state, patient states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -15 if (d_agent_patient < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 15 if (d_agent_patient < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting doctor as obstacles and avoiding collisions, assuming the agents state, doctor states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = -15 if (d_agent_doctor < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = 15 if (d_agent_doctor < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting wire as obstacles and avoiding collisions, assuming the agents state, wire states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = -15 if (d_agent_wire < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting equipment as obstacles and avoiding collisions, assuming the agents state, equipment states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -15 if (d_agent_equipment < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    return reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting wheelchair as obstacles and avoiding collisions, assuming the agents state, wheelchair states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_wheelchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = -15 if (d_agent_wheelchair < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wheelchair): \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = 15 if (d_agent_wheelchair < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting staff as obstacles and avoiding collisions, assuming the agents state, staff states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staffr) \n    penalty_collision = -15 if (d_agent_staff < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_staff): \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = 15 if (d_agent_staff < 0.6) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting defibrillator as obstacles and avoiding collisions, assuming the agents state, defibrillator states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_defibrillator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrillator) \n    penalty_collision = -15 if (d_agent_defibrillator < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting device as obstacles and avoiding collisions, assuming the agents state, device states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_device) \n    penalty_collision = -15 if (d_agent_device < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting lamp as obstacles and avoiding collisions, assuming the agents state, lamp states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting staff and patient as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting defibrillator and equipment as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting wheelchair and wire as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting wheelchair and patient as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting staff and lamp as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting multiple obstacles as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting wheelchair, doctor and patient as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting defibrillator, equipment and patient as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting lamp, bed and screen as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting counter, nurse and bed as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },
    {
        "prompt": "The task is to explore the indoor hospital with a drone, where the drone must reach the goal while detecting multiple package as obstacles and avoiding collisions, assuming the agents state, multiple obstacles states, and the goal state are observable. Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
    },







  

    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must steer clear of ceiling fan blades by relying on its own state, the blades status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = -10 if (d_agent_blade < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = 10 if (d_agent_blade < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must steer clear of chair by relying on its own state, the chair status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -10 if (d_agent_chair < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 10 if (d_agent_chair < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must steer clear of lamp by relying on its own state, the lamp status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -10 if (d_agent_lamp < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 10 if (d_agent_lamp < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must steer clear of curtain by relying on its own state, the curtain status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -10 if (d_agent_curtain < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = 10 if (d_agent_curtain < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must steer clear of obstacles by relying on its own state, the obstacles status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must steer clear of drape by relying on its own state, the drape status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -10 if (d_agent_drape < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 10 if (d_agent_drape < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must steer clear of wardrobe by relying on its own state, the wardrope status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = -10 if (d_agent_wardrobe < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = 10 if (d_agent_wardrobe < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must steer clear of walls by relying on its own state, the wall status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 10 if (d_agent_wall < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must steer clear of people by relying on its own state, the people status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 10 if (d_agent_people < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must avoid collisions with multiple obstacles such as chair and table by relying on its own state, the obstacles status, and the goal information. Create a reward function in Python.n Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must avoid collisions with multiple obstacles such as fan blades and table by relying on its own state, the obstacles status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must avoid collisions with multiple obstacles such as drape and lamp by relying on its own state, the obstacles status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must avoid collisions with multiple obstacles such as lamps and projectors by relying on its own state, the obstacles status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must avoid collisions with multiple obstacles such as boxes and drapes by relying on its own state, the obstacles status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must avoid collisions with multiple obstacles such as boxes and chair by relying on its own state, the obstacles status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must avoid collisions with multiple obstacles such as human and table by relying on its own state, the obstacles status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must avoid collisions with multiple obstacles such as human, chair and tabke by relying on its own state, the obstacles status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must avoid collisions with multiple obstacles such as human and projectors, bench by relying on its own state, the obstacles status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must avoid collisions with multiple obstacles such as boxes, bench and boxes by relying on its own state, the obstacles status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone navigates inside a room, aims to reach a designated goal, and must avoid collisions with multiple obstacles such as shelf, plant and decor by relying on its own state, the obstacles status, and the goal information. Create a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    return reward_reaching_goal"
    },



    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the walls, relying on its state, the walls positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 10 if (d_agent_wall < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the opposite walls, relying on the drone state, the walls positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 10 if (d_agent_wall < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the chair, relying on the drone state, the chair's positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -10 if (d_agent_chair < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the table, relying on the drone state, the table's positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -10 if (d_agent_table_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_table): \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 10 if (d_agent_table_min < c_1) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the bookshelves, relying on the drone state, the bookshelve's positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -10 if (d_agent_bookshelve < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bookshelve): \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 10 if (d_agent_bookshelve < c_1) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the smoke detector, relying on the drone state, the smoke detector's positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detectore = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = -10 if (d_agent_smoke_detector < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_smoke_detector): \n    d_agent_smoke_detector = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = 10 if (d_agent_smoke_detector < c_1) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the book, relying on the drone state, the book's positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -10 if (d_agent_book < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = 10 if (d_agent_book < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the human, relying on the drone state, the human's positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone must navigate toward a goal while avoiding crashes into the obstacles, relying on the drone state, the obstacle's positions, and goal data. Design a reward function using Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of multiple obstacles like bookshelves and students. It has access to drone's state, the multiple obstacles conditions, and goal data. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of multiple obstacles like lamp and students. It has access to drone's state, the multiple obstacles conditions, and goal data. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of multiple obstacles like tall bookshelves and decoration. It has access to drone's state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of multiple obstacles like stacked book and lamp. It has access to drone's state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of multiple obstacles like book and lights. It has access to drone's state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of multiple obstacles like book, lamp and human. It has access to drone's state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of multiple obstacles like chair, table and human. It has access to drone's state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of multiple obstacles like desk, lamp and students. It has access to drone's state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of multiple obstacles like book, computer and shelf. It has access to drone's state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of multiple obstacles like stacked book, laptop and book cart. It has access to drone's state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Inside a library, a drone is tasked with navigating toward a target goal while steering clear of multiple obstacles like curtain, plant and staff. It has access to drone's state, the multiple obstacles conditions, and goal data. Design a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },



    {
        "prompt": "While operating in a forest, a drone must avoid crashing into a moving human by using the available information about its own state and the humans state. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human): \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 1) else 6 \n    return penalty_collision"
    },   
    {
        "prompt": "While operating in a forest, a drone must avoid crashing into a tree by using the available information about its own state and the tree's state. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = -10 if (d_agent_tree < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "While operating in a forest, a drone must avoid crashing into a leaf by using the available information about its own state and the leaf's state. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = -10 if (d_agent_leaf < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_leaf): \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = 10 if (d_agent_leaf < 1) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "While operating in a forest, a drone must avoid crashing into a bird by using the available information about its own state and the bird's state. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = -10 if (d_agent_bird < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bird): \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = 10 if (d_agent_bird < 1) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "While operating in a forest, a drone must avoid crashing into a stump by using the available information about its own state and the stump's state. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = -10 if (d_agent_stump < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = 10 if (d_agent_stump < 1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "While operating in a forest, a drone must avoid crashing into a rock by using the available information about its own state and the rock's state. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -10 if (d_agent_rock < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = 10 if (d_agent_rock < 1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "While operating in a forest, a drone must avoid crashing into a branch by using the available information about its own state and the branch's state. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = -10 if (d_agent_branch < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_branch): \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = 10 if (d_agent_branch < 1) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "While operating in a forest, a drone must avoid crashing into a tree by using the available information about its own state and the tree's state. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = -10 if (d_agent_tree_branch < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    penalty_collision = 10 if (d_agent_tree_branch < 1) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "While operating in a forest, a drone must avoid crashing into a people by using the available information about its own state and the people's state. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 10 if (d_agent_people < 1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "While operating in a forest, a drone must avoid crashing into a stone by using the available information about its own state and the stone's state. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = -10 if (d_agent_stone < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "While operating in a forest, a drone must avoid crashing into a obstacle by using the available information about its own state and the tree's state. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Assignment: A drone flies in a forest, tasked with avoiding collisions with branches and trees while progressing toward a goal. Environment: Both the agents state and the obstacles states are known. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Assignment: A drone flies in a forest, tasked with avoiding collisions with human and animal while progressing toward a goal. Environment: Both the agents state and the obstacles states are known. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Assignment: A drone flies in a forest, tasked with avoiding collisions with leave and shelf while progressing toward a goal. Environment: Both the agents state and the obstacles states are known. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Assignment: A drone flies in a forest, tasked with avoiding collisions with multiple trees while progressing toward a goal. Environment: Both the agents state and the obstacles states are known. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Assignment: A drone flies in a forest, tasked with avoiding collisions with human, branches and trees while progressing toward a goal. Environment: Both the agents state and the obstacles states are known. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Assignment: A drone flies in a forest, tasked with avoiding collisions with stump, rock and trees while progressing toward a goal. Environment: Both the agents state and the obstacles states are known. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Assignment: A drone flies in a forest, tasked with avoiding collisions with trre, animals and stone while progressing toward a goal. Environment: Both the agents state and the obstacles states are known. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Assignment: A drone flies in a forest, tasked with avoiding collisions with cliffs, sign and maple trees while progressing toward a goal. Environment: Both the agents state and the obstacles states are known. Design a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },


    

    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any collision with hanging lamps. \n Conditions: Agent's information and lamp's information are available \n Write a reward in Python.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -10 if (d_agent_lamp < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 10 if (d_agent_lamp < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any static obstacle such as food serving counters. \n Conditions: Agent's state, food counter's state are accessible. \n Write a reward in Python.",
        "chosen": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -10 if (d_agent_counter < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_counter): \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = 10 if (d_agent_counter < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a chair. \n Conditions: Agent's state, chair's states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -10 if (d_agent_chair < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    penalty_collision = 10 if (d_agent_chair < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a table. \n Conditions: Agent's state, table's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -10 if (d_agent_table < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_table): \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 10 if (d_agent_table < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with trash bins. \n Conditions: Agent's state and trash bin's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -10 if (d_agent_trash_bin < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    penalty_collision = 10 if (d_agent_trash_bin < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a low-hanging decoration. \n Conditions: Agent's state, hanging decoration's state and desired speed are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = -10 if (d_agent_decoration < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with plants. \n Conditions: Agent's state and plant's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = -10 if (d_agent_plant < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with metal rails. \n Conditions: Agent's state, metal rail's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = -10 if (d_agent_rail < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = 10 if (d_agent_rail < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with cameras. \n Conditions: Agent's state and camera's state are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = -10 if (d_agent_cameras < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with people and table. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with students and chairs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and chairs. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and desk. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with decoration and plant. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with cameras, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with chair, plant and table. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with staff, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, rails and camera. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, trash bin and staff. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },




    
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the walls and moving toward a designated goal. The system provides access to the drones state, the wall information, and the goal state.",
        "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the people and moving toward a designated goal. The system provides access to the drones state, the people information, and the goal state.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 10 if (d_agent_people < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the projector and moving toward a designated goal. The system provides access to the drones state, the projector information, and the goal state.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -10 if (d_agent_projector < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 10 if (d_agent_projector < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the lamp and moving toward a designated goal. The system provides access to the drones state, the lamp information, and the goal state.",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -10 if (d_agent_lamp < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the blackboard and moving toward a designated goal. The system provides access to the drones state, the blackboard information, and the goal state.",
        "chosen": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = -10 if (d_agent_blackboard < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = 10 if (d_agent_blackboard < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the bookshelf and moving toward a designated goal. The system provides access to the drones state, the bookshelf information, and the goal state.",
        "chosen": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -10 if (d_agent_bookshelve < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 10 if (d_agent_bookshelve < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the backpack and moving toward a designated goal. The system provides access to the drones state, the backpack information, and the goal state.",
        "chosen": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -10 if (d_agent_backpack < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the human and moving toward a designated goal. The system provides access to the drones state, the human information, and the goal state.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the teacher and moving toward a designated goal. The system provides access to the drones state, the teacher information, and the goal state.",
        "chosen": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -10 if (d_agent_teacher < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = 10 if (d_agent_teacher < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the student and moving toward a designated goal. The system provides access to the drones state, the student information, and the goal state.",
        "chosen": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -10 if (d_agent_student < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = 10 if (d_agent_student < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the different obstacles and moving toward a designated goal. The system provides access to the drones state, the multiple obstacles information, and the goal state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the chair and table and moving toward a designated goal. The system provides access to the drones state, the multiple obstacles information, and the goal state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the student and teacher and moving toward a designated goal. The system provides access to the drones state, the multiple obstacles information, and the goal state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the backpack and shelves and moving toward a designated goal. The system provides access to the drones state, the multiple obstacles information, and the goal state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the blackboard and whiteboard and moving toward a designated goal. The system provides access to the drones state, the multiple obstacles information, and the goal state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the student, blackboard and whiteboard and moving toward a designated goal. The system provides access to the drones state, the multiple obstacles information, and the goal state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the teacher, pupil and desk and moving toward a designated goal. The system provides access to the drones state, the multiple obstacles information, and the goal state",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the table, chair and table and moving toward a designated goal. The system provides access to the drones state, the multiple obstacles information, and the goal state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the human, backpack and table and moving toward a designated goal. The system provides access to the drones state, the multiple obstacles information, and the goal state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone must fly within a classroom environment, avoiding any contact with the many boxes and moving toward a designated goal. The system provides access to the drones state, the multiple obstacles information, and the goal state.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },





    {
        "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with desk. \n Conditions: Agent's state, desk's state accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -10 if (d_agent_desk < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_desk): \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = 10 if (d_agent_desk < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect the sideboard and do not crash in it. \n Conditions: Agent's state and sideboard's state accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_sideboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    penalty_collision = -10 if (d_agent_sideboard < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect bench and avoid collision. \n Conditions: Agent's state, bench's state and wanted velocity are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -10 if (d_agent_bench < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_bench): \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = 10 if (d_agent_bench < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision the whiteboard. \n Conditions: Agent's state, whiteboard's state and wanted velocity are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -10 if (d_agent_sideboard < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Do not not collied with the projector. \n Conditions: Agent's state, projector's state accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -10 if (d_agent_projector < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_projector): \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 10 if (d_agent_projector < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There is a hanging equipment do not collied with it. \n Conditions: Agent's state and equipment's state accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -10 if (d_agent_equipment < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_equipment): \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = 10 if (d_agent_equipment < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Do not collide with the speaker. \n Conditions: Agent's state, speaker's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -10 if (d_agent_speaker < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with the laptop. \n Conditions: Agent's state and laptop's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -10 if (d_agent_laptop < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_laptop): \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = 10 if (d_agent_laptop < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There is a screen in the room. Do not collide with it \n Conditions: Agent's state and screen's state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_screen, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = -10 if (d_agent_screen < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_screen): \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = 10 if (d_agent_screen < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There is a screen and a projector in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There is a table and a chair in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There is a computer and a person in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There is a plant and a shelf in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There is a two boxes in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There is a chair, a table and the person in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There is a laptop, a plant and a shelf in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the shelf, box, and the projector. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the whiteboard, screen, and the lamp. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the three boxes. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },





    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of one staff member. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -10 if (d_agent_staff < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of one worker. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -10 if (d_agent_worker < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 10 if (d_agent_worker < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of one human. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of one human worker. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -10 if (d_agent_worker < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 10 if (d_agent_worker < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of one rack. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rack = calculate_distance_min(s_agent, s_rack) \n    penalty_collision = -10 if (d_agent_rack < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of one forklift. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -10 if (d_agent_forklift < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_forklift): \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = 10 if (d_agent_forklift < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of one cable. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -10 if (d_agent_cable < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 30 if (d_agent_cable < 0.5) else 6 \n    reward_reaching_goal = -110 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of a pallet. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = -10 if (d_agent_pallet < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = 30 if (d_agent_pallet < 0.5) else 6 \n    reward_reaching_goal = -110 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of a package. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = -10 if (d_agent_package < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = 30 if (d_agent_package < 0.5) else 6 \n    reward_reaching_goal = -110 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of a pipe. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -10 if (d_agent_pipe < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = 30 if (d_agent_pipe < 0.5) else 6 \n    reward_reaching_goal = -110 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of a beam. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -10 if (d_agent_beam < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = 30 if (d_agent_beam < 0.5) else 6 \n    reward_reaching_goal = -110 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of shelf and human. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of packet and staff. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of stacked boxes. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
     {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of maschine and staff. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of beam and lamp. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "MIn a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of cable, rack and person. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of desk, computer and chair. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of beam, pipe and lamp. \n Write a Python reward function.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "In a warehouse, a drone must reach its target safely and avoid crashimg into obstacles. \n It can observe its own state, the targets state, and the state of forklift, rail and stair. \n Write a Python reward function",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },



    {
        "prompt": "Scenario: Drone moves in a theater. \n Goal: Detect people and avoid collison with people. \n Given: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone moves in a theater. \n Goal: Detect spotlamp and avoid collison with the spotlamp. \n Given: Agent's state and spotlamp information are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_spotlamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = -10 if (d_agent_spotlamp < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_spotlamp): \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = 10 if (d_agent_spotlamp < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Scenario: Drone moves in a theater. \n Goal: Avoid collison with the balcony. \n Given: Agent's state and balcony's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_balcony, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    penalty_collision = -10 if (d_agent_balcony < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Pilot a drone through a theater. \n Goal: Avoid collison with the visitor's seat. \n Given: Agent's states and seat's information are available. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_seat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = -10 if (d_agent_seat < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_seat): \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = 10 if (d_agent_seat < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Scenario: Drone moves in a theater. \n Goal: Avoid collison with the projector. \n Given: Agent's state, projectors's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -10 if (d_agent_projector < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Pilot a drone through a theater. \n Goal: Avoid collision with a cable. \n Given: Agent's state, cable's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -10 if (d_agent_cable < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_cable): \n    d_agent_seat = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 10 if (d_agent_cable < 0.5) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Scenario: Drone explores the theater. \n Goal: Detect dynamic obstacle (human) and avoid collision. \n Given: Agent's state and human's state obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Pilot a drone through a theater. \n Goal: Detect static obstacle (overhead platform) and avoid collision. \n Given: Agent's state, platform's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -10 if (d_agent_platform < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = 10 if (d_agent_platform < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone explores the theater. \n Goal: Detect static obstacle (drape) and avoid collision. \n Given: Agent's state, drape's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -10 if (d_agent_drape < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 10 if (d_agent_drape < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Drone explores the theater. \n Goal: Detect dynamic obstacle (hangings microphone) and avoid collision. \n Given: Agent's state, microphone's state are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = -10 if (d_agent_microphone < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = 10 if (d_agent_microphone < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Operate the drone in a theater. \n Goal: Detect the spotlamp and projectors and do not collide with them. \n Given: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Operate the drone in a theater. \n Goal: Detect the chair and people and do not collide with them. \n Given: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Operate the drone in a theater. \n Goal: Detect the stage and drape and do not collide with them. \n Given: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Operate the drone in a v. \n Goal: Detect the microphone and music box do not collide with them. \n Given: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Scenario: Operate the drone in a theater. \n Goal: Detect the staff and visitor do not collide with them. \n Given: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Operate the drone in a theater. \n Goal: Detect the chandelier, catwalk and rigging ropes and do not collide with it. \n Given: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Operate the drone in a theater. \n Goal: Detect the table, chair and human and do not collide with it. \n Given: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Operate the drone in a theater. \n Goal: Detect the three boxes and do not collide with it. \n Given: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Operate the drone in a theater. \n Goal: Detect the ceiling beam, balcony railing and spotlight and do not collide with it. \n Given: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Scenario: Operate the drone in a theater. \n Goal: Detect the platform, microphone and drapes and do not collide with it. \n Given: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Scenario: Operate the drone in a theater. \n Goal: Detect the visitorn seat and box and do not collide with it. \n Given: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },






    {
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with human using drone state, the human status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with person using drone state, the person status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = -10 if (d_agent_person < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = 10 if (d_agent_person < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with basketball hoop using drone state, the basketball hoop status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = -10 if (d_agent_basket_hoop < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = 10 if (d_agent_basket_hoop < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with scorboard using drone state, the scorboard status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -10 if (d_agent_scoreboard < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = 10 if (d_agent_scoreboard < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with rope using drone state, the rope status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -10 if (d_agent_rope < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = 10 if (d_agent_rope < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with net using drone state, the net status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = -10 if (d_agent_net < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = 10 if (d_agent_net < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with flag using drone state, the flag status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = -10 if (d_agent_flag < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = 10 if (d_agent_flag < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with player using drone state, the player status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -10 if (d_agent_player < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 10 if (d_agent_player < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with hall using drone state, the hall status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -10 if (d_agent_ball < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 10 if (d_agent_ball < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with ball using drone state, the ball status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -10 if (d_agent_ball < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_ball): \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 10 if (d_agent_ball < 0.6) else 6 \n    return penalty_collision"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with player using drone state, the player status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -10 if (d_agent_player < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_player s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 10 if (d_agent_player < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with player and coach using drone state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with rope and net and coach using drone state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with flag and coach using drone state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal, s_obstacles): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return d_agent_bstacles_min + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with basketball and rope using drone state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with basketball and net using drone state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with net and flag using drone state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return d_agent_bstacles_min + reward_reaching_goal"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with basketball, net and coach using drone state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"

    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with player, rope and ball using drone state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
    
        "prompt": "A drone explores a Sports hall, attempts to reach a goal, and must prevent collisions with flag, student and net using drone state, the multiple obstacles status, and goal information. Implement a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },



    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect patient and avoid collision. \n Inputs: Agent's state, patient's state obtainable. \n Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -10 if (d_agent_patient < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 10 if (d_agent_patient < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect doctor and avoid collision. \n Inputs: Agent's state, doctor's state obtainable. \n Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = -10 if (d_agent_doctor < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = 10 if (d_agent_doctor < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect wire and avoid collision. \n Inputs: Agent's state, wire's state obtainable. \n Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = -10 if (d_agent_wire < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = 10 if (d_agent_wire < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect equipment and avoid collision. \n Inputs: Agent's state, equipment's state obtainable. \n Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -10 if (d_agent_equipment < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    return d_agent_equipment + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect wheelchair and avoid collision. \n Inputs: Agent's state, wheelchair's state obtainable. \n Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_wheelchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = -10 if (d_agent_wheelchair < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_wheelchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_weelchair = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 10 if (d_agent_wheelchair < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"

    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect staff and avoid collision. \n Inputs: Agent's state, staff's state obtainable. \n Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staffr) \n    penalty_collision = -10 if (d_agent_staff < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_staff): \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = 10 if (d_agent_staff < 0.6) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect defibrillator and avoid collision. \n Inputs: Agent's state, defibrillator's state obtainable. \n Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_defibrillator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrillator) \n    penalty_collision = -10 if (d_agent_defibrillator < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_defibrillator s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrllator) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return d_agent_defibrillator + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect device and avoid collision. \n Inputs: Agent's state, device's state obtainable. \n Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_device) \n    penalty_collision = -10 if (d_agent_device < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 10 if (d_agent_device < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect lamp and avoid collision. \n Inputs: Agent's state, lamp's state obtainable. \n Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -10 if (d_agent_lamp < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return d_agent_lamp + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect staff and patient and avoid collision. \n Inputs: Agent's state, multiple obstacle's state obtainable. \n Write a reward function in Python..",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return d_agent_obstacles_min + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect defibrillator and equipment and avoid collision. \n Inputs: Agent's state, multiple obstacle's state obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstaclest) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect wire and wheelchair and avoid collision. \n Inputs: Agent's state, multiple obstacle's state obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstaclest) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect wheelchair and patient and avoid collision. \n Inputs: Agent's state, multiple obstacle's state obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect staff and lamp and avoid collision. \n Inputs: Agent's state, multiple obstacle's state obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect multiple obstacles and avoid collision. \n Inputs: Agent's state, multiple obstacle's state obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstaclest) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect doctor, wheelchair and patient and avoid collision. \n Inputs: Agent's state, multiple obstacle's state obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect equipment, wheelchair and defibrillator and avoid collision. \n Inputs: Agent's state, multiple obstacle's state obtainable. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect lamp, bed and screen and avoid collision. \n Inputs: Agent's state, multiple obstacle's state obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect counter, nurse and counter and avoid collision. \n Inputs: Agent's state, multiple obstacle's state obtainable. \n Write a reward function in Python",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    },
    {
        "prompt": "Operation: Drone moves in a hospital. \n Duties: Detect multiple boxes and avoid collision. \n Inputs: Agent's state, multiple obstacle's state obtainable. \n Write a reward function in Python.",
        "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
        "rejected": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstaclest) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"

    },





    [
  
  {
    "prompt": "A drone is operating along Parking Garage. It must avoid colliding with concrete columns or wayfinding signs. The states of the agent, the ride guardrail, and the wayfinding signs are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -19 if (d_agent_goal < 0.2) else 17 \n    return reward_reaching_goal"
  },
  {
    "prompt": "A drone is operating inside a busy Parking Garage. Detect ramp guardrail and aviod it. The states of the agent, the ramp guardrail are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_ramp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ramp = calculate_distance_min(s_agent, s_ramp) \n    penalty_collision = -17 if (d_agent_ramp < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_ramp): \n    d_agent_ramp = calculate_distance_min(s_agent, s_ramp) \n    penalty_collision = 17 if (d_agent_ramp < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating Parking Garage common room. Objectives: It must avoid colliding with payment kiosks. Conditions: States of the drone and the payment kiosk are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_payment_kiosk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_payment_kiosk = calculate_distance_min(s_agent, s_payment_kiosk) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_payment_kiosk): \n    d_agent_payment_kiosk = calculate_distance_min(s_agent, s_payment_kiosk) \n    penalty_collision = 17 if (d_agent_payment_kiosk < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: Inside a drive aisle, the drone must maneuver around roll-up door. All entity states (agent, roll-up door) are known. Provide a Python reward function.",
    "chosen": "def reward(s_agent, s_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_door = calculate_distance_min(s_agent, s_door) \n    penalty_collision = -17 if (d_agent_door < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_door): \n    d_agent_door = calculate_distance_min(s_agent, s_door) \n    penalty_collision = 17 if (d_agent_door < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Task: A drone is flying through a drive aisle. Requirement: Detect the three wheel stops and do not collide with it. Given: The states for the drone and many wheel stops are known. Write a Python reward function.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -19 if (d_agent_goal < 0.2) else 17 \n    return d_agent_multiple_obstacles_min + reward_reaching_goal"
  },
  {
    "prompt": "A drone operates near a service corridor during an event. So not collide with car. The states of the agent, the car are known. Write the Python reward function.",
    "chosen": "def reward(s_agent, s_car, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_car = calculate_distance_min(s_agent, s_car) \n    penalty_collision = -17 if (d_agent_car < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_car, s_goal): \n    d_agent_car = calculate_distance_min(s_agent, s_car) \n    penalty_collision = 17 if (d_agent_car < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: Navigate Parking Garage. Objectives: Do not collide hit with truck. Conditions: States of the agent, truck are obtainable. Deliver: Python reward function.",
    "chosen": "def reward(s_agent, s_truck, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_truck = calculate_distance_min(s_agent, s_truck) \n    penalty_collision = -17 if (d_agent_truck < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_truck): \n    d_agent_truck = calculate_distance_min(s_agent, s_truck) \n    penalty_collision = 17 if (d_agent_truck < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Context: Within a drive aisle, the drone must steer clear of wall. All states (agent, wall) are known. Provide a Python reward function for training.",
    "chosen": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -17 if (d_agent_wall < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_wall): \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 17 if (d_agent_wall < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Task Briefing: Environment: parking level. Avoid: Hitting with Parking Garage's vehicle. Known: Agent, Parking Garage vehicle states. Create the Python reward function.",
    "chosen": "def reward(s_agent, s_vehicle, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vehicle = calculate_distance_min(s_agent, s_vehicle) \n    penalty_collision = -17 if (d_agent_vehicle < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_vehicle): \n    d_agent_vehicle = calculate_distance_min(s_agent, s_vehicle) \n     penalty_collision = 17 if (d_agent_vehicle < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating Parking Garage. Objectives: It must avoid colliding with pay stations human. Conditions: The states of the drone and human are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -19 if (d_agent_human < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_human): \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 19 if (d_agent_human < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying through Parking Garage. Objectives: Avoid collision with two traffic cone lines. Conditions: The states of the agent, traffic cone lines and attendants are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -17 if (d_agent_goal < 0.2) else 19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is navigating Parking Garage. Objectives: It must avoid colliding with any truck, overhead cable bundle and gate arm. Conditions: Agent's, truck and gate arm states are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -17 if (d_agent_goal < 0.2) else 19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is flying through Parking Garage. Objectives: Do not collide with any EV charging station. Conditions: The states of the drone and the EV charging station are obtainable. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_charging_station, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_charging_station = calculate_distance_min(s_agent, s_charging_station) \n    penalty = -19 if (d_agent_charging_station < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_charging_station): \n    d_agent_charging_station = calculate_distance_min(s_agent, s_charging_station) \n    penalty = -19 if (d_agent_charging_station < 0.5) else 17 \n    return penalty"
  },
  {
    "prompt": "A drone is operating along Parking Garage and must avoid contact with any gate. The states of the drone and the gate are known. Write a Python reward function for this case.",
    "chosen": "def reward(s_agent, s_gate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gate = calculate_distance_min(s_agent, s_gate) \n    penalty = -19 if (d_agent_gate < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_gate): \n    d_agent_gate = calculate_distance_min(s_agent, s_gate) \n    penalty = -19 if (d_agent_gate < 0.5) else 17 \n    return penalty"
  },
  {
    "prompt": "A drone is operating in Parking Garage. It must avoid colliding with the motorcycle, attendant and sign. The states of the agent, motorcycle, attendant and sign are known. Write a reward function in Python",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "A drone is operating in Parking Garage. It must avoid colliding with bollards and wayfinding signs. The states of the drone and the multiple obstacles are known. Write a reward function in Python",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "A drone is inspecting in Parking Garage. It must avoid colliding with Parking Garage ventilation ducts. Agent's state and Parking Garage ventilation ducts's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_ventilation, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ventilation = calculate_distance_min(s_agent, s_ventilation) \n    penalty_collision = -19 if (d_agent_ventilation < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_ventilation): \n    d_agent_ventilation = calculate_distance_min(s_agent, s_ventilation) \n    penalty_collision = -19 if (d_agent_ventilation < 0.5) else 17 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating Parking Garage. Goal: It must avoid colliding with overhead conduit. Assumptions: The states of the drone and the overhead conduit area are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_conduit, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_conduit = calculate_distance_min(s_agent, s_conduit) \n    penalty_collision = -19 if (d_agent_conduit < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_conduit): \n    d_agent_conduit = calculate_distance_min(s_agent, s_conduit) \n    penalty_collision = -19 if (d_agent_conduit < 0.5) else 17 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating Parking Garage. Goal: It must avoid colliding with Parking Garage ventilation ducts, wayfinding signs and wheel stops. Assumptions: The agent's state, Parking Garage ventilation ducts's state, wheel stop's state and wayfinding signs' states are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Scenario: A drone is navigating Parking Garage. Goal: Detect wayfinding signs and structural brackets and avoid drive aisle corners. Assumptions: The states of the drone and gates, pay stations and barricades state are availalbe. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    return penalty_collisionl"
  },
  {
    "prompt": "Scenario: A drone is navigating Parking Garage. Goal: Drone goal is to reach the target. Assumptions: The states of the drone and the target are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    reward_reaching_target = 17 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return reward_reaching_target",
    "rejected": "def reward(s_agent, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    return d_agent_target"
  },



  
  {
    "prompt": "Mission: A drone is operating along Rainforest. \n Objectives: It must avoid colliding with tree trunks or hanging vines. \n Conditions: The states of the agent, the ride guardrail, and the trail markers are known. \n Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -19 if (d_agent_goal < 0.2) else 17 \n    return reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is operating inside a busy Rainforest. \n Objectives: Detect fallen log barrier and avoid it. \n Conditions: The states of the agent, the fallen log barrier are known. \n Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_fallen_log, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fallen_log = calculate_distance_min(s_agent, s_fallen_log) \n    penalty_collision = -17 if (d_agent_fallen_log < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_fallen_log): \n    d_agent_fallen_log = calculate_distance_min(s_agent, s_fallen_log) \n    penalty_collision = 17 if (d_agent_fallen_log < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating Rainforest clearing. Objectives: It must avoid colliding with termite mounds. Conditions: States of the drone and the payment kiosk are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_termite_mound, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_termite_mound = calculate_distance_min(s_agent, s_termite_mound) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_termite_mound): \n    d_agent_termite_mound = calculate_distance_min(s_agent, s_termite_mound) \n    penalty_collision = 17 if (d_agent_termite_mound < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: Inside a forest trail, the drone must maneuver around thick vine curtain. All entity states (agent, thick vine curtain) are known. Provide a Python reward function.",
    "chosen": "def reward(s_agent, s_vine_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vine_curtain = calculate_distance_min(s_agent, s_vine_curtain) \n    penalty_collision = -17 if (d_agent_vine_curtain < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_vine_curtain): \n    d_agent_vine_curtain = calculate_distance_min(s_agent, s_vine_curtain) \n    penalty_collision = 17 if (d_agent_vine_curtain < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Task: A drone is flying through a forest trail. Requirement: Detect the three boulders and do not collide with it. Given: The states for the drone and many boulders are known. Write a Python reward function.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -19 if (d_agent_goal < 0.2) else 17 \n    return d_agent_multiple_obstacles_min + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone operates near a riverbank during the monsoon. \n Objectives: Do not collide with wild boar. \n Conditions: The states of the agent, the wild boar are known. Write the Python reward function.",
    "chosen": "def reward(s_agent, s_boar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_boar = calculate_distance_min(s_agent, s_boar) \n    penalty_collision = -17 if (d_agent_boar < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_boar, s_goal): \n    d_agent_boar = calculate_distance_min(s_agent, s_boar) \n    penalty_collision = 17 if (d_agent_boar < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: Navibamboo gate Rainforest. \n Objectives: Do not collide with with elephant. \n Conditions: States of the agent, elephant are obtainable. \n Deliver: Python reward function.",
    "chosen": "def reward(s_agent, s_elephant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_elephant = calculate_distance_min(s_agent, s_elephant) \n    penalty_collision = -17 if (d_agent_elephant < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_elephant): \n    d_agent_elephant = calculate_distance_min(s_agent, s_elephant) \n    penalty_collision = 17 if (d_agent_elephant < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Context: Within a forest trail, the drone must steer clear of cliff face. All states (agent, cliff face) are known. Provide a Python reward function for training.",
    "chosen": "def reward(s_agent, s_cliff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cliff = calculate_distance_min(s_agent, s_cliff) \n    penalty_collision = -17 if (d_agent_cliff < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_cliff): \n    d_agent_cliff = calculate_distance_min(s_agent, s_cliff) \n    penalty_collision = 17 if (d_agent_cliff < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Task Briefing: Environment: forest floor. Avoid: Hitting Rainforest's vehicle. Known: Agent, Rainforest vehicle states. Create the Python reward function.",
    "chosen": "def reward(s_agent, s_wild_animal, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wild_animal = calculate_distance_min(s_agent, s_wild_animal) \n    penalty_collision = -17 if (d_agent_wild_animal < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_wild_animal): \n    d_agent_wild_animal = calculate_distance_min(s_agent, s_wild_animal) \n     penalty_collision = 17 if (d_agent_wild_animal < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating Rainforest. Objectives: It must avoid colliding with forest ranger. Conditions: The states of the drone and human are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_ranger, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ranger = calculate_distance_min(s_agent, s_ranger) \n    penalty_collision = -19 if (d_agent_ranger < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_ranger): \n    d_agent_ranger = calculate_distance_min(s_agent, s_ranger) \n    penalty_collision = 19 if (d_agent_ranger < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying through Rainforest. Objectives: Avoid collision with two thorny bush lines. Conditions: The states of the agent, thorny bush lines and attendants are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -17 if (d_agent_goal < 0.2) else 19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is navigating Rainforest. Objectives: It must avoid colliding with any elephant, overhanging liana bundle and fallen branch. Conditions: Agent's, elephant and fallen branch states are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -17 if (d_agent_goal < 0.2) else 19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is flying through Rainforest. \n Objectives: Do not collide with any large tree stump. \n Conditions: The states of the drone and the large tree stump are obtainable. \n Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_tree_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_stump = calculate_distance_min(s_agent, s_tree_stump) \n    penalty = -19 if (d_agent_tree_stump < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_tree_stump): \n    d_agent_tree_stump = calculate_distance_min(s_agent, s_tree_stump) \n    penalty = -19 if (d_agent_tree_stump < 0.5) else 17 \n    return penalty"
  },
  {
    "prompt": "Mission: A drone is operating along Rainforest and must avoid contact with any bamboo gate. \n Conditions: The states of the drone and the bamboo gate are known. Write a Python reward function for this case.",
    "chosen": "def reward(s_agent, s_bamboo_gate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bamboo_gate = calculate_distance_min(s_agent, s_bamboo_gate) \n    penalty = -19 if (d_agent_bamboo_gate < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_bamboo_gate): \n    d_agent_bamboo_gate = calculate_distance_min(s_agent, s_bamboo_gate) \n    penalty = -19 if (d_agent_bamboo_gate < 0.5) else 17 \n    return penalty"
  },
  {
    "prompt": "A drone is operating in Rainforest. \n Objectives: It must avoid colliding with the vine tangles, ranger and signpost. \n Conditions: The states of the agent, vine tangles, ranger and signpost are known. Write a reward function in Python",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "A drone is operating in Rainforest. It must avoid colliding with bollards and trail markers. The states of the drone and the multiple obstacles are known. Write a reward function in Python",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "A drone is inspecting in Rainforest. It must avoid colliding with Rainforest buttress roots. Agent's state and Rainforest buttress roots's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_buttress_roots, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_buttress_roots = calculate_distance_min(s_agent, s_buttress_roots) \n    penalty_collision = -19 if (d_agent_buttress_roots < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_buttress_roots): \n    d_agent_buttress_roots = calculate_distance_min(s_agent, s_buttress_roots) \n    penalty_collision = -19 if (d_agent_buttress_roots < 0.5) else 17 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating Rainforest. Goal: It must avoid colliding with overhanging lianas. Assumptions: The states of the drone and the overhanging lianas area are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_lianas, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lianas = calculate_distance_min(s_agent, s_lianas) \n    penalty_collision = -19 if (d_agent_lianas < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_lianas): \n    d_agent_lianas = calculate_distance_min(s_agent, s_lianas) \n    penalty_collision = -19 if (d_agent_lianas < 0.5) else 17 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating Rainforest. Goal: It must avoid colliding with Rainforest buttress roots, trail markers and boulders. Assumptions: The agent's state, Rainforest buttress roots's state, wheel stop's state and trail markers' states are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Scenario: A drone is navigating Rainforest. Goal: Detect trail markers and tree buttresses and avoid forest trail corners. Assumptions: The states of the drone and bamboo gates, pay stations and thorny barriers state are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    return penalty_collisionl"
  },
  {
    "prompt": "Scenario: A drone is navigating Rainforest. Goal: Drone goal is to reach the target. Assumptions: The states of the drone and the target are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    reward_reaching_target = 17 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return reward_reaching_target",
    "rejected": "def reward(s_agent, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    return d_agent_target"
  },





  
  {
    "prompt": "Mission: A drone is operating along Rainforest. \n Objectives: It must avoid colliding with tree trunks or hanging vines. \n Conditions: The states of the agent, the ride guardrail, and the trail markers are known. \n Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -19 if (d_agent_goal < 0.2) else 17 \n    return reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is operating inside a busy Rainforest. \n Objectives: Detect fallen log barrier and avoid it. \n Conditions: The states of the agent, the fallen log barrier are known. \n Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_fallen_log, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_fallen_log = calculate_distance_min(s_agent, s_fallen_log) \n    penalty_collision = -17 if (d_agent_fallen_log < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_fallen_log): \n    d_agent_fallen_log = calculate_distance_min(s_agent, s_fallen_log) \n    penalty_collision = 17 if (d_agent_fallen_log < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating Rainforest clearing. Objectives: It must avoid colliding with termite mounds. Conditions: States of the drone and the payment kiosk are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_termite_mound, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_termite_mound = calculate_distance_min(s_agent, s_termite_mound) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_termite_mound): \n    d_agent_termite_mound = calculate_distance_min(s_agent, s_termite_mound) \n    penalty_collision = 17 if (d_agent_termite_mound < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: Inside a forest trail, the drone must maneuver around thick vine curtain. All entity states (agent, thick vine curtain) are known. Provide a Python reward function.",
    "chosen": "def reward(s_agent, s_vine_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_vine_curtain = calculate_distance_min(s_agent, s_vine_curtain) \n    penalty_collision = -17 if (d_agent_vine_curtain < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_vine_curtain): \n    d_agent_vine_curtain = calculate_distance_min(s_agent, s_vine_curtain) \n    penalty_collision = 17 if (d_agent_vine_curtain < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Task: A drone is flying through a forest trail. Requirement: Detect the three boulders and do not collide with it. Given: The states for the drone and many boulders are known. Write a Python reward function.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -19 if (d_agent_goal < 0.2) else 17 \n    return d_agent_multiple_obstacles_min + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone operates near a riverbank during the monsoon. \n Objectives: Do not collide with wild boar. \n Conditions: The states of the agent, the wild boar are known. Write the Python reward function.",
    "chosen": "def reward(s_agent, s_boar, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_boar = calculate_distance_min(s_agent, s_boar) \n    penalty_collision = -17 if (d_agent_boar < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_boar, s_goal): \n    d_agent_boar = calculate_distance_min(s_agent, s_boar) \n    penalty_collision = 17 if (d_agent_boar < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: Navibamboo gate Rainforest. \n Objectives: Do not collide with with elephant. \n Conditions: States of the agent, elephant are obtainable. \n Deliver: Python reward function.",
    "chosen": "def reward(s_agent, s_elephant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_elephant = calculate_distance_min(s_agent, s_elephant) \n    penalty_collision = -17 if (d_agent_elephant < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_elephant): \n    d_agent_elephant = calculate_distance_min(s_agent, s_elephant) \n    penalty_collision = 17 if (d_agent_elephant < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Context: Within a forest trail, the drone must steer clear of cliff face. All states (agent, cliff face) are known. Provide a Python reward function for training.",
    "chosen": "def reward(s_agent, s_cliff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cliff = calculate_distance_min(s_agent, s_cliff) \n    penalty_collision = -17 if (d_agent_cliff < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_cliff): \n    d_agent_cliff = calculate_distance_min(s_agent, s_cliff) \n    penalty_collision = 17 if (d_agent_cliff < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Task Briefing: Environment: forest floor. Avoid: Hitting Rainforest's vehicle. Known: Agent, Rainforest vehicle states. Create the Python reward function.",
    "chosen": "def reward(s_agent, s_wild_animal, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wild_animal = calculate_distance_min(s_agent, s_wild_animal) \n    penalty_collision = -17 if (d_agent_wild_animal < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_wild_animal): \n    d_agent_wild_animal = calculate_distance_min(s_agent, s_wild_animal) \n     penalty_collision = 17 if (d_agent_wild_animal < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating Rainforest. Objectives: It must avoid colliding with forest ranger. Conditions: The states of the drone and human are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_ranger, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ranger = calculate_distance_min(s_agent, s_ranger) \n    penalty_collision = -19 if (d_agent_ranger < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_ranger): \n    d_agent_ranger = calculate_distance_min(s_agent, s_ranger) \n    penalty_collision = 19 if (d_agent_ranger < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying through Rainforest. Objectives: Avoid collision with two thorny bush lines. Conditions: The states of the agent, thorny bush lines and attendants are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -17 if (d_agent_goal < 0.2) else 19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is navigating Rainforest. Objectives: It must avoid colliding with any elephant, overhanging liana bundle and fallen branch. Conditions: Agent's, elephant and fallen branch states are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -17 if (d_agent_goal < 0.2) else 19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is flying through Rainforest. \n Objectives: Do not collide with any large tree stump. \n Conditions: The states of the drone and the large tree stump are obtainable. \n Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_tree_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_stump = calculate_distance_min(s_agent, s_tree_stump) \n    penalty = -19 if (d_agent_tree_stump < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_tree_stump): \n    d_agent_tree_stump = calculate_distance_min(s_agent, s_tree_stump) \n    penalty = -19 if (d_agent_tree_stump < 0.5) else 17 \n    return penalty"
  },
  {
    "prompt": "Mission: A drone is operating along Rainforest and must avoid contact with any bamboo gate. \n Conditions: The states of the drone and the bamboo gate are known. Write a Python reward function for this case.",
    "chosen": "def reward(s_agent, s_bamboo_gate, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bamboo_gate = calculate_distance_min(s_agent, s_bamboo_gate) \n    penalty = -19 if (d_agent_bamboo_gate < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_bamboo_gate): \n    d_agent_bamboo_gate = calculate_distance_min(s_agent, s_bamboo_gate) \n    penalty = -19 if (d_agent_bamboo_gate < 0.5) else 17 \n    return penalty"
  },
  {
    "prompt": "A drone is operating in Rainforest. \n Objectives: It must avoid colliding with the vine tangles, ranger and signpost. \n Conditions: The states of the agent, vine tangles, ranger and signpost are known. Write a reward function in Python",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "A drone is operating in Rainforest. It must avoid colliding with bollards and trail markers. The states of the drone and the multiple obstacles are known. Write a reward function in Python",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "A drone is inspecting in Rainforest. It must avoid colliding with Rainforest buttress roots. Agent's state and Rainforest buttress roots's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_buttress_roots, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_buttress_roots = calculate_distance_min(s_agent, s_buttress_roots) \n    penalty_collision = -19 if (d_agent_buttress_roots < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_buttress_roots): \n    d_agent_buttress_roots = calculate_distance_min(s_agent, s_buttress_roots) \n    penalty_collision = -19 if (d_agent_buttress_roots < 0.5) else 17 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating Rainforest. Goal: It must avoid colliding with overhanging lianas. Assumptions: The states of the drone and the overhanging lianas area are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_lianas, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lianas = calculate_distance_min(s_agent, s_lianas) \n    penalty_collision = -19 if (d_agent_lianas < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_lianas): \n    d_agent_lianas = calculate_distance_min(s_agent, s_lianas) \n    penalty_collision = -19 if (d_agent_lianas < 0.5) else 17 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating Rainforest. Goal: It must avoid colliding with Rainforest buttress roots, trail markers and boulders. Assumptions: The agent's state, Rainforest buttress roots's state, wheel stop's state and trail markers' states are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Scenario: A drone is navigating Rainforest. Goal: Detect trail markers and tree buttresses and avoid forest trail corners. Assumptions: The states of the drone and bamboo gates, pay stations and thorny barriers state are available. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    return penalty_collisionl"
  },
  {
    "prompt": "Scenario: A drone is navigating Rainforest. Goal: Drone goal is to reach the target. Assumptions: The states of the drone and the target are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    reward_reaching_target = 17 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return reward_reaching_target",
    "rejected": "def reward(s_agent, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    return d_agent_target"
  },




  
  {
    "prompt": "Mission: \n A drone is operating along Science Lab. Objectives: \n It must avoid colliding with concrete columns or wayfinding signs. Conditions: \n The states of the agent, the ride guardrail, and the wayfinding signs are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -19 if (d_agent_goal < 0.2) else 17 \n    return reward_reaching_goal"
  },
  {
    "prompt": "Mission: \n A drone is operating inside a busy Science Lab. Objectives: \n Detect centrifuge machine and aviod it. Conditions: \n The states of the agent, the centrifuge machine are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_centrifuge_machine, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_centrifuge_machine = calculate_distance_min(s_agent, s_centrifuge_machine) \n    penalty_collision = -17 if (d_agent_centrifuge_machine < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_centrifuge_machine): \n    d_agent_centrifuge_machine = calculate_distance_min(s_agent, s_centrifuge_machine) \n    penalty_collision = 17 if (d_agent_centrifuge_machine < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating Science Lab open workspace. Objectives: It must avoid colliding with lab equipment. Conditions: States of the drone and the lab equipment are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_lab_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lab_equipment = calculate_distance_min(s_agent, s_lab_equipment) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_lab_equipment): \n    d_agent_lab_equipment = calculate_distance_min(s_agent, s_lab_equipment) \n    penalty_collision = 17 if (d_agent_lab_equipment < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: Inside a lab corridor, the drone must maneuver around lab curtain. All entity states (agent, lab curtain) are known. Provide a Python reward function.",
    "chosen": "def reward(s_agent, s_lab_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lab_curtain = calculate_distance_min(s_agent, s_lab_curtain) \n    penalty_collision = -17 if (d_agent_lab_curtain < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_lab_curtain): \n    d_agent_lab_curtain = calculate_distance_min(s_agent, s_lab_curtain) \n    penalty_collision = 17 if (d_agent_lab_curtain < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Task: A drone is flying through a lab corridor. Requirement: Detect the three lab technicians and do not collide with it. Given: The states for the drone and many lab technicians are known. Write a Python reward function.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -19 if (d_agent_goal < 0.2) else 17 \n    return d_agent_multiple_obstacles_min + reward_reaching_goal"
  },
  {
    "prompt": "Mission: \n A drone operates near a chemical storage area during experiments. Objectives: \n So not collide with robot. Conditions: \n The states of the agent, the robot are known. Write the Python reward function.",
    "chosen": "def reward(s_agent, s_lab_robot, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lab_robot = calculate_distance_min(s_agent, s_lab_robot) \n    penalty_collision = -17 if (d_agent_lab_robot < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_lab_robot, s_goal): \n    d_agent_lab_robot = calculate_distance_min(s_agent, s_lab_robot) \n    penalty_collision = 17 if (d_agent_lab_robot < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: Navigate Science Lab. Objectives: Do not collide hit with large apparatus. Conditions: States of the agent, apparatus are obtainable. Deliver: Python reward function.",
    "chosen": "def reward(s_agent, s_apparatus, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_apparatus = calculate_distance_min(s_agent, s_apparatus) \n    penalty_collision = -17 if (d_agent_apparatus < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_apparatus): \n    d_agent_apparatus = calculate_distance_min(s_agent, s_apparatus) \n    penalty_collision = 17 if (d_agent_apparatus < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Context: Within a lab corridor, the drone must steer clear of wall. All states (agent, wall) are known. Provide a Python reward function for training.",
    "chosen": "def reward(s_agent, s_lab_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lab_wall = calculate_distance_min(s_agent, s_lab_wall) \n    penalty_collision = -17 if (d_agent_lab_wall < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_lab_wall): \n    d_agent_lab_wall = calculate_distance_min(s_agent, s_lab_wall) \n    penalty_collision = 17 if (d_agent_lab_wall < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Task Briefing: Environment: lab floor. Avoid: Hitting with robotic arm. Known: Agent, robotic arm states. Create the Python reward function.",
    "chosen": "def reward(s_agent, s_robotic_arm, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_robotic_arm = calculate_distance_min(s_agent, s_robotic_arm) \n    penalty_collision = -17 if (d_agent_robotic_arm < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_robotic_arm): \n    d_agent_robotic_arm = calculate_distance_min(s_agent, s_robotic_arm) \n     penalty_collision = 17 if (d_agent_robotic_arm < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating Science Lab. Objectives: It must avoid colliding with technician. Conditions: The states of the drone and technician are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_technician, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_technician = calculate_distance_min(s_agent, s_technician) \n    penalty_collision = -19 if (d_agent_technician < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_technician): \n    d_agent_technician = calculate_distance_min(s_agent, s_technician) \n    penalty_collision = 19 if (d_agent_technician < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying through Science Lab. Objectives: Avoid collision with two traffic cone lines. Conditions: The states of the agent, wires, technician and warning signs are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -17 if (d_agent_goal < 0.2) else 19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is navigating Science Lab. Objectives: It must avoid colliding with any truck, overhead cable bundle and gate arm. Conditions: Agent's, wall and dropped tool states are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -17 if (d_agent_goal < 0.2) else 19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is flying through Science Lab. Objectives: Do not collide with any centrifuge. Conditions: The states of the drone and the centrifuge are obtainable. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_centrifuge, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_centrifuge = calculate_distance_min(s_agent, s_centrifuge) \n    penalty = -19 if (d_agent_centrifuge < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_centrifuge): \n    d_agent_centrifuge = calculate_distance_min(s_agent, s_centrifuge) \n    penalty = -19 if (d_agent_centrifuge < 0.5) else 17 \n    return penalty"
  },
  {
    "prompt": "A drone is operating along Science Lab and must avoid contact with any secure_door. The states of the drone and the secure_door are known. Write a Python reward function for this case.",
    "chosen": "def reward(s_agent, s_secure_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_secure_door = calculate_distance_min(s_agent, s_secure_door) \n    penalty = -19 if (d_agent_secure_door < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_secure_door): \n    d_agent_secure_door = calculate_distance_min(s_agent, s_secure_door) \n    penalty = -19 if (d_agent_secure_door < 0.5) else 17 \n    return penalty"
  },
  {
    "prompt": "A drone is operating in Science Lab. It must avoid colliding with the motorcycle, attendant and sign. The states of the agent, cables, storage racks and safety barricades are known. Write a reward function in Python",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "A drone is operating in Science Lab. It must avoid colliding with bollards and wayfinding signs. The states of the drone and the multiple obstacles are known. Write a reward function in Python",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "A drone is inspecting in Science Lab. It must avoid colliding with Science Lab pipes. Agent's state and Science Lab pipes's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -19 if (d_agent_pipe < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_pipe): \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -19 if (d_agent_pipe < 0.5) else 17 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating Science Lab. Goal: It must avoid colliding with cable. Assumptions: The states of the drone and the cable's state are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -19 if (d_agent_cable < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_cable): \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -19 if (d_agent_cable < 0.5) else 17 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating Science Lab. Goal: It must avoid colliding with Science Lab's chair, cabinet and student. Assumptions: The agent's state, chair, cabinet and student' states are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Scenario: A drone is navigating Science Lab. Goal: Detect waste containers and gas cylindes and avoid lab door and do not collide. Assumptions: The states of the drone, waste containers, gas cylindes and avoid lab door state are availalbe. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    return penalty_collisionl"
  },
  {
    "prompt": "Scenario: A drone is navigating Science Lab. Goal: Drone goal is to reach the target. Assumptions: The states of the drone and the target are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    reward_reaching_target = 17 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return reward_reaching_target",
    "rejected": "def reward(s_agent, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    return d_agent_target"
  },





  {
    "prompt": "Mission: \n A drone is operating along Church. Objectives: \n It must avoid colliding with concrete columns or hymn boards. Conditions: \n The states of the agent, the altar rail, and the hymn boards are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -19 if (d_agent_goal < 0.2) else 17 \n    return reward_reaching_goal"
  },
  {
    "prompt": "Mission: \n A drone is operating inside a busy Church. Objectives: \n Detect candelabra and aviod it. Conditions: \n The states of the agent, the candelabra are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_candelabra, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_centrifuge_machine = calculate_distance_min(s_agent, s_candelabra) \n    penalty_collision = -17 if (d_agent_centrifuge_machine < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_candelabra): \n    d_agent_centrifuge_machine = calculate_distance_min(s_agent, s_candelabra) \n    penalty_collision = 17 if (d_agent_centrifuge_machine < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating Church open workspace. Objectives: It must avoid colliding with church equipment. Conditions: States of the drone and the church equipment are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_church_fixtures, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lab_equipment = calculate_distance_min(s_agent, s_church_fixtures) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_church_fixtures): \n    d_agent_lab_equipment = calculate_distance_min(s_agent, s_church_fixtures) \n    penalty_collision = 17 if (d_agent_lab_equipment < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: Inside a church corridor, the drone must maneuver around church curtain. All entity states (agent, church curtain) are known. Provide a Python reward function.",
    "chosen": "def reward(s_agent, s_choir_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lab_curtain = calculate_distance_min(s_agent, s_choir_curtain) \n    penalty_collision = -17 if (d_agent_lab_curtain < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_choir_curtain): \n    d_agent_lab_curtain = calculate_distance_min(s_agent, s_choir_curtain) \n    penalty_collision = 17 if (d_agent_lab_curtain < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Task: A drone is flying through a church corridor. Requirement: Detect the three church parishioners and do not collide with it. Given: The states for the drone and many church parishioners are known. Write a Python reward function.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -19 if (d_agent_goal < 0.2) else 17 \n    return d_agent_multiple_obstacles_min + reward_reaching_goal"
  },
  {
    "prompt": "Mission: \n A drone operates near a sacristy area during experiments. Objectives: \n So not collide with processional stand. Conditions: \n The states of the agent, the processional stand are known. Write the Python reward function.",
    "chosen": "def reward(s_agent, s_processional_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_processional_stand = calculate_distance_min(s_agent, s_processional_stand) \n    penalty_collision = -17 if (d_agent_processional_stand < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_processional_stand, s_goal): \n    d_agent_processional_stand = calculate_distance_min(s_agent, s_processional_stand) \n    penalty_collision = 17 if (d_agent_processional_stand < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: Navigate Church. Objectives: Do not collide hit with baptismal font. Conditions: States of the agent, baptismal font are obtainable. Deliver: Python reward function.",
    "chosen": "def reward(s_agent, s_baptismal_font, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_baptismal_font = calculate_distance_min(s_agent, s_baptismal_font) \n    penalty_collision = -17 if (d_agent_baptismal_font < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_baptismal_font): \n    d_agent_baptismal_font = calculate_distance_min(s_agent, s_baptismal_font) \n    penalty_collision = 17 if (d_agent_baptismal_font < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Context: Within a church corridor, the drone must steer clear of wall. All states (agent, wall) are known. Provide a Python reward function for training.",
    "chosen": "def reward(s_agent, s_church_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_church_wall = calculate_distance_min(s_agent, s_church_wall) \n    penalty_collision = -17 if (d_agent_church_wall < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_church_wall): \n    d_agent_church_wall = calculate_distance_min(s_agent, s_church_wall) \n    penalty_collision = 17 if (d_agent_church_wall < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Task Briefing: Environment: church floor. Avoid: Hitting with processional stand. Known: Agent, processional stand states. Create the Python reward function.",
    "chosen": "def reward(s_agent, s_processional_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_robotic_arm = calculate_distance_min(s_agent, s_processional_stand) \n    penalty_collision = -17 if (d_agent_robotic_arm < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_processional_stand): \n    d_agent_robotic_arm = calculate_distance_min(s_agent, s_processional_stand) \n     penalty_collision = 17 if (d_agent_robotic_arm < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating Church. Objectives: It must avoid colliding with parishioner. Conditions: The states of the drone and parishioner are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_parishioner, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_technician = calculate_distance_min(s_agent, s_parishioner) \n    penalty_collision = -19 if (d_agent_technician < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_parishioner): \n    d_agent_technician = calculate_distance_min(s_agent, s_parishioner) \n    penalty_collision = 19 if (d_agent_technician < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying through Church. Objectives: Avoid collision with two traffic cone lines. Conditions: The states of the agent, wires, parishioner and warning signs are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -17 if (d_agent_goal < 0.2) else 19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is navigating Church. Objectives: It must avoid colliding with any truck, overhead hanging lamp chains and entrance barrier. Conditions: Agent's, wall and pastor are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -17 if (d_agent_goal < 0.2) else 19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is flying through Church. Objectives: Do not collide with any bible. Conditions: The states of the drone and the bible are obtainable. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_bible, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bible = calculate_distance_min(s_agent, s_bible) \n    penalty = -19 if (d_agent_bible < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_bible): \n    d_agent_bible = calculate_distance_min(s_agent, s_bible) \n    penalty = -19 if (d_agent_bible < 0.5) else 17 \n    return penalty"
  },
  {
    "prompt": "A drone is operating along Church and must avoid contact with any sacristy  door. The states of the drone and the sacristy door are known. Write a Python reward function for this case.",
    "chosen": "def reward(s_agent, s_sacristy_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sacristy_door = calculate_distance_min(s_agent, s_sacristy_door) \n    penalty = -19 if (d_agent_sacristy_door < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_sacristy_door): \n    d_agent_sacristy_door = calculate_distance_min(s_agent, s_sacristy_door) \n    penalty = -19 if (d_agent_sacristy_door < 0.5) else 17 \n    return penalty"
  },
  {
    "prompt": "A drone is operating in Church. It must avoid colliding with the confessional booth, usher and hymn board. The states of the agent, hanging lamp chains, storage racks and safety barricades are known. Write a reward function in Python",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "A drone is operating in Church. It must avoid colliding with altar rails and hymn boards. The states of the drone and the multiple obstacles are known. Write a reward function in Python",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "A drone is inspecting in Church. It must avoid colliding with Church organ pipess. Agent's state and Church organ pipess's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_organ_pipes, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_organ_pipes) \n    penalty_collision = -19 if (d_agent_pipe < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_organ_pipes): \n    d_agent_pipe = calculate_distance_min(s_agent, s_organ_pipes) \n    penalty_collision = -19 if (d_agent_pipe < 0.5) else 17 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating Church. Goal: It must avoid colliding with hanging lamp chain. Assumptions: The states of the drone and the hanging lamp chain's state are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_lamp_chain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp_chain = calculate_distance_min(s_agent, s_lamp_chain) \n    penalty_collision = -19 if (d_agent_lamp_chain < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_lamp_chain): \n    d_agent_lamp_chain = calculate_distance_min(s_agent, s_lamp_chain) \n    penalty_collision = -19 if (d_agent_lamp_chain < 0.5) else 17 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating Church. Goal: It must avoid colliding with Church's pew, pulpit and parishioner. Assumptions: The agent's state, pew, pulpit and parishioner' states are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Scenario: A drone is navigating Church. Goal: Detect altars and benchs and avoid church door and do not collide. Assumptions: The states of the drone, altar, benches and avoid church door state are availalbe. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    return penalty_collisionl"
  },
  {
    "prompt": "Scenario: A drone is navigating Church. Goal: Drone goal is to reach the target. Assumptions: The states of the drone and the target are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    reward_reaching_target = 17 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return reward_reaching_target",
    "rejected": "def reward(s_agent, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    return d_agent_target"
  },




  
  {
    "prompt": "Mission: \n A drone is operating along Art Museum. Objectives: \n It must avoid colliding with concrete columns or exhibit placards. Conditions: \n The states of the agent, the stanchion, and the exhibit placards are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -19 if (d_agent_goal < 0.2) else 17 \n    return reward_reaching_goal"
  },
  {
    "prompt": "Mission: \n A drone is operating inside a busy Art Museum. Objectives: \n Detect sculpture pedestal and aviod it. Conditions: \n The states of the agent, the sculpture pedestal are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_sculpture_pedestal, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sculpture_pedestal = calculate_distance_min(s_agent, s_sculpture_pedestal) \n    penalty_collision = -17 if (d_agent_sculpture_pedestal < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_sculpture_pedestal): \n    d_agent_sculpture_pedestal = calculate_distance_min(s_agent, s_sculpture_pedestal) \n    penalty_collision = 17 if (d_agent_sculpture_pedestal < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating Art Museum open workspace. Objectives: It must avoid colliding with gallery fixtures. Conditions: States of the drone and the gallery fixturest are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_gallery_fixtures, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gallery_fixtures = calculate_distance_min(s_agent, s_gallery_fixtures) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_gallery_fixtures): \n    d_agent_gallery_fixtures = calculate_distance_min(s_agent, s_gallery_fixtures) \n    penalty_collision = 17 if (d_agent_gallery_fixtures < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: Inside a art museum corridor, the drone must maneuver around art museum curtain. All entity states (agent, art museum curtain) are known. Provide a Python reward function.",
    "chosen": "def reward(s_agent, s_gallery_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gallery_curtain = calculate_distance_min(s_agent, s_gallery_curtain) \n    penalty_collision = -17 if (d_agent_gallery_curtain < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_gallery_curtain): \n    d_agent_gallery_curtain = calculate_distance_min(s_agent, s_gallery_curtain) \n    penalty_collision = 17 if (d_agent_gallery_curtain < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Task: A drone is flying through a art museum corridor. Requirement: Detect the three art museum visitors and do not collide with it. Given: The states for the drone and many art museum visitors are known. Write a Python reward function.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles_min < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles_min = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -19 if (d_agent_goal < 0.2) else 17 \n    return d_agent_multiple_obstacles_min + reward_reaching_goal"
  },
  {
    "prompt": "Mission: \n A drone operates near a staff service area during experiments. Objectives: \n So not collide with display_stand. Conditions: \n The states of the agent, the display_stand are known. Write the Python reward function.",
    "chosen": "def reward(s_agent, s_display_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display_stand = calculate_distance_min(s_agent, s_display_stand) \n    penalty_collision = -17 if (d_agent_display_stand < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_display_stand, s_goal): \n    d_agent_display_stand = calculate_distance_min(s_agent, s_display_stand) \n    penalty_collision = 17 if (d_agent_display_stand < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: Navigate Art Museum. Objectives: Do not collide hit with sculpture plinth. Conditions: States of the agent, sculpture plinth are obtainable. Deliver: Python reward function.",
    "chosen": "def reward(s_agent, s_sculpture_plinth, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sculpture_plinth = calculate_distance_min(s_agent, s_sculpture_plinth) \n    penalty_collision = -17 if (d_agent_sculpture_plinth < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_sculpture_plinth): \n    d_agent_sculpture_plinth = calculate_distance_min(s_agent, s_sculpture_plinth) \n    penalty_collision = 17 if (d_agent_sculpture_plinth < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Context: Within a art museum corridor, the drone must steer clear of wall. All states (agent, wall) are known. Provide a Python reward function for training.",
    "chosen": "def reward(s_agent, s_gallery_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_gallery_wall = calculate_distance_min(s_agent, s_gallery_wall) \n    penalty_collision = -17 if (d_agent_gallery_wall < 0.5) else 17 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_gallery_wall): \n    d_agent_gallery_wall = calculate_distance_min(s_agent, s_gallery_wall) \n    penalty_collision = 17 if (d_agent_gallery_wall < 0.5) else -17 \n    return penalty_collision"
  },
  {
    "prompt": "Task Briefing: Environment: art museum floor. Avoid: Hitting with display stand. Known: Agent, display stand states. Create the Python reward function.",
    "chosen": "def reward(s_agent, s_display_stand, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_display_stand = calculate_distance_min(s_agent, s_display_stand) \n    penalty_collision = -17 if (d_agent_display_stand < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_display_stand): \n    d_agent_display_stand = calculate_distance_min(s_agent, s_display_stand) \n     penalty_collision = 17 if (d_agent_display_stand < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is navigating Art Museum. Objectives: It must avoid colliding with visitor. Conditions: The states of the drone and visitor are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_visitor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_visitor = calculate_distance_min(s_agent, s_visitor) \n    penalty_collision = -19 if (d_agent_visitor < 0.5) else 4 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_visitor): \n    d_agent_visitor = calculate_distance_min(s_agent, s_visitor) \n    penalty_collision = 19 if (d_agent_visitor < 0.5) else -4 \n    return penalty_collision"
  },
  {
    "prompt": "Mission: A drone is flying through Art Museum. Objectives: Avoid collision with two cone lines. Conditions: The states of the agent and two cone lines are known. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -17 if (d_agent_goal < 0.2) else 19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is navigating Art Museum. Objectives: It must avoid colliding with any picture, overhead wires and ticket barrier. Conditions: Agent's, picture's, wire's and ticket barrier's states are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = -17 if (d_agent_goal < 0.2) else 19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Mission: A drone is flying through Art Museum. Objectives: Do not collide with any sculpture pedestal. Conditions: The states of the drone and the sculpture pedestal are obtainable. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_sculpture_pedestal, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sculpture_pedestal = calculate_distance_min(s_agent, s_sculpture_pedestal) \n    penalty = -19 if (d_agent_sculpture_pedestal < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_sculpture_pedestal): \n    d_agent_sculpture_pedestal = calculate_distance_min(s_agent, s_sculpture_pedestal) \n    penalty = -19 if (d_agent_sculpture_pedestal < 0.5) else 17 \n    return penalty"
  },
  {
    "prompt": "A drone is operating along Art Museum and must avoid contact with any staff only door. The states of the drone and the staff only door are known. Write a Python reward function for this case.",
    "chosen": "def reward(s_agent, s_staff_door, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_door = calculate_distance_min(s_agent, s_staff_door) \n    penalty = -19 if (d_agent_door < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_staff_door): \n    d_agent_door = calculate_distance_min(s_agent, s_staff_door) \n    penalty = -19 if (d_agent_door < 0.5) else 17 \n    return penalty"
  },
  {
    "prompt": "A drone is operating in Art Museum. It must avoid colliding with the freestanding partition, docent and exhibit placard. The states of the agent, suspension wires, storage racks and safety barricades are known. Write a reward function in Python",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "A drone is operating in Art Museum. It must avoid colliding with stanchions and exhibit placards. The states of the drone and the multiple obstacles are known. Write a reward function in Python",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "A drone is inspecting in Art Museum. It must avoid colliding with Art Museum organ hanging installations. Agent's state and Art Museum organ hanging installations's state are accessible. Write a reward function in Python.",
    "chosen": "def reward(s_agent, s_installation, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_installation = calculate_distance_min(s_agent, s_installation) \n    penalty_collision = -19 if (d_agent_installation < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_installation): \n    d_agent_installation = calculate_distance_min(s_agent, s_installation) \n    penalty_collision = -19 if (d_agent_installation < 0.5) else 17 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating Art Museum. Goal: It must avoid colliding with suspension wire. Assumptions: The states of the drone and the suspension wire's state are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_suspension_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_suspension_wire = calculate_distance_min(s_agent, s_suspension_wire) \n    penalty_collision = -19 if (d_agent_suspension_wire < 0.5) else 17 \n    reward_reaching_goal = 19 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_suspension_wire): \n    d_agent_suspension_wire = calculate_distance_min(s_agent, s_suspension_wire) \n    penalty_collision = -19 if (d_agent_suspension_wire < 0.5) else 17 \n    return penalty_collision"
  },
  {
    "prompt": "Scenario: A drone is navigating Art Museum. Goal: It must avoid colliding with Art Museum's pew, pulpit and visitor. Assumptions: The agent's state, pew, pulpit and visitor' states are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -19 \n    return d_agent_multiple_obstacles + reward_reaching_goal"
  },
  {
    "prompt": "Scenario: A drone is navigating Art Museum. Goal: Detect waste containers and gas cylindes and avoid art museum door and do not collide. Assumptions: The states of the drone, freestanding partition, docent and exhibit placard state are availalbe. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    reward_reaching_goal = 17 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal",
    "rejected": "def reward(s_agent, s_multiple_obstacles, s_goal): \n    d_agent_multiple_obstacles = calculate_distance_min(s_agent, s_multiple_obstacles) \n    penalty_collision = -19 if (d_agent_multiple_obstacles < 0.5) else 17 \n    return penalty_collisionl"
  },
  {
    "prompt": "Scenario: A drone is navigating Art Museum. Goal: Drone goal is to reach the target. Assumptions: The states of the drone and the target are known. Instruction: Implement a reward function in Python.",
    "chosen": "def reward(s_agent, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    reward_reaching_target = 17 if (d_agent_target < 0.2) else -d_agent_target**2 \n    return reward_reaching_target",
    "rejected": "def reward(s_agent, s_target): \n    d_agent_target = calculate_distance(s_agent, s_target) \n    return d_agent_target"
  }









]







]



