[
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chairs. \n Conditions: Agent's state and chair's status and desired speed are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chair. \n Conditions: Agent's state and chair's status and desired speed are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with ceiling fan blades. \n Conditions: Agent's state and staic fan blades's status and desired speed are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives:Avoid collision with hanging lamps. \n Conditions: Agent's state and lamp's status and desired speed are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with curtain. \n Conditions: Agent's state and static curtain's status and desired speed are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with avoid drapes. \n Conditions: Agent's state and drape's status and desired speed are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with obstacles. \n Conditions: Agent's state and obstacle's status and desired speed are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with static obstacle (wardrobes). \n Conditions: Agent's state, wardrobe's state and desired speed are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone in-door navigation and reach other side of the small room. \n Objectives: Do not collide with the walls of the room. \n Conditions: Agent's state, obstacle's state and desired speed are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Guide the drone through an indoor space to the far side of a small room. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, obstacle's state and desired speed are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid hitting the surrounding walls. \n Conditions: Agent's state, obstacle's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Navigate without crashing into walls. \n Conditions: Agent's state, obstacle's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (chairs) and avoid collision. \n Conditions: Agent's state, chair's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (table) and avoid collision. \n Conditions: Agent's state, table's state and desired speed are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (smoke detectors) and avoid collision. \n Conditions: Agent's state, smoke detector's state and desired speed are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (stackes books) and avoid collision. \n Conditions: Agent's state, book's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state and desired speed are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect static obstacle (trees) and avoid collision. \n Conditions: Agent's state, tree's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle (leaves) and avoid collision. \n Conditions: Agent's state, leaves's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect birds and avoid collision. \n Conditions: Agent's state, bird's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with stumps. \n Conditions: Agent's state, stump's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle (rocks) and avoid collision. \n Conditions: Agent's state, rock's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect thin branches and avoid collision. \n Conditions: Agent's state, branche's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with thick tree branches. \n Conditions: Agent's state, tree branche's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect cliffs and avoid collision. \n Conditions: Agent's state, cliff's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any static obstacle such as food serving counters. \n Conditions: Agent's state, food counter's state and desired speed are accessible. \n Write a reward in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with chairs. \n Conditions: Agent's state, chair's states and desired speed are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with table. \n Conditions: Agent's state, table's state and desired speed are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with trash bins. \n Conditions: Agent's state trash bin's state and desired speed are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with low-hanging decorations. \n Conditions: Agent's state, hanging decoration's state and desired speed are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with plants. \n Conditions: Agent's state, plant's state and desired speed are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with metal rails. \n Conditions: Agent's state, metal rail's state and desired speed are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with cameras. \n Conditions: Agent's state, camera's state and desired speed are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone in-door navigation in a classroom. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, people's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a classroom. \n Objectives: Navigate without crashing into overhead lamps. \n Conditions: Agent's state, overhead lamp's state and wanted velocity are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (tall bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state and wanted velocity are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (backpacks) and avoid collision. \n Conditions: Agent's state, backpack's state and wanted velocity are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state and wanted velocity are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with desk. \n Conditions: Agent's state, desk's state and wanted velocity are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect sidboards and do not crash in it \n Conditions: Agent's state, sidboard's state and wanted velocity are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect bench and avoid collision. \n Conditions: Agent's state, bench's state and wanted velocity are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There are hanging equipments do not collied with it. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with laptops. \n Conditions: Agent's state and laptop's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There a tablets in the room. Do not collide with them \n Conditions: Agent's state, tablet's state and wanted velocity are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state and wanted velocity are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (workers) and avoid collision. \n Conditions: Agent's state, workers's state and wanted velocity are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with high storage racks. \n Conditions: Agent's state and storage rack's information and wanted velocity are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with forklifts. \n Conditions: Agent's state and forklift's information and wanted velocity are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with hanging cables. \n Conditions: Agent's state and cable's information and wanted velocity are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission:Operate the drone in a warehouse. \n Objectives: Avoid collison with stacks of pallets. \n Conditions: Agent's state and pallet's information and wanted velocity are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with overhead pipes. \n Conditions: Agent's state and pipe's information and wanted velocity are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect people and avoid collison with overhead beams. \n Conditions: Agent's states and overhead beam information and wanted velocity are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with people. \n Conditions: Agent's state, people's state and wanted velocity are  obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with spotlamps. \n Conditions: Agent's state and spotlamp information and wanted velocity are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with balconies. \n Conditions: Agent's state, balcony's state and wanted velocity are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Detect people and avoid collison with audience seating. \n Conditions: Agent's states and audience seating information and wanted velocity are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with projectors. \n Conditions: Agent's state, projectors's state and wanted velocity are  obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collision with cabels. \n Conditions: Agent's state, cabel's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state and people's state and wanted velocity are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Detect static obstacle (overhead platforms) and avoid collision. \n Conditions: Agent's state, platform's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the theater. \n Objectives: Detect static obstacle (drapes) and avoid collision. \n Conditions: Agent's state, drape's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (hangings microphones) and avoid collision. \n Conditions: Agent's state, microphone's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state and wanted velocity are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect  dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state and desired speed are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect static obstacle (basket hoops) and avoid collision. \n Conditions: Agent's state, basket hoop's state and desired velocity are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with volleyball nets. \n Conditions: Agent's state, volleyball net's state and desired velocity are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with loose balls. \n Conditions: Agent's state, ball's state and desired velocity are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect dynamic obstacle (doctors) and avoid collision. \n Conditions: Agent's state, doctor's state and desired velocity are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Detect static obstacle (wires) and avoid collision. \n Conditions: Agent's state, v's state and wanted velocity are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the hospital. \n Objectives: Avoid collision with medical equipment stands. \n Conditions: Agent's state, medical equipment's state and desired velocity are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the hospital. \n Objectives: Avoid  any collision with wall-mounted emergency devices. \n Conditions: Agent's state, emergency device's state and wanted velocity are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives:  Avoid collision with lamps. \n Conditions: Agent's state, obstacle's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chairs. \n Conditions: Agent's state and chair's status. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chair. \n Conditions: Agent's state and chair's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with ceiling fan blades. \n Conditions: Agent's state and staic fan blades's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives:Avoid collision with hanging lamps. \n Conditions: Agent's state and lamp's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with curtain. \n Conditions: Agent's state and static curtain's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with avoid drapes. \n Conditions: Agent's state and drape's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with obstacles. \n Conditions: Agent's state and obstacle's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with static obstacle (wardrobes). \n Conditions: Agent's state, wardrobe's state are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone in-door navigation and reach other side of the small room. \n Objectives: Do not collide with the walls of the room. \n Conditions: Agent's state, obstacle's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Guide the drone through an indoor space to the far side of a small room. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, obstacle's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid hitting the surrounding walls. \n Conditions: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Navigate without crashing into walls. \n Conditions: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (cables) and avoid collision. \n Conditions: Agent's state, cable's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (chairs) and avoid collision. \n Conditions: Agent's state, chair's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (table) and avoid collision. \n Conditions: Agent's state, table's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (smoke detectors) and avoid collision. \n Conditions: Agent's state, smoke detector's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (stackes books) and avoid collision. \n Conditions: Agent's state, book's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (shelves) and avoid collision. \n Conditions: Agent's state, shelve's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect static obstacle (trees) and avoid collision. \n Conditions: Agent's state, tree's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect birds and avoid collision. \n Conditions: Agent's state, bird's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with stumps. \n Conditions: Agent's state, stump's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle (rocks) and avoid collision. \n Conditions: Agent's state, rock's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect thin branches and avoid collision. \n Conditions: Agent's state, branche's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect cliffs and avoid collision. \n Conditions: Agent's state, cliff's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any obstacle with hanging lamps. \n Conditions: Agent's information and lamp's information are available \n Write a reward in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any static obstacle such as food serving counters. \n Conditions: Agent's state, food counter's state are accessible. \n Write a reward in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with chairs. \n Conditions: Agent's state, chair's states are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with low-hanging decorations. \n Conditions: Agent's state, hanging decoration's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with plants. \n Conditions: Agent's state, plant's state are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with metal rails. \n Conditions: Agent's state, metal rail's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with cameras. \n Conditions: Agent's state, camera's state are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone in-door navigation in a classroom. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a classroom. \n Objectives: Navigate without crashing into overhead lamps. \n Conditions: Agent's state, overhead lamp's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (tall bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (backpacks) and avoid collision. \n Conditions: Agent's state, backpack's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with desk. \n Conditions: Agent's state, desk's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect sidboards and do not crash in it \n Conditions: Agent's state, sidboard's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect bench and avoid collision. \n Conditions: Agent's state, bench's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There are hanging equipments do not collied with it. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with laptops. \n Conditions: Agent's state and laptop's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There a tablets in the room. Do not collide with them \n Conditions: Agent's state, tablet's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (workers) and avoid collision. \n Conditions: Agent's state, workers's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with forklifts. \n Conditions: Agent's state and forklift's information are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with overhead pipes. \n Conditions: Agent's state and pipe's information are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect people and avoid collison with overhead beams. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with people. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Detect people and avoid collison with audience seating. \n Conditions: Agent's states and audience seating information are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with projectors. \n Conditions: Agent's state, projectors's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collision with cabels. \n Conditions: Agent's state, cabel's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state and people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Detect static obstacle (overhead platforms) and avoid collision. \n Conditions: Agent's state, platform's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the theater. \n Objectives: Detect static obstacle (drapes) and avoid collision. \n Conditions: Agent's state, drape's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (hangings microphones) and avoid collision. \n Conditions: Agent's state, microphone's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect  dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (climbing ropes) and avoid collision. \n Conditions: Agent's state, climbing rope's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with hanging flags. \n Conditions: Agent's state, flag's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with loose balls. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Detect dynamic obstacle (patients) and avoid collision. \n Conditions: Agent's state, patient's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect dynamic obstacle (doctors) and avoid collision. \n Conditions: Agent's state, doctor's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Detect static obstacle (wires) and avoid collision. \n Conditions: Agent's state, wire's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect static obstacle (staff) and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Avoid collision with defibrillators. \n Conditions: Agent's state, obstacle's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the hospital. \n Objectives: Avoid  any collision with wall-mounted emergency devices. \n Conditions: Agent's state, emergency device's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives:  Avoid collision with lamps. \n Conditions: Agent's state, lamp's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a hospital. \n Objectives: Avoid to collide with static obstacle such as beds. \n Conditions: Agent's state, bed's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chairs. \n Conditions: Agent's state and chair's status. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chair. \n Conditions: Agent's state and chair's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with ceiling fan blades. \n Conditions: Agent's state and staic fan blades's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives:Avoid collision with hanging lamps. \n Conditions: Agent's state and lamp's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with curtain. \n Conditions: Agent's state and static curtain's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with avoid drapes. \n Conditions: Agent's state and drape's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with obstacles. \n Conditions: Agent's state and obstacle's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with static obstacle (wardrobes). \n Conditions: Agent's state, wardrobe's state are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone in-door navigation and reach other side of the small room. \n Objectives: Do not collide with the walls of the room. \n Conditions: Agent's state, obstacle's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Guide the drone through an indoor space to the far side of a small room. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, obstacle's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid hitting the surrounding walls. \n Conditions: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Navigate without crashing into walls. \n Conditions: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (cables) and avoid collision. \n Conditions: Agent's state, cable's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (chairs) and avoid collision. \n Conditions: Agent's state, chair's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (table) and avoid collision. \n Conditions: Agent's state, table's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (smoke detectors) and avoid collision. \n Conditions: Agent's state, smoke detector's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (stackes books) and avoid collision. \n Conditions: Agent's state, book's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (shelves) and avoid collision. \n Conditions: Agent's state, shelve's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect static obstacle (trees) and avoid collision. \n Conditions: Agent's state, tree's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect birds and avoid collision. \n Conditions: Agent's state, bird's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with stumps. \n Conditions: Agent's state, stump's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle (rocks) and avoid collision. \n Conditions: Agent's state, rock's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect thin branches and avoid collision. \n Conditions: Agent's state, branche's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect cliffs and avoid collision. \n Conditions: Agent's state, cliff's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any obstacle with hanging lamps. \n Conditions: Agent's information and lamp's information are available \n Write a reward in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any static obstacle such as food serving counters. \n Conditions: Agent's state, food counter's state are accessible. \n Write a reward in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with chairs. \n Conditions: Agent's state, chair's states are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with low-hanging decorations. \n Conditions: Agent's state, hanging decoration's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with plants. \n Conditions: Agent's state, plant's state are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with metal rails. \n Conditions: Agent's state, metal rail's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with cameras. \n Conditions: Agent's state, camera's state are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone in-door navigation in a classroom. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a classroom. \n Objectives: Navigate without crashing into overhead lamps. \n Conditions: Agent's state, overhead lamp's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (tall bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (backpacks) and avoid collision. \n Conditions: Agent's state, backpack's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with desk. \n Conditions: Agent's state, desk's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect sidboards and do not crash in it \n Conditions: Agent's state, sidboard's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect bench and avoid collision. \n Conditions: Agent's state, bench's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There are hanging equipments do not collied with it. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with laptops. \n Conditions: Agent's state and laptop's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There a tablets in the room. Do not collide with them \n Conditions: Agent's state, tablet's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (workers) and avoid collision. \n Conditions: Agent's state, workers's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with forklifts. \n Conditions: Agent's state and forklift's information are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with overhead pipes. \n Conditions: Agent's state and pipe's information are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect people and avoid collison with overhead beams. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with people. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Detect people and avoid collison with audience seating. \n Conditions: Agent's states and audience seating information are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with projectors. \n Conditions: Agent's state, projectors's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collision with cabels. \n Conditions: Agent's state, cabel's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state and people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Detect static obstacle (overhead platforms) and avoid collision. \n Conditions: Agent's state, platform's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the theater. \n Objectives: Detect static obstacle (drapes) and avoid collision. \n Conditions: Agent's state, drape's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (hangings microphones) and avoid collision. \n Conditions: Agent's state, microphone's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect  dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (climbing ropes) and avoid collision. \n Conditions: Agent's state, climbing rope's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with hanging flags. \n Conditions: Agent's state, flag's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with loose balls. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Detect dynamic obstacle (patients) and avoid collision. \n Conditions: Agent's state, patient's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect dynamic obstacle (doctors) and avoid collision. \n Conditions: Agent's state, doctor's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Detect static obstacle (wires) and avoid collision. \n Conditions: Agent's state, wire's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect static obstacle (staff) and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Avoid collision with defibrillators. \n Conditions: Agent's state, obstacle's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the hospital. \n Objectives: Avoid  any collision with wall-mounted emergency devices. \n Conditions: Agent's state, emergency device's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives:  Avoid collision with lamps. \n Conditions: Agent's state, lamp's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a hospital. \n Objectives: Avoid to collide with static obstacle such as beds. \n Conditions: Agent's state, bed's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chairs. \n Conditions: Agent's state and chair's status. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chair. \n Conditions: Agent's state and chair's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with ceiling fan blades. \n Conditions: Agent's state and staic fan blades's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives:Avoid collision with hanging lamps. \n Conditions: Agent's state and lamp's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with curtain. \n Conditions: Agent's state and static curtain's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with avoid drapes. \n Conditions: Agent's state and drape's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with obstacles. \n Conditions: Agent's state and obstacle's status are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with static obstacle (wardrobes). \n Conditions: Agent's state, wardrobe's state are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone in-door navigation and reach other side of the small room. \n Objectives: Do not collide with the walls of the room. \n Conditions: Agent's state, obstacle's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Guide the drone through an indoor space to the far side of a small room. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, obstacle's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid hitting the surrounding walls. \n Conditions: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Navigate without crashing into walls. \n Conditions: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (cables) and avoid collision. \n Conditions: Agent's state, cable's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (chairs) and avoid collision. \n Conditions: Agent's state, chair's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (table) and avoid collision. \n Conditions: Agent's state, table's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (smoke detectors) and avoid collision. \n Conditions: Agent's state, smoke detector's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect thin obstacle (stackes books) and avoid collision. \n Conditions: Agent's state, book's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (shelves) and avoid collision. \n Conditions: Agent's state, shelve's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect static obstacle (trees) and avoid collision. \n Conditions: Agent's state, tree's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect birds and avoid collision. \n Conditions: Agent's state, bird's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with stumps. \n Conditions: Agent's state, stump's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle (rocks) and avoid collision. \n Conditions: Agent's state, rock's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect thin branches and avoid collision. \n Conditions: Agent's state, branche's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a forest. \n Objectives: Detect cliffs and avoid collision. \n Conditions: Agent's state, cliff's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any obstacle with hanging lamps. \n Conditions: Agent's information and lamp's information are available \n Write a reward in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any static obstacle such as food serving counters. \n Conditions: Agent's state, food counter's state are accessible. \n Write a reward in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with chairs. \n Conditions: Agent's state, chair's states are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with low-hanging decorations. \n Conditions: Agent's state, hanging decoration's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with plants. \n Conditions: Agent's state, plant's state are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with metal rails. \n Conditions: Agent's state, metal rail's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in the mensa. \n Objectives:  Avoid to collide with cameras. \n Conditions: Agent's state, camera's state are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone in-door navigation in a classroom. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a classroom. \n Objectives: Navigate without crashing into overhead lamps. \n Conditions: Agent's state, overhead lamp's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (tall bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (backpacks) and avoid collision. \n Conditions: Agent's state, backpack's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with desk. \n Conditions: Agent's state, desk's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect sidboards and do not crash in it \n Conditions: Agent's state, sidboard's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect bench and avoid collision. \n Conditions: Agent's state, bench's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There are hanging equipments do not collied with it. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with laptops. \n Conditions: Agent's state and laptop's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a conference room. \n Objectives: There a tablets in the room. Do not collide with them \n Conditions: Agent's state, tablet's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (workers) and avoid collision. \n Conditions: Agent's state, workers's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with forklifts. \n Conditions: Agent's state and forklift's information are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with overhead pipes. \n Conditions: Agent's state and pipe's information are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a warehouse. \n Objectives: Detect people and avoid collison with overhead beams. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with people. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Detect people and avoid collison with audience seating. \n Conditions: Agent's states and audience seating information are available. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with projectors. \n Conditions: Agent's state, projectors's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collision with cabels. \n Conditions: Agent's state, cabel's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state and people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a theater. \n Objectives: Detect static obstacle (overhead platforms) and avoid collision. \n Conditions: Agent's state, platform's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the theater. \n Objectives: Detect static obstacle (drapes) and avoid collision. \n Conditions: Agent's state, drape's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (hangings microphones) and avoid collision. \n Conditions: Agent's state, microphone's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect  dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (climbing ropes) and avoid collision. \n Conditions: Agent's state, climbing rope's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with hanging flags. \n Conditions: Agent's state, flag's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with loose balls. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Detect dynamic obstacle (patients) and avoid collision. \n Conditions: Agent's state, patient's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect dynamic obstacle (doctors) and avoid collision. \n Conditions: Agent's state, doctor's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Detect static obstacle (wires) and avoid collision. \n Conditions: Agent's state, wire's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Pilot a drone through a hospital. \n Objectives: Detect static obstacle (staff) and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives: Avoid collision with defibrillators. \n Conditions: Agent's state, obstacle's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, v_target):\n    d_obs = np.linalg.norm(pos - obs)\n    d_goal = np.linalg.norm(pos - goal)\n    v_penalty = np.linalg.norm(vel - v_target)\n    penalty = np.exp(-d_obs) * 10\n    return -d_goal - 0.3 * v_penalty - penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone explores the hospital. \n Objectives: Avoid  any collision with wall-mounted emergency devices. \n Conditions: Agent's state, emergency device's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(p, v, obstacle, goal, v_desired):\n    goal_reward = -np.linalg.norm(p - goal)\n    collision_risk = -50 if np.linalg.norm(p - obstacle) < 0.8 else 0\n    velocity_mismatch = np.linalg.norm(v - v_desired)\n    return goal_reward - 0.2 * velocity_mismatch + collision_risk\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Operate the drone in a hospital. \n Objectives:  Avoid collision with lamps. \n Conditions: Agent's state, lamp's state are usable. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(pos, vel, obs, goal, target_vel):\n    to_obs = np.linalg.norm(pos - obs)\n    to_goal = np.linalg.norm(pos - goal)\n    speed_diff = np.linalg.norm(vel - target_vel)\n    reward = -1.5 * to_goal\n    if to_obs < 1.1:\n        reward -= 15\n    reward -= 0.1 * speed_diff\n    return reward\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  },
  {
    "prompt": "Mission: Drone indoor exploration in a hospital. \n Objectives: Avoid to collide with static obstacle such as beds. \n Conditions: Agent's state, bed's state are accessible. \n Write a reward function in Python.",
    "chosen": "import numpy as np\n    def reward(agent_pos, agent_vel, chair_pos, goal_pos, desired_vel):\n    dist_chair = np.linalg.norm(agent_pos - chair_pos)\n    dist_goal = np.linalg.norm(agent_pos - goal_pos)\n    speed_penalty = np.linalg.norm(agent_vel - desired_vel)\n    if dist_chair < 1.0:\n        return -25\n    return -dist_goal - 0.5 * speed_penalty\n",
    "rejected": "import numpy as np\n    def reward(agent_pos, chair_pos, goal_pos):\n    distance = agent_pos - chair_pos\n    if distance == 0:\n        reward = 100\n    else:\n        reward = -1\n    return reward\n"
  }
]
