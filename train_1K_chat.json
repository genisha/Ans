[

    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with ceiling fan blades. \n Conditions: Agent's state and static fan blades's status are available. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = -15 if (d_agent_blade < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = 15 if (d_agent_blade < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chair. \n Conditions: Agent's state and chair's status are available. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with hanging lamps. \n Conditions: Agent's state and lamp's status are available. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with curtain. \n Conditions: Agent's state and static curtain's status available. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -15 if (d_agent_curtain < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = 15 if (d_agent_curtain < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with obstacles. \n Conditions: Agent's state and obstacles's status are available. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with drapes. \n Conditions: Agent's state and drape's status are available. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -15 if (d_agent_drape < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 15 if (d_agent_drape < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with static obstacle (wardrobe). \n Conditions: Agent's state, wardrobe's state are available. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = -15 if (d_agent_wardrobe < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = 15 if (d_agent_wardrobe < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone in-door navigation and reach other side of the small room. \n Objectives: Do not collide with the walls of the room. \n Conditions: Agent's state, wall's information accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space to the far side of a small room. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, people's state accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with chairs and tables. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with fan blades and curtains. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with drapes and people. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with lamps and projectors. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with boxes and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Avoid collision with boxes and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans, chairs and table. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans, projector and bench. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with people, boxes and bench. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with shelf, plants and curtains. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },




    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid hitting the surrounding walls. \n Conditions: Agent's state, wall's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Navigate without crashing into walls. \n Conditions: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (chairs) and avoid collision. \n Conditions: Agent's state, chair's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (table) and avoid collision. \n Conditions: Agent's state, table's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 15 if (d_agent_table_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect bookshelves and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -15 if (d_agent_bookshelve < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 15 if (d_agent_bookshelve < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect smoke detectors and avoid collision. \n Conditions: Agent's state, smoke detector's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detectore = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = -15 if (d_agent_smoke_detector < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detector = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = 15 if (d_agent_smoke_detector < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (stacked books) and avoid collision. \n Conditions: Agent's state, book's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -15 if (d_agent_book < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = 15 if (d_agent_book < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect chairs and tabels and avoid collision. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect students and shelves and avoid collision. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with lamps and plants. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with decorations and tall shelves. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stack books and lamps. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with books and lights. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with books, lights and humans. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with chair, table and humans. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with desks, lamps and students. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stacked books, computers and staffs. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stacked books, laptops and book carts. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with  curtains, plants and staffs. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state obtainable. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },   
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect static obstacle such as a tree and avoid collision. \n Conditions: Agent's state, tree's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = -15 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = 15 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle such as a leaf and avoid collision. \n Conditions: Agent's state, leaf's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = -15 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = 15 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect birds and avoid collision. \n Conditions: Agent's state, bird's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = -15 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = 15 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with stumps. \n Conditions: Agent's state and stump's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = -15 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = 15 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle such as a rock and avoid collision. \n Conditions: Agent's state, rock's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -15 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = 15 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect thin branches and avoid collision. \n Conditions: Agent's state, branche's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = -15 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = 15 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with thick tree branches. \n Conditions: Agent's state, tree branche's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = -15 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = 15 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect people and avoid collision. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect stones and avoid collision. \n Conditions: Agent's state and stone's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = -15 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = 15 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect stones and trees and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect branches and trees and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect humans and animals and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect leaves and trees avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with the many trees. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with trees, branches and humans. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with stumps, birds and humans. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with trees, animals and stones. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },


    

    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any collision with hanging lamps. \n Conditions: Agent's information and lamp's information are available \n Write a reward in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any static obstacle such as food serving counters. \n Conditions: Agent's state, food counter's state are accessible. \n Write a reward in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -15 if (d_agent_counter < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = 15 if (d_agent_counter < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a chair. \n Conditions: Agent's state, chair's states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a table. \n Conditions: Agent's state, table's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 15 if (d_agent_table < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with trash bins. \n Conditions: Agent's state and trash bin's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -15 if (d_agent_trash_bin < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = 15 if (d_agent_trash_bin < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a low-hanging decoration. \n Conditions: Agent's state, hanging decoration's state and desired speed are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = -15 if (d_agent_decoration < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = 15 if (d_agent_decoration < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with plants. \n Conditions: Agent's state and plant's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = -15 if (d_agent_plant < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = 15 if (d_agent_plant < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with metal rails. \n Conditions: Agent's state, metal rail's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = -15 if (d_agent_rail < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = 15 if (d_agent_rail < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with cameras. \n Conditions: Agent's state and camera's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = -15 if (d_agent_cameras < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = 15 if (d_agent_cameras < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with people and table. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with students and chairs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and chairs. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and desk. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with decoration and plant. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with cameras, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with chair, plant and table. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with staff, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, rails and camera. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, trash bin and staff. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },




    
    {
        "prompt":[{"content": "Mission: Drone in-door navigation in a classroom. \n Objectives: Do not collide with the a wall of the room. \n Conditions: Agent's state, wall's location are avialable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone in-door navigation in a classroom. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state and people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a classroom. \n Objectives: Avoid hitting the ceiling projector. \n Conditions: Agent's state and projector's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 15 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a classroom. \n Objectives: Navigate without crashing into overhead lamps. \n Conditions: Agent's state, overhead lamp's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect static obstacle (blackboard) and avoid collision. \n Conditions: Agent's state, blackboard's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = -15 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = 15 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (tall bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -15 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 15 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (backpack) and avoid collision. \n Conditions: Agent's state and backpack's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -15 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = 15 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Do not collide with human. \n Conditions: Agent's state and human's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect dynamic obstacle (a teacher) and avoid collision. \n Conditions: Agent's state and teacher's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -15 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = 15 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect dynamic obstacle (a student) and avoid collision. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -15 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = 15 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with student and teacher. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with chair and desk. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with student and backpack. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves and backpack. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with blackboards and whiteboards. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with teacher, blackboards and whiteboards. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with teacher, pupils and desk. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves, chair and table. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves, chair and table. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with three boxes. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },





    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_people + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with desk. \n Conditions: Agent's state, desk's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -15 if (d_agent_desk < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_desk): \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = 15 if (d_agent_desk < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect the sideboard and do not crash in it. \n Conditions: Agent's state and sideboard's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_sideboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    penalty_collision = -15 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_sideboard s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_sideboard + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect bench and avoid collision. \n Conditions: Agent's state, bench's state and wanted velocity are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -15 if (d_agent_bench < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bench): \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = 15 if (d_agent_bench < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision the whiteboard. \n Conditions: Agent's state, whiteboard's state and wanted velocity are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -15 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_whiteboard s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_whiteboard + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Do not not collied with the projector. \n Conditions: Agent's state, projector's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_projector): \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 15 if (d_agent_projector < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a hanging equipment do not collied with it. \n Conditions: Agent's state and equipment's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -15 if (d_agent_equipment < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_equipment): \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = 15 if (d_agent_equipment < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Do not collide with the speaker. \n Conditions: Agent's state, speaker's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -15 if (d_agent_speaker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_speaker s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_speaker + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with the laptop. \n Conditions: Agent's state and laptop's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -15 if (d_agent_laptop < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_laptop): \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = 15 if (d_agent_laptop < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a screen in the room. Do not collide with it \n Conditions: Agent's state and screen's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_screen, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = -15 if (d_agent_screen < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_screen): \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = 15 if (d_agent_screen < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a screen and a projector in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a table and a chair in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a computer and a person in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a plant and a shelf in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a two boxes in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a chair, a table and the person in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a laptop, a plant and a shelf in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the shelf, box, and the projector. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the whiteboard, screen, and the lamp. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the three boxes. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal","role":"assistant"}]
    },





    {
        "prompt":[{"content": "ission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (one staff) and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -15 if (d_agent_staff < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_staff s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_staff + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a worker) and avoid collision. \n Conditions: Agent's state and worker's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -15 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 15 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_human + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a worker) and avoid collision. \n Conditions: Agent's state and worker's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -15 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 15 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with high storage racks. \n Conditions: Agent's state and storage rack's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rack = calculate_distance_min(s_agent, s_rack) \n    penalty_collision = -15 if (d_agent_rack < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rack = calculate_distance_min(s_agent, s_rack) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_rack + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with a forklift . \n Conditions: Agent's state and forklift's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -15 if (d_agent_forklift < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_forklift): \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = 15 if (d_agent_forklift < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with a hanging cable. \n Conditions: Agent's state and cable's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -15 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 30 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission:Operate the drone in a warehouse. \n Objectives: Avoid collison with a stack of pallets. \n Conditions: Agent's state and pallet's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = -15 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = 30 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with a package. \n Conditions: Agent's state and package's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = -15 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = 30 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with overhead pipes. \n Conditions: Agent's state and pipe's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -15 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = 30 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the overhead beam and do not collide with it. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -15 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = 30 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the shelves and human and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the pakets and staffs and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the stackes boxes and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal","role":"assistant"}]
    },
     {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the maschines and staffs and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the beams and hanging lamps and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the cabel, rack and people and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the desk, chair and computer and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the beam, pipes and lamps and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the forklift, stairs and rails and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with people. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_people + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Detect spotlamp and avoid collison with the spotlamp. \n Conditions: Agent's state and spotlamp information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_spotlamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = -15 if (d_agent_spotlamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_spotlamp): \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = 15 if (d_agent_spotlamp < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Avoid collison with the balcony. \n Conditions: Agent's state and balcony's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_balcony, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    penalty_collision = -15 if (d_agent_balcony < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_baloncy, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_balcony + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collison with the visitor's seat. \n Conditions: Agent's states and seat's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_seat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = -15 if (d_agent_seat < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_seat): \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = 15 if (d_agent_seat < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Avoid collison with the projector. \n Conditions: Agent's state, projectors's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_projector + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collision with a cabel. \n Conditions: Agent's state, cabel's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cabel, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabel = calculate_distance_min(s_agent, s_cabel) \n    penalty_collision = -15 if (d_agent_cabel < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cabel): \n    d_agent_seat = calculate_distance_min(s_agent, s_cabel) \n    penalty_collision = 15 if (d_agent_cabel < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state and human's state obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Detect static obstacle (overhead platform) and avoid collision. \n Conditions: Agent's state, platform's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -15 if (d_agent_platform < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = 15 if (d_agent_platform < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect static obstacle (drape) and avoid collision. \n Conditions: Agent's state, drape's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -15 if (d_agent_drape < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 15 if (d_agent_drape < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (hangings microphone) and avoid collision. \n Conditions: Agent's state, microphone's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = -15 if (d_agent_microphone < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = 15 if (d_agent_microphone < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the spotlamp and projectors and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the chair and people and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the stage and drape and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a v. \n Objectives: Detect the microphone and music box do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the staff and visitor do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the chandelier, catwalk and rigging ropes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the table, chair and human and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the three boxes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the ceiling beam, balcony railing and spotlight and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the platform, microphone and drapes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the visitorn seat and box and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content":  "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min + reward_reaching_goal","role":"assistant"}]
    },






    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect  dynamic obstacle (person) and avoid collision. \n Conditions: Agent's state, person's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = -15 if (d_agent_person < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = 15 if (d_agent_person < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the static obstacle basket hoop and avoid collision. \n Conditions: Agent's state, basket hoop's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = -15 if (d_agent_basket_hoop < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = 15 if (d_agent_basket_hoop < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the scoreboard and avoid collision. \n Conditions: Agent's state, scoreboard's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -15 if (d_agent_scoreboard < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = 15 if (d_agent_scoreboard < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the climbing rope and avoid collision. \n Conditions: Agent's state and climbing rope's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -15 if (d_agent_rope < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = 15 if (d_agent_rope < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with volleyball nets. \n Conditions: Agent's state and net's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = -15 if (d_agent_net < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = 15 if (d_agent_net < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with hanging flags. \n Conditions: Agent's state and flag's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = -15 if (d_agent_flag < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = 15 if (d_agent_flag < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (moving players) and avoid collision. \n Conditions: Agent's state and player's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with a ball. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle flying ball and avoid collision. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_ball): \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 15 if (d_agent_ball < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (player) and avoid collision. \n Conditions: Agent's state and player's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_player s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with ball and player. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with rope and net. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with coach and flag. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and rope. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with coach, basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with player, ball and rope. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with flag, student and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_obstacles_min reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the patient and avoid collision. \n Conditions: Agent's state and patient's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -15 if (d_agent_patient < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 15 if (d_agent_patient < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect dynamic obstacle such as a doctor and avoid collision. \n Conditions: Agent's state and doctor's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = -15 if (d_agent_doctor < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = 15 if (d_agent_doctor < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the wire and avoid collision. \n Conditions: Agent's state and wire's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = -15 if (d_agent_wire < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_wire + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the hospital. \n Objectives: Avoid collision with a medical equipment. \n Conditions: Agent's state and equipment's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -15 if (d_agent_equipment < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent,s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    return d_agent_equipment + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the wheelchair and avoid collisions. \n Conditions: Agent's state and wheelchair's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wheelchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = -15 if (d_agent_wheelchair < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wheelchair): \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = 15 if (d_agent_wheelchair < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staffr) \n    penalty_collision = -15 if (d_agent_staff < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_staff): \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = 15 if (d_agent_staff < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Avoid collision with the defibrillator. \n Conditions: Agent's state and defibrillator's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_defibrillator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrillator) \n    penalty_collision = -15 if (d_agent_defibrillator < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_defibrillator,  s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrillator) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_defibrillator + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the hospital. \n Objectives: Avoid  any collision with wall-mounted emergency devices. \n Conditions: Agent's state and device's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_device) \n    penalty_collision = -15 if (d_agent_device < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_device) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_device + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives:  Avoid collision with the lamp. \n Conditions: Agent's state and lamp's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 0 \n    return d_agent_lamp + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and patient avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the defibrillator and equipment avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the wire and wheelchair avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the patient and wheelchair avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and lamp avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the three packages and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the doctor, the patient and the wheelchair and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the defibrillator, the equipment and the wheelchair and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the lamp, the bed and the screen and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the counter, the nurse and the patient and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect  are three boxes and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else 0 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision","role":"assistant"}]
    },




















    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with ceiling fan blades. \n Conditions: Agent's state and static fan blades's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = -15 if (d_agent_blade < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = 15 if (d_agent_blade < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chair. \n Conditions: Agent's state and chair's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with hanging lamps. \n Conditions: Agent's state and lamp's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with curtain. \n Conditions: Agent's state and static curtain's status available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -15 if (d_agent_curtain < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = 15 if (d_agent_curtain < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with obstacles. \n Conditions: Agent's state and obstacles's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with drapes. \n Conditions: Agent's state and drape's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -15 if (d_agent_drape < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 15 if (d_agent_drape < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with static obstacle (wardrobe). \n Conditions: Agent's state, wardrobe's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = -15 if (d_agent_wardrobe < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = 15 if (d_agent_wardrobe < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone in-door navigation and reach other side of the small room. \n Objectives: Do not collide with the walls of the room. \n Conditions: Agent's state, wall's information accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space to the far side of a small room. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, people's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with chairs and tables. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with fan blades and curtains. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with drapes and people. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with lamps and projectors. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with boxes and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Avoid collision with boxes and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans, chairs and table. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans, projector and bench. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with people, boxes and bench. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with shelf, plants and curtains. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid hitting the surrounding walls. \n Conditions: Agent's state, wall's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Navigate without crashing into walls. \n Conditions: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (chairs) and avoid collision. \n Conditions: Agent's state, chair's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (table) and avoid collision. \n Conditions: Agent's state, table's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 15 if (d_agent_table_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect bookshelves and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -15 if (d_agent_bookshelve < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 15 if (d_agent_bookshelve < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect smoke detectors and avoid collision. \n Conditions: Agent's state, smoke detector's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detectore = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = -15 if (d_agent_smoke_detector < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detector = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = 15 if (d_agent_smoke_detector < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (stacked books) and avoid collision. \n Conditions: Agent's state, book's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -15 if (d_agent_book < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = 15 if (d_agent_book < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect chairs and tabels and avoid collision. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect students and shelves and avoid collision. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with lamps and plants. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with decorations and tall shelves. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stack books and lamps. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with books and lights. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with books, lights and humans. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with chair, table and humans. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with desks, lamps and students. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stacked books, computers and staffs. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stacked books, laptops and book carts. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with  curtains, plants and staffs. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state obtainable. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },   
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect static obstacle such as a tree and avoid collision. \n Conditions: Agent's state, tree's state are obtainable. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = -15 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = 15 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle such as a leaf and avoid collision. \n Conditions: Agent's state, leaf's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = -15 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = 15 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect birds and avoid collision. \n Conditions: Agent's state, bird's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = -15 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = 15 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with stumps. \n Conditions: Agent's state and stump's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = -15 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = 15 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle such as a rock and avoid collision. \n Conditions: Agent's state, rock's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -15 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = 15 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect thin branches and avoid collision. \n Conditions: Agent's state, branche's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = -15 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = 15 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with thick tree branches. \n Conditions: Agent's state, tree branche's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = -15 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = 15 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect people and avoid collision. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect stones and avoid collision. \n Conditions: Agent's state and stone's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = -15 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = 15 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect stones and trees and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect branches and trees and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect humans and animals and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect leaves and trees avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with the many trees. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with trees, branches and humans. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with stumps, birds and humans. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with trees, animals and stones. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },


    

    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any collision with hanging lamps. \n Conditions: Agent's information and lamp's information are available \n Write a reward in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any static obstacle such as food serving counters. \n Conditions: Agent's state, food counter's state are accessible. \n Write a reward in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -15 if (d_agent_counter < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = 15 if (d_agent_counter < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a chair. \n Conditions: Agent's state, chair's states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a table. \n Conditions: Agent's state, table's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 15 if (d_agent_table < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with trash bins. \n Conditions: Agent's state and trash bin's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -15 if (d_agent_trash_bin < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = 15 if (d_agent_trash_bin < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a low-hanging decoration. \n Conditions: Agent's state, hanging decoration's state and desired speed are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = -15 if (d_agent_decoration < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = 15 if (d_agent_decoration < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with plants. \n Conditions: Agent's state and plant's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = -15 if (d_agent_plant < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = 15 if (d_agent_plant < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with metal rails. \n Conditions: Agent's state, metal rail's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = -15 if (d_agent_rail < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = 15 if (d_agent_rail < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with cameras. \n Conditions: Agent's state and camera's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = -15 if (d_agent_cameras < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = 15 if (d_agent_cameras < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with people and table. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with students and chairs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and chairs. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and desk. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with decoration and plant. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with cameras, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with chair, plant and table. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with staff, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, rails and camera. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, trash bin and staff. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },




    
    {
        "prompt":[{"content": "Mission: Drone in-door navigation in a classroom. \n Objectives: Do not collide with the a wall of the room. \n Conditions: Agent's state, wall's location are avialable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone in-door navigation in a classroom. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state and people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a classroom. \n Objectives: Avoid hitting the ceiling projector. \n Conditions: Agent's state and projector's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 15 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a classroom. \n Objectives: Navigate without crashing into overhead lamps. \n Conditions: Agent's state, overhead lamp's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect static obstacle (blackboard) and avoid collision. \n Conditions: Agent's state, blackboard's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = -15 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = 15 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (tall bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -15 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 15 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (backpack) and avoid collision. \n Conditions: Agent's state and backpack's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -15 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = 15 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Do not collide with human. \n Conditions: Agent's state and human's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect dynamic obstacle (a teacher) and avoid collision. \n Conditions: Agent's state and teacher's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -15 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = 15 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect dynamic obstacle (a student) and avoid collision. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -15 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = 15 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with student and teacher. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with chair and desk. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with student and backpack. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves and backpack. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with blackboards and whiteboards. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with teacher, blackboards and whiteboards. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with teacher, pupils and desk. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves, chair and table. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves, chair and table. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with three boxes. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },





    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_people + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with desk. \n Conditions: Agent's state, desk's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -15 if (d_agent_desk < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_desk): \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = 15 if (d_agent_desk < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect the sideboard and do not crash in it. \n Conditions: Agent's state and sideboard's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_sideboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    penalty_collision = -15 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_sideboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_sideboard + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect bench and avoid collision. \n Conditions: Agent's state, bench's state and wanted velocity are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -15 if (d_agent_bench < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bench): \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = 15 if (d_agent_bench < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision the whiteboard. \n Conditions: Agent's state, whiteboard's state and wanted velocity are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -15 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_whiteboard + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Do not not collied with the projector. \n Conditions: Agent's state, projector's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_projector): \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 15 if (d_agent_projector < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a hanging equipment do not collied with it. \n Conditions: Agent's state and equipment's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -15 if (d_agent_equipment < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_equipment): \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = 15 if (d_agent_equipment < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Do not collide with the speaker. \n Conditions: Agent's state, speaker's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -15 if (d_agent_speaker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speakers) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_speaker + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with the laptop. \n Conditions: Agent's state and laptop's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -15 if (d_agent_laptop < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_laptop): \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = 15 if (d_agent_laptop < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a screen in the room. Do not collide with it \n Conditions: Agent's state and screen's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_screen, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = -15 if (d_agent_screen < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_screen): \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = 15 if (d_agent_screen < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a screen and a projector in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a table and a chair in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a computer and a person in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a plant and a shelf in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a two boxes in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a chair, a table and the person in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a laptop, a plant and a shelf in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstcales + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the shelf, box, and the projector. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstcales + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the whiteboard, screen, and the lamp. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstcales + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the three boxes. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstcales + reward_reaching_goal","role":"assistant"}]
    },





    {
        "prompt":[{"content": "ission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (one staff) and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -15 if (d_agent_staff < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a worker) and avoid collision. \n Conditions: Agent's state and worker's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -15 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 15 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a worker) and avoid collision. \n Conditions: Agent's state and worker's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -15 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 15 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with high storage racks. \n Conditions: Agent's state and storage rack's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rack = calculate_distance_min(s_agent, s_rack) \n    penalty_collision = -15 if (d_agent_rack < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with a forklift . \n Conditions: Agent's state and forklift's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -15 if (d_agent_forklift < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_forklift): \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = 15 if (d_agent_forklift < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with a hanging cable. \n Conditions: Agent's state and cable's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -15 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 30 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission:Operate the drone in a warehouse. \n Objectives: Avoid collison with a stack of pallets. \n Conditions: Agent's state and pallet's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = -15 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = 30 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with a package. \n Conditions: Agent's state and package's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = -15 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = 30 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with overhead pipes. \n Conditions: Agent's state and pipe's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -15 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = 30 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the overhead beam and do not collide with it. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -15 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = 30 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the shelves and human and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the pakets and staffs and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the stackes boxes and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal","role":"assistant"}]
    },
     {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the maschines and staffs and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the beams and hanging lamps and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the cabel, rack and people and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the desk, chair and computer and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the beam, pipes and lamps and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the forklift, stairs and rails and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with people. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_people + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Detect spotlamp and avoid collison with the spotlamp. \n Conditions: Agent's state and spotlamp information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_spotlamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = -15 if (d_agent_spotlamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_spotlamp): \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = 15 if (d_agent_spotlamp < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Avoid collison with the balcony. \n Conditions: Agent's state and balcony's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_balcony, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    penalty_collision = -15 if (d_agent_balcony < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_balcony, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_balcony + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collison with the visitor's seat. \n Conditions: Agent's states and seat's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_seat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = -15 if (d_agent_seat < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_seat): \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = 15 if (d_agent_seat < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Avoid collison with the projector. \n Conditions: Agent's state, projectors's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_projector,  s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_projector + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collision with a cabel. \n Conditions: Agent's state, cabel's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cabel, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabel = calculate_distance_min(s_agent, s_cabel) \n    penalty_collision = -15 if (d_agent_cabel < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cabel): \n    d_agent_seat = calculate_distance_min(s_agent, s_cabel) \n    penalty_collision = 15 if (d_agent_cabel < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state and human's state obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Detect static obstacle (overhead platform) and avoid collision. \n Conditions: Agent's state, platform's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -15 if (d_agent_platform < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = 15 if (d_agent_platform < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect static obstacle (drape) and avoid collision. \n Conditions: Agent's state, drape's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -15 if (d_agent_drape < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 15 if (d_agent_drape < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (hangings microphone) and avoid collision. \n Conditions: Agent's state, microphone's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = -15 if (d_agent_microphone < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = 15 if (d_agent_microphone < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the spotlamp and projectors and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the chair and people and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the stage and drape and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a v. \n Objectives: Detect the microphone and music box do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the staff and visitor do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the chandelier, catwalk and rigging ropes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the table, chair and human and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the three boxes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the ceiling beam, balcony railing and spotlight and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the platform, microphone and drapes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the visitorn seat and box and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal","role":"assistant"}]    },






    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect  dynamic obstacle (person) and avoid collision. \n Conditions: Agent's state, person's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = -15 if (d_agent_person < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = 15 if (d_agent_person < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the static obstacle basket hoop and avoid collision. \n Conditions: Agent's state, basket hoop's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = -15 if (d_agent_basket_hoop < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = 15 if (d_agent_basket_hoop < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the scoreboard and avoid collision. \n Conditions: Agent's state, scoreboard's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -15 if (d_agent_scoreboard < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = 15 if (d_agent_scoreboard < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the climbing rope and avoid collision. \n Conditions: Agent's state and climbing rope's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -15 if (d_agent_rope < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = 15 if (d_agent_rope < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with volleyball nets. \n Conditions: Agent's state and net's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = -15 if (d_agent_net < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = 15 if (d_agent_net < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with hanging flags. \n Conditions: Agent's state and flag's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = -15 if (d_agent_flag < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = 15 if (d_agent_flag < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (moving players) and avoid collision. \n Conditions: Agent's state and player's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with a ball. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle flying ball and avoid collision. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_ball): \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 15 if (d_agent_ball < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (player) and avoid collision. \n Conditions: Agent's state and player's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_player s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with ball and player. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with rope and net. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with coach and flag. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and rope. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with coach, basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with player, ball and rope. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with flag, student and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the patient and avoid collision. \n Conditions: Agent's state and patient's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -15 if (d_agent_patient < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 15 if (d_agent_patient < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect dynamic obstacle such as a doctor and avoid collision. \n Conditions: Agent's state and doctor's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = -15 if (d_agent_doctor < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = 15 if (d_agent_doctor < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the wire and avoid collision. \n Conditions: Agent's state and wire's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = -15 if (d_agent_wire < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the hospital. \n Objectives: Avoid collision with a medical equipment. \n Conditions: Agent's state and equipment's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -15 if (d_agent_equipment < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the wheelchair and avoid collisions. \n Conditions: Agent's state and wheelchair's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wheelchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = -15 if (d_agent_wheelchair < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wheelchair): \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = 15 if (d_agent_wheelchair < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staffr) \n    penalty_collision = -15 if (d_agent_staff < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_staff): \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = 15 if (d_agent_staff < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Avoid collision with the defibrillator. \n Conditions: Agent's state and defibrillator's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_defibrillator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrillator) \n    penalty_collision = -15 if (d_agent_defibrillator < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the hospital. \n Objectives: Avoid  any collision with wall-mounted emergency devices. \n Conditions: Agent's state and device's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_device) \n    penalty_collision = -15 if (d_agent_device < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives:  Avoid collision with the lamp. \n Conditions: Agent's state and lamp's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and patient avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the defibrillator and equipment avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the wire and wheelchair avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the patient and wheelchair avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and lamp avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the three packages and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the doctor, the patient and the wheelchair and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the defibrillator, the equipment and the wheelchair and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the lamp, the bed and the screen and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the counter, the nurse and the patient and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect  are three boxes and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision","role":"assistant"}]
    },














    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with ceiling fan blades. \n Conditions: Agent's state and static fan blades's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = -20 if (d_agent_blade < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = 20 if (d_agent_blade < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chair. \n Conditions: Agent's state and chair's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -20 if (d_agent_chair < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 20 if (d_agent_chair < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with hanging lamps. \n Conditions: Agent's state and lamp's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -20 if (d_agent_lamp < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 20 if (d_agent_lamp < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with curtain. \n Conditions: Agent's state and static curtain's status available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -20 if (d_agent_curtain < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = 20 if (d_agent_curtain < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with obstacles. \n Conditions: Agent's state and obstacles's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with drapes. \n Conditions: Agent's state and drape's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -20 if (d_agent_drape < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_drape): \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 20 if (d_agent_drape < 0.7) else 5 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with static obstacle (wardrobe). \n Conditions: Agent's state, wardrobe's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = -20 if (d_agent_wardrobe < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.5) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone in-door navigation and reach other side of the small room. \n Objectives: Do not collide with the walls of the room. \n Conditions: Agent's state, wall's information accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -20 if (d_agent_wall < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 20 if (d_agent_wall < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space to the far side of a small room. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, people's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -20 if (d_agent_people < 0.7) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.1) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 20 if (d_agent_people < 0.7) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.1) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with chairs and tables. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with fan blades and curtains. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with drapes and people. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with lamps and projectors. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with boxes and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Avoid collision with boxes and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < c_1) else 5 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans, chairs and table. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < c_1) else 5 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans, projector and bench. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n   reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with people, boxes and bench. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with shelf, plants and curtains. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = 15 if (d_agent_goal < c_2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < c_1) else 5 \n    reward_reaching_goal = -15 if (d_agent_goal < c_2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid hitting the surrounding walls. \n Conditions: Agent's state, wall's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 10 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Navigate without crashing into walls. \n Conditions: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.5) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (chairs) and avoid collision. \n Conditions: Agent's state, chair's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -10 if (d_agent_chair < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (table) and avoid collision. \n Conditions: Agent's state, table's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -10 if (d_agent_table_min < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    returnreward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect bookshelves and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -10 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bookshelve): \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 10 if (d_agent_bookshelve < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect smoke detectors and avoid collision. \n Conditions: Agent's state, smoke detector's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detectore = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = -10 if (d_agent_smoke_detector < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detector = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = 10 if (d_agent_smoke_detector < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (stacked books) and avoid collision. \n Conditions: Agent's state, book's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -10 if (d_agent_book < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect chairs and tabels and avoid collision. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect students and shelves and avoid collision. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with lamps and plants. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with decorations and tall shelves. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stack books and lamps. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with books and lights. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with books, lights and humans. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with chair, table and humans. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with desks, lamps and students. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stacked books, computers and staffs. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stacked books, laptops and book carts. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with  curtains, plants and staffs. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -12 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 12 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },   
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect static obstacle such as a tree and avoid collision. \n Conditions: Agent's state, tree's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = -12 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = 12 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle such as a leaf and avoid collision. \n Conditions: Agent's state, leaf's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = -12 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = 12 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect birds and avoid collision. \n Conditions: Agent's state, bird's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = -12 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = 12 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with stumps. \n Conditions: Agent's state and stump's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = -12 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = 12 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle such as a rock and avoid collision. \n Conditions: Agent's state, rock's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -12 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = 12 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect thin branches and avoid collision. \n Conditions: Agent's state, branche's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = -12 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = 12 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with thick tree branches. \n Conditions: Agent's state, tree branche's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = -12 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = 12 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect people and avoid collision. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -12 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 12 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect stones and avoid collision. \n Conditions: Agent's state and stone's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = -12 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = 12 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect stones and trees and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect branches and trees and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect humans and animals and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect leaves and trees avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with the many trees. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with trees, branches and humans. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with stumps, birds and humans. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with trees, animals and stones. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 16 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -16 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },


    

    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -20 if (d_agent_human < 1) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any collision with hanging lamps. \n Conditions: Agent's information and lamp's information are available \n Write a reward in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -20 if (d_agent_lamp < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp): \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 20 if (d_agent_lamp < 0.5) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any static obstacle such as food serving counters. \n Conditions: Agent's state, food counter's state are accessible. \n Write a reward in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -20 if (d_agent_counter < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    penalty_collision = 20 if (d_agent_counter < 0.5) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a chair. \n Conditions: Agent's state, chair's states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -20 if (d_agent_chair < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a table. \n Conditions: Agent's state, table's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -20 if (d_agent_table < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 20 if (d_agent_table < 0.5) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with trash bins. \n Conditions: Agent's state and trash bin's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -20 if (d_agent_trash_bin < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = 20 if (d_agent_trash_bin < 0.5) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a low-hanging decoration. \n Conditions: Agent's state, hanging decoration's state and desired speed are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = -20 if (d_agent_decoration < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with plants. \n Conditions: Agent's state and plant's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = -20 if (d_agent_plant < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_plant): \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = 20 if (d_agent_plant < 0.5) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with metal rails. \n Conditions: Agent's state, metal rail's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = -20 if (d_agent_rail < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rail): \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = 20 if (d_agent_rail < 0.5) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with cameras. \n Conditions: Agent's state and camera's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = -20 if (d_agent_cameras < 0.5) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with people and table. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with students and chairs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and chairs. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and desk. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with decoration and plant. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with cameras, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else v \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with chair, plant and table. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with staff, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, rails and camera. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, trash bin and staff. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 20 if (d_agent_obstacles_min < 0.8) else 3 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },




    
    {
        "prompt":[{"content": "Mission: Drone in-door navigation in a classroom. \n Objectives: Do not collide with the a wall of the room. \n Conditions: Agent's state, wall's location are avialable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone in-door navigation in a classroom. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state and people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people): \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 10 if (d_agent_people < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a classroom. \n Objectives: Avoid hitting the ceiling projector. \n Conditions: Agent's state and projector's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -10 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_projector): \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 10 if (d_agent_projector < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a classroom. \n Objectives: Navigate without crashing into overhead lamps. \n Conditions: Agent's state, overhead lamp's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -10 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect static obstacle (blackboard) and avoid collision. \n Conditions: Agent's state, blackboard's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = -10 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = 10 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (tall bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -10 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 10 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (backpack) and avoid collision. \n Conditions: Agent's state and backpack's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -10 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Do not collide with human. \n Conditions: Agent's state and human's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect dynamic obstacle (a teacher) and avoid collision. \n Conditions: Agent's state and teacher's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -10 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_teacher): \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = 10 if (d_agent_teacher < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect dynamic obstacle (a student) and avoid collision. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -10 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with student and teacher. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with chair and desk. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with student and backpack. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves and backpack. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with blackboards and whiteboards. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with teacher, blackboards and whiteboards. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with teacher, pupils and desk. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves, chair and table. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves, chair and table. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with three boxes. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },





    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -12 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with desk. \n Conditions: Agent's state, desk's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -12 if (d_agent_desk < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_desk): \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = 12 if (d_agent_desk < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect the sideboard and do not crash in it. \n Conditions: Agent's state and sideboard's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_sideboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    penalty_collision = -12 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect bench and avoid collision. \n Conditions: Agent's state, bench's state and wanted velocity are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -12 if (d_agent_bench < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bench): \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = 12 if (d_agent_bench < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision the whiteboard. \n Conditions: Agent's state, whiteboard's state and wanted velocity are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -12 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Do not not collied with the projector. \n Conditions: Agent's state, projector's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -12 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_projector): \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 12 if (d_agent_projector < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a hanging equipment do not collied with it. \n Conditions: Agent's state and equipment's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -12 if (d_agent_equipment < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_equipment): \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = 12 if (d_agent_equipment < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Do not collide with the speaker. \n Conditions: Agent's state, speaker's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -12 if (d_agent_speaker < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with the laptop. \n Conditions: Agent's state and laptop's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -12 if (d_agent_laptop < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_laptop): \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = 12 if (d_agent_laptop < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a screen in the room. Do not collide with it \n Conditions: Agent's state and screen's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_screen, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = -12 if (d_agent_screen < 0.5) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_screen): \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = 12 if (d_agent_screen < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a screen and a projector in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a table and a chair in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a computer and a person in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a plant and a shelf in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a two boxes in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a chair, a table and the person in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 12 if (d_agent_obstacles_min < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a laptop, a plant and a shelf in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the shelf, box, and the projector. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the whiteboard, screen, and the lamp. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the three boxes. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -12 if (d_agent_obstacles_min < 0.6) else 0 \n    reward_reaching_goal = 14 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -14 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal","role":"assistant"}]
    },





    {
        "prompt":[{"content": "ission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (one staff) and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -11 if (d_agent_staff < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a worker) and avoid collision. \n Conditions: Agent's state and worker's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -11 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 11 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -11 if (d_agent_human < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a worker) and avoid collision. \n Conditions: Agent's state and worker's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -11 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 11 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with high storage racks. \n Conditions: Agent's state and storage rack's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rack = calculate_distance_min(s_agent, s_rack) \n    penalty_collision = -11 if (d_agent_rack < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with a forklift . \n Conditions: Agent's state and forklift's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -11 if (d_agent_forklift < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_forklift): \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = 11 if (d_agent_forklift < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with a hanging cable. \n Conditions: Agent's state and cable's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -11 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 11 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission:Operate the drone in a warehouse. \n Objectives: Avoid collison with a stack of pallets. \n Conditions: Agent's state and pallet's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = -11 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = 11 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with a package. \n Conditions: Agent's state and package's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = -11 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = 11 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with overhead pipes. \n Conditions: Agent's state and pipe's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -11 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = 11 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the overhead beam and do not collide with it. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -11 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = 11 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the shelves and human and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the pakets and staffs and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 11 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the stackes boxes and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
    ,"role":"assistant"}]},
     {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the maschines and staffs and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 11 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the beams and hanging lamps and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the cabel, rack and people and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the desk, chair and computer and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the beam, pipes and lamps and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the forklift, stairs and rails and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -11 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 20 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -20 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with people. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -14 if (d_agent_people < 0.5) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Detect spotlamp and avoid collison with the spotlamp. \n Conditions: Agent's state and spotlamp information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_spotlamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = -14 if (d_agent_spotlamp < 0.5) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_spotlamp): \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = 14 if (d_agent_spotlamp < 0.5) else 5 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Avoid collison with the balcony. \n Conditions: Agent's state and balcony's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_balcony, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    penalty_collision = -14 if (d_agent_balcony < 0.5) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collison with the visitor's seat. \n Conditions: Agent's states and seat's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_seat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = -14 if (d_agent_seat < 0.5) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_seat): \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = 14 if (d_agent_seat < 0.5) else 5 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Avoid collison with the projector. \n Conditions: Agent's state, projectors's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -14 if (d_agent_projector < 0.5) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collision with a cabel. \n Conditions: Agent's state, cabel's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cabel, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabel = calculate_distance_min(s_agent, s_cabel) \n    penalty_collision = -14 if (d_agent_cabel < 0.5) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cabel): \n    d_agent_seat = calculate_distance_min(s_agent, s_cabel) \n    penalty_collision = 14 if (d_agent_cabel < 0.5) else 5 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state and human's state obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -14 if (d_agent_human < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 14 if (d_agent_human < 0.8) else 5 \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Detect static obstacle (overhead platform) and avoid collision. \n Conditions: Agent's state, platform's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -14 if (d_agent_platform < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = 14 if (d_agent_platform < 0.8) else 5 \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect static obstacle (drape) and avoid collision. \n Conditions: Agent's state, drape's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -14 if (d_agent_drape < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 14 if (d_agent_drape < 0.8) else 5 \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (hangings microphone) and avoid collision. \n Conditions: Agent's state, microphone's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = -14 if (d_agent_microphone < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = 14 if (d_agent_microphone < 0.8) else 5 \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the spotlamp and projectors and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the chair and people and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the stage and drape and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a v. \n Objectives: Detect the microphone and music box do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 14 if (d_agent_obstacles_min < 0.8) else 5 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the staff and visitor do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 14 if (d_agent_obstacles_min < 0.8) else 5 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the chandelier, catwalk and rigging ropes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the table, chair and human and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the three boxes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the ceiling beam, balcony railing and spotlight and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the platform, microphone and drapes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the visitorn seat and box and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -14 if (d_agent_obstacles_min < 0.8) else 5 \n    reward_reaching_goal = 25 if (d_agent_goal < 0.2) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -25 if (d_agent_goal < 0.2) else math.exp(d_agent_goal) \n    return reward_reaching_goal","role":"assistant"}]
    },






    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -19 if (d_agent_human < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 19 if (d_agent_human < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect  dynamic obstacle (person) and avoid collision. \n Conditions: Agent's state, person's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = -19 if (d_agent_person < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = 19 if (d_agent_person < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the static obstacle basket hoop and avoid collision. \n Conditions: Agent's state, basket hoop's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = -19 if (d_agent_basket_hoop < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = 19 if (d_agent_basket_hoop < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the scoreboard and avoid collision. \n Conditions: Agent's state, scoreboard's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -19 if (d_agent_scoreboard < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = 19 if (d_agent_scoreboard < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the climbing rope and avoid collision. \n Conditions: Agent's state and climbing rope's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -19 if (d_agent_rope < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = 19 if (d_agent_rope < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with volleyball nets. \n Conditions: Agent's state and net's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = -19 if (d_agent_net < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = 19 if (d_agent_net < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with hanging flags. \n Conditions: Agent's state and flag's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = -19 if (d_agent_flag < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = 19 if (d_agent_flag < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (moving players) and avoid collision. \n Conditions: Agent's state and player's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -19 if (d_agent_player < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 19 if (d_agent_player < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with a ball. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -19 if (d_agent_ball < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 19 if (d_agent_ball < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle flying ball and avoid collision. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -19 if (d_agent_ball < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_ball): \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 19 if (d_agent_ball < 0.6) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (player) and avoid collision. \n Conditions: Agent's state and player's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -19 if (d_agent_player < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_player s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 19 if (d_agent_player < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with ball and player. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with rope and net. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with coach and flag. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and rope. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with coach, basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with player, ball and rope. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with flag, student and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the patient and avoid collision. \n Conditions: Agent's state and patient's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -19 if (d_agent_patient < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 19 if (d_agent_patient < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect dynamic obstacle such as a doctor and avoid collision. \n Conditions: Agent's state and doctor's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = -19 if (d_agent_doctor < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = 19 if (d_agent_doctor < 0.6) else 3 \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the wire and avoid collision. \n Conditions: Agent's state and wire's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = -19 if (d_agent_wire < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the hospital. \n Objectives: Avoid collision with a medical equipment. \n Conditions: Agent's state and equipment's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -19 if (d_agent_equipment < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the wheelchair and avoid collisions. \n Conditions: Agent's state and wheelchair's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wheelchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = -19 if (d_agent_wheelchair < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wheelchair): \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = 19 if (d_agent_wheelchair < 0.6) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staffr) \n    penalty_collision = -19 if (d_agent_staff < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_staff): \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = 19 if (d_agent_staff < 0.6) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Avoid collision with the defibrillator. \n Conditions: Agent's state and defibrillator's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_defibrillator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrillator) \n    penalty_collision = -19 if (d_agent_defibrillator < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the hospital. \n Objectives: Avoid  any collision with wall-mounted emergency devices. \n Conditions: Agent's state and device's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_device) \n    penalty_collision = -19 if (d_agent_device < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives:  Avoid collision with the lamp. \n Conditions: Agent's state and lamp's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -19 if (d_agent_lamp < 0.6) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -15 if (d_agent_goal < 0.3) else math.exp(d_agent_goal) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and patient avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the defibrillator and equipment avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the wire and wheelchair avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the patient and wheelchair avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and lamp avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the three packages and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the doctor, the patient and the wheelchair and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the defibrillator, the equipment and the wheelchair and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the lamp, the bed and the screen and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the counter, the nurse and the patient and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect  are three boxes and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -19 if (d_agent_obstacles_min < 1) else 3 \n    reward_reaching_goal = 15 if (d_agent_goal < 0.3) else -math.exp(d_agent_goal) \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 19 if (d_agent_obstacles_min < 1) else 3 \n    return penalty_collision","role":"assistant"}]
    },











 
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with ceiling fan blades. \n Conditions: Agent's state and static fan blades's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = -10 if (d_agent_blade < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = 10 if (d_agent_blade < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chair. \n Conditions: Agent's state and chair's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -10 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 10 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with hanging lamps. \n Conditions: Agent's state and lamp's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -10 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 10 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with curtain. \n Conditions: Agent's state and static curtain's status available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -10 if (d_agent_curtain < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = 10 if (d_agent_curtain < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with obstacles. \n Conditions: Agent's state and obstacles's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with drapes. \n Conditions: Agent's state and drape's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -10 if (d_agent_drape < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 10 if (d_agent_drape < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with static obstacle (wardrobe). \n Conditions: Agent's state, wardrobe's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = -10 if (d_agent_wardrobe < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = 10 if (d_agent_wardrobe < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone in-door navigation and reach other side of the small room. \n Objectives: Do not collide with the walls of the room. \n Conditions: Agent's state, wall's information accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 10 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space to the far side of a small room. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, people's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 10 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with chairs and tables. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with fan blades and curtains. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with drapes and people. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with lamps and projectors. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with boxes and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Avoid collision with boxes and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans, chairs and table. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans, projector and bench. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with people, boxes and bench. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with shelf, plants and curtains. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = 5 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.7) else 0 \n    reward_reaching_goal = -5 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid hitting the surrounding walls. \n Conditions: Agent's state, wall's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Navigate without crashing into walls. \n Conditions: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (chairs) and avoid collision. \n Conditions: Agent's state, chair's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (table) and avoid collision. \n Conditions: Agent's state, table's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 15 if (d_agent_table_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect bookshelves and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -15 if (d_agent_bookshelve < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 15 if (d_agent_bookshelve < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect smoke detectors and avoid collision. \n Conditions: Agent's state, smoke detector's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detectore = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = -15 if (d_agent_smoke_detector < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detector = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = 15 if (d_agent_smoke_detector < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (stacked books) and avoid collision. \n Conditions: Agent's state, book's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -15 if (d_agent_book < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = 15 if (d_agent_book < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect chairs and tabels and avoid collision. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect students and shelves and avoid collision. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < c_2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < c_1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < c_2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with lamps and plants. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with decorations and tall shelves. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stack books and lamps. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with books and lights. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with books, lights and humans. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with chair, table and humans. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with desks, lamps and students. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stacked books, computers and staffs. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stacked books, laptops and book carts. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with  curtains, plants and staffs. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },   
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect static obstacle such as a tree and avoid collision. \n Conditions: Agent's state, tree's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = -15 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = 15 if (d_agent_tree < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle such as a leaf and avoid collision. \n Conditions: Agent's state, leaf's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = -15 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = 15 if (d_agent_leaf < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect birds and avoid collision. \n Conditions: Agent's state, bird's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = -15 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = 15 if (d_agent_bird < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with stumps. \n Conditions: Agent's state and stump's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = -15 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = 15 if (d_agent_stump < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle such as a rock and avoid collision. \n Conditions: Agent's state, rock's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -15 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = 15 if (d_agent_rock < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect thin branches and avoid collision. \n Conditions: Agent's state, branche's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = -15 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = 15 if (d_agent_branch < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with thick tree branches. \n Conditions: Agent's state, tree branche's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = -15 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = 15 if (d_agent_tree_branch < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect people and avoid collision. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect stones and avoid collision. \n Conditions: Agent's state and stone's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = -15 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = 15 if (d_agent_stone < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect stones and trees and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect branches and trees and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect humans and animals and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect leaves and trees avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with the many trees. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with trees, branches and humans. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with stumps, birds and humans. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with trees, animals and stones. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal",
        "role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },


    

    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 1) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any collision with hanging lamps. \n Conditions: Agent's information and lamp's information are available \n Write a reward in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any static obstacle such as food serving counters. \n Conditions: Agent's state, food counter's state are accessible. \n Write a reward in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -15 if (d_agent_counter < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = 15 if (d_agent_counter < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a chair. \n Conditions: Agent's state, chair's states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 15 if (d_agent_chair < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a table. \n Conditions: Agent's state, table's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -15 if (d_agent_table < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 15 if (d_agent_table < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with trash bins. \n Conditions: Agent's state and trash bin's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -15 if (d_agent_trash_bin < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = 15 if (d_agent_trash_bin < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a low-hanging decoration. \n Conditions: Agent's state, hanging decoration's state and desired speed are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = -15 if (d_agent_decoration < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = 15 if (d_agent_decoration < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with plants. \n Conditions: Agent's state and plant's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = -15 if (d_agent_plant < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = 15 if (d_agent_plant < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with metal rails. \n Conditions: Agent's state, metal rail's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = -15 if (d_agent_rail < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = 15 if (d_agent_rail < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with cameras. \n Conditions: Agent's state and camera's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = -15 if (d_agent_cameras < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = 15 if (d_agent_cameras < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with people and table. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with students and chairs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and chairs. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and desk. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with decoration and plant. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with cameras, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with chair, plant and table. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with staff, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, rails and camera. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, trash bin and staff. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },




    
    {
        "prompt":[{"content": "Mission: Drone in-door navigation in a classroom. \n Objectives: Do not collide with the a wall of the room. \n Conditions: Agent's state, wall's location are avialable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -15 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 15 if (d_agent_wall < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone in-door navigation in a classroom. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state and people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 15 if (d_agent_people < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a classroom. \n Objectives: Avoid hitting the ceiling projector. \n Conditions: Agent's state and projector's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 15 if (d_agent_projector < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a classroom. \n Objectives: Navigate without crashing into overhead lamps. \n Conditions: Agent's state, overhead lamp's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect static obstacle (blackboard) and avoid collision. \n Conditions: Agent's state, blackboard's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = -15 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = 15 if (d_agent_blackboard < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (tall bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -15 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 15 if (d_agent_bookshelve < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (backpack) and avoid collision. \n Conditions: Agent's state and backpack's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -15 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = 15 if (d_agent_backpack < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Do not collide with human. \n Conditions: Agent's state and human's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect dynamic obstacle (a teacher) and avoid collision. \n Conditions: Agent's state and teacher's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -15 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = 15 if (d_agent_teacher < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect dynamic obstacle (a student) and avoid collision. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -15 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.3) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = 15 if (d_agent_student < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.3) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with student and teacher. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with chair and desk. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with student and backpack. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves and backpack. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with blackboards and whiteboards. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with teacher, blackboards and whiteboards. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with teacher, pupils and desk. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves, chair and table. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves, chair and table. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with three boxes. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },





    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with desk. \n Conditions: Agent's state, desk's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -15 if (d_agent_desk < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_desk): \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = 15 if (d_agent_desk < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect the sideboard and do not crash in it. \n Conditions: Agent's state and sideboard's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_sideboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    penalty_collision = -15 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect bench and avoid collision. \n Conditions: Agent's state, bench's state and wanted velocity are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -15 if (d_agent_bench < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bench): \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = 15 if (d_agent_bench < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision the whiteboard. \n Conditions: Agent's state, whiteboard's state and wanted velocity are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -15 if (d_agent_sideboard < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Do not not collied with the projector. \n Conditions: Agent's state, projector's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_projector): \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 15 if (d_agent_projector < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a hanging equipment do not collied with it. \n Conditions: Agent's state and equipment's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -15 if (d_agent_equipment < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_equipment): \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = 15 if (d_agent_equipment < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Do not collide with the speaker. \n Conditions: Agent's state, speaker's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -15 if (d_agent_speaker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with the laptop. \n Conditions: Agent's state and laptop's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -15 if (d_agent_laptop < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_laptop): \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = 15 if (d_agent_laptop < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a screen in the room. Do not collide with it \n Conditions: Agent's state and screen's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_screen, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = -15 if (d_agent_screen < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_screen): \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = 15 if (d_agent_screen < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a screen and a projector in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a table and a chair in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a computer and a person in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a plant and a shelf in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a two boxes in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a chair, a table and the person in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a laptop, a plant and a shelf in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the shelf, box, and the projector. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the whiteboard, screen, and the lamp. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the three boxes. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal","role":"assistant"}]
    },





    {
        "prompt":[{"content": "ission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (one staff) and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -15 if (d_agent_staff < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a worker) and avoid collision. \n Conditions: Agent's state and worker's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -15 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 15 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a worker) and avoid collision. \n Conditions: Agent's state and worker's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -15 if (d_agent_worker < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 15 if (d_agent_worker < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with high storage racks. \n Conditions: Agent's state and storage rack's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rack = calculate_distance_min(s_agent, s_rack) \n    penalty_collision = -15 if (d_agent_rack < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with a forklift . \n Conditions: Agent's state and forklift's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -15 if (d_agent_forklift < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_forklift): \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = 15 if (d_agent_forklift < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with a hanging cable. \n Conditions: Agent's state and cable's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -15 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 30 if (d_agent_cable < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission:Operate the drone in a warehouse. \n Objectives: Avoid collison with a stack of pallets. \n Conditions: Agent's state and pallet's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = -15 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = 30 if (d_agent_pallet < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with a package. \n Conditions: Agent's state and package's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = -15 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = 30 if (d_agent_package < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with overhead pipes. \n Conditions: Agent's state and pipe's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -15 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = 30 if (d_agent_pipe < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the overhead beam and do not collide with it. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -15 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = 30 if (d_agent_beam < 0.5) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the shelves and human and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the pakets and staffs and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the stackes boxes and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal","role":"assistant"}]
    },
     {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the maschines and staffs and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the beams and hanging lamps and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the cabel, rack and people and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the desk, chair and computer and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the beam, pipes and lamps and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the forklift, stairs and rails and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with people. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -15 if (d_agent_people < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Detect spotlamp and avoid collison with the spotlamp. \n Conditions: Agent's state and spotlamp information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_spotlamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = -15 if (d_agent_spotlamp < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_spotlamp): \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = 15 if (d_agent_spotlamp < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Avoid collison with the balcony. \n Conditions: Agent's state and balcony's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_balcony, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    penalty_collision = -15 if (d_agent_balcony < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collison with the visitor's seat. \n Conditions: Agent's states and seat's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_seat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = -15 if (d_agent_seat < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_seat): \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = 15 if (d_agent_seat < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Avoid collison with the projector. \n Conditions: Agent's state, projectors's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -15 if (d_agent_projector < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collision with a cabel. \n Conditions: Agent's state, cabel's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cabel, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabel = calculate_distance_min(s_agent, s_cabel) \n    penalty_collision = -15 if (d_agent_cabel < 0.5) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cabel): \n    d_agent_seat = calculate_distance_min(s_agent, s_cabel) \n    penalty_collision = 15 if (d_agent_cabel < 0.5) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state and human's state obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Detect static obstacle (overhead platform) and avoid collision. \n Conditions: Agent's state, platform's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -15 if (d_agent_platform < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = 15 if (d_agent_platform < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect static obstacle (drape) and avoid collision. \n Conditions: Agent's state, drape's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -15 if (d_agent_drape < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 15 if (d_agent_drape < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (hangings microphone) and avoid collision. \n Conditions: Agent's state, microphone's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = -15 if (d_agent_microphone < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = 15 if (d_agent_microphone < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the spotlamp and projectors and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the chair and people and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the stage and drape and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a v. \n Objectives: Detect the microphone and music box do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the staff and visitor do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the chandelier, catwalk and rigging ropes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the table, chair and human and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the three boxes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the ceiling beam, balcony railing and spotlight and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the platform, microphone and drapes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the visitorn seat and box and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal","role":"assistant"}]
    },






    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 15 if (d_agent_human < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect  dynamic obstacle (person) and avoid collision. \n Conditions: Agent's state, person's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = -15 if (d_agent_person < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = 15 if (d_agent_person < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the static obstacle basket hoop and avoid collision. \n Conditions: Agent's state, basket hoop's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = -15 if (d_agent_basket_hoop < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = 15 if (d_agent_basket_hoop < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the scoreboard and avoid collision. \n Conditions: Agent's state, scoreboard's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -15 if (d_agent_scoreboard < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = 15 if (d_agent_scoreboard < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the climbing rope and avoid collision. \n Conditions: Agent's state and climbing rope's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -15 if (d_agent_rope < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = 15 if (d_agent_rope < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with volleyball nets. \n Conditions: Agent's state and net's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = -15 if (d_agent_net < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = 15 if (d_agent_net < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with hanging flags. \n Conditions: Agent's state and flag's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = -15 if (d_agent_flag < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = 15 if (d_agent_flag < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (moving players) and avoid collision. \n Conditions: Agent's state and player's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with a ball. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle flying ball and avoid collision. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -15 if (d_agent_ball < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_ball): \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 15 if (d_agent_ball < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (player) and avoid collision. \n Conditions: Agent's state and player's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_player s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 15 if (d_agent_player < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with ball and player. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with rope and net. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with coach and flag. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and rope. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with coach, basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content":"def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with player, ball and rope. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with flag, student and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return d_agent_obstacles_min + reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the patient and avoid collision. \n Conditions: Agent's state and patient's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -15 if (d_agent_patient < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 15 if (d_agent_patient < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect dynamic obstacle such as a doctor and avoid collision. \n Conditions: Agent's state and doctor's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = -15 if (d_agent_doctor < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = 15 if (d_agent_doctor < 0.6) else 0 \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the wire and avoid collision. \n Conditions: Agent's state and wire's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = -15 if (d_agent_wire < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the hospital. \n Objectives: Avoid collision with a medical equipment. \n Conditions: Agent's state and equipment's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -15 if (d_agent_equipment < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the wheelchair and avoid collisions. \n Conditions: Agent's state and wheelchair's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wheelchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = -15 if (d_agent_wheelchair < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wheelchair): \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = 15 if (d_agent_wheelchair < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staffr) \n    penalty_collision = -15 if (d_agent_staff < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_staff): \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = 15 if (d_agent_staff < 0.6) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Avoid collision with the defibrillator. \n Conditions: Agent's state and defibrillator's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_defibrillator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrillator) \n    penalty_collision = -15 if (d_agent_defibrillator < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the hospital. \n Objectives: Avoid  any collision with wall-mounted emergency devices. \n Conditions: Agent's state and device's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_device) \n    penalty_collision = -15 if (d_agent_device < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives:  Avoid collision with the lamp. \n Conditions: Agent's state and lamp's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -15 if (d_agent_lamp < 0.6) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -10 if (d_agent_goal < 0.2) else 3*d_agent_goal \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and patient avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the defibrillator and equipment avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the wire and wheelchair avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the patient and wheelchair avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and lamp avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the three packages and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the doctor, the patient and the wheelchair and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the defibrillator, the equipment and the wheelchair and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the lamp, the bed and the screen and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the counter, the nurse and the patient and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect  are three boxes and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -15 if (d_agent_obstacles_min < 0.8) else 0 \n    reward_reaching_goal = 10 if (d_agent_goal < 0.2) else -3*d_agent_goal \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 15 if (d_agent_obstacles_min < 0.8) else 0 \n    return penalty_collision","role":"assistant"}]
    },







  

    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with ceiling fan blades. \n Conditions: Agent's state and static fan blades's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = -10 if (d_agent_blade < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_blade, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blade = calculate_distance_min(s_agent, s_blade) \n    penalty_collision = 10 if (d_agent_blade < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with chair. \n Conditions: Agent's state and chair's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -10 if (d_agent_chair < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = 10 if (d_agent_chair < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with hanging lamps. \n Conditions: Agent's state and lamp's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -10 if (d_agent_lamp < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 10 if (d_agent_lamp < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with curtain. \n Conditions: Agent's state and static curtain's status available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = -10 if (d_agent_curtain < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_curtain, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_curtain = calculate_distance_min(s_agent, s_curtain) \n    penalty_collision = 10 if (d_agent_curtain < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with obstacles. \n Conditions: Agent's state and obstacles's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with drapes. \n Conditions: Agent's state and drape's status are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -10 if (d_agent_drape < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 10 if (d_agent_drape < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a room. \n Objectives: Avoid collision with static obstacle (wardrobe). \n Conditions: Agent's state, wardrobe's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = -10 if (d_agent_wardrobe < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wardrobe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wardrobe = calculate_distance_min(s_agent, s_wardrobe) \n    penalty_collision = 10 if (d_agent_wardrobe < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone in-door navigation and reach other side of the small room. \n Objectives: Do not collide with the walls of the room. \n Conditions: Agent's state, wall's information accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 10 if (d_agent_wall < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space to the far side of a small room. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state, people's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 10 if (d_agent_people < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with chairs and tables. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with fan blades and curtains. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with drapes and people. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with lamps and projectors. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with boxes and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Avoid collision with boxes and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans and chairs. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans, chairs and table. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with humans, projector and bench. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with people, boxes and bench. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Guide the drone through an indoor space such as a small room. \n Objectives: Prevent contact with shelf, plants and curtains. \n Conditions: Agent's state, obstacles' state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    return reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid hitting the surrounding walls. \n Conditions: Agent's state, wall's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 10 if (d_agent_wall < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Navigate without crashing into walls. \n Conditions: Agent's state, obstacle's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = 10 if (d_agent_wall < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (chairs) and avoid collision. \n Conditions: Agent's state, chair's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -10 if (d_agent_chair < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (table) and avoid collision. \n Conditions: Agent's state, table's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -10 if (d_agent_table_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_table): \n    d_agent_table_min = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 10 if (d_agent_table_min < c_1) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect bookshelves and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -10 if (d_agent_bookshelve < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bookshelve): \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 10 if (d_agent_bookshelve < c_1) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect smoke detectors and avoid collision. \n Conditions: Agent's state, smoke detector's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_smoke_detector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_smoke_detectore = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = -10 if (d_agent_smoke_detector < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_smoke_detector): \n    d_agent_smoke_detector = calculate_distance_min(s_agent, s_smoke_detector) \n    penalty_collision = 10 if (d_agent_smoke_detector < c_1) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect obstacle (stacked books) and avoid collision. \n Conditions: Agent's state, book's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = -10 if (d_agent_book < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_book, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_book = calculate_distance_min(s_agent, s_book) \n    penalty_collision = 10 if (d_agent_book < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < c_1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect chairs and tabels and avoid collision. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < c_2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Detect students and shelves and avoid collision. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < c_1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < c_2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < c_1) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with lamps and plants. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with decorations and tall shelves. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stack books and lamps. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with books and lights. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with books, lights and humans. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with chair, table and humans. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with desks, lamps and students. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stacked books, computers and staffs. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with stacked books, laptops and book carts. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a library. \n Objectives: Avoid collisions with  curtains, plants and staffs. \n Conditions: Agent's state, obstacles' states are accessible. \n Write a reward function in Python","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human): \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 1) else 6 \n    return penalty_collision","role":"assistant"}]
    },   
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect static obstacle such as a tree and avoid collision. \n Conditions: Agent's state, tree's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_tree, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree = calculate_distance_min(s_agent, s_tree) \n    penalty_collision = -10 if (d_agent_tree < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle such as a leaf and avoid collision. \n Conditions: Agent's state, leaf's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_leaf, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = -10 if (d_agent_leaf < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_leaf): \n    d_agent_leaf = calculate_distance_min(s_agent, s_leaf) \n    penalty_collision = 10 if (d_agent_leaf < 1) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect birds and avoid collision. \n Conditions: Agent's state, bird's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bird, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = -10 if (d_agent_bird < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bird): \n    d_agent_bird = calculate_distance_min(s_agent, s_bird) \n    penalty_collision = 10 if (d_agent_bird < 1) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with stumps. \n Conditions: Agent's state and stump's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = -10 if (d_agent_stump < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_stump, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stump = calculate_distance_min(s_agent, s_stump) \n    penalty_collision = 10 if (d_agent_stump < 1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect obstacle such as a rock and avoid collision. \n Conditions: Agent's state, rock's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = -10 if (d_agent_rock < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rock, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rock = calculate_distance_min(s_agent, s_rock) \n    penalty_collision = 10 if (d_agent_rock < 1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect thin branches and avoid collision. \n Conditions: Agent's state, branche's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = -10 if (d_agent_branch < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_branch): \n    d_agent_branch = calculate_distance_min(s_agent, s_branch) \n    penalty_collision = 10 if (d_agent_branch < 1) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collision with thick tree branches. \n Conditions: Agent's state, tree branche's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_tree_branch, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_tree_branch = calculate_distance_min(s_agent, s_tree_branch) \n    penalty_collision = -10 if (d_agent_tree_branch < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    penalty_collision = 10 if (d_agent_tree_branch < 1) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect people and avoid collision. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 10 if (d_agent_people < 1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect stones and avoid collision. \n Conditions: Agent's state and stone's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_stone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_stone = calculate_distance_min(s_agent, s_stone) \n    penalty_collision = -10 if (d_agent_stone < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect stones and trees and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect branches and trees and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect humans and animals and avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Detect leaves and trees avoid collision. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with the many trees. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with trees, branches and humans. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with stumps, birds and humans. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with trees, animals and stones. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a forest. \n Objectives: Avoid collisions with maple trees, cliffs and signs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision","role":"assistant"}]
    },


    

    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 1) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 1) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any collision with hanging lamps. \n Conditions: Agent's information and lamp's information are available \n Write a reward in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -10 if (d_agent_lamp < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = 10 if (d_agent_lamp < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid any static obstacle such as food serving counters. \n Conditions: Agent's state, food counter's state are accessible. \n Write a reward in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_counter, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = -10 if (d_agent_counter < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_counter): \n    d_agent_counter = calculate_distance_min(s_agent, s_counter) \n    penalty_collision = 10 if (d_agent_counter < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a chair. \n Conditions: Agent's state, chair's states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_chair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_chair = calculate_distance_min(s_agent, s_chair) \n    penalty_collision = -10 if (d_agent_chair < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    penalty_collision = 10 if (d_agent_chair < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a table. \n Conditions: Agent's state, table's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_table, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = -10 if (d_agent_table < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_table): \n    d_agent_table = calculate_distance_min(s_agent, s_table) \n    penalty_collision = 10 if (d_agent_table < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with trash bins. \n Conditions: Agent's state and trash bin's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_trash_bin, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_trash_bin = calculate_distance_min(s_agent, s_trash_bin) \n    penalty_collision = -10 if (d_agent_trash_bin < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    penalty_collision = 10 if (d_agent_trash_bin < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with a low-hanging decoration. \n Conditions: Agent's state, hanging decoration's state and desired speed are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_decoration, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_decoration = calculate_distance_min(s_agent, s_decoration) \n    penalty_collision = -10 if (d_agent_decoration < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Avoid to collide with plants. \n Conditions: Agent's state and plant's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_plant, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_plant = calculate_distance_min(s_agent, s_plant) \n    penalty_collision = -10 if (d_agent_plant < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with metal rails. \n Conditions: Agent's state, metal rail's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = -10 if (d_agent_rail < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rail, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rail = calculate_distance_min(s_agent, s_rail) \n    penalty_collision = 10 if (d_agent_rail < 0.5) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in the mensa. \n Objectives: Do not collide with cameras. \n Conditions: Agent's state and camera's state are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cameras, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cameras = calculate_distance_min(s_agent, s_cameras) \n    penalty_collision = -10 if (d_agent_cameras < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with people and table. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with students and chairs. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and chairs. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with plants and desk. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with decoration and plant. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with cameras, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with chair, plant and table. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with staff, student and table. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, rails and camera. \n Conditions: Agent's state and obstacles' states are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a mensa. \n Objectives: Avoid collisions with food counter, trash bin and staff. \n Conditions: Agent's state and obstacles' states are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal","role":"assistant"}]
    },




    
    {
        "prompt":[{"content": "Mission: Drone in-door navigation in a classroom. \n Objectives: Do not collide with the a wall of the room. \n Conditions: Agent's state, wall's location are avialable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wall, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wall = calculate_distance_min(s_agent, s_wall) \n    penalty_collision = -10 if (d_agent_wall < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone in-door navigation in a classroom. \n Objectives: Prevent contact with the people. \n Conditions: Agent's state and people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = 10 if (d_agent_people < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a classroom. \n Objectives: Avoid hitting the ceiling projector. \n Conditions: Agent's state and projector's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -10 if (d_agent_projector < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 10 if (d_agent_projector < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a classroom. \n Objectives: Navigate without crashing into overhead lamps. \n Conditions: Agent's state, overhead lamp's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -10 if (d_agent_lamp < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect static obstacle (blackboard) and avoid collision. \n Conditions: Agent's state, blackboard's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = -10 if (d_agent_blackboard < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_blackboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_blackboard = calculate_distance_min(s_agent, s_blackboard) \n    penalty_collision = 10 if (d_agent_blackboard < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (tall bookshelves) and avoid collision. \n Conditions: Agent's state, bookshelve's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = -10 if (d_agent_bookshelve < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bookshelve, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bookshelve = calculate_distance_min(s_agent, s_bookshelve) \n    penalty_collision = 10 if (d_agent_bookshelve < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect obstacle (backpack) and avoid collision. \n Conditions: Agent's state and backpack's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_backpack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_backpack = calculate_distance_min(s_agent, s_backpack) \n    penalty_collision = -10 if (d_agent_backpack < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Do not collide with human. \n Conditions: Agent's state and human's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect dynamic obstacle (a teacher) and avoid collision. \n Conditions: Agent's state and teacher's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = -10 if (d_agent_teacher < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_teacher, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_teacher = calculate_distance_min(s_agent, s_teacher) \n    penalty_collision = 10 if (d_agent_teacher < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Detect dynamic obstacle (a student) and avoid collision. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = -10 if (d_agent_student < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.3) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_student, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_student = calculate_distance_min(s_agent, s_student) \n    penalty_collision = 10 if (d_agent_student < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.3) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with student and teacher. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with chair and desk. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with student and backpack. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves and backpack. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with blackboards and whiteboards. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with teacher, blackboards and whiteboards. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with teacher, pupils and desk. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves, chair and table. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with shelves, chair and table. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a classroom. \n Objectives: Avoid collision with three boxes. \n Conditions: Agent's state and student's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]
    },





    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect dynamic obstacle (people) and avoid collision. \n Conditions: Agent's state, people's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with desk. \n Conditions: Agent's state, desk's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_desk, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = -10 if (d_agent_desk < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_desk): \n    d_agent_desk = calculate_distance_min(s_agent, s_desk) \n    penalty_collision = 10 if (d_agent_desk < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect the sideboard and do not crash in it. \n Conditions: Agent's state and sideboard's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_sideboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_sideboard = calculate_distance_min(s_agent, s_sideboard) \n    penalty_collision = -10 if (d_agent_sideboard < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Detect bench and avoid collision. \n Conditions: Agent's state, bench's state and wanted velocity are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_bench, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = -10 if (d_agent_bench < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_bench): \n    d_agent_bench = calculate_distance_min(s_agent, s_bench) \n    penalty_collision = 10 if (d_agent_bench < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision the whiteboard. \n Conditions: Agent's state, whiteboard's state and wanted velocity are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_whiteboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_whiteboard = calculate_distance_min(s_agent, s_whiteboard) \n    penalty_collision = -10 if (d_agent_sideboard < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Do not not collied with the projector. \n Conditions: Agent's state, projector's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -10 if (d_agent_projector < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_projector): \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = 10 if (d_agent_projector < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a hanging equipment do not collied with it. \n Conditions: Agent's state and equipment's state accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -10 if (d_agent_equipment < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_equipment): \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = 10 if (d_agent_equipment < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Do not collide with the speaker. \n Conditions: Agent's state, speaker's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_speaker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_speaker = calculate_distance_min(s_agent, s_speaker) \n    penalty_collision = -10 if (d_agent_speaker < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone indoor exploration in a conference room. \n Objectives: Avoid collision with the laptop. \n Conditions: Agent's state and laptop's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_laptop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = -10 if (d_agent_laptop < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_laptop): \n    d_agent_laptop = calculate_distance_min(s_agent, s_laptop) \n    penalty_collision = 10 if (d_agent_laptop < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a screen in the room. Do not collide with it \n Conditions: Agent's state and screen's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_screen, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = -10 if (d_agent_screen < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_screen): \n    d_agent_screen = calculate_distance_min(s_agent, s_screen) \n    penalty_collision = 10 if (d_agent_screen < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a screen and a projector in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a table and a chair in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a computer and a person in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a plant and a shelf in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a two boxes in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a chair, a table and the person in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.",
         "chosen": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: There is a laptop, a plant and a shelf in the room. Do not collide with them \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the shelf, box, and the projector. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the whiteboard, screen, and the lamp. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a conference room. \n Objectives: Avoid collision with the three boxes. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal","role":"assistant"}]
    },





    {
        "prompt":[{"content": "ission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (one staff) and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = -10 if (d_agent_staff < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a worker) and avoid collision. \n Conditions: Agent's state and worker's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -10 if (d_agent_worker < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 10 if (d_agent_worker < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a human) and avoid collision. \n Conditions: Agent's state, human's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Detect dynamic obstacle (a worker) and avoid collision. \n Conditions: Agent's state and worker's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_worker, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = -10 if (d_agent_worker < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_worker): \n    d_agent_worker = calculate_distance_min(s_agent, s_worker) \n    penalty_collision = 10 if (d_agent_worker < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with high storage racks. \n Conditions: Agent's state and storage rack's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rack, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rack = calculate_distance_min(s_agent, s_rack) \n    penalty_collision = -10 if (d_agent_rack < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a warehouse. \n Objectives: Avoid collison with a forklift . \n Conditions: Agent's state and forklift's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_forklift, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = -10 if (d_agent_forklift < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_forklift): \n    d_agent_forklift = calculate_distance_min(s_agent, s_forklift) \n    penalty_collision = 10 if (d_agent_forklift < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with a hanging cable. \n Conditions: Agent's state and cable's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = -10 if (d_agent_cable < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cable, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cable = calculate_distance_min(s_agent, s_cable) \n    penalty_collision = 30 if (d_agent_cable < 0.5) else 6 \n    reward_reaching_goal = -110 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission:Operate the drone in a warehouse. \n Objectives: Avoid collison with a stack of pallets. \n Conditions: Agent's state and pallet's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = -10 if (d_agent_pallet < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_pallet, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pallet = calculate_distance_min(s_agent, s_pallet) \n    penalty_collision = 30 if (d_agent_pallet < 0.5) else 6 \n    reward_reaching_goal = -110 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with a package. \n Conditions: Agent's state and package's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = -10 if (d_agent_package < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_package, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_package = calculate_distance_min(s_agent, s_package) \n    penalty_collision = 30 if (d_agent_package < 0.5) else 6 \n    reward_reaching_goal = -110 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Avoid collison with overhead pipes. \n Conditions: Agent's state and pipe's information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = -10 if (d_agent_pipe < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_pipe, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_pipe) \n    penalty_collision = 30 if (d_agent_pipe < 0.5) else 6 \n    reward_reaching_goal = -110 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the overhead beam and do not collide with it. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = -10 if (d_agent_beam < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_beam, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_pipe = calculate_distance_min(s_agent, s_beam) \n    penalty_collision = 30 if (d_agent_beam < 0.5) else 6 \n    reward_reaching_goal = -110 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the shelves and human and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the pakets and staffs and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the stackes boxes and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal","role":"assistant"}]
    },
     {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the maschines and staffs and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the beams and hanging lamps and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the cabel, rack and people and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the desk, chair and computer and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the beam, pipes and lamps and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a warehouse. \n Objectives: Detect the forklift, stairs and rails and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal","role":"assistant"}]
    },



    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Detect people and avoid collison with people. \n Conditions: Agent's state, people's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_people, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_people = calculate_distance_min(s_agent, s_people) \n    penalty_collision = -10 if (d_agent_people < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Detect spotlamp and avoid collison with the spotlamp. \n Conditions: Agent's state and spotlamp information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_spotlamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = -10 if (d_agent_spotlamp < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_spotlamp): \n    d_agent_spotlamp = calculate_distance_min(s_agent, s_spotlamp) \n    penalty_collision = 10 if (d_agent_spotlamp < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Avoid collison with the balcony. \n Conditions: Agent's state and balcony's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_balcony, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_balcony = calculate_distance_min(s_agent, s_balcony) \n    penalty_collision = -10 if (d_agent_balcony < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collison with the visitor's seat. \n Conditions: Agent's states and seat's information are available. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_seat, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = -10 if (d_agent_seat < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_seat): \n    d_agent_seat = calculate_distance_min(s_agent, s_seat) \n    penalty_collision = 10 if (d_agent_seat < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone moves in a theater. \n Objectives: Avoid collison with the projector. \n Conditions: Agent's state, projectors's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_projector, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_projector = calculate_distance_min(s_agent, s_projector) \n    penalty_collision = -10 if (d_agent_projector < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Avoid collision with a cabel. \n Conditions: Agent's state, cabel's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_cabel, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_cabel = calculate_distance_min(s_agent, s_cabel) \n    penalty_collision = -10 if (d_agent_cabel < 0.5) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_cabel): \n    d_agent_seat = calculate_distance_min(s_agent, s_cabel) \n    penalty_collision = 10 if (d_agent_cabel < 0.5) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state and human's state obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a theater. \n Objectives: Detect static obstacle (overhead platform) and avoid collision. \n Conditions: Agent's state, platform's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = -10 if (d_agent_platform < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_platform, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_platform = calculate_distance_min(s_agent, s_platform) \n    penalty_collision = 10 if (d_agent_platform < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect static obstacle (drape) and avoid collision. \n Conditions: Agent's state, drape's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = -10 if (d_agent_drape < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_drape, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_drape = calculate_distance_min(s_agent, s_drape) \n    penalty_collision = 10 if (d_agent_drape < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the theater. \n Objectives: Detect dynamic obstacle (hangings microphone) and avoid collision. \n Conditions: Agent's state, microphone's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = -10 if (d_agent_microphone < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_microphone, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_microphone = calculate_distance_min(s_agent, s_microphone) \n    penalty_collision = 10 if (d_agent_microphone < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the spotlamp and projectors and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the chair and people and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the stage and drape and do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a v. \n Objectives: Detect the microphone and music box do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the staff and visitor do not collide with them. \n Conditions: Agent's states and overhead beam information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the chandelier, catwalk and rigging ropes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the table, chair and human and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the three boxes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the ceiling beam, balcony railing and spotlight and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the platform, microphone and drapes and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a theater. \n Objectives: Detect the visitorn seat and box and do not collide with it. \n Conditions: Agent's states and obstacles information are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal","role":"assistant"}]
    },






    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (human) and avoid collision. \n Conditions: Agent's state, human's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = -10 if (d_agent_human < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_human, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_human = calculate_distance_min(s_agent, s_human) \n    penalty_collision = 10 if (d_agent_human < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect  dynamic obstacle (person) and avoid collision. \n Conditions: Agent's state, person's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = -10 if (d_agent_person < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_person, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_person = calculate_distance_min(s_agent, s_person) \n    penalty_collision = 10 if (d_agent_person < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the static obstacle basket hoop and avoid collision. \n Conditions: Agent's state, basket hoop's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = -10 if (d_agent_basket_hoop < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_basket_hoop, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_basket_hoop = calculate_distance_min(s_agent, s_basket_hoop) \n    penalty_collision = 10 if (d_agent_basket_hoop < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the scoreboard and avoid collision. \n Conditions: Agent's state, scoreboard's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = -10 if (d_agent_scoreboard < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_scoreboard, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_scoreboard = calculate_distance_min(s_agent, s_scoreboard) \n    penalty_collision = 10 if (d_agent_scoreboard < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect the climbing rope and avoid collision. \n Conditions: Agent's state and climbing rope's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = -10 if (d_agent_rope < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_rope, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_rope = calculate_distance_min(s_agent, s_rope) \n    penalty_collision = 10 if (d_agent_rope < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with volleyball nets. \n Conditions: Agent's state and net's state are obtainable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = -10 if (d_agent_net < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_net, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_net = calculate_distance_min(s_agent, s_net) \n    penalty_collision = 10 if (d_agent_net < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with hanging flags. \n Conditions: Agent's state and flag's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = -10 if (d_agent_flag < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_flag, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_flag = calculate_distance_min(s_agent, s_flag) \n    penalty_collision = 10 if (d_agent_flag < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (moving players) and avoid collision. \n Conditions: Agent's state and player's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -10 if (d_agent_player < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 10 if (d_agent_player < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with a ball. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -10 if (d_agent_ball < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 10 if (d_agent_ball < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle flying ball and avoid collision. \n Conditions: Agent's state, ball's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_ball, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = -10 if (d_agent_ball < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_ball): \n    d_agent_ball = calculate_distance_min(s_agent, s_ball) \n    penalty_collision = 10 if (d_agent_ball < 0.6) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Detect dynamic obstacle (player) and avoid collision. \n Conditions: Agent's state and player's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_player, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = -10 if (d_agent_player < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_player s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_player = calculate_distance_min(s_agent, s_player) \n    penalty_collision = 10 if (d_agent_player < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with ball and player. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with rope and net. \n Conditions: Agent's state and obstacles state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with coach and flag. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal, s_obstacles): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return d_agent_bstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and rope. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return d_agent_bstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with coach, basketball and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"

,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with player, ball and rope. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the sports hall. \n Objectives: Avoid collision with flag, student and net. \n Conditions: Agent's state and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
    ,"role":"assistant"}]},



    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the patient and avoid collision. \n Conditions: Agent's state and patient's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = -10 if (d_agent_patient < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_patient, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_patient = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 10 if (d_agent_patient < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect dynamic obstacle such as a doctor and avoid collision. \n Conditions: Agent's state and doctor's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = -10 if (d_agent_doctor < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_doctor, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_doctor = calculate_distance_min(s_agent, s_doctor) \n    penalty_collision = 10 if (d_agent_doctor < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the wire and avoid collision. \n Conditions: Agent's state and wire's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = -10 if (d_agent_wire < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wire, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wire = calculate_distance_min(s_agent, s_wire) \n    penalty_collision = 10 if (d_agent_wire < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the hospital. \n Objectives: Avoid collision with a medical equipment. \n Conditions: Agent's state and equipment's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    penalty_collision = -10 if (d_agent_equipment < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_equipment, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    d_agent_equipment = calculate_distance_min(s_agent, s_equipment) \n    return d_agent_equipment + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Detect the wheelchair and avoid collisions. \n Conditions: Agent's state and wheelchair's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_wheelchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_wheelchair = calculate_distance_min(s_agent, s_wheelchair) \n    penalty_collision = -10 if (d_agent_wheelchair < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_wheelchair, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_weelchair = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 10 if (d_agent_wheelchair < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"

,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and avoid collision. \n Conditions: Agent's state, staff's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_staff, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_staff = calculate_distance_min(s_agent, s_staffr) \n    penalty_collision = -10 if (d_agent_staff < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_staff): \n    d_agent_staff = calculate_distance_min(s_agent, s_staff) \n    penalty_collision = 10 if (d_agent_staff < 0.6) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives: Avoid collision with the defibrillator. \n Conditions: Agent's state and defibrillator's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_defibrillator, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrillator) \n    penalty_collision = -10 if (d_agent_defibrillator < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_defibrillator s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_defibrillator = calculate_distance_min(s_agent, s_defibrllator) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return d_agent_defibrillator + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Drone explores the hospital. \n Objectives: Avoid  any collision with wall-mounted emergency devices. \n Conditions: Agent's state and device's state are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_device) \n    penalty_collision = -10 if (d_agent_device < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_device, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_device = calculate_distance_min(s_agent, s_patient) \n    penalty_collision = 10 if (d_agent_device < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Operate the drone in a hospital. \n Objectives:  Avoid collision with the lamp. \n Conditions: Agent's state and lamp's state are usable. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    penalty_collision = -10 if (d_agent_lamp < 0.6) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_lamp, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_lamp = calculate_distance_min(s_agent, s_lamp) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return d_agent_lamp + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and patient avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return d_agent_obstacles_min + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the defibrillator and equipment avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstaclest) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the wire and wheelchair avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstaclest) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the patient and wheelchair avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the staff and lamp avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the three packages and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstaclest) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the doctor, the patient and the wheelchair and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the defibrillator, the equipment and the wheelchair and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the lamp, the bed and the screen and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return reward_reaching_goal"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect the counter, the nurse and the patient and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],"chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],"rejected":[{"content": "def reward(s_agent, s_obstacles): \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.8) else 6 \n    return penalty_collision"
,"role":"assistant"}]},
    {
        "prompt":[{"content": "Mission: Pilot a drone through a hospital. \n Objectives: Detect  are three boxes and avoid collision. \n Conditions: Agent's statea and obstacles' states are accessible. \n Write a reward function in Python.","role":"user"}],
        "chosen":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstacles) \n    penalty_collision = -10 if (d_agent_obstacles_min < 0.8) else 6 \n    reward_reaching_goal = 11 if (d_agent_goal < 0.2) else -d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}],
        "rejected":[{"content": "def reward(s_agent, s_obstacles, s_goal): \n    d_agent_goal = calculate_distance(s_agent, s_goal) \n    d_agent_obstacles_min = calculate_distance_min(s_agent, s_obstaclest) \n    penalty_collision = 10 if (d_agent_obstacles_min < 0.6) else 6 \n    reward_reaching_goal = -11 if (d_agent_goal < 0.2) else d_agent_goal**2 \n    return penalty_collision + reward_reaching_goal","role":"assistant"}]

    }







]


